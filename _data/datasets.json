{"124_120_mnist": {"pipeline": {"_id": "8785bdda-90d6-424c-a6f4-b1c87ecbf444", "primitives": ["keras.applications.resnet50.preprocess_input", "keras.applications.resnet50.ResNet50", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"keras-applications-resnet50-preprocess_input#1": {}, "keras-applications-resnet50-ResNet50#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 368, "max_depth": 4, "learning_rate": 0.08286649208168284, "gamma": 0.9469738923406584, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"keras-applications-resnet50-preprocess_input#1": {}, "keras-applications-resnet50-ResNet50#1": {}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "resnet50/xgbclassifier", "template": "5bd0d82949e71569e8bf8047", "id": "8785bdda-90d6-424c-a6f4-b1c87ecbf444", "loader": {"data_modality": "image", "task_type": "classification"}, "score": 0.9702334186456246, "rank": 0.029766581354530024, "metric": "accuracy", "ts": "2018-10-25T04:17:29.530000", "dataset": "mnist_dataset_TRAIN", "test_id": "20181024211334782162"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "124_120_mnist", "about": {"problemID": "mnist_problem", "problemName": "mnist_problem", "problemDescription": "Multiclass image classification problem. Each image belongs to one of 10 classes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "mnist_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.143, "stratified": false, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "124-120-mnist"}, "124_138_cifar100": {"pipeline": {"_id": "5ca9b1bc-41b7-4e46-b918-b5b03fb19ca8", "primitives": ["keras.applications.mobilenet.preprocess_input", "keras.applications.mobilenet.MobileNet", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "mobilenet/xgbclassifier", "template": "5bd0d82949e71569e8bf8043", "id": "5ca9b1bc-41b7-4e46-b918-b5b03fb19ca8", "loader": {"data_modality": "image", "task_type": "classification"}, "score": 0.17987999999999998, "rank": 0.8201200000005341, "metric": "accuracy", "ts": "2018-10-24T22:21:20.209000", "dataset": "cifar100_dataset_TRAIN", "test_id": "20181024210707633906"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "124_138_cifar100", "about": {"problemID": "cifar100_problem", "problemName": "cifar100_problem", "problemDescription": "Multiclass image classification problem. Each image belongs to one of 100 classes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "cifar100_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.167, "stratified": false, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "124-138-cifar100"}, "124_174_cifar10": {"pipeline": {"_id": "abb2c0d5-cc70-4d1d-8f6b-c0e88fc164b8", "primitives": ["keras.applications.resnet50.preprocess_input", "keras.applications.resnet50.ResNet50", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"keras-applications-resnet50-preprocess_input#1": {}, "keras-applications-resnet50-ResNet50#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"keras-applications-resnet50-preprocess_input#1": {}, "keras-applications-resnet50-ResNet50#1": {}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "resnet50/xgbclassifier", "template": "5bd0d82949e71569e8bf8047", "id": "abb2c0d5-cc70-4d1d-8f6b-c0e88fc164b8", "loader": {"data_modality": "image", "task_type": "classification"}, "score": 0.47992, "rank": 0.5200800000002906, "metric": "accuracy", "ts": "2018-10-24T21:56:28.369000", "dataset": "cifar10_dataset_TRAIN", "test_id": "20181024211334782162"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "124_174_cifar10", "about": {"problemID": "cifar10_problem", "problemName": "cifar10_problem", "problemDescription": "Multiclass image classification problem. Each image belongs to one of 10 classes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "cifar10_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.167, "stratified": false, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "124-174-cifar10"}, "124_188_usps": {"pipeline": {"_id": "9b805115-671c-4a12-92b0-58e5bcfe8415", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "keras.applications.mobilenet.preprocess_input", "keras.applications.mobilenet.MobileNet", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "image/classification/default", "template": "5bceaa5d49e71569e8bf7f7e", "id": "9b805115-671c-4a12-92b0-58e5bcfe8415", "loader": {"data_modality": "image", "task_type": "classification"}, "score": 0.9764089716354356, "rank": 0.023591028365500803, "metric": "accuracy", "ts": "2018-10-31T05:33:35.092000", "dataset": "usps_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "124_188_usps", "about": {"problemID": "usps_problem", "problemName": "usps_problem", "problemDescription": "Multiclass image classification problem. Each image belongs to one of 10 classes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "usps_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.216, "stratified": false, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "124-188-usps"}, "1491_one_hundred_plants_margin": {"pipeline": {"_id": "febd5b88-435f-440f-bb44-d7c114a3ce07", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 14, "min_samples_split": 0.020416383338558622, "min_samples_leaf": 0.006334270276119016, "n_estimators": 449, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "febd5b88-435f-440f-bb44-d7c114a3ce07", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7790904761904761, "rank": 0.22090952380991938, "metric": "f1Macro", "ts": "2018-10-25T05:55:55.840000", "dataset": "1491_one_hundred_plants_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "1491_one_hundred_plants_margin", "about": {"problemID": "1491_one_hundred_plants_margin_problem", "problemName": "one_hundred_plants_margin_problem", "problemDescription": "**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2010   \n**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.     \n\n### Description\n\nOne-hundred plant species leaves dataset (Class = Margin).\n \n### Sources\n```\n   (a) Original owners of colour Leaves Samples:\n\n James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n The colour images are not included.  \n The Leaves were collected in the Royal Botanic Gardens, Kew, UK.  \n email: james.cope@kingston.ac.uk  \n   \n   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.  \n Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk  \n```\n\n### Dataset Information\n\nThe original data directory contains the binary images (masks) of the leaf samples (colour images not included).\nThere are three features for each image: Shape, Margin and Texture.\nFor each feature, a 64 element vector is given per leaf sample.\nThese vectors are taken as a contiguous descriptor (for shape) or histograms (for texture and margin).\nSo, there are three different files, one for each feature problem:  \n * 'data_Sha_64.txt' -> prediction based on shape\n * 'data_Tex_64.txt' -> prediction based on texture\n * 'data_Mar_64.txt' -> prediction based on margin [**dataset provided here**] \n\nEach row has a 64-element feature vector followed by the Class label.\nThere is a total of 1600 samples with 16 samples per leaf class (100 classes), and no missing values.\n\n### Attributes Information\n\nThree 64 element feature vectors per sample.\n\n### Relevant Papers\n\nCharles Mallah, James Cope, James Orwell. \nPlant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. \nSignal Processing, Pattern Recognition and Applications, in press.\n\nJ. Cope, P. Remagnino, S. Barman, and P. Wilkin.\nPlant texture classification using gabor co-occurrences.\nAdvances in Visual Computing,\npages 699-677, 2010.\n\nT. Beghin, J. Cope, P. Remagnino, and S. Barman.\nShape and texture based plant leaf classification. \nIn: Advanced Concepts for Intelligent Vision Systems,\npages 345-353. Springer, 2010.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "1491_one_hundred_plants_margin_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 65, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "1491-one-hundred-plants-margin"}, "1567_poker_hand": {"pipeline": {"_id": "cb45d108-6f90-456e-a731-9f949c6b4df4", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 48}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 932, "max_depth": 5, "learning_rate": 0.5336259708839836, "gamma": 0.5997026418500812, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "cb45d108-6f90-456e-a731-9f949c6b4df4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.449261657133072, "rank": 0.5507383428670173, "metric": "f1Macro", "ts": "2018-10-25T09:36:50.059000", "dataset": "1567_poker_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "1567_poker_hand", "about": {"problemID": "1567_poker_hand_problem", "problemName": "poker_hand_problem", "problemDescription": "**Author**: Robert Cattral, Franz Oppacher    \n**Source**: UCI    \n**Please cite**:   \n\n* Abstract: \nPurpose is to predict poker hands\n\n* Source - Creators:   \nRobert Cattral (cattral '@' gmail.com)\nFranz Oppacher (oppacher '@' scs.carleton.ca) \nCarleton University, Department of Computer Science \nIntelligent Systems Research Unit \n1125 Colonel By Drive, Ottawa, Ontario, Canada, K1S5B6\n\n\n* Data Set Information:\n\nEach record is an example of a hand consisting of five playing cards drawn from a standard deck of 52. Each card is described using two attributes (suit and rank), for a total of 10 predictive attributes. There is one Class attribute that describes the \"Poker Hand\". The order of cards is important, which is why there are 480 possible Royal Flush hands as compared to 4 (one for each suit).\n\n\n* Attribute Information:\n\n1) S1 \"Suit of card #1\"    \nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}    \n\n2) C1 \"Rank of card #1\"    \nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)    \n\n3) S2 \"Suit of card #2\"    \nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}    \n\n4) C2 \"Rank of card #2\"   \nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   \n\n5) S3 \"Suit of card #3\"   \nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   \n\n6) C3 \"Rank of card #3\"   \nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   \n\n7) S4 \"Suit of card #4\"   \nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   \n\n8) C4 \"Rank of card #4\"   \nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   \n\n9) S5 \"Suit of card #5\"   \nOrdinal (1-4) representing {Hearts, Spades, Diamonds, Clubs}   \n\n10) C5 \"Rank of card 5\"   \nNumerical (1-13) representing (Ace, 2, 3, ... , Queen, King)   \n\n11) CLASS \"Poker Hand\"   \nOrdinal (0-9)   \n\n0: Nothing in hand; not a recognized poker hand    \n1: One pair; one pair of equal ranks within five cards   \n2: Two pairs; two pairs of equal ranks within five cards   \n3: Three of a kind; three equal ranks within five cards   \n4: Straight; five cards, sequentially ranked with no gaps   \n5: Flush; five cards with the same suit   \n6: Full house; pair + different rank three of a kind   \n7: Four of a kind; four equal ranks within five cards   \n8: Straight flush; straight + flush   \n9: Royal flush; {Ace, King, Queen, Jack, Ten} + flush   \n\n\n* Relevant Papers:\n\nR. Cattral, F. Oppacher, D. Deugo. Evolutionary Data Mining with Automatic Rule Generalization. Recent Advances in Computers, Computing and Communications, pp.296-300, WSEAS Press, 2002. \nNote: This was a slightly different dataset that had more classes, and was considerably more difficult.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "1567_poker_hand_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "1567-poker-hand"}, "185_baseball": {"pipeline": {"_id": "17385666-31da-4b6e-ab7f-8ac7080a4d55", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 615, "max_depth": 10, "learning_rate": 0.4283964003430297, "gamma": 0.05736310121980537, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "17385666-31da-4b6e-ab7f-8ac7080a4d55", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6921128080904511, "rank": 0.30788719191014446, "metric": "f1Macro", "ts": "2018-10-25T01:19:21.426000", "dataset": "185_baseball_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "185_baseball", "about": {"problemID": "185_baseball_problem", "problemName": "baseball_problem", "problemDescription": "**Author**: Jeffrey S. Simonoff  \n**Source**: [AnalCatData](http://www.stern.nyu.edu/~jsimonof/AnalCatData) - 2003  \n**Please cite**: Jeffrey S. Simonoff, Analyzing Categorical Data, Springer-Verlag, New York, 2003  \n \nDatabase of baseball players and play statistics, including 'Games_played', 'At_bats', 'Runs', 'Hits', 'Doubles', 'Triples', 'Home_runs', 'RBIs', 'Walks', 'Strikeouts', 'Batting_average', 'On_base_pct', 'Slugging_pct' and 'Fielding_ave' \n\nNotes:  \n* Quotes, Single-Quotes and Backslashes were removed, Blanks replaced with Underscores\n* Player is an identifier that should be ignored when modelling the data", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "185_baseball_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 18, "colName": "Hall_of_Fame"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "185-baseball"}, "196_autoMpg": {"pipeline": {"_id": "1357a8f6-e600-40b9-aa66-8fd875a5e937", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 97, "max_depth": 3, "learning_rate": 0.1460934655544769, "gamma": 0.9134575778620468, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "1357a8f6-e600-40b9-aa66-8fd875a5e937", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 8.419079389879517, "rank": 8.419079389879721, "metric": "meanSquaredError", "ts": "2018-10-24T21:59:20.941000", "dataset": "196_autoMpg_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "196_autoMpg", "about": {"problemID": "196_autoMpg_problem", "problemName": "autoMpg_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Identifier attribute deleted.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n\n 1. Title: Auto-Mpg Data\n \n 2. Sources:\n    (a) Origin:  This dataset was taken from the StatLib library which is\n                 maintained at Carnegie Mellon University. The dataset was \n                 used in the 1983 American Statistical Association Exposition.\n    (c) Date: July 7, 1993\n \n 3. Past Usage:\n     -  See 2b (above)\n     -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n        In Proceedings on the Tenth International Conference of Machine \n        Learning, 236-243, University of Massachusetts, Amherst. Morgan\n        Kaufmann.\n \n 4. Relevant Information:\n \n    This dataset is a slightly modified version of the dataset provided in\n    the StatLib library.  In line with the use by Ross Quinlan (1993) in\n    predicting the attribute \"mpg\", 8 of the original instances were removed \n    because they had unknown values for the \"mpg\" attribute.  The original \n    dataset is available in the file \"auto-mpg.data-original\".\n \n    \"The data concerns city-cycle fuel consumption in miles per gallon,\n     to be predicted in terms of 3 multivalued discrete and 5 continuous\n     attributes.\" (Quinlan, 1993)\n \n 5. Number of Instances: 398\n \n 6. Number of Attributes: 9 including the class attribute\n \n 7. Attribute Information:\n \n     1. mpg:           continuous\n     2. cylinders:     multi-valued discrete\n     3. displacement:  continuous\n     4. horsepower:    continuous\n     5. weight:        continuous\n     6. acceleration:  continuous\n     7. model year:    multi-valued discrete\n     8. origin:        multi-valued discrete\n     9. car name:      string (unique for each instance)\n \n 8. Missing Attribute Values:  horsepower has 6 missing values", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "196_autoMpg_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "196-autoMpg"}, "22_handgeometry": {"pipeline": {"_id": "293c4ef5-a764-48b1-b585-661891883d7f", "primitives": ["keras.applications.mobilenet.preprocess_input", "keras.applications.mobilenet.MobileNet", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 982, "max_depth": 7, "learning_rate": 0.08527414478340234, "gamma": 0.12834488934418165, "min_child_weight": 6}}, "tunable_hyperparameters": {"keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "image/regression/default", "template": "5bceaa5d49e71569e8bf7f7f", "id": "293c4ef5-a764-48b1-b585-661891883d7f", "loader": {"data_modality": "image", "task_type": "regression"}, "score": 0.3482798499827529, "rank": 0.3482798499832347, "metric": "meanSquaredError", "ts": "2018-10-31T04:16:12.714000", "dataset": "22_handgeometry_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "22_handgeometry", "about": {"problemID": "22_handgeometry_problem", "problemName": "Hand geometry: Wrist width prediction problem", "problemDescription": "There are a total of 112 raw hand image files, each corresponding to the left hand of one of \nthe 112 different users. This has been split into 74 train images and 38 test images. The 74 training instances are \nlabeled with a real number (the target variable WRISTBREADTH) in unknown units.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "22_handgeometry_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "WRISTBREADTH"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "22-handgeometry"}, "26_radon_seed": {"pipeline": {"_id": "5d7c735a-4e3f-46bf-b274-7034b748e1f6", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "5d7c735a-4e3f-46bf-b274-7034b748e1f6", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.0258526077198939, "rank": 0.025852607720157746, "metric": "rootMeanSquaredError", "ts": "2018-10-31T04:09:01.654000", "dataset": "26_radon_seed_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "26_radon_seed", "about": {"problemID": "26_radon_seed_problem", "problemName": "Radon level prediction problem", "problemDescription": "This is a regression problem. The task is to predict the log radon levels given a data point, which is a house in a certain county in MN.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "26_radon_seed_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 29, "colName": "log_radon"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "26-radon-seed"}, "27_wordLevels": {"pipeline": {"_id": "1f6659e7-a77a-4ced-8649-fd6e9893ee18", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 24}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 23, "min_samples_split": 0.049763615103220096, "min_samples_leaf": 0.0079643025281499, "n_estimators": 69, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "1f6659e7-a77a-4ced-8649-fd6e9893ee18", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.2970657140962024, "rank": 0.7029342859047364, "metric": "f1Macro", "ts": "2018-10-25T04:35:48.467000", "dataset": "27_ws_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "27_wordLevels", "about": {"problemID": "27_wordLevels_problem", "problemName": "Word Level Prediction Problem", "problemDescription": "The task is to classify English words according to CEFR language levels. For each word, part-of-speech, the word lemma and usage frequency is provided.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.1.1", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "27_wordLevels_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Level.Teachers.Average"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "27-wordLevels"}, "299_libras_move": {"pipeline": {"_id": "3c35e547-c422-4527-9107-b56067afc190", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 81}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 785, "max_depth": 5, "learning_rate": 0.06137533681783447, "gamma": 0.05424952349089551, "min_child_weight": 10}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "3c35e547-c422-4527-9107-b56067afc190", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 5.8905609664596295, "rank": 5.890560966460207, "metric": "meanSquaredError", "ts": "2018-10-24T21:08:52.992000", "dataset": "299_libras_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "299_libras_move", "about": {"problemID": "299_libras_move_problem", "problemName": "libras_move_problem", "problemDescription": "**Author**: Daniel Baptista Dias, Sarajane Marques Peres, Helton Hideraldo Biscaro  \nUniversity of Sao Paulo, School of Art, Sciences and Humanities, Sao Paulo, SP, Brazil  \n**Source**: Unknown - November 2008  \n**Please cite**:   \n\n### LIBRAS Movement Database\nLIBRAS, acronym of the Portuguese name \"LIngua BRAsileira de Sinais\", is the official brazilian sign language. The dataset (movement_libras) contains 15 classes of 24 instances each, where each class references to a hand movement type in LIBRAS. The hand movement is represented as a bidimensional curve performed by the hand in a period of time. The curves were obtained from videos of hand movements, with the Libras performance from 4 different people, during 2 sessions. Each video corresponds to only one hand movement and has about $7$ seconds. Each video corresponds to a function F in a functions space which is the continual version of the input dataset. In the video pre-processing, a time normalization is carried out selecting 45 frames from each video, in according to an uniform distribution. In each frame, the centroid pixels of the segmented objects (the hand) are found, which compose the discrete version of the curve F with 45 points. All curves are normalized in the unitary space.\nIn order to prepare these movements to be analysed by algorithms, we have carried out a mapping operation, that is, each curve F is mapped in a representation with 90 features, with representing the coordinates of movement. \nEach instance represents 45 points on a bi-dimensional space, which can be plotted in an ordered way (from 1 through 45 as the X coordinate) in order to draw the path of the movement.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "299_libras_move_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 91, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "299-libras-move"}, "30_personae": {"pipeline": {"_id": "3ab05dde-7159-4d9b-a8af-11cf94e0183a", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 84}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 27, "min_samples_split": 0.3182028231135956, "min_samples_leaf": 0.050857438096426975, "n_estimators": 385, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "3ab05dde-7159-4d9b-a8af-11cf94e0183a", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.7479084967320262, "rank": 0.2520915032686359, "metric": "f1", "ts": "2018-10-31T05:18:01.356000", "dataset": "30_personae_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "30_personae", "about": {"problemID": "30_personae_problem", "problemName": "Personality prediction from text", "problemDescription": "The task is to classify the personality of the author of an input text", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "30_personae_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 6, "colName": "extrovert"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "30-personae"}, "313_spectrometer": {"pipeline": {"_id": "b2e41267-0697-4a74-9ee4-d408a1213ea0", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 65}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 26, "min_samples_split": 0.023951213340844844, "min_samples_leaf": 0.007263448127979376, "n_estimators": 380, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "b2e41267-0697-4a74-9ee4-d408a1213ea0", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.3868493358725052, "rank": 0.6131506641277626, "metric": "f1Macro", "ts": "2018-10-25T06:22:55.276000", "dataset": "313_spectrometer_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "313_spectrometer", "about": {"problemID": "313_spectrometer_problem", "problemName": "spectrometer_problem", "problemDescription": "**Author**:   \n  \n**Source**: Unknown - 1988  \n**Please cite**:   \n\n1. Title: Part of the IRAS Low Resolution Spectrometer Database\n \n2. Sources:\n(a) Originator: Infra-Red Astronomy Satellite Project Database\n(b) Donor: John Stutz <STUTZ@pluto.arc.nasa.gov> \n(c) Date: March 1988 (approximately)\n\n3. Past Usage: unknown\n-- A NASA-Ames research group concerned with unsupervised learning tasks may have used this database during their empirical studies of their algorithm/system (AUTOCLASS II).  See the 1988 Machine Learning Conference Proceedings, 54-64, for a description of their algorithm.\n\n4. Relevant Information: (from John Stutz)\n The Infra-Red Astronomy Satellite (IRAS) was the first attempt to map the full sky at infra-red wavelengths.  This could not be done from ground observatories because large portions of the infra-red spectrum is absorbed by the atmosphere.  The primary observing program was the full high resolution sky mapping performed by scanning at 4 frequencies. The Low Resolution Observation (IRAS-LRS) program observed high intensity sources over two continuous spectral bands.  This database derives from a subset of the higher quality LRS observations taken between 12h and 24h right ascension. \nThis database contains 531 high quality spectra derived from the IRAS-LRS database.  The original data contained 100 spectral measurements in each of two overlapping bands.  Of these, 44 blue band and 49 red band channels contain usable flux measurements.  Only these are included here.  The original spectral intensities values are compressed to 4-digits, and each spectrum includes 5 rescaling parameters.  We have used the LRS specified algorithm to rescale these to units of spectral intensity (Janskys).  Total intensity differences have been eliminated by normalizing each spectrum to a mean value of 5000.\nThis database was originally obtained for use in development and testing of our AutoClass system for Bayesian classification.  We have not retained any results from this development, having concentrated our efforts of a 5425 element version of the same data.  Our classifications were based upon simultaneous modeling of all 93 spectral intensities. With the larger database we were able to find classes that correspond well with known spectral types associated with particular stellar types. We also found classes that match with the spectra expected of certain stellar processes under investigation by Ames astronomers.  These classes have considerably enlarged the set of stars being investigated by those researchers.  \n\nOriginal Data\nThe original fortran data file is given in spectra-2.data.  The file spectra-2.head contains information about the .data file contents and how to rescale the compressed spectral intensities. \n\n5. Number of Instances: 531\n \n6. Number of Attributes: 103 (including the 10-attribute \"header\")\n \n7. Attribute Information: \n1. LRS-name: (Suspected format: 5 digits, \"+\" or \"-\", 4 digits)\n2. LRS-class: integer - The LRS-class values range from 0 - 99 with\nthe 10's digit giving the basic class and the 1's digit giving the subclass. These classes are based on features (peaks, valleys, and trends) of the spectral curves.  \n3. ID-type: integer\n4. Right-Ascension: float - Astronomical longitude. 1h = 15deg\n5. Declination: float - Astronomical lattitude. -90 <= Dec <= 90\n6. Scale Factor: float - Proportional to source strength\n7. Blue base 1: integer - linear rescaling coefficient\n8. Blue base 2: integer - linear rescaling coefficient\n9. Red base 1: integer - linear rescaling coefficient\n10. Red base 2: integer - linear rescaling coefficient\n11-54: fluxes from the following 44 blue-band channel wavelengths: \n(all given as floating point numerals)\n55-103: fluxes from the following 49 red-band channel wavelengths:  (all given as floating point numerals)\n\nUCI: http://archive.ics.uci.edu/ml/datasets/Low+Resolution+Spectrometer", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "313_spectrometer_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "LRS-class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "313-spectrometer"}, "32_wikiqa": {"pipeline": {"_id": "1bc247b6-2d94-4262-8c6f-4b618b999b9f", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 490, "max_depth": 7, "learning_rate": 0.7204850621139542, "gamma": 0.06475367660790698, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "multi_table/classification/default", "template": "5bceaa5e49e71569e8bf7f8a", "id": "1bc247b6-2d94-4262-8c6f-4b618b999b9f", "loader": {"data_modality": "multi_table", "task_type": "classification"}, "score": 0.08769151169980946, "rank": 0.9123084883006974, "metric": "f1", "ts": "2018-10-31T04:19:06.623000", "dataset": "32_wikiqa_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "32_wikiqa", "about": {"problemID": "32_wikiqa_problem", "problemName": "WikiQA: A Challenge Dataset for Open-Domain Question Answering", "problemDescription": "Given a question sentence and a candidate sentence, the task is to predict if the candidate is an answer sentence or not.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "32_wikiqa_dataset", "targets": [{"targetIndex": 0, "resID": "3", "colIndex": 3, "colName": "isAnswer"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "32-wikiqa"}, "38_sick": {"pipeline": {"_id": "0fa7413e-1aa6-4e80-a5db-c8cb79111c50", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 20}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 710, "max_depth": 5, "learning_rate": 0.2258796255739629, "gamma": 0.49837248749214313, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "0fa7413e-1aa6-4e80-a5db-c8cb79111c50", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9520002838794228, "rank": 0.04799971612098373, "metric": "f1Macro", "ts": "2018-10-25T00:15:57.939000", "dataset": "38_sick_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "38_sick", "about": {"problemID": "38_sick_problem", "problemName": "sick_problem", "problemDescription": "**Author**:   \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/thyroid+disease)   \n**Please cite**: Thyroid disease records supplied by the Garavan Institute and J. Ross Quinlan, New South Wales Institute, Syndney, Australia. 1987.\n\nAttribute information:\n\n```\nsick, negative.   |  classes\n\nage:    continuous.\nsex:    M, F.\non thyroxine:   f, t.\nquery on thyroxine:  f, t.\non antithyroid medication: f, t.\nsick:    f, t.\npregnant:   f, t.\nthyroid surgery:  f, t.\nI131 treatment:   f, t.\nquery hypothyroid:  f, t.\nquery hyperthyroid:  f, t.\nlithium:   f, t.\ngoitre:    f, t.\ntumor:    f, t.\nhypopituitary:   f, t.\npsych:    f, t.\nTSH measured:   f, t.\nTSH:    continuous.\nT3 measured:   f, t.\nT3:    continuous.\nTT4 measured:   f, t.\nTT4:    continuous.\nT4U measured:   f, t.\nT4U:    continuous.\nFTI measured:   f, t.\nFTI:    continuous.\nTBG measured:   f, t.\nTBG:    continuous.\nreferral source:  WEST, STMW, SVHC, SVI, SVHD, other.\n```\n\n``` \n Num Instances:     3772\n Num Attributes:    30\n Num Continuous:    7 (Int 1 / Real 6)\n Num Discrete:      23\n Missing values:    6064 /  5.4%\n```\n\n```\n     name                      type enum ints real     missing    distinct  (1)\n   1 'age'                     Int    0% 100%   0%     1 /  0%    93 /  2%   0% \n   2 'sex'                     Enum  96%   0%   0%   150 /  4%     2 /  0%   0% \n   3 'on thyroxine'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   4 'query on thyroxine'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   5 'on antithyroid medicati  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   6 'sick'                    Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   7 'pregnant'                Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   8 'thyroid surgery'         Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   9 'I131 treatment'          Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  10 'query hypothyroid'       Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  11 'query hyperthyroid'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  12 'lithium'                 Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  13 'goitre'                  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  14 'tumor'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  15 'hypopituitary'           Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  16 'psych'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  17 'TSH measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  18 'TSH'                     Real   0%  11%  79%   369 / 10%   287 /  8%   2% \n  19 'T3 measured'             Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  20 'T3'                      Real   0%   9%  71%   769 / 20%    69 /  2%   0% \n  21 'TT4 measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  22 'TT4'                     Real   0%  94%   0%   231 /  6%   241 /  6%   1% \n  23 'T4U measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  24 'T4U'                     Real   0%   2%  87%   387 / 10%   146 /  4%   1% \n  25 'FTI measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  26 'FTI'                     Real   0%  90%   0%   385 / 10%   234 /  6%   2% \n  27 'TBG measured'            Enum 100%   0%   0%     0 /  0%     1 /  0%   0% \n  28 'TBG'                     Real   0%   0%   0%  3772 /100%     0 /  0%   0% \n  29 'referral source'         Enum 100%   0%   0%     0 /  0%     5 /  0%   0% \n  30 'Class'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0%\n```", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "38_sick_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 30, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "38-sick"}, "4550_MiceProtein": {"pipeline": {"_id": "6c9eccca-b8e6-423a-bcb1-69cee7fbcc0a", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 46}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 22, "min_samples_split": 0.3407476331065742, "min_samples_leaf": 0.07966104759275049, "n_estimators": 344, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "6c9eccca-b8e6-423a-bcb1-69cee7fbcc0a", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 1.6993574622760076e-15, "metric": "f1Macro", "ts": "2018-10-25T05:53:12.003000", "dataset": "4550_MiceProtein_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "4550_MiceProtein", "about": {"problemID": "4550_MiceProtein_problem", "problemName": "MiceProtein_problem", "problemDescription": "**Author**: Clara Higuera, Katheleen J. Gardiner, Krzysztof J. Cios  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Mice+Protein+Expression) - 2015   \n**Please cite**: Higuera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126.\n\n**Deactivated because the attributes Genotype, Treatment and Behavior should be ignored. They leak information about the target. Use version 4 instead.** \n\nExpression levels of 77 proteins measured in the cerebral cortex of 8 classes of control and Down syndrome mice exposed to context fear conditioning, a task used to assess associative learning.\n\n### Source:\n```\nClara Higuera Department of Software Engineering and Artificial Intelligence, Faculty of Informatics and the Department of Biochemistry and Molecular Biology, Faculty of Chemistry, University Complutense, Madrid, Spain. \nEmail: clarahiguera '@' ucm.es \n\nKatheleen J. Gardiner, creator and owner of the protein expression data, is currently with the Linda Crnic Institute for Down Syndrome, Department of Pediatrics, Department of Biochemistry and Molecular Genetics, Human Medical Genetics and Genomics, and Neuroscience Programs, University of Colorado, School of Medicine, Aurora, Colorado, USA. \nEmail: katheleen.gardiner '@' ucdenver.edu \n\nKrzysztof J. Cios is currently with the Department of Computer Science, Virginia Commonwealth University, Richmond, Virginia, USA, and IITiS Polish Academy of Sciences, Poland. \nEmail: kcios '@' vcu.edu \n```\n\n### Data Set Information\n\nThe data set consists of the expression levels of 77 proteins/protein modifications that produced detectable signals in the nuclear fraction of cortex. There are 38 control mice and 34 trisomic mice (Down syndrome), for a total of 72 mice. In the experiments, 15 measurements were registered of each protein per sample/mouse. Therefore, for control mice, there are 38x15, or 570 measurements, and for trisomic mice, there are 34x15, or 510 measurements. The dataset contains a total of 1080 measurements per protein. Each measurement can be considered as an independent sample/mouse. \n\nThe eight classes of mice are described based on features such as genotype, behavior and treatment. According to genotype, mice can be control or trisomic. According to behavior, some mice have been stimulated to learn (context-shock) and others have not (shock-context) and in order to assess the effect of the drug memantine in recovering the ability to learn in trisomic mice, some mice have been injected with the drug and others have not. \n\nClasses: \n```\n* c-CS-s: control mice, stimulated to learn, injected with saline (9 mice) \n* c-CS-m: control mice, stimulated to learn, injected with memantine (10 mice) \n* c-SC-s: control mice, not stimulated to learn, injected with saline (9 mice) \n* c-SC-m: control mice, not stimulated to learn, injected with memantine (10 mice) \n* t-CS-s: trisomy mice, stimulated to learn, injected with saline (7 mice) \n* t-CS-m: trisomy mice, stimulated to learn, injected with memantine (9 mice) \n* t-SC-s: trisomy mice, not stimulated to learn, injected with saline (9 mice) \n* t-SC-m: trisomy mice, not stimulated to learn, injected with memantine (9 mice) \n```\n\nThe aim is to identify subsets of proteins that are discriminant between the classes. \n\n### Attribute Information:\n\n```\n1 Mouse ID \n2..78 Values of expression levels of 77 proteins; the names of proteins are followed by &acirc;&euro;&oelig;_n&acirc;&euro;\u009d indicating that they were measured in the nuclear fraction. For example: DYRK1A_n \n79 Genotype: control (c) or trisomy (t) \n80 Treatment type: memantine (m) or saline (s) \n81 Behavior: context-shock (CS) or shock-context (SC) \n82 Class: c-CS-s, c-CS-m, c-SC-s, c-SC-m, t-CS-s, t-CS-m, t-SC-s, t-SC-m \n```\n\n### Relevant Papers:\n\nHiguera C, Gardiner KJ, Cios KJ (2015) Self-Organizing Feature Maps Identify Proteins Critical to Learning in a Mouse Model of Down Syndrome. PLoS ONE 10(6): e0129126. [Web Link] journal.pone.0129126 \n\nAhmed MM, Dhanasekaran AR, Block A, Tong S, Costa ACS, Stasko M, et al. (2015) Protein Dynamics Associated with Failed and Rescued Learning in the Ts65Dn Mouse Model of Down Syndrome. PLoS ONE 10(3): e0119491.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "4550_MiceProtein_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 82, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "4550-MiceProtein"}, "49_facebook": {"pipeline": {"_id": "f8ce2307-054a-48bb-9e58-540b26af8ed4", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 48}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 453, "max_depth": 4, "learning_rate": 0.749320216648741, "gamma": 0.4920883652784268, "min_child_weight": 7}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "graph/graph_matching/default", "template": "5bceaa5d49e71569e8bf7f7b", "id": "f8ce2307-054a-48bb-9e58-540b26af8ed4", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.6359562841530055, "rank": 0.3640437158474632, "metric": "accuracy", "ts": "2018-10-31T04:34:29.656000", "dataset": "49_facebook_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "49_facebook", "about": {"problemID": "49_facebook_problem", "problemName": "Facebook graph matching problem", "problemDescription": "Data for 49_facebook consists of two graphs G1 and G2 with a known partial mapping (both matches and mismatches) between the nodes. The problem is given a pair of nodes, to determine if they match or not", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "49_facebook_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "49-facebook"}, "534_cps_85_wages": {"pipeline": {"_id": "deb54401-bc65-4326-afae-5d1e89cbd9c8", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 33}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 27, "max_depth": 3, "learning_rate": 0.16954155198477916, "gamma": 0.6172648819872297, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "deb54401-bc65-4326-afae-5d1e89cbd9c8", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 19.106868056138715, "rank": 19.10686805613893, "metric": "meanSquaredError", "ts": "2018-10-24T20:58:53.349000", "dataset": "534_cps_85_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "534_cps_85_wages", "about": {"problemID": "534_cps_85_wages_problem", "problemName": "cps_85_wages_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDeterminants of Wages from the 1985 Current Population Survey\n\nSummary:\nThe Current Population Survey (CPS) is used to supplement census information between census years. These data consist of a random sample of 534 persons from the CPS, with information on wages and other characteristics of the workers, including sex, number of years of education, years of work experience, occupational status, region of residence and union membership. We wish to determine (i) whether wages are related to these characteristics and (ii) whether there is a gender gap in wages.\nBased on residual plots, wages were log-transformed to stabilize the variance. Age and work experience were almost perfectly correlated (r=.98). Multiple regression of log wages against sex, age, years of education, work experience, union membership, southern residence, and occupational status showed that these covariates were related to wages (pooled F test, p < .0001). The effect of age was not significant after controlling for experience. Standardized residual plots showed no patterns, except for one large outlier with lower wages than expected. This was a male, with 22 years of experience and 12 years of education, in a management position, who lived in the north and was not a union member. Removing this person from the analysis did not substantially change the results, so that the final model included the entire sample.\nAdjusting for all other variables in the model, females earned 81% (75%, 88%) the wages of males (p < .0001). Wages increased 41% (28%, 56%) for every 5 additional years of education (p < .0001). They increased by 11% (7%, 14%) for every additional 10 years of experience (p < .0001). Union members were paid 23% (12%, 36%) more than non-union members (p < .0001). Northerns were paid 11% (2%, 20%) more than southerns (p =.016). Management and professional positions were paid most, and service and clerical positions were paid least (pooled F-test, p < .0001). Overall variance explained was R2 = .35.\nIn summary, many factors describe the variations in wages: occupational status, years of experience, years of education, sex, union membership and region of residence. However, despite adjustment for all factors that were available, there still appeared to be a gender gap in wages. There is no readily available explanation for this gender gap.\n\nAuthorization: Public Domain\n\nReference: Berndt, ER. The Practice of Econometrics. 1991. NY: Addison-Wesley.\n\nDescription:  The datafile contains 534 observations on 11 variables sampled from the Current Population Survey of 1985.  This data set demonstrates multiple regression, confounding, transformations, multicollinearity, categorical variables, ANOVA, pooled tests of significance, interactions and model building strategies.\n\nVariable names in order from left to right:\nEDUCATION: Number of years of education.\nSOUTH: Indicator variable for Southern Region (1=Person lives in \t\tSouth, 0=Person lives elsewhere).\nSEX: Indicator variable for sex (1=Female, 0=Male).\nEXPERIENCE: Number of years of work experience.\nUNION: Indicator variable for union membership (1=Union member, \t\t0=Not union member).\nWAGE: Wage (dollars per hour).\nAGE: Age (years).\nRACE: Race (1=Other, 2=Hispanic, 3=White).\nOCCUPATION: Occupational category (1=Management, \t\t2=Sales, 3=Clerical, 4=Service, 5=Professional, 6=Other).\nSECTOR: Sector (0=Other, 1=Manufacturing, 2=Construction).\nMARR: Marital Status (0=Unmarried,  1=Married)\n\n\nTherese Stukel\nDartmouth Hitchcock Medical Center\nOne Medical Center Dr.\nLebanon, NH 03756\ne-mail: stukel@dartmouth.edu\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "534_cps_85_wages_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "WAGE"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "534-cps-85-wages"}, "57_hypothyroid": {"pipeline": {"_id": "87969bb2-7286-4882-a373-744838896d90", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 36}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 564, "max_depth": 6, "learning_rate": 0.10866772050652573, "gamma": 0.0518952226754833, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "87969bb2-7286-4882-a373-744838896d90", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8789375234612213, "rank": 0.12106247653907819, "metric": "f1Macro", "ts": "2018-10-25T01:40:50.906000", "dataset": "57_hd_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "57_hypothyroid", "about": {"problemID": "57_hypothyroid_problem", "problemName": "hypothyroid_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n;\n ; Thyroid disease records supplied by the Garavan Institute and J. Ross\n ; Quinlan, New South Wales Institute, Syndney, Australia.\n ;\n ; 1987.\n ;\n \n hypothyroid, primary hypothyroid, compensated hypothyroid,\n secondary hypothyroid,\n negative.\t\t\t|  classes\n \n age:\t\t\t\tcontinuous.\n sex:\t\t\t\tM, F.\n on thyroxine:\t\t\tf, t.\n query on thyroxine:\t\tf, t.\n on antithyroid medication:\tf, t.\n sick:\t\t\t\tf, t.\n pregnant:\t\t\tf, t.\n thyroid surgery:\t\tf, t.\n I131 treatment:\t\t\tf, t.\n query hypothyroid:\t\tf, t.\n query hyperthyroid:\t\tf, t.\n lithium:\t\t\tf, t.\n goitre:\t\t\t\tf, t.\n tumor:\t\t\t\tf, t.\n hypopituitary:\t\t\tf, t.\n psych:\t\t\t\tf, t.\n TSH measured:\t\t\tf, t.\n TSH:\t\t\t\tcontinuous.\n T3 measured:\t\t\tf, t.\n T3:\t\t\t\tcontinuous.\n TT4 measured:\t\t\tf, t.\n TT4:\t\t\t\tcontinuous.\n T4U measured:\t\t\tf, t.\n T4U:\t\t\t\tcontinuous.\n FTI measured:\t\t\tf, t.\n FTI:\t\t\t\tcontinuous.\n TBG measured:\t\t\tf, t.\n TBG:\t\t\t\tcontinuous.\n referral source:\t\tWEST, STMW, SVHC, SVI, SVHD, other.\n\n\n Num Instances:     3772\n Num Attributes:    30\n Num Continuous:    7 (Int 1 / Real 6)\n Num Discrete:      23\n Missing values:    6064 /  5.4%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 'age'                     Int    0% 100%   0%     1 /  0%    93 /  2%   0% \n   2 'sex'                     Enum  96%   0%   0%   150 /  4%     2 /  0%   0% \n   3 'on thyroxine'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   4 'query on thyroxine'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   5 'on antithyroid medicati  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   6 'sick'                    Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   7 'pregnant'                Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   8 'thyroid surgery'         Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   9 'I131 treatment'          Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  10 'query hypothyroid'       Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  11 'query hyperthyroid'      Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  12 'lithium'                 Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  13 'goitre'                  Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  14 'tumor'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  15 'hypopituitary'           Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  16 'psych'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  17 'TSH measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  18 'TSH'                     Real   0%  11%  79%   369 / 10%   287 /  8%   2% \n  19 'T3 measured'             Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  20 'T3'                      Real   0%   9%  71%   769 / 20%    69 /  2%   0% \n  21 'TT4 measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  22 'TT4'                     Real   0%  94%   0%   231 /  6%   241 /  6%   1% \n  23 'T4U measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  24 'T4U'                     Real   0%   2%  87%   387 / 10%   146 /  4%   1% \n  25 'FTI measured'            Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  26 'FTI'                     Real   0%  90%   0%   385 / 10%   234 /  6%   2% \n  27 'TBG measured'            Enum 100%   0%   0%     0 /  0%     1 /  0%   0% \n  28 'TBG'                     Real   0%   0%   0%  3772 /100%     0 /  0%   0% \n  29 'referral source'         Enum 100%   0%   0%     0 /  0%     5 /  0%   0% \n  30 'Class'                   Enum 100%   0%   0%     0 /  0%     4 /  0%   0%", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "57_hypothyroid_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 30, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "57-hypothyroid"}, "59_umls": {"pipeline": {"_id": "0a3998ed-f5d2-4555-a5ff-83921a3e4592", "primitives": ["networkx.link_prediction_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 84}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 473, "max_depth": 5, "learning_rate": 0.3659136487171657, "gamma": 0.352653031147647, "min_child_weight": 6}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "graph/link_prediction/default", "template": "5bceaa5d49e71569e8bf7f7d", "id": "0a3998ed-f5d2-4555-a5ff-83921a3e4592", "loader": {"data_modality": "graph", "task_type": "link_prediction"}, "score": 0.8823809523809523, "rank": 0.11761904761975718, "metric": "accuracy", "ts": "2018-10-31T04:18:31.718000", "dataset": "59_umls_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "59_umls", "about": {"problemID": "59_umls_problem", "problemName": "UMLS Link prediction problem", "problemDescription": "The UMLS includes a semantic network with 135 concepts and 49 binary predicates. The concepts are nodes of the graph and the predicates are relationship(edge) types. There can be multiple relationships between two concepts. Given a partial set of relationships, the task is to predict if a relationship of a certain type exists between two nodes (concepts)", "taskType": "linkPrediction", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "59_umls_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 4, "colName": "linkExists"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.95, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "59-umls"}, "60_jester": {"pipeline": {"_id": "f9c5c934-1bd1-4424-982b-dc9278b725d8", "primitives": ["featuretools.dfs", "lightfm.LightFM"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "lightfm-LightFM#1": {"epochs": 1, "num_threads": 1, "loss": "logistic", "learning_schedule": "adadelta", "no_components": 15, "k": 4}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "lightfm-LightFM#1": {"loss": {"type": "str", "default": "warp", "values": ["warp", "logistic", "bpr", "warp-kos"]}, "learning_schedule": {"type": "str", "default": "adagrad", "values": ["adagrad", "adadelta"]}, "no_components": {"type": "int", "default": 5, "range": [5, 15]}, "k": {"type": "int", "default": 2, "range": [2, 10]}}}, "name": "single_table/collaborative_filtering/default", "template": "5bceaa5e49e71569e8bf7f86", "id": "f9c5c934-1bd1-4424-982b-dc9278b725d8", "loader": {"data_modality": "single_table", "task_type": "collaborative_filtering"}, "score": 3.98648456987024, "rank": 3.986484569870645, "metric": "meanAbsoluteError", "ts": "2018-10-31T06:00:30.128000", "dataset": "60_jester_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "60_jester", "about": {"problemID": "60_jester_problem", "problemName": "Ratings from the Jester Online Joke Recommender System", "problemDescription": "This is an instance of the problem of Collaborative Filtering. Anonymous Ratings from the Jester Online Joke Recommender System. Over 1.7 million continuous ratings (-10.00 to +10.00) of 150 jokes from 59,132 users.", "taskType": "collaborativeFiltering", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "60_jester_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "rating"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanAbsoluteError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "60-jester"}, "66_chlorineConcentration": {"pipeline": {"_id": "a9b01025-7052-4bd3-a5e9-aaf59f3e46f4", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 157, "max_depth": 3, "learning_rate": 0.6785628075295358, "gamma": 0.39253504708632836, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "a9b01025-7052-4bd3-a5e9-aaf59f3e46f4", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.4274867368186673, "rank": 0.5725132631822059, "metric": "f1Macro", "ts": "2018-10-31T09:25:39.408000", "dataset": "66_cn_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "66_chlorineConcentration", "about": {"problemID": "66_chlorineConcentration_problem", "problemName": "66_chlorineConcentration_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.1.1", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "66_chlorineConcentration_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.892, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "66-chlorineConcentration"}, "6_70_com_amazon": {"pipeline": {"_id": "bfb4af1e-f614-4298-ad20-8924e80cf8ee", "primitives": ["community.CommunityBestPartition"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"community-CommunityBestPartition#1": {}}, "tunable_hyperparameters": {"community-CommunityBestPartition#1": {}}, "name": "graph/community_detection/default", "template": "5bceaa5e49e71569e8bf7f85", "id": "bfb4af1e-f614-4298-ad20-8924e80cf8ee", "loader": {"data_modality": "graph", "task_type": "community_detection"}, "score": 0.8177902567006615, "rank": 0.1822097432994283, "metric": "normalizedMutualInformation", "ts": "2018-10-31T04:40:05.745000", "dataset": "6_70_com_amazon_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "6_70_com_amazon", "about": {"problemID": "6_70_com_amazon_problem", "problemName": "Inferring community for a node in the graph problem", "problemDescription": "Network was collected by crawling Amazon website. It is based on Customers Who Bought This Item Also Bought feature of the Amazon website. If a product i is frequently co-purchased with product j, the graph contains an undirected edge from i to j. Each product category provided by Amazon defines each ground-truth community.", "taskType": "communityDetection", "taskSubType": "nonOverlapping", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "6_70_com_amazon_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "community"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.05, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "normalizedMutualInformation"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "6-70-com-amazon"}, "6_86_com_DBLP": {"pipeline": {"_id": "eb32a781-0e19-4e8a-bb77-993270cee5dc", "primitives": ["community.CommunityBestPartition"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"community-CommunityBestPartition#1": {}}, "tunable_hyperparameters": {"community-CommunityBestPartition#1": {}}, "name": "graph/community_detection/default", "template": "5bceaa5e49e71569e8bf7f85", "id": "eb32a781-0e19-4e8a-bb77-993270cee5dc", "loader": {"data_modality": "graph", "task_type": "community_detection"}, "score": 0.8183600366333517, "rank": 0.1816399633667441, "metric": "normalizedMutualInformation", "ts": "2018-10-31T05:06:02.141000", "dataset": "6_86_com_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "6_86_com_DBLP", "about": {"problemID": "6_86_com_DBLP_problem", "problemName": "Inferring community for a node in the graph problem", "problemDescription": "The DBLP computer science bibliography provides a comprehensive list of research papers in computer science. We construct a co-authorship network where two authors are connected if they publish at least one paper together. Publication venue, e.g, journal or conference, defines an individual ground-truth community; authors who published to a certain journal or conference form a community.", "taskType": "communityDetection", "taskSubType": "nonOverlapping", "problemVersion": "1.0", "problemSchemaVersion": "3.1.1"}, "inputs": {"data": [{"datasetID": "6_86_com_DBLP_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "community"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.05, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "normalizedMutualInformation"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "6-86-com-DBLP"}, "Airline-Sentiment-2-w-AA": {"pipeline": {"_id": "e52a93c2-7e62-411f-831e-d33dc559c977", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 961}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 26, "min_samples_split": 0.15638589050379575, "min_samples_leaf": 0.007209559629029468, "n_estimators": 453, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "e52a93c2-7e62-411f-831e-d33dc559c977", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.9053961564299294, "rank": 0.09460384357035409, "metric": "accuracy", "ts": "2018-10-31T04:49:32.809000", "dataset": "Airline-Sentiment-2-w-AA_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "Airline-Sentiment-2-w-AA", "about": {"problemID": "Airline-Sentiment-2-w-AA_problem", "problemName": "classification", "problemDescription": "multiclass", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "Airline-Sentiment-2-w-AA_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "airline_sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "Airline-Sentiment-2-w-AA"}, "chemicals-and-disease-DFE": {"pipeline": {"_id": "38914608-d204-47f0-9d33-57a17fa55d7c", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": true, "max_features": 352}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 28, "min_samples_split": 0.013180209433266636, "min_samples_leaf": 0.028406385662575074, "n_estimators": 174, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "38914608-d204-47f0-9d33-57a17fa55d7c", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.870462330199463, "rank": 0.1295376698005569, "metric": "accuracy", "ts": "2018-10-31T05:00:01.340000", "dataset": "chemicals-and-disease-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "chemicals-and-disease-DFE", "about": {"problemID": "chemicals-and-disease-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "chemicals-and-disease-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 8, "colName": "verify_relationship"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "chemicals-and-disease-DFE"}, "Coachella-2015-2-DFE": {"pipeline": {"_id": "053e591d-159c-4e5f-965d-f43b1c79b3de", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": false, "max_features": 557}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 28, "min_samples_split": 0.04698577182632929, "min_samples_leaf": 0.02482884520508544, "n_estimators": 89, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "053e591d-159c-4e5f-965d-f43b1c79b3de", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.5968797288468636, "rank": 0.4031202711539625, "metric": "accuracy", "ts": "2018-10-31T05:16:33.732000", "dataset": "Coachella-2015-2-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "Coachella-2015-2-DFE", "about": {"problemID": "Coachella-2015-2-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "Coachella-2015-2-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "coachella_sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "Coachella-2015-2-DFE"}, "Corporate-messaging-DFE": {"pipeline": {"_id": "5134d5aa-c668-4b37-8437-e1e59eb13d0d", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 307}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 23, "min_samples_split": 0.25238724901302967, "min_samples_leaf": 0.00026858912202132, "n_estimators": 138, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "5134d5aa-c668-4b37-8437-e1e59eb13d0d", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.8323892910286241, "rank": 0.16761070897162636, "metric": "accuracy", "ts": "2018-10-31T05:52:08.998000", "dataset": "Corporate-messaging-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "Corporate-messaging-DFE", "about": {"problemID": "Corporate-messaging-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "Corporate-messaging-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "category"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "Corporate-messaging-DFE"}, "first-gop-debate-twitter-sentiment": {"pipeline": {"_id": "cdd2faa5-83fc-49cf-8273-8503cbf803ed", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 747}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 15, "min_samples_split": 0.0785425849540231, "min_samples_leaf": 0.04769038326847279, "n_estimators": 337, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "cdd2faa5-83fc-49cf-8273-8503cbf803ed", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.6263500922022113, "rank": 0.37364990779867746, "metric": "accuracy", "ts": "2018-10-31T04:31:34.731000", "dataset": "first-gop-debate-twitter-sentiment_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "first-gop-debate-twitter-sentiment", "about": {"problemID": "first-gop-debate-twitter-sentiment_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "first-gop-debate-twitter-sentiment_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "first-gop-debate-twitter-sentiment"}, "LL0_1008_analcatdata_reviewer": {"pipeline": {"_id": "f2ff1288-815a-4ba2-81e4-540670dd482c", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 46}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 221, "max_depth": 8, "learning_rate": 0.5344652060950527, "gamma": 0.9302433788133522, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "f2ff1288-815a-4ba2-81e4-540670dd482c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.693129560842945, "rank": 0.3068704391576045, "metric": "f1Macro", "ts": "2018-10-25T00:37:55.095000", "dataset": "LL0_1008_analcatdata_reviewer_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1008_analcatdata_reviewer", "about": {"problemID": "LL0_1008_analcatdata_reviewer_problem", "problemName": "analcatdata_reviewer_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1008_analcatdata_reviewer_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1008-analcatdata-reviewer"}, "LL0_1026_grub_damage": {"pipeline": {"_id": "e1f02c89-fcf4-4872-a161-30c4a9e8c053", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 15, "min_samples_split": 0.1332061092996443, "min_samples_leaf": 0.016859023916418248, "n_estimators": 58, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "e1f02c89-fcf4-4872-a161-30c4a9e8c053", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7926280255692021, "rank": 0.2073719744314064, "metric": "f1Macro", "ts": "2018-10-25T06:31:31.963000", "dataset": "LL0_1026_grub_damage_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1026_grub_damage", "about": {"problemID": "LL0_1026_grub_damage_problem", "problemName": "grub_damage_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1026_grub_damage_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1026-grub-damage"}, "LL0_1027_esl": {"pipeline": {"_id": "fea8e96d-6073-4a9f-ba8b-fa102e3df957", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 55}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 387, "max_depth": 5, "learning_rate": 0.13428328833021852, "gamma": 0.27121466329958177, "min_child_weight": 10}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "fea8e96d-6073-4a9f-ba8b-fa102e3df957", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.28218320827555826, "rank": 0.28218320827592963, "metric": "meanSquaredError", "ts": "2018-10-24T21:13:12.177000", "dataset": "LL0_1027_esl_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1027_esl", "about": {"problemID": "LL0_1027_esl_problem", "problemName": "LL0_1027_esl_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n1. Title: Employee Selection (Ordinal ESL)\n\n2. Source Informaion:\nDonor: Arie Ben David\nMIS, Dept. of Technology Management\nHolon Academic Inst. of Technology\n52 Golomb St.\nHolon 58102\nIsrael\nabendav@hait.ac.il\nOwner: Yoav Ganzah\nBusiness Administration School\nTel Aviv Univerity\nRamat Aviv 69978\nIsrael\n\n3. Past Usage:\n\n4. Relevant Information\nThe ESL data set contains 488 profiles of applicants for certain industrial\njobs.  Expert psychologists of a recruiting company, based upon psychometric\ntest results and interviews with the candidates, determined the values of the\ninput attributes. The output is the an overall score corresponding to the\ndegree of fitness of the candidate to this type of job.\n\n\n5. Number of Instances: 488\n\n6. Number of Attributes: 4 input, 1 output.\n\n7. Attribute Information: All input and output values are ORDINAL.\n\n8. Missing Attribute Values: None.\n\n9. Class Distribution:", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1027_esl_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "out1"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1027-esl"}, "LL0_1028_swd": {"pipeline": {"_id": "be74b32c-6fc0-4fa7-9ee3-d841cf12f7fe", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 96}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 897, "max_depth": 3, "learning_rate": 0.42932652672860205, "gamma": 0.6960912296424173, "min_child_weight": 8}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "be74b32c-6fc0-4fa7-9ee3-d841cf12f7fe", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.376507274182242, "rank": 0.37650727418257524, "metric": "meanSquaredError", "ts": "2018-10-24T20:57:57.554000", "dataset": "LL0_1028_swd_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1028_swd", "about": {"problemID": "LL0_1028_swd_problem", "problemName": "LL0_1028_swd_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n1. Title: Social Workers Decisions (Ordinal SWD)\n\n2. Source Informaion:\nDonor: Arie Ben David\nMIS, Dept. of Technology Management\nHolon Academic Inst. of Technology\n52 Golomb St.\nHolon 58102\nIsrael\nabendav@hait.ac.il\nOwner: Yoav Ganzah\nBusiness Administration School\nTel Aviv Univerity\nRamat Aviv 69978\nIsrael\n\n3. Past Usage:\n\n4. Relevant Information\nThe SWD data set contains real-world assessments of qualified social workers\nregarding the risk facing children if they stayed with their families at\nhome.  This evaluation of risk assessment is often presented to judicial\ncourts to help decide what is in the best interest of an alleged abused or\nneglected child.\n\n\n5. Number of Instances: 1000\n\n6. Number of Attributes: 10 input, 1 output.\n\n7. Attribute Information: All input and output values are ORDINAL.\n\n8. Missing Attribute Values: None.\n\n9. Class Distribution:", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1028_swd_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "Out1"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1028-swd"}, "LL0_1030_era": {"pipeline": {"_id": "352a08bc-c76a-486c-8cd9-33bbb3f5bd34", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 32}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 484, "max_depth": 3, "learning_rate": 0.017121024925487838, "gamma": 0.923950754308671, "min_child_weight": 9}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "352a08bc-c76a-486c-8cd9-33bbb3f5bd34", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.4500271444644794, "rank": 2.4500271444650252, "metric": "meanSquaredError", "ts": "2018-10-24T21:29:19.983000", "dataset": "LL0_1030_era_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1030_era", "about": {"problemID": "LL0_1030_era_problem", "problemName": "LL0_1030_era_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n1. Title: Employee Rejection\\Acceptance  (Orinal ERA)\n\n2. Source Informaion:\nDonor: Arie Ben David\nMIS, Dept. of Technology Management\nHolon Academic Inst. of Technology\n52 Golomb St.\nHolon 58102\nIsrael\nabendav@hait.ac.il\nOwner: Yoav Ganzah\nBusiness Administration School\nTel Aviv Univerity\nRamat Aviv 69978\nIsrael\n\n3. Past Usage:\n\n4. Relevant Information\nThe ERA data set was originally gathered during an academic decision-making\nexperiment aiming at determining which are the most important qualities of\ncandidates for a certain type of jobs. Unlike the ESL data set (enclosed)\nwhich was collected from expert recruiters, this data set was collected\nduring a MBA academic course.\nThe input in the data set are features of a candidates such as past\nexperience, verbal skills, etc., and the output is the subjective judgment of\na decision-maker to which degree he or she tends to accept the applicant to\nthe job or to reject him altogether (the lowest score means total tendency to\nreject an applicant and vice versa).\n\n5. Number of Instances: 1000\n\n6. Number of Attributes: 4 input, 1 output.\n\n7. Attribute Information: All input and output values are ORDINAL.\n\n8. Missing Attribute Values: None.\n\n9. Class Distribution:", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1030_era_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "out1"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1030-era"}, "LL0_1036_sylva_agnostic": {"pipeline": {"_id": "82d1a292-7290-4039-9d17-44bbd81d85a8", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 280, "max_depth": 6, "learning_rate": 0.43828291104706485, "gamma": 0.279072462686639, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "82d1a292-7290-4039-9d17-44bbd81d85a8", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9775278012822562, "rank": 0.022472198718656917, "metric": "f1Macro", "ts": "2018-10-31T04:54:17.126000", "dataset": "LL0_1036_sylva_agnostic_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1036_sylva_agnostic", "about": {"problemID": "LL0_1036_sylva_agnostic_problem", "problemName": "LL0_1036_sylva_agnostic_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nModified by TunedIT (converted to ARFF format)\n\n\nSYLVA is the ecology database\n\n\nThe task of SYLVA is to classify forest cover types. The forest cover type for 30 x 30 meter cells is obtained from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. We brought it back to a two-class classification problem (classifying Ponderosa pine vs. everything else). The \"agnostic learning track\" data consists in 216 input variables. Each pattern is composed of 4 records: 2 true records matching the target and 2 records picked at random. Thus 1/2 of the features are distracters.\n\nData type: non-sparse\nNumber of features: 216\nNumber of examples and check-sums:\nPos_ex\tNeg_ex\tTot_ex\tCheck_sum\nTrain\t  805\t12281\t13086\t238271607.00\nValid\t   81\t 1228\t 1309\t23817234.00\n\n\nThis dataset contains samples from both training and validation datasets.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1036_sylva_agnostic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 217, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1036-sylva-agnostic"}, "LL0_1037_ada_prior": {"pipeline": {"_id": "36e934fe-609f-4759-8f21-0537597568ff", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 82}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 683, "max_depth": 5, "learning_rate": 0.14877380030897647, "gamma": 0.7675104096118671, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "36e934fe-609f-4759-8f21-0537597568ff", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7967962623634381, "rank": 0.20320373763723892, "metric": "f1Macro", "ts": "2018-10-25T00:40:42.273000", "dataset": "LL0_1037_ada_prior_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1037_ada_prior", "about": {"problemID": "LL0_1037_ada_prior_problem", "problemName": "ada_prior_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nModified by TunedIT (converted to ARFF format)\n\n\nADA is the marketing database\n\nThe task of ADA is to discover high revenue people from census data. This is a two-class classification problem. The raw data from the census bureau is known as the Adult database in the UCI machine-learning repository. The 14 original attributes (features) include age, workclass,  education, education,\nmarital status, occupation, native country, etc. It contains continuous, binary and categorical features. This dataset is from \"prior knowledge track\", i.e. has access to the original features and their identity.\n\n\nNumber of examples:\nPos_ex\tNeg_ex\tTot_ex\nTrain\t 1029\t 3118\t 4147\nValid\t  103\t  312\t  415\n\nThis dataset contains samples from both training and validation datasets.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1037_ada_prior_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 15, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1037-ada-prior"}, "LL0_1038_gina_agnostic": {"pipeline": {"_id": "214e2565-63b5-4503-9cbc-d86bb507437e", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 97}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 583, "max_depth": 6, "learning_rate": 0.11166268601114093, "gamma": 0.4244421359219067, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "214e2565-63b5-4503-9cbc-d86bb507437e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.950611444680615, "rank": 0.04938855532019329, "metric": "f1Macro", "ts": "2018-10-25T01:13:27.754000", "dataset": "LL0_1038_gina_agnostic_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1038_gina_agnostic", "about": {"problemID": "LL0_1038_gina_agnostic_problem", "problemName": "LL0_1038_gina_agnostic_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\n\nModified by TunedIT (converted to ARFF format)\n\n\nGINA is digit recognition database\n\nThe task of GINA is handwritten digit recognition. For the \"agnostic learning track\" we chose the problem of separating two-digit odd numbers from two-digit even numbers. Only the unit digit is informative for that task, therefore at least 1/2 of the features are distracters. Additionally, the pixels that are almost always blank were removed and the pixel order was randomized to hide the feature identity.  This is a two class classification problem with sparse continuous input variables, in which each class is composed of several clusters. It is a problem with heterogeneous classes.\n\nData type: non-sparse\nNumber of features: 970\nNumber of examples and check-sums:\nPos_ex\tNeg_ex\tTot_ex\tCheck_sum\nTrain\t 1550\t 1603\t 3153\t164947945.00\nValid\t  155\t  160\t  315\t16688946.00\n\n\nThis dataset contains samples from both training and validation datasets.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1038_gina_agnostic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 971, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1038-gina-agnostic"}, "LL0_1040_sylva_prior": {"pipeline": {"_id": "6826dd9c-d56d-456f-b869-0fa220fd7dcc", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 58}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 879, "max_depth": 6, "learning_rate": 0.1251344286036915, "gamma": 0.46067790466337777, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6826dd9c-d56d-456f-b869-0fa220fd7dcc", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9787497259379345, "rank": 0.02125027406248494, "metric": "f1Macro", "ts": "2018-10-25T00:28:50.777000", "dataset": "LL0_1040_sylva_prior_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1040_sylva_prior", "about": {"problemID": "LL0_1040_sylva_prior_problem", "problemName": "LL0_1040_sylva_prior_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nModified by TunedIT (converted to ARFF format)\n\n\nSYLVA is the ecology database\n\n\nThe task of SYLVA is to classify forest cover types. The forest cover type for 30 x 30 meter cells is obtained from US Forest Service (USFS) Region 2 Resource Information System (RIS) data. We brought it back to a two-class classification problem (classifying Ponderosa pine vs. everything else). The \"agnostic learning track\" data consists in 216 input variables. Each pattern is composed of 4 records: 2 true records matching the target and 2 records picked at random. Thus 1/2 of the features are distracters. The \"prior knowledge track\" data is identical to the \"agnostic learning track\" data, except that the distracters are removed and the identity of the features is revealed. For that track, the forest cover original ids are revealed for training data.\n\nData type: non-sparse\nNumber of features: 108\nNumber of examples and check-sums:\nPos_ex\tNeg_ex\tTot_ex\tCheck_sum\nTrain\t  805\t12281\t13086\t118996108.00\nValid\t   81\t 1228\t 1309\t11904801.00", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1040_sylva_prior_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 109, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1040-sylva-prior"}, "LL0_1041_gina_prior2": {"pipeline": {"_id": "cd86f5d0-cfa2-4687-af43-7106827ef717", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "cd86f5d0-cfa2-4687-af43-7106827ef717", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9196007904082604, "rank": 0.08039920959255703, "metric": "f1Macro", "ts": "2018-10-31T04:16:36.757000", "dataset": "LL0_1041_gina_prior2_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1041_gina_prior2", "about": {"problemID": "LL0_1041_gina_prior2_problem", "problemName": "LL0_1041_gina_prior2_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nModified by TunedIT (converted to ARFF format)\n\n\nGINA is digit recognition database\n\nThe task of GINA is handwritten digit recognition.\n\nData type: non-sparse\nNumber of features: 784\nNumber of examples and check-sum:\nTot_ex\tCheck_sum\n3468\t90979365.00", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1041_gina_prior2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 785, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1041-gina-prior2"}, "LL0_1043_ada_agnostic": {"pipeline": {"_id": "8e603206-fd9d-4244-a396-929fdea14d11", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 2}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 91, "max_depth": 3, "learning_rate": 0.31874698992998607, "gamma": 0.4227289879113959, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "8e603206-fd9d-4244-a396-929fdea14d11", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7969645514355318, "rank": 0.20303544856473443, "metric": "f1Macro", "ts": "2018-10-25T01:31:19.852000", "dataset": "LL0_1043_ada_agnostic_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1043_ada_agnostic", "about": {"problemID": "LL0_1043_ada_agnostic_problem", "problemName": "LL0_1043_ada_agnostic_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets from the Agnostic Learning vs. Prior Knowledge Challenge (http://www.agnostic.inf.ethz.ch)\n\nDataset from: http://www.agnostic.inf.ethz.ch/datasets.php\n\nDescription can be found http://clopinet.com/isabelle/Projects/agnostic/Dataset.pdf\n\n\nModified by TunedIT (converted to ARFF format)\n\n\nADA is the marketing database\n\nThe task of ADA is to discover high revenue people from census data. This is a two-class classification problem. The raw data from the census bureau is known as the Adult database in the UCI machine-learning repository. The 14 original attributes (features) include age, workclass,  education,\nmarital status, occupation, native country, etc. It contains continuous, binary and categorical features. This dataset is from the \"agnostic learning track\", i.e. has access to a preprocessed numeric representation eliminating categorical variables, but the identity of the features is not revealed.\n\n\n\nData type: non-sparse\nNumber of features: 48\nNumber of examples and check-sums:\nPos_ex Neg_ex Tot_ex Check_sum\nTrain  1029  3118  4147 6798109.00\nValid   103   312   415 681151.00\n\n\nThis dataset contains samples from both training and validation datasets.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1043_ada_agnostic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 49, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1043-ada-agnostic"}, "LL0_1044_eye_movements": {"pipeline": {"_id": "9637cdaf-62f0-4ecc-8f42-f7eb7bf0aef7", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 906, "max_depth": 7, "learning_rate": 0.19555184031317685, "gamma": 0.24781218745684386, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "9637cdaf-62f0-4ecc-8f42-f7eb7bf0aef7", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7312293958676382, "rank": 0.2687706041324546, "metric": "f1Macro", "ts": "2018-10-31T05:36:11.657000", "dataset": "LL0_1044_eye_movements_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1044_eye_movements", "about": {"problemID": "LL0_1044_eye_movements_problem", "problemName": "LL0_1044_eye_movements_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nJarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. Data set at http://www.cis.hut.fi/eyechallenge2005/\n\nCompetition 1 (preprocessed data)\nA straight-forward classification task. We provide pre-computed feature vectors for each word in the eye movement trajectory, with class labels.\n\nThe dataset consist of several assignments. Each assignment consists of a question followed by ten sentences (titles of news articles). One of the sentences is the correct answer to the question (C) and five of the sentences are irrelevant to the question (I). Four of the sentences are relevant to the question (R), but they do not answer it.\n\n\n* Features are in columns, feature vectors in rows.\n* Each assignment is a time sequence of 22-dimensional feature vectors.\n* The first column is the line number, second the assignment number and the next 22 columns (3 to 24) are the different features. Columns 25 to 27 contain extra information about the example. The training data set contains the classification label in the 28th column: \"0\" for irrelevant, \"1\" for relevant and \"2\" for the correct answer.\n* Each example (row) represents a single word. You are asked to return the classification of each read sentence.\n* The 22 features provided are commonly used in psychological studies on eye movement. All of them are not necessarily relevant in this context.\n\nThe objective of the Challenge is to predict the classification labels (I, R, C).\n\n\n\nPlease see the technical report for information of eye movements, experimental setup, baseline methods and references:\n\nJarkko Salojarvi, Kai Puolamaki, Jaana Simola, Lauri Kovanen, Ilpo Kojo, Samuel Kaski. Inferring Relevance from Eye Movements: Feature Extraction. Helsinki University of Technology, Publications in Computer and Information Science, Report A82. 3 March 2005. [PDF]\n\n\n\nModified by TunedIT (converted to ARFF format)\n\n\nFEATURES\n\nThe values in columns marked with an asterisk (*) are same for all occurances of the word.\n\nCOL\tNAME\t\tDESCRIPTION\n1\t#line\t\tLine number\n2\t#assg\t\tAssignment Number\n3\tfixcount\tNumber of fixations to the word\n4*\tfirstPassCnt\tNumber of fixations to the word when it is first encountered\n5*\tP1stFixation\t'1' if fixation occured when the sentence the word was in was encountered the first time\n6*\tP2stFixation\t'1' if fixation occured when the sentence the word was in was encountered the second time\n7*\tprevFixDur\tDuration of previous fixation\n8*\tfirstfixDur\tDuration of the first fixation when the word is first encountered\n9*\tfirstPassFixDur\tSum of durations of fixations when the word is first encountered\n10*\tnextFixDur\tDuration of the next fixation when gaze initially moves from the word\n11\tfirstSaccLen\tLength of the first saccade\n12\tlastSaccLen\tDistance between fixation on the word and the next fixation\n13\tprevFixPos\tDistance between the first fixation preceding the word and the beginning ot the word\n14\tlandingPos\tDistance between the first fixation on the word and the beginning of the word\n15\tleavingPos\tDistance between the last fixation on the word and the beginning of the word\n16\ttotalFixDur\tSum of all durations of fixations to the word\n17\tmeanFixDur\tMean duration of the fixations to the word\n18*\tnRegressFrom\tNumber of regressions leaving from the word\n19*\tregressLen\tSum of durations of regressions initiating from this word\n20*\tnextWordRegress\t'1' if a regression initiated from the following word\n21*\tregressDur\tSum of durations of the fixations on the word during regression\n22\tpupilDiamMax\tMaximum pupil diameter\n23\tpupilDiamLag\tMaximum pupil diameter 0.5 - 1.5 seconds after the beginning of fixation\n24\ttimePrtctg\tFirst fixation duration divided by the total number of fixations\n25\tnWordsInTitle\tNumber of word in the sentence (title) this word is in\n26\ttitleNo\t\tTitle number\n27\twordNo\t\tWord number (ordinal) in this title\n28\tlabel\t\tClassification for training data ('0'=irrelevant, '1'=relevant, '2'=correct)", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1044_eye_movements_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 28, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1044-eye-movements"}, "LL0_1046_mozilla4": {"pipeline": {"_id": "6ee67d69-3c6b-4352-9484-9e1412a5c746", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 77}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 727, "max_depth": 9, "learning_rate": 0.2655893023474001, "gamma": 0.014692318188940012, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6ee67d69-3c6b-4352-9484-9e1412a5c746", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9491770542459855, "rank": 0.05082294575466156, "metric": "f1Macro", "ts": "2018-10-24T23:55:01.891000", "dataset": "LL0_1046_mozilla4_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1046_mozilla4", "about": {"problemID": "LL0_1046_mozilla4_problem", "problemName": "LL0_1046_mozilla4_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE Software Engineering Repository data set made publicly\navailable in order to encourage repeatable, verifiable, refutable, and/or\nimprovable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promisedata.org/repository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n(c) 2007  A. Gunes Koru\nContact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843\nThis data set is distributed under the\nCreative Commons Attribution-Share Alike 3.0 License\nhttp://creativecommons.org/licenses/by-sa/3.0/\n\nYou are free:\n\n* to Share -- copy, distribute and transmit the work\n* to Remix -- to adapt the work\n\nUnder the following conditions:\n\nAttribution. You must attribute the work in the manner specified by\nthe author or licensor (but not in any way that suggests that they endorse\nyou or your use of the work).\n\nShare Alike. If you alter, transform, or build upon this work, you\nmay distribute the resulting work only under the same, similar or a\ncompatible license.\n\n* For any reuse or distribution, you must make clear to others the\nlicense terms of this work.\n* Any of the above conditions can be waived if you get permission from\nthe copyright holder.\n* Apart from the remix rights granted under this license, nothing in\nthis license impairs or restricts the author's moral rights.\n\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n\n\n1. Title: Recurrent event (defect fix) and size data for Mozilla Classes\nThis one includes a binary attribute (event) to show defect fix.\nThe data is at the \"observation\" level. Each modification made to\na C++ class was entered as an observation. A newly added class\ncreated an observation. The observation period was between\nMay 29, 2002 and Feb 22, 2006.\n\n2. Sources\n(a) Creator: A. Gunes Koru\n(b) Date: February 23, 2007\n(c) Contact: gkoru AT umbc DOT edu Phone: +1 (410) 455 8843\n\n3. Donor: A. Gunes Koru\n\n4. Past Usage: This data set was used for:\n\nA. Gunes Koru, Dongsong Zhang, and Hongfang Liu, \"Modeling the\nEffect of Size on Defect Proneness for Open-Source Software\",\nPredictive Models in Software Engineering Workshop, PROMISE 2007,\nMay 20th 2007, Minneapolis, Minnesota, US.\n\nAbstract:\nQuality is becoming increasingly important with the continuous\nadoption of open-source software.  Previous research has found that\nthere is generally a positive relationship between module size and\ndefect proneness. Therefore, in open-source software development, it\nis important to monitor module size and understand its impact on\ndefect proneness. However, traditional approaches to quality\nmodeling, which measure specific system snapshots and obtain future\ndefect counts, are not well suited because open-source modules\nusually evolve and their size changes over time. In this study, we\nused Cox proportional hazards modeling with recurrent events to\nstudy the effect of class size on defect-proneness in the Mozilla\nproduct. We found that the effect of size was significant, and we\nquantified this effect on defect proneness.\n\nThe full paper can be downloaded from A. Gunes Koru's Website\nhttp://umbc.edu/~gkoru\nby following the Publications link or from the Web site of PROMISE 2007.\n\n5. Features:\n\nThis data set is used to create a conditional Cox Proportional\nHazards Model\n\nid: A numeric identification assigned to each separate C++ class\n(Note that the id's do not increment from the first to the last\ndata row)\n\nstart: A time infinitesimally greater than the time of the modification\nthat created this observation (practically, modification time). When a\nclass is introduced to a system, a new observation is entered with start=0\n\nend: Either the time of the next modification, or the end of the\nobservation period, or the time of deletion, whichever comes first.\n\nevent: event is set to 1 if a defect fix takes place\nat the time represented by 'end', or 0 otherwise.  A class deletion\nis handled easily by entering a final observation whose event is set\nto 1 if the class is deleted for corrective maintenance, or 0 otherwise.\n\nsize: It is a time-dependent covariate and its column carries the\nnumber of source Lines of Code of the C++ classes\nat time 'start'. Blank and comment lines are not counted.\n\nstate: Initially set to 0, and it becomes 1 after the class\nexperiences an event, and remains at 1 thereafter.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1046_mozilla4_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "state"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1046-mozilla4"}, "LL0_1049_pc4": {"pipeline": {"_id": "72b18f55-3c9d-4669-ae76-0be70dac06c2", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 95}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 246, "max_depth": 7, "learning_rate": 0.5932515326915814, "gamma": 0.3995747743724506, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "72b18f55-3c9d-4669-ae76-0be70dac06c2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7895622897026175, "rank": 0.21043771029764605, "metric": "f1Macro", "ts": "2018-10-25T07:08:49.764000", "dataset": "LL0_1049_pc4_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1049_pc4", "about": {"problemID": "LL0_1049_pc4_problem", "problemName": "LL0_1049_pc4_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc1.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**PC4 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1049_pc4_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "c"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1049-pc4"}, "LL0_1050_pc3": {"pipeline": {"_id": "f67a46ab-51e0-45ec-b3e3-52c82219a9fe", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 23}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 657, "max_depth": 7, "learning_rate": 0.9232170001632393, "gamma": 0.37831643416124117, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f67a46ab-51e0-45ec-b3e3-52c82219a9fe", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6865966787783797, "rank": 0.31340332122192066, "metric": "f1Macro", "ts": "2018-10-25T01:17:33.805000", "dataset": "LL0_1050_pc3_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1050_pc3", "about": {"problemID": "LL0_1050_pc3_problem", "problemName": "LL0_1050_pc3_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc3.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**PC3 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1050_pc3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "c"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1050-pc3"}, "LL0_1053_jm1": {"pipeline": {"_id": "757d2f78-cc5e-4fde-8799-d2871345c66d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 100}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 19, "min_samples_split": 0.014107912532487669, "min_samples_leaf": 0.006237795597743797, "n_estimators": 67, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "757d2f78-cc5e-4fde-8799-d2871345c66d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6332562081166886, "rank": 0.3667437918838575, "metric": "f1Macro", "ts": "2018-10-25T05:44:09.592000", "dataset": "LL0_1053_jm1_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1053_jm1", "about": {"problemID": "LL0_1053_jm1_problem", "problemName": "LL0_1053_jm1_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is a PROMISE data set made publicly available in order to encourage repeatable, verifiable, refutable, and/or improvable predictive models of software engineering.\n\nIf you publish material based on PROMISE data sets then, please follow the acknowledgment guidelines posted on [the PROMISE repository web page](http://promise.site.uottawa.ca/SERepository).\n\n## Title/Topic\nJM1/software defect prediction\n\n\n## Sources\n* **Creators:**  NASA, then the NASA Metrics Data Program, http://mdp.ivv.nasa.gov. \n* **Contacts:** \n  * Mike Chapman, Galaxy Global Corporation (Robert.Chapman@ivv.nasa.gov) +1-304-367-8341\n  * Pat Callis, NASA, NASA project manager for MDP (Patrick.E.Callis@ivv.nasa.gov) +1-304-367-8309\n\n* **Donor:** Tim Menzies (tim@barmag.net)\n\n* **Date:**  December 2nd, 2004\n\n## Past usage\n**_How Good is Your Blind Spot Sampling Policy?_; 2003; Tim Menzies and Justin S. Di Stefano; 2004 IEEE Conference on High Assurance Software Engineering (http://menzies.us/pdf/03blind.pdf).**\n\n### Results:\n* Very simple learners (ROCKY) perform as well in this domain as more sophisticated methods (e.g. J48, model trees, model trees) for predicting detects\n* Many learners have very low false alarm rates.\n* Probability of detection (PD) rises with effort and rarely rises above it.\n* High PDs are associated with high PFs (probability of failure)\n* PD, PF, effort can change significantly while accuracy remains essentially stable\n* With two notable exceptions, detectors learned from one data set (e.g. KC2) have nearly they same properties when applied to another (e.g. PC2, KC2). Exceptions:\n* LinesOfCode measures generate wider inter-data-set variances;\n* Precision's inter-data-set variances vary wildly\n\n**_\"Assessing Predictors of Software Defects\"_, T. Menzies and J. DiStefano and A. Orrego and R. Chapman, 2004,**\n**Proceedings, workshop on Predictive Software Models, Chicago, Available from http://menzies.us/pdf/04psm.pdf.**\n\n### Results:\n* From JM1, Naive Bayes generated PDs of 25% with PF of 20%\n* Naive Bayes out-performs J48 for defect detection\n* When learning on more and more data, little improvement is seen after processing 300 examples.\n* PDs are much higher from data collected below the sub-sub-system level.\n* Accuracy is a surprisingly uninformative measure of success for a defect detector. Two detectors with the same accuracy can have widely varying PDs and PFs.\n\n## Relevant information\n* JM1 is written in \"C\" and is a real-time predictive ground system: Uses simulations to generate predictions\n* Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality. The nature of association is under dispute.\n\nNotes on McCabe and Halstead follow.\n\n* The McCabe and Halstead measures are \"module\"-based where a \"module\" is the smallest unit of functionality. In C or Smalltalk, \"modules\" would be called \"function\" or \"method\" respectively.\n\n* Defect detectors can be assessed according to the following measures:\n\n    module actually has defects\n    +-------------+------------+\n    |     no      |     yes    |\n    +-----+-------------+------------+\n    classifier predicts no defects |  no |      a      |      b     |\n    +-----+-------------+------------+\n    classifier predicts some defects | yes |      c      |      d     |\n    +-----+-------------+------------+\n\n\n    accuracy                   = acc          = (a+d)/(a+b+c+d\n    probability of detection   = pd  = recall = d/(b+d)\n    probability of false alarm = pf           = c/(a+c)\n    precision                  = prec         = d/(c+d)\n    effort                     = amount of code selected by detector = (c.LOC + d.LOC)/(Total LOC)\n\n\nIdeally, detectors have high PDs, low PFs, and low effort. This ideal state rarely happens:\n\n* PD and effort are linked. The more modules that trigger the detector, the higher the PD. However, effort also gets increases\n* High PD or low PF comes at the cost of high PF or low PD (respectively). This linkage can be seen in a standard receiver operator curve (ROC).  Suppose, for example, LOC> x is used as the detector (i.e. we assume large modules have more errors). LOC > x represents a family of detectors. At x=0, EVERY module is predicted to have errors. This detector has a high PD but also a high false alarm rate. At x=0, NO module is predicted to have errors. This detector has a low false alarm rate but won't detect anything at all. At 0<x<1, a set of detectors are generated as shown below:\n\n    pd\n    1 |           x  x  x                KEY:\n    |        x     .                   \".\"  denotes the line PD=PF\n    |     x      .                     \"x\"  denotes the roc curve\n    |   x      .                            for a set of detectors\n    |  x     .\n    | x    .\n    | x  .\n    |x .\n    |x\n    x------------------ pf\n    0                   1\n\nNote that:\n* The only way to make no mistakes (PF=0) is to do nothing (PD=0)\n* The only way to catch more detects is to make more mistakes (increasing PD means increasing PF).\n* Our detector bends towards the \"sweet spot\" of <PD=1,PF=0> but does not reach it.\n* The line pf=pd on the above graph represents the \"no information\" line. If pf=pd then the detector is pretty useless. The better the detector, the more it rises above PF=PD towards the \"sweet spot\".\n\nNOTES ON MCCABE/HALSTEAD\n========================\nMcCabe argued that code with complicated pathways are more error-prone.  His metrics therefore reflect the pathways within a code module.\n\n    @Article{mccabe76,\n    title  = \"A Complexity Measure\",\n    author  = \"T.J. McCabe\",\n    pages  = \"308--320\",\n    journal = \"IEEE Transactions on Software Engineering\",\n    year  = \"1976\",\n    volume  = \"2\",\n    month  = \"December\",\n    number  = \"4\"}\n\nHalstead argued that code that is hard to read is more likely to be fault prone. Halstead estimates reading complexity by counting the number of concepts in a module; e.g. number of unique operators.\n\n    @Book{halstead77,\n    Author    = \"M.H. Halstead\",\n    Title    = \"Elements of Software Science\",\n    Publisher = \"Elsevier \",\n    Year    = 1977}\n\nWe study these static code measures since they are useful, easy to use, and widely used:\n\n* USEFUL: E.g. this data set can generate highly accurate predictors for defects\n* EASY TO USE: Static code measures (e.g. lines of code, the McCabe/Halstead measures) can be automatically and cheaply collected.\n* WIDELY USED: Many researchers use static measures to guide software quality predictions (see the reference list in the above \"blind spot\" paper. Verification and validation (V\\&V) textbooks advise using static code complexity measures to decide which modules are worthy of manual inspections.  Further, we know of several large government software contractors that won't review software modules _unless_ tools like McCabe predict that they are fault prone.  Hence, defect detectors have a major economic impact when they may force programmers to rewrite code.\n\nNevertheless, the merits of these metrics has been widely criticized.  Static code measures are hardly a complete characterization of the internals of a function. Fenton offers an insightful example where the same functionality is achieved using different programming language constructs resulting in different static measurements for that module. Fenton uses this example to argue the uselessness of static code measures.\n\n    @Book{fenton97,\n    author    = \"N.E. Fenton and S.L. Pfleeger\",\n    title     = {Software metrics: a Rigorous \\& Practical Approach},\n    publisher = {International Thompson Press},\n    year      = {1997}}\n\nAn alternative interpretation of Fenton's example is that static measures can never be a definite and certain indicator of the presence of a fault.  Rather, defect detectors based on static measures are best viewed as probabilistic statements that the frequency of faults tends to increase in code modules that trigger the detector.  By definition, such probabilistic statements will are not categorical claims with some a non-zero false alarm rate. The research challenge for data miners is to ensure that these false alarms do not cripple their learned theories.\n\nThe McCabe metrics are a collection of four software metrics: essential complexity, cyclomatic complexity, design complexity and LOC, Lines of Code.\n\n* Cyclomatic Complexity, or \"v(G)\", measures the number of \"linearly independent paths\". A set of paths is said to be linearly independent if no path in the set is a linear combination of any other paths in the set through a program's \"flowgraph\". A flowgraph is a directed graph where each node corresponds to a program statement, and each arc indicates the flow of control from one statement to another. \"v(G)\" is calculated by \"v(G) = e - n + 2\" where \"G\" is a program's flowgraph, \"e\" is the number of arcs in the flowgraph, and \"n\" is the number of nodes in the flowgraph. The standard McCabes rules (\"v(G)\">10), are used to identify fault-prone module.\n* Essential Complexity, or \"ev(G)$\" is the extent to which a flowgraph can be \"reduced\" by decomposing all the subflowgraphs of $G$ that are \"D-structured primes\". Such \"D-structured primes\" are also sometimes referred to as \"proper one-entry one-exit subflowgraphs\" (for a more thorough discussion of D-primes, see the Fenton text referenced above). \"ev(G)\" is calculated using \"ev(G)= v(G) - m\" where $m$ is the number of subflowgraphs of \"G\" that are D-structured primes.\n* Design Complexity, or \"iv(G)\", is the cyclomatic complexity of a module's reduced flowgraph.  The flowgraph, \"G\", of a module is reduced to eliminate any complexity which does not influence the interrelationship between design modules.  According to McCabe, this complexity measurement reflects the modules calling patterns to its immediate subordinate modules.\n* Lines of code is measured according to McCabe's line counting conventions.\n\nThe Halstead falls into three groups: the base measures, the derived measures, and lines of code measures.\n\n* Base measures:\n  * mu1             = number of unique operators\n  * mu2             = number of unique operands\n  * N1              = total occurrences of operators\n  * N2              = total occurrences of operands\n  * length     = N  = N1 + N2\n  * vocabulary = mu = mu1 + mu2\n  * Constants set for each function:\n  * mu1' =  2 = potential operator count (just the function name and the \"return\" operator)\n  * mu2'      = potential operand count. (the number of arguments to the module)\n\nFor example, the expression \"return max(w+x,x+y)\" has \"N1=4\" operators \"return, max, +,+)\", \"N2=4\" operands (w,x,x,y), \"mu1=3\" unique operators (return, max,+), and \"mu2=3\" unique operands (w,x,y).\n\n* Derived measures:\n  * P = volume = V = N * log2(mu) (the number of mental comparisons needed to write\na program of length N)\n  * V* = volume on minimal implementation = (2 + mu2')*log2(2 + mu2')\n  * L  = program length = V*/N\n  * D  = difficulty = 1/L\n  * L' = 1/D\n  * I  = intelligence = L'*V'\n  * E  = effort to write program = V/L\n  * T  = time to write program = E/18 seconds\n\n## Number of instances\n10885\n\n## Number of attributes\n22 (5 different lines of code measure, 3 McCabe metrics, 4 base Halstead measures, 8 derived Halstead measures, a branch-count, and 1 goal field)\n\n## Attribute Information\n1. loc             : numeric % McCabe's line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead\n12. t               : numeric % Halstead's time estimator\n13. lOCode          : numeric % Halstead's line count\n14. lOComment       : numeric % Halstead's count of lines of comments\n15. lOBlank         : numeric % Halstead's count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21: branchCount     : numeric % of the flow graph\n22. defects         : {false,true} % module has/has not one or more reported defects\n\n## Missing attributes\nNone\n\n## Class Distribution\nThe class value (defects) is discrete\nfalse: 2106 = 19.35%\ntrue:  8779 = 80.65%", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1053_jm1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "defects"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1053-jm1"}, "LL0_1054_mc2": {"pipeline": {"_id": "eb972b97-0f28-4d07-9b95-7be1ebd1e527", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 34}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 17, "min_samples_split": 0.041519688963139866, "min_samples_leaf": 0.020019897310999037, "n_estimators": 394, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "eb972b97-0f28-4d07-9b95-7be1ebd1e527", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7803081232492997, "rank": 0.2196918767515331, "metric": "f1Macro", "ts": "2018-10-25T04:35:42.310000", "dataset": "LL0_1054_mc2_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1054_mc2", "about": {"problemID": "LL0_1054_mc2_problem", "problemName": "mc2_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/mc2.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**MC2 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. The specific type of software is unknown. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1054_mc2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 40, "colName": "c"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1054-mc2"}, "LL0_1063_kc2": {"pipeline": {"_id": "44cf89ac-33e8-4f75-9793-1f9b5f508d28", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 33}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 5, "min_samples_split": 0.2379134326945446, "min_samples_leaf": 0.056403043920106644, "n_estimators": 26, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "44cf89ac-33e8-4f75-9793-1f9b5f508d28", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7904543740735972, "rank": 0.20954562592659515, "metric": "f1Macro", "ts": "2018-10-25T05:39:35.895000", "dataset": "LL0_1063_kc2_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1063_kc2", "about": {"problemID": "LL0_1063_kc2_problem", "problemName": "LL0_1063_kc2_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc2.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**KC2 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. Data from software for science data processing. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Attribute Information  \n\n1. loc             : numeric % McCabe's line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead \n12. t               : numeric % Halstead's time estimator\n13. lOCode          : numeric % Halstead's line count\n14. lOComment       : numeric % Halstead's count of lines of comments\n15. lOBlank         : numeric % Halstead's count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21. branchCount     : numeric % of the flow graph\n22. problems        : {false,true} % module has/has not one or more reported defects\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1063_kc2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "problems"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1063-kc2"}, "LL0_1065_kc3": {"pipeline": {"_id": "86bfb699-b825-47c7-987d-acddfdc7c531", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 20, "min_samples_split": 0.030483877410368888, "min_samples_leaf": 0.01913990936199921, "n_estimators": 329, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "86bfb699-b825-47c7-987d-acddfdc7c531", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6745826445844666, "rank": 0.32541735541569095, "metric": "f1Macro", "ts": "2018-10-25T06:04:37.305000", "dataset": "LL0_1065_kc3_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1065_kc3", "about": {"problemID": "LL0_1065_kc3_problem", "problemName": "kc3_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc3.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**KC3 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. The specific type of software is unknown. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Attribute Information  \n\n1. loc             : numeric % McCabe's line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead \n12. t               : numeric % Halstead's time estimator\n13. lOCode          : numeric % Halstead's line count\n14. lOComment       : numeric % Halstead's count of lines of comments\n15. lOBlank         : numeric % Halstead's count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21. branchCount     : numeric % of the flow graph\n22. problems        : {false,true} % module has/has not one or more reported defects\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1065_kc3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 40, "colName": "c"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1065-kc3"}, "LL0_1067_kc1": {"pipeline": {"_id": "197e3baf-c2eb-4dd0-a1e2-a7afaedaa6d4", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 686, "max_depth": 10, "learning_rate": 0.8309106050330572, "gamma": 0.8466027141625403, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "197e3baf-c2eb-4dd0-a1e2-a7afaedaa6d4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6705431790450602, "rank": 0.32945682095568396, "metric": "f1Macro", "ts": "2018-10-31T05:19:21.903000", "dataset": "LL0_1067_kc1_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1067_kc1", "about": {"problemID": "LL0_1067_kc1_problem", "problemName": "LL0_1067_kc1_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/kc1.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n**KC1 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. Data from software for storage management for receiving and processing ground data. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Attribute Information  \n\n1. loc             : numeric % McCabe's line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead \n12. t               : numeric % Halstead's time estimator\n13. lOCode          : numeric % Halstead's line count\n14. lOComment       : numeric % Halstead's count of lines of comments\n15. lOBlank         : numeric % Halstead's count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21. branchCount     : numeric % of the flow graph\n22. problems        : {false,true} % module has/has not one or more reported defects\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1067_kc1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "defects"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1067-kc1"}, "LL0_1068_pc1": {"pipeline": {"_id": "d4acc639-e7b5-4b7b-aac4-83990fa37361", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 4}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 6, "learning_rate": 0.5267274617101032, "gamma": 0.3546769801496925, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d4acc639-e7b5-4b7b-aac4-83990fa37361", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.707399633964101, "rank": 0.29260036603593353, "metric": "f1Macro", "ts": "2018-10-25T00:07:17.075000", "dataset": "LL0_1068_pc1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1068_pc1", "about": {"problemID": "LL0_1068_pc1_problem", "problemName": "LL0_1068_pc1_problem", "problemDescription": "**Author**: Mike Chapman, NASA  \n**Source**: [tera-PROMISE](http://openscience.us/repo/defect/mccabehalsted/pc1.html) - 2004  \n**Please cite**: Sayyad Shirabad, J. and Menzies, T.J. (2005) The PROMISE Repository of Software Engineering Databases. School of Information Technology and Engineering, University of Ottawa, Canada.  \n  \n\n**PC1 Software defect prediction**  \nOne of the NASA Metrics Data Program defect data sets. Data from flight software for earth orbiting satellite. Data comes from McCabe and Halstead features extractors of source code.  These features were defined in the 70s in an attempt to objectively characterize code features that are associated with software quality.\n\n### Attribute Information  \n\n1. loc             : numeric % McCabe's line count of code\n2. v(g)            : numeric % McCabe \"cyclomatic complexity\"\n3. ev(g)           : numeric % McCabe \"essential complexity\"\n4. iv(g)           : numeric % McCabe \"design complexity\"\n5. n               : numeric % Halstead total operators + operands\n6. v               : numeric % Halstead \"volume\"\n7. l               : numeric % Halstead \"program length\"\n8. d               : numeric % Halstead \"difficulty\"\n9. i               : numeric % Halstead \"intelligence\"\n10. e               : numeric % Halstead \"effort\"\n11. b               : numeric % Halstead \n12. t               : numeric % Halstead's time estimator\n13. lOCode          : numeric % Halstead's line count\n14. lOComment       : numeric % Halstead's count of lines of comments\n15. lOBlank         : numeric % Halstead's count of blank lines\n16. lOCodeAndComment: numeric\n17. uniq_Op         : numeric % unique operators\n18. uniq_Opnd       : numeric % unique operands\n19. total_Op        : numeric % total operators\n20. total_Opnd      : numeric % total operands\n21. branchCount     : numeric % of the flow graph\n22. branchCount     : numeric % of the flow graph\n23. defects         : {false,true} % module has/has not one or more reported defects\n\n### Relevant papers  \n\n- Shepperd, M. and Qinbao Song and Zhongbin Sun and Mair, C. (2013)\nData Quality: Some Comments on the NASA Software Defect Datasets, IEEE Transactions on Software Engineering, 39.\n\n- Tim Menzies and Justin S. Di Stefano (2004) How Good is Your Blind Spot Sampling Policy? 2004 IEEE Conference on High Assurance\nSoftware Engineering.\n\n- T. Menzies and J. DiStefano and A. Orrego and R. Chapman (2004) Assessing Predictors of Software Defects\", Workshop on Predictive Software Models, Chicago", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1068_pc1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "defects"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1068-pc1"}, "LL0_1071_mw1": {"pipeline": {"_id": "2ea59a50-e352-4ec2-bd0e-1a22edad4988", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 73}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 439, "max_depth": 4, "learning_rate": 0.8416163082444599, "gamma": 0.5576671534427898, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "2ea59a50-e352-4ec2-bd0e-1a22edad4988", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6629033522861963, "rank": 0.33709664771468656, "metric": "f1Macro", "ts": "2018-10-25T00:06:08.863000", "dataset": "LL0_1071_mw1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1071_mw1", "about": {"problemID": "LL0_1071_mw1_problem", "problemName": "mw1_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%-*- text -*-\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\nThis is a PROMISE data set made publicly available in order to encourage\nrepeatable, verifiable, refutable, and/or improvable predictive models\nof software engineering.\n\nIf you publish material based on PROMISE data sets then, please\nfollow the acknowledgment guidelines posted on the PROMISE repository\nweb page http://promise.site.uottawa.ca/SERepository .\n%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n1. Title/Topic: MW1/software defect prediction\n\n(c) 2007 : Tim Menzies  : tim@menzies.us\nThis data set is distributed under the\nCreative Commons Attribution-Share Alike 3.0 License\nhttp://creativecommons.org/licenses/by-sa/3.0/\n\nYou are free:\n\n* to Share -- copy, distribute and transmit the work\n* to Remix -- to adapt the work\n\nUnder the following conditions:\n\nAttribution. You must attribute the work in the manner specified by\nthe author or licensor (but not in any way that suggests that they endorse\nyou or your use of the work).\n\nShare Alike. If you alter, transform, or build upon this work, you\nmay distribute the resulting work only under the same, similar or a\ncompatible license.\n\n* For any reuse or distribution, you must make clear to others the\nlicense terms of this work.\n* Any of the above conditions can be waived if you get permission from\nthe copyright holder.\n* Apart from the remix rights granted under this license, nothing in\nthis license impairs or restricts the author's moral rights.\nFor more deatils on this data set, see\nhttp://promisedata.org/repository/data/kc2/kc2.arff", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1071_mw1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "c"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1071-mw1"}, "LL0_1097_ICU": {"pipeline": {"_id": "99aadddd-c6c7-400a-9bfd-e25865520d2c", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 910, "max_depth": 5, "learning_rate": 0.691152984917424, "gamma": 0.7769212079710964, "min_child_weight": 3}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "99aadddd-c6c7-400a-9bfd-e25865520d2c", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.17115525000458126, "rank": 0.17115525000468582, "metric": "meanSquaredError", "ts": "2018-10-31T04:23:34.035000", "dataset": "LL0_1097_ICU_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1097_ICU", "about": {"problemID": "LL0_1097_ICU_problem", "problemName": "ICU_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.\nSource: TunedIT: http://tunedit.org/repo/DASL\n\nDASL file http://lib.stat.cmu.edu/DASL/Datafiles/ICU.html\n\nReference:\nAuthorization:   Contact authors\nDescription:   The data consist of 200 subjects from a larger study on the survival of patients following admission to an adult intensive care unit (ICU).  The study used logistic regression to predict the probability of survival for these patients until their discharge from the hospital.  The dependent variable is the binary variable Vital Status (STA).  Nineteen possible predictor variables, both discrete and continuous, were also observed.\n\nNumber of cases:   200\nVariable Names:\n\nID:   ID number of the patient\nSTA:   Vital status (0 = Lived, 1 = Died)\nAGE:   Patient's age in years\nSEX:   Patient's sex (0 = Male, 1 = Female)\nRACE:   Patient's race (1 = White, 2 = Black, 3 = Other)\nSER:   Service at ICU admission (0 = Medical, 1 = Surgical)\nCAN:   Is cancer part of the present problem? (0 = No, 1 = Yes)\nCRN:   History of chronic renal failure (0 = No, 1 = Yes)\nINF:", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1097_ICU_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "LOC"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1097-ICU"}, "LL0_1100_popularkids": {"pipeline": {"_id": "9d6489e2-1634-43f1-adb0-301a49447c7b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 92}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 925, "max_depth": 7, "learning_rate": 0.8786178513176527, "gamma": 0.27115034330814836, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9d6489e2-1634-43f1-adb0-301a49447c7b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.4751289254485857, "rank": 0.5248710745514931, "metric": "f1Macro", "ts": "2018-10-25T00:30:41.656000", "dataset": "LL0_1100_popularkids_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1100_popularkids", "about": {"problemID": "LL0_1100_popularkids_problem", "problemName": "LL0_1100_popularkids_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets of Data And Story Library, project illustrating use of basic statistic methods, converted to arff format by Hakan Kjellerstrand.\nSource: TunedIT: http://tunedit.org/repo/DASL\n\nDASL file http://lib.stat.cmu.edu/DASL/Datafiles/PopularKids.html\n\nStudents' Goals\n,\n\nWhat Makes Kids Popular\n\nReference:   Chase, M. A., and Dummer, G. M. (1992), \"The Role of Sports as a Social Determinant for Children,\" Research Quarterly for Exercise and Sport, 63, 418-424\n\nAuthorization:   Contact authors\nDescription:        Subjects were students in grades 4-6 from three school districts in Ingham and Clinton Counties, Michigan.  Chase and Dummer stratified their sample, selecting students from urban, suburban, and rural school districts with approximately 1/3 of their sample coming from each district.  Students indicated whether good grades, athletic ability, or popularity was most important to them.  They also ranked four factors:  grades, sports, looks, and money, in order of their importance for popularity.  The questionnaire also asked for gender, grade level, and other demographic information.\nNumber of cases:   478\nVariable Names:\n\nGender:   Boy or girl\nGrade:   4, 5 or 6\nAge:   Age in years\nRace:   White, Other\nUrban/Rural:   Rural, Suburban, or Urban school district\nSchool:   Brentwood Elementary, Brentwood Middle, Ridge, Sand, Eureka, Brown, Main, Portage, Westdale Middle\nGoals:   Student's choice in the personal goals question where options were 1 = Make Good Grades,  2 = Be Popular,  3 = Be Good in Sports\nGrades:   Rank of \"make good grades\"  (1=most important for popularity, 4=least important)\nSports:   Rank of \"being good at sports\"  (1=most important for popularity, 4=least important)\nLooks:   Rank of \"being handsome or pretty\"  (1=most important for popularity, 4=least important)\nMoney:   Rank of \"having lots of money\"  (1=most important for popularity, 4=least important)", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1100_popularkids_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "Goals"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1100-popularkids"}, "LL0_1113_kddcup99": {"pipeline": {"_id": "aa742b61-e550-4cb6-9163-2915faa1f9b9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 0}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "aa742b61-e550-4cb6-9163-2915faa1f9b9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7566166426705603, "rank": 0.24338335732974445, "metric": "f1Macro", "ts": "2018-10-25T01:44:03.868000", "dataset": "LL0_1113_kddcup99_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1113_kddcup99", "about": {"problemID": "LL0_1113_kddcup99_problem", "problemName": "LL0_1113_kddcup99_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is a 10% stratified subsample of the data from the 1999 ACM KDD Cup (http://www.sigkdd.org/kddcup/index.php).\n\nModified by TunedIT (converted to ARFF format)\n\nhttp://www.sigkdd.org/kddcup/index.php?section=1999&method=info\nThis is the data set used for The Third International Knowledge Discovery and Data Mining Tools Competition, which was held in conjunction with KDD-99 The Fifth International Conference on Knowledge Discovery and Data Mining. The competition task was to build a network intrusion detector, a predictive model capable of distinguishing between ``bad'' connections, called intrusions or attacks, and \"good\" normal connections. This database contains a standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment.\nThe training and test datasets are also available in the UC Irvine KDD archive.\n\n\n\n\nKDD Cup 1999: Tasks\n\nThis document is adapted from the paper Cost-based Modeling and Evaluation for Data Mining With Application to Fraud and Intrusion Detection: Results from the JAM Project by Salvatore J. Stolfo, Wei Fan, Wenke Lee, Andreas Prodromidis, and Philip K. Chan.\n\nIntrusion Detector Learning\n\nSoftware to detect network intrusions protects a computer network from unauthorized users, including perhaps insiders. The intrusion detector learning task is to build a predictive model (i.e. a classifier) capable of distinguishing between ``bad'' connections, called intrusions or attacks, and ``good'' normal connections.\n\nThe 1998 DARPA Intrusion Detection Evaluation Program was prepared and managed by MIT Lincoln Labs. The objective was to survey and evaluate research in intrusion detection. A standard set of data to be audited, which includes a wide variety of intrusions simulated in a military network environment, was provided. The 1999 KDD intrusion detection contest uses a version of this dataset.\n\nLincoln Labs set up an environment to acquire nine weeks of raw TCP dump data for a local-area network (LAN) simulating a typical U.S. Air Force LAN. They operated the LAN as if it were a true Air Force environment, but peppered it with multiple attacks.\n\nThe raw training data was about four gigabytes of compressed binary TCP dump data from seven weeks of network traffic. This was processed into about five million connection records. Similarly, the two weeks of test data yielded around two million connection records.\n\nA connection is a sequence of TCP packets starting and ending at some well defined times, between which data flows to and from a source IP address to a target IP address under some well defined protocol. Each connection is labeled as either normal, or as an attack, with exactly one specific attack type. Each connection record consists of about 100 bytes.\n\nAttacks fall into four main categories:\n\n* DOS: denial-of-service, e.g. syn flood;\n* R2L: unauthorized access from a remote machine, e.g. guessing password;\n* U2R: unauthorized access to local superuser (root) privileges, e.g., various ``buffer overflow'' attacks;\n* probing: surveillance and other probing, e.g., port scanning.\n\nIt is important to note that the test data is not from the same probability distribution as the training data, and it includes specific attack types not in the training data. This makes the task more realistic. Some intrusion experts believe that most novel attacks are variants of known attacks and the \"signature\" of known attacks can be sufficient to catch novel variants. The datasets contain a total of 24 training attack types, with an additional 14 types in the test data only.\n\nDerived Features\n\nStolfo et al. defined higher-level features that help in distinguishing normal connections from attacks. There are several categories of derived features.\n\nThe ``same host'' features examine only the connections in the past two seconds that have the same destination host as the current connection, and calculate statistics related to protocol behavior, service, etc.\n\nThe similar ``same service'' features examine only the connections in the past two seconds that have the same service as the current connection.\n\n\"Same host\" and \"same service\" features are together called time-based traffic features of the connection records.\n\nSome probing attacks scan the hosts (or ports) using a much larger time interval than two seconds, for example once per minute. Therefore, connection records were also sorted by destination host, and features were constructed using a window of 100 connections to the same host instead of a time window. This yields a set of so-called host-based traffic features.\n\nUnlike most of the DOS and probing attacks, there appear to be no sequential patterns that are frequent in records of R2L and U2R attacks. This is because the DOS and probing attacks involve many connections to some host(s) in a very short period of time, but the R2L and U2R attacks are embedded in the data portions of packets, and normally involve only a single connection.\n\nUseful algorithms for mining the unstructured data portions of packets automatically are an open research question. Stolfo et al. used domain knowledge to add features that look for suspicious behavior in the data portions, such as the number of failed login attempts. These features are called ``content'' features.\n\nA complete listing of the set of features defined for the connection records is given in the three tables below. The data schema of the contest dataset is available in machine-readable form.\n\nfeature name  description  type\nduration  length (number of seconds) of the connection  continuous\nprotocol_type  type of the protocol, e.g. tcp, udp, etc.  discrete\nservice  network service on the destination, e.g., http, telnet, etc.  discrete\nsrc_bytes  number of data bytes from source to destination  continuous\ndst_bytes  number of data bytes from destination to source  continuous\nflag  normal or error status of the connection  discrete\nland  1 if connection is from/to the same host/port; 0 otherwise  discrete\nwrong_fragment  number of ``wrong'' fragments  continuous\nurgent  number of urgent packets  continuous\n\nTable 1: Basic features of individual TCP connections.\n\nfeature name  description  type\nhot  number of ``hot'' indicators  continuous\nnum_failed_logins  number of failed login attempts  continuous\nlogged_in  1 if successfully logged in; 0 otherwise  discrete\nnum_compromised  number of ``compromised'' conditions  continuous\nroot_shell  1 if root shell is obtained; 0 otherwise  discrete\nsu_attempted  1 if ``su root'' command attempted; 0 otherwise  discrete\nnum_root  number of ``root'' accesses  continuous\nnum_file_creations  number of file creation operations  continuous\nnum_shells  number of shell prompts  continuous\nnum_access_files  number of operations on access control files  continuous\nnum_outbound_cmds  number of outbound commands in an ftp session  continuous\nis_hot_login  1 if the login belongs to the ``hot'' list; 0 otherwise  discrete\nis_guest_login  1 if the login is a ``guest''login; 0 otherwise  discrete\n\nTable 2: Content features within a connection suggested by domain knowledge.\n\nfeature name  description  type\ncount  number of connections to the same host as the current connection in the past two seconds  continuous\nNote: The following features refer to these same-host connections.\nserror_rate  % of connections that have ``SYN'' errors  continuous\nrerror_rate  % of connections that have ``REJ'' errors  continuous\nsame_srv_rate  % of connections to the same service  continuous\ndiff_srv_rate  % of connections to different services  continuous\nsrv_count  number of connections to the same service as the current connection in the past two seconds  continuous\nNote: The following features refer to these same-service connections.\nsrv_serror_rate  % of connections that have ``SYN'' errors  continuous\nsrv_rerror_rate  % of connections that have ``REJ'' errors  continuous\nsrv_diff_host_rate  % of connections to different hosts  continuous\n\nTable 3: Traffic features computed using a two-second time window.\n\n\n\n\nhttp://www.sigkdd.org/kddcup", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1113_kddcup99_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 42, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1113-kddcup99"}, "LL0_1115_teachingAssistant": {"pipeline": {"_id": "5ae11aa8-b2af-4272-a397-439f17eaf286", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 24}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 195, "max_depth": 6, "learning_rate": 0.956996105625371, "gamma": 0.43959351497631327, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "5ae11aa8-b2af-4272-a397-439f17eaf286", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7164550264550265, "rank": 0.28354497354564684, "metric": "f1Macro", "ts": "2018-10-25T01:06:15.580000", "dataset": "LL0_1115_teachingAssistant_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1115_teachingAssistant", "about": {"problemID": "LL0_1115_teachingAssistant_problem", "problemName": "teachingAssistant_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDataset from the MLRR repository: http://axon.cs.byu.edu:5000/", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1115_teachingAssistant_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1115-teachingAssistant"}, "LL0_1121_badges2": {"pipeline": {"_id": "03c4224c-79c4-479e-8c8b-84eed3b014b7", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 21}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 206, "max_depth": 4, "learning_rate": 0.17219471342319215, "gamma": 0.8421243136960459, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "03c4224c-79c4-479e-8c8b-84eed3b014b7", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 2.4217232047574197e-16, "metric": "f1Macro", "ts": "2018-10-24T23:51:01.396000", "dataset": "LL0_1121_badges2_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1121_badges2", "about": {"problemID": "LL0_1121_badges2_problem", "problemName": "badges2_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDataset from the MLRR repository: http://axon.cs.byu.edu:5000/", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1121_badges2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 12, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1121-badges2"}, "LL0_1176_internet_advertisements": {"pipeline": {"_id": "727a79e4-cf8b-4e63-a79f-9291847fd543", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 112, "max_depth": 4, "learning_rate": 0.21162606701299813, "gamma": 0.7434527870159133, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "727a79e4-cf8b-4e63-a79f-9291847fd543", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9442683869267139, "rank": 0.055731613073643785, "metric": "f1Macro", "ts": "2018-10-25T01:17:31.481000", "dataset": "LL0_1176_internet_advertisements_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1176_internet_advertisements", "about": {"problemID": "LL0_1176_internet_advertisements_problem", "problemName": "LL0_1176_internet_advertisements_problem", "problemDescription": "**Author**: Nicholas Kushmerick  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/Internet+Advertisements) - 1998  \n**Please cite**:   \n\n### Description\n\nThis dataset represents a set of possible advertisements on Internet pages\n\n### Sources\n\n(a) Creator and donor:\n\nNicholas Kushmerick - nick@ucd.ie\n\n### Dataset Information\n\nThe features encode the geometry of the image (if available) as well as phrases occurring in the URL, the image's URL and alt text, the anchor text, and words occurring near the anchor text. The task is to predict whether an image is an advertisement (\"ad\") or not (\"nonad\").\n\n### Atributtes Information\n\nThere are : 3 continuous attributes. The others are binary.\nThis is the \"STANDARD encoding\" mentioned in the [Kushmerick, 99] (see below). \nOne or more of the three continuous features are missing in 28% of the instances.\nMissing values should be interpreted as \"unknown\".\n\n### Relevant Papers  \n\nN. Kushmerick (1999). \"Learning to remove Internet advertisements\", 3rd Int Conf Autonomous Agents.  \nAvailable at: http://rexa.info/paper/2fdc1cee89b7f4f2c9227d6f5d9b05d22c5ab3e9", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1176_internet_advertisements_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1559, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1176-internet-advertisements"}, "LL0_11_balance_scale": {"pipeline": {"_id": "ac3c75a5-8c97-4543-a8e6-693e8f7f14b9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 14}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 948, "max_depth": 9, "learning_rate": 0.9559502128567418, "gamma": 0.0620878707339777, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "ac3c75a5-8c97-4543-a8e6-693e8f7f14b9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7291950270431555, "rank": 0.27080497295705547, "metric": "f1Macro", "ts": "2018-10-25T00:29:46.963000", "dataset": "LL0_11_balance_scale_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_11_balance_scale", "about": {"problemID": "LL0_11_balance_scale_problem", "problemName": "LL0_11_balance_scale_problem", "problemDescription": "**Author**: Siegler, R. S. (donated by Tim Hume)  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/balance+scale) - 1994  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**Balance Scale Weight & Distance Database**  \nThis data set was generated to model psychological experimental results.  Each example is classified as having the balance scale tip to the right, tip to the left, or be balanced. The attributes are the left weight, the left distance, the right weight, and the right distance. The correct way to find the class is the greater of (left-distance * left-weight) and (right-distance * right-weight). If they are equal, it is balanced.\n\n### Attribute description  \nThe attributes are the left weight, the left distance, the right weight, and the right distance.\n\n### Relevant papers  \nShultz, T., Mareschal, D., & Schmidt, W. (1994). Modeling Cognitive Development on Balance Scale Phenomena. Machine Learning, Vol. 16, pp. 59-88.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_11_balance_scale_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-11-balance-scale"}, "LL0_1217_click_prediction_small": {"pipeline": {"_id": "e527a09e-282d-4300-827d-22734ae07b5d", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 728, "max_depth": 7, "learning_rate": 0.8115154472646, "gamma": 0.7757114534490216, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "e527a09e-282d-4300-827d-22734ae07b5d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5339609155579291, "rank": 0.4660390844429844, "metric": "f1Macro", "ts": "2018-10-31T05:53:24.202000", "dataset": "LL0_1217_click_prediction_small_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1217_click_prediction_small", "about": {"problemID": "LL0_1217_click_prediction_small_problem", "problemName": "LL0_1217_click_prediction_small_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nEven smaller sample of version 1", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1217_click_prediction_small_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "click"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1217-click-prediction-small"}, "LL0_1219_click_prediction_small": {"pipeline": {"_id": "e6c5a5b9-1312-4ff9-9db8-6bcd9ed8d8c2", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 5}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 521, "max_depth": 5, "learning_rate": 0.852265139431179, "gamma": 0.9014370631313158, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "e6c5a5b9-1312-4ff9-9db8-6bcd9ed8d8c2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5814005439213072, "rank": 0.41859945607875754, "metric": "f1Macro", "ts": "2018-10-25T01:14:28.327000", "dataset": "LL0_1219_click_prediction_small_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1219_click_prediction_small", "about": {"problemID": "LL0_1219_click_prediction_small_problem", "problemName": "LL0_1219_click_prediction_small_problem", "problemDescription": "**Author**: Tencent Inc.  \n**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012  \n**Please cite**:   \n\nThis data is derived from the 2012 KDD Cup. The data is subsampled to 1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).\n\nThe data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. \nThe task is to build the best possible model to predict whether a user will click on a given ad.\n\nA search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called \u2018depth\u2019. The order of an ad in the displayed list is called \u2018position\u2019.  An ad is displayed as a short text called \u2018title\u2019, followed by a slightly longer text called \u2019description\u2019, and a URL  called \u2018display URL\u2019.   \nTo construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  (\u2018depth\u2019, \u2018position\u2019).  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.\n\nThe dataset has the following features:  \n* Click \u2013 binary variable indicating whether a user clicked on at least one ad. \n* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.\n* Url_hash - URL is hashed for anonymity\n* AdID \n* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others\u2019 ads.\n* Depth - number of ads displayed to a user in a session\n* Position - order of an ad in the displayed list\n* QueryID - is the key of the data file 'queryid_tokensid.txt'. (follow the link to the original KDD Cup page, track 2)\n* KeywordID - is the key of  'purchasedkeyword_tokensid.txt' (follow the link to the original KDD Cup page, track 2)\n* TitleID - is the key of 'titleid_tokensid.txt'\n* DescriptionID - is the key of 'descriptionid_tokensid.txt' (follow the link to the original KDD Cup page, track 2)\n* UserID \u2013 is also the key of 'userid_profile.txt' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1219_click_prediction_small_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "click"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1219-click-prediction-small"}, "LL0_1220_click_prediction_small": {"pipeline": {"_id": "e886121c-2998-4faf-b177-72a230f32e18", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 66}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 800, "max_depth": 4, "learning_rate": 0.6902924846471642, "gamma": 0.10412918209131106, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "e886121c-2998-4faf-b177-72a230f32e18", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5808444881285195, "rank": 0.41915551187228234, "metric": "f1Macro", "ts": "2018-10-25T01:13:35.384000", "dataset": "LL0_1220_click_prediction_small_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1220_click_prediction_small", "about": {"problemID": "LL0_1220_click_prediction_small_problem", "problemName": "LL0_1220_click_prediction_small_problem", "problemDescription": "**Author**: Tencent Inc.  \n**Source**: [KDD Cup](https://www.kddcup2012.org/) - 2012  \n**Please cite**:   \n\n**0.1% balanced subsample of the original KDD dataset**  \n\nThis data is derived from the 2012 KDD Cup. The data is subsampled to 0.1% of the original number of instances, downsampling the majority class (click=0) so that the target feature is reasonably balanced (5 to 1).\n\nThe data is about advertisements shown alongside search results in a search engine, and whether or not people clicked on these ads. \nThe task is to build the best possible model to predict whether a user will click on a given ad.\n\nA search session contains information on user id, the query issued by the user, ads displayed to the user, and target feature indicating whether a user clicked at least one of the ads in this session. The number of ads displayed to a user in a session is called \u2018depth\u2019. The order of an ad in the displayed list is called \u2018position\u2019.  An ad is displayed as a short text called \u2018title\u2019, followed by a slightly longer text called \u2019description\u2019, and a URL  called \u2018display URL\u2019.   \nTo construct this dataset each session was split into multiple instances. Each instance describes an ad displayed under a certain setting  (\u2018depth\u2019, \u2018position\u2019).  Instances with the same user id, ad id, query, and setting are merged. Each ad and each user have some additional properties located in separate data files that can be looked up using ids in the instances.\n\nThe dataset has the following features:  \n* Click \u2013 binary variable indicating whether a user clicked on at least one ad. \n* Impression - the number of search sessions in which AdID was impressed by UserID who issued Query.\n* Url_hash - URL is hashed for anonymity\n* AdID \n* AdvertiserID - some advertisers consistently optimize their ads, so the title and description of their ads are more attractive than those of others\u2019 ads.\n* Depth - number of ads displayed to a user in a session\n* Position - order of an ad in the displayed list\n* QueryID - is the key of the data file 'queryid_tokensid.txt'. (follow the link to the original KDD Cup page, track 2)\n* KeywordID - is the key of  'purchasedkeyword_tokensid.txt' (follow the link to the original KDD Cup page, track 2)\n* TitleID - is the key of 'titleid_tokensid.txt'\n* DescriptionID - is the key of 'descriptionid_tokensid.txt' (follow the link to the original KDD Cup page, track 2)\n* UserID \u2013 is also the key of 'userid_profile.txt' (follow the link to the original KDD Cup page, track 2). 0 is a special value denoting that the user could be identified.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1220_click_prediction_small_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "click"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1220-click-prediction-small"}, "LL0_1245_lungcancer_shedden": {"pipeline": {"_id": "e7d3d5df-f5f8-4a0b-ad88-d48937a6723c", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 30}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 16, "min_samples_split": 0.020546225376457655, "min_samples_leaf": 0.026202442513306917, "n_estimators": 484}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "e7d3d5df-f5f8-4a0b-ad88-d48937a6723c", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 6.8449536305521175, "rank": 6.844953630552979, "metric": "meanSquaredError", "ts": "2018-10-24T20:38:56.509000", "dataset": "LL0_1245_lungcancer_shedden_dataset_TRAIN", "test_id": "20181024201213536304"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1245_lungcancer_shedden", "about": {"problemID": "LL0_1245_lungcancer_shedden_problem", "problemName": "lungcancer_shedden_problem", "problemDescription": "**Author**: Kerby Shedden et al.  \nMichel Lang  \n**Source**: Unknown - Date unknown  \n**Please cite**: Shedden, K., Taylor, J. M. G., Enkemann, S. A., Tsao, M. S., Yeatman, T. J., Gerald, W. L., \u2026 Sharma, A. (2008). Gene Expression-Based Survival Prediction in Lung Adenocarcinoma: A Multi-Site, Blinded Validation Study: Director\u2019s Challenge Consortium for the Molecular Classification of Lung Adenocarcinoma. Nature Medicine, 14(8), 822\u2013827. doi:10.1038/nm.1790\n\nfRMA-normalized. Only \"Kratz-genes\"*.\n\n\\* (see: A practical molecular assay to predict survival in resected non-squamous, non-small-cell lung cancer: development and international validation studies\nKratz, Johannes R et al.\nThe Lancet , Volume 379 , Issue 9818 , 823 - 832)", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1245_lungcancer_shedden_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "OS_years"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1245-lungcancer-shedden"}, "LL0_12_mfeat_factors": {"pipeline": {"_id": "38680559-88c2-4497-9607-7c109ffc2a37", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 45}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 648, "max_depth": 9, "learning_rate": 0.4382508392965393, "gamma": 0.25733266144121714, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "38680559-88c2-4497-9607-7c109ffc2a37", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9673159665300932, "rank": 0.03268403347089854, "metric": "f1Macro", "ts": "2018-10-25T00:58:01.695000", "dataset": "LL0_12_mfeat_factors_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_12_mfeat_factors", "about": {"problemID": "LL0_12_mfeat_factors_problem", "problemName": "LL0_12_mfeat_factors_problem", "problemDescription": "**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**Multiple Features Dataset: Factors**  \nOne of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. \n\n### Attribute Information  \nThe attributes represent 216 profile correlations. No more information is known.\n\n### Relevant Papers  \nA slightly different version of the database is used in  \nM. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.\n \nThe database as is is used in:  \nA.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_12_mfeat_factors_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 217, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-12-mfeat-factors"}, "LL0_13_breast_cancer": {"pipeline": {"_id": "d78ffa22-a65f-4120-8751-59bb6edb34b4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 58}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 18, "min_samples_split": 0.4747147752053658, "min_samples_leaf": 0.07257290699509819, "n_estimators": 195, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "d78ffa22-a65f-4120-8751-59bb6edb34b4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6571763811635934, "rank": 0.34282361883656726, "metric": "f1Macro", "ts": "2018-10-25T05:59:42.699000", "dataset": "LL0_13_breast_cancer_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_13_breast_cancer", "about": {"problemID": "LL0_13_breast_cancer_problem", "problemName": "breast_cancer_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nCitation Request:\n    This breast cancer domain was obtained from the University Medical Centre,\n    Institute of Oncology, Ljubljana, Yugoslavia.  Thanks go to M. Zwitter and \n    M. Soklic for providing the data.  Please include this citation if you plan\n    to use this database.\n \n 1. Title: Breast cancer data (Michalski has used this)\n \n 2. Sources: \n    -- Matjaz Zwitter & Milan Soklic (physicians)\n       Institute of Oncology \n       University Medical Center\n       Ljubljana, Yugoslavia\n    -- Donors: Ming Tan and Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n    -- Date: 11 July 1988\n \n 3. Past Usage: (Several: here are some)\n      -- Michalski,R.S., Mozetic,I., Hong,J., & Lavrac,N. (1986). The \n         Multi-Purpose Incremental Learning System AQ15 and its Testing \n         Application to Three Medical Domains.  In Proceedings of the \n         Fifth National Conference on Artificial Intelligence, 1041-1045,\n         Philadelphia, PA: Morgan Kaufmann.\n         -- accuracy range: 66%-72%\n      -- Clark,P. & Niblett,T. (1987). Induction in Noisy Domains.  In \n         Progress in Machine Learning (from the Proceedings of the 2nd\n         European Working Session on Learning), 11-30, Bled, \n         Yugoslavia: Sigma Press.\n         -- 8 test results given: 65%-72% accuracy range\n      -- Tan, M., & Eshelman, L. (1988). Using weighted networks to \n         represent classification knowledge in noisy domains.  Proceedings \n         of the Fifth International Conference on Machine Learning, 121-134,\n         Ann Arbor, MI.\n         -- 4 systems tested: accuracy range was 68%-73.5%\n     -- Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A\n        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko\n        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.\n        -- Assistant-86: 78% accuracy\n \n 4. Relevant Information:\n      This is one of three domains provided by the Oncology Institute\n      that has repeatedly appeared in the machine learning literature.\n      (See also lymphography and primary-tumor.)\n \n      This data set includes 201 instances of one class and 85 instances of\n      another class.  The instances are described by 9 attributes, some of\n      which are linear and some are nominal.\n \n 5. Number of Instances: 286\n \n 6. Number of Attributes: 9 + the class attribute\n \n 7. Attribute Information:\n    1. Class: no-recurrence-events, recurrence-events\n    2. age: 10-19, 20-29, 30-39, 40-49, 50-59, 60-69, 70-79, 80-89, 90-99.\n    3. menopause: lt40, ge40, premeno.\n    4. tumor-size: 0-4, 5-9, 10-14, 15-19, 20-24, 25-29, 30-34, 35-39, 40-44,\n                   45-49, 50-54, 55-59.\n    5. inv-nodes: 0-2, 3-5, 6-8, 9-11, 12-14, 15-17, 18-20, 21-23, 24-26,\n                  27-29, 30-32, 33-35, 36-39.\n    6. node-caps: yes, no.\n    7. deg-malig: 1, 2, 3.\n    8. breast: left, right.\n    9. breast-quad: left-up, left-low, right-up, right-low, central.\n   10. irradiat: yes, no.\n \n 8. Missing Attribute Values: (denoted by \"?\")\n    Attribute #:  Number of instances with missing values:\n    6.             8\n    9.             1.\n \n 9. Class Distribution:\n     1. no-recurrence-events: 201 instances\n     2. recurrence-events: 85 instances\n\n Num Instances:     286\n Num Attributes:    10\n Num Continuous:    0 (Int 0 / Real 0)\n Num Discrete:      10\n Missing values:    9 /  0.3%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 'age'                     Enum 100%   0%   0%     0 /  0%     6 /  2%   0% \n   2 'menopause'               Enum 100%   0%   0%     0 /  0%     3 /  1%   0% \n   3 'tumor-size'              Enum 100%   0%   0%     0 /  0%    11 /  4%   0% \n   4 'inv-nodes'               Enum 100%   0%   0%     0 /  0%     7 /  2%   0% \n   5 'node-caps'               Enum  97%   0%   0%     8 /  3%     2 /  1%   0% \n   6 'deg-malig'               Enum 100%   0%   0%     0 /  0%     3 /  1%   0% \n   7 'breast'                  Enum 100%   0%   0%     0 /  0%     2 /  1%   0% \n   8 'breast-quad'             Enum 100%   0%   0%     1 /  0%     5 /  2%   0% \n   9 'irradiat'                Enum 100%   0%   0%     0 /  0%     2 /  1%   0% \n  10 'Class'                   Enum 100%   0%   0%     0 /  0%     2 /  1%   0%", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_13_breast_cancer_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-13-breast-cancer"}, "LL0_1435_fourclass": {"pipeline": {"_id": "4b87d083-ad35-4456-bfcd-c5bc4d3b7790", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 487, "max_depth": 5, "learning_rate": 0.016645299220841014, "gamma": 0.010134972123397534, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "4b87d083-ad35-4456-bfcd-c5bc4d3b7790", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.02966623284525377, "rank": 0.029666232845802082, "metric": "meanSquaredError", "ts": "2018-10-24T21:12:57.815000", "dataset": "LL0_1435_fourclass_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1435_fourclass", "about": {"problemID": "LL0_1435_fourclass_problem", "problemName": "fourclass_problem", "problemDescription": "**Author**: Tin Kam Ho and Eugene M. Kleinberg.  \n**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  \n**Please cite**: Tin Kam Ho and Eugene M. Kleinberg.\nBuilding projectable classifiers of arbitrary complexity.\nIn Proceedings of the 13th International Conference on Pattern Recognition, pages 880-885, Vienna, Austria, August 1996.  \n\n#Dataset from the LIBSVM data repository.\n\nPreprocessing: transform to two-class", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1435_fourclass_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1435-fourclass"}, "LL0_1442_MegaWatt1": {"pipeline": {"_id": "55e628d9-b494-405e-8d1d-326cb8a2300b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 32}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 13, "min_samples_split": 0.14458107070904017, "min_samples_leaf": 0.02386611280129273, "n_estimators": 115, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "55e628d9-b494-405e-8d1d-326cb8a2300b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7074730929447911, "rank": 0.2925269070556526, "metric": "f1Macro", "ts": "2018-10-25T05:25:56.788000", "dataset": "LL0_1442_MegaWatt1_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1442_MegaWatt1", "about": {"problemID": "LL0_1442_MegaWatt1_problem", "problemName": "MegaWatt1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nMega watt", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1442_MegaWatt1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1442-MegaWatt1"}, "LL0_1443_pizzacutter1": {"pipeline": {"_id": "1b74a3c4-6669-4702-b714-c6f2d790778d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 3}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 78, "max_depth": 6, "learning_rate": 0.6808486147384117, "gamma": 0.501367932261173, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "1b74a3c4-6669-4702-b714-c6f2d790778d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7293754207027718, "rank": 0.2706245792977329, "metric": "f1Macro", "ts": "2018-10-24T23:59:44.165000", "dataset": "LL0_1443_pizzacutter1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1443_pizzacutter1", "about": {"problemID": "LL0_1443_pizzacutter1_problem", "problemName": "LL0_1443_pizzacutter1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nPizza cutter", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1443_pizzacutter1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1443-pizzacutter1"}, "LL0_1446_CostaMadre1": {"pipeline": {"_id": "d9b0aa15-265a-4cbc-96df-d7de9045c94e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 121, "max_depth": 10, "learning_rate": 0.9638634415748741, "gamma": 0.4233161613201809, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d9b0aa15-265a-4cbc-96df-d7de9045c94e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6597610379835444, "rank": 0.34023896201684695, "metric": "f1Macro", "ts": "2018-10-25T01:29:52.790000", "dataset": "LL0_1446_CostaMadre1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1446_CostaMadre1", "about": {"problemID": "LL0_1446_CostaMadre1_problem", "problemName": "CostaMadre1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nCosta madre 1", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1446_CostaMadre1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1446-CostaMadre1"}, "LL0_1447_castmetal1": {"pipeline": {"_id": "d33913d6-dfb8-48ae-90f5-54646ac41742", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 18}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 504, "max_depth": 5, "learning_rate": 0.6916478784301425, "gamma": 0.03504861032879325, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d33913d6-dfb8-48ae-90f5-54646ac41742", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7237548179011594, "rank": 0.27624518209958754, "metric": "f1Macro", "ts": "2018-10-25T01:07:41.386000", "dataset": "LL0_1447_castmetal1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1447_castmetal1", "about": {"problemID": "LL0_1447_castmetal1_problem", "problemName": "LL0_1447_castmetal1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\ncast metal 1", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1447_castmetal1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1447-castmetal1"}, "LL0_1449_MeanWhile1": {"pipeline": {"_id": "66dbccce-0597-4740-97cf-eec44a057533", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 55}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 23, "min_samples_split": 0.053178008740840936, "min_samples_leaf": 0.036867510266447016, "n_estimators": 83, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "66dbccce-0597-4740-97cf-eec44a057533", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7226573771956095, "rank": 0.27734262280517397, "metric": "f1Macro", "ts": "2018-10-25T05:25:31.108000", "dataset": "LL0_1449_MeanWhile1_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1449_MeanWhile1", "about": {"problemID": "LL0_1449_MeanWhile1_problem", "problemName": "MeanWhile1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nMean While 1", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1449_MeanWhile1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1449-MeanWhile1"}, "LL0_1451_piechart1": {"pipeline": {"_id": "f71d9d93-942c-4c0e-8839-be25add14728", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 232, "max_depth": 7, "learning_rate": 0.7232952148947142, "gamma": 0.9676416014162713, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f71d9d93-942c-4c0e-8839-be25add14728", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7272036776946146, "rank": 0.2727963223056787, "metric": "f1Macro", "ts": "2018-10-25T00:04:25.995000", "dataset": "LL0_1451_piechart1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1451_piechart1", "about": {"problemID": "LL0_1451_piechart1_problem", "problemName": "LL0_1451_piechart1_problem", "problemDescription": "**Author**: Hans Bauer Jesus\",\"Deter Bergman  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\npie chart 1", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1451_piechart1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 38, "colName": "def"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1451-piechart1"}, "LL0_1459_artificial_characters": {"pipeline": {"_id": "f1a5ab76-8d9f-405a-96c2-65123901d571", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 495, "max_depth": 4, "learning_rate": 0.7758392748851672, "gamma": 0.08783564526463539, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "f1a5ab76-8d9f-405a-96c2-65123901d571", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9089765033890076, "rank": 0.09102349661126949, "metric": "f1Macro", "ts": "2018-10-31T04:34:24.268000", "dataset": "LL0_1459_artificial_characters_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1459_artificial_characters", "about": {"problemID": "LL0_1459_artificial_characters_problem", "problemName": "LL0_1459_artificial_characters_problem", "problemDescription": "**Author**: H. Altay Guvenir, Burak Acar, Haldun Muderrisoglu    \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Artificial+Characters) - 1992  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\nThis database has been artificially generated. It describes the structure of the capital letters A, C, D, E, F, G, H, L, P, R, indicated by a number 1-10, in that order (A=1,C=2,...). Each letter's structure is described by a set of segments (lines) which resemble the way an automatic program would segment an image. The dataset consists of 600 such descriptions per letter. \n\nOriginally, each 'instance' (letter) was stored in a separate file, each consisting of between 1 and 7 segments, numbered 0,1,2,3,... Here they are merged. That means that the first 5 instances describe the first 5 segments of the first segmentation of the first letter (A). Also, the training set (100 examples) and test set (the rest) are merged. The next 7 instances describe another segmentation (also of the letter A) and so on.\n\n### Attribute Information  \n\n* V1: object number, the number of the segment (0,1,2,..,7)  \n* V2-V5: the initial and final coordinates of a segment in a cartesian plane (XX1,YY1,XX2,YY2).  \n* V6: size, this is the length of a segment computed by using the geometric distance between two points A(X1,Y1) and B(X2,Y2).\n* V7: diagonal, this is the length of the diagonal of the smallest rectangle which includes the picture of the character. The value of this attribute is the same in each object.\n\n### Relevant Papers  \n\nM. Botta, A. Giordana, L. Saitta: \"Learning Fuzzy Concept Definitions\", IEEE-Fuzzy Conference, 1993.  \nM. Botta, A. Giordana: \"Learning Quantitative Feature in a Symbolic Environment\", LNAI 542, 1991, pp. 296-305.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1459_artificial_characters_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1459-artificial-characters"}, "LL0_1460_banana": {"pipeline": {"_id": "8071909c-5b28-4e64-a08c-44b8adfef4d3", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 559, "max_depth": 4, "learning_rate": 0.48417905990622534, "gamma": 0.6581254533283819, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "8071909c-5b28-4e64-a08c-44b8adfef4d3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9031384297563925, "rank": 0.09686157024397843, "metric": "f1Macro", "ts": "2018-10-31T04:09:26.932000", "dataset": "LL0_1460_banana_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1460_banana", "about": {"problemID": "LL0_1460_banana_problem", "problemName": "LL0_1460_banana_problem", "problemDescription": "**Author**:   \n**Source**: KEEL\n**Please cite**:   \n\nAn artificial data set where instances belongs to several clusters with a banana shape. There are two attributes At1 and At2 corresponding to the x and y axis, respectively. The class label (-1 and 1) represents one of the two banana shapes in the dataset.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1460_banana_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1460-banana"}, "LL0_1462_banknote_authentication": {"pipeline": {"_id": "7114529d-a47c-4d76-b564-1afed6930a73", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 10}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 104, "max_depth": 4, "learning_rate": 0.5305594797447611, "gamma": 0.06050834124691373, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "7114529d-a47c-4d76-b564-1afed6930a73", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9981546730753079, "rank": 0.0018453269256114176, "metric": "f1Macro", "ts": "2018-10-25T00:03:36.600000", "dataset": "LL0_1462_banknote_authentication_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1462_banknote_authentication", "about": {"problemID": "LL0_1462_banknote_authentication_problem", "problemName": "LL0_1462_banknote_authentication_problem", "problemDescription": "Author: Volker Lohweg (University of Applied Sciences, Ostwestfalen-Lippe)  \nSource: [UCI](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) - 2012  \nPlease cite: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html) \n\nDataset about distinguishing genuine and forged banknotes. Data were extracted from images that were taken from genuine and forged banknote-like specimens. For digitization, an industrial camera usually used for print inspection was used. The final images have 400x 400 pixels. Due to the object lens and distance to the investigated object gray-scale pictures with a resolution of about 660 dpi were gained. A Wavelet Transform tool was used to extract features from these images.\n\n### Attribute Information  \n\nV1. variance of Wavelet Transformed image (continuous)  \nV2. skewness of Wavelet Transformed image (continuous)  \nV3. curtosis of Wavelet Transformed image (continuous)  \nV4. entropy of image (continuous)  \n\nClass (target). Presumably 1 for genuine and 2 for forged", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1462_banknote_authentication_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1462-banknote-authentication"}, "LL0_1464_blood_transfusion_service_center": {"pipeline": {"_id": "2491c3f1-bf78-4dd9-bc24-8e926d054d48", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 95}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 709, "max_depth": 4, "learning_rate": 0.8676838347896283, "gamma": 0.9751334069760365, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "2491c3f1-bf78-4dd9-bc24-8e926d054d48", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6705744228880268, "rank": 0.3294255771124541, "metric": "f1Macro", "ts": "2018-10-25T01:09:15.160000", "dataset": "LL0_1464_blood_transfusion_service_center_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1464_blood_transfusion_service_center", "about": {"problemID": "LL0_1464_blood_transfusion_service_center_problem", "problemName": "LL0_1464_blood_transfusion_service_center_problem", "problemDescription": "**Author**: Prof. I-Cheng Yeh  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Blood+Transfusion+Service+Center)  \n**Please cite**: Yeh, I-Cheng, Yang, King-Jang, and Ting, Tao-Ming, \"Knowledge discovery on RFM model using Bernoulli sequence\", Expert Systems with Applications, 2008.   \n\n**Blood Transfusion Service Center Data Set**  \nData taken from the Blood Transfusion Service Center in Hsin-Chu City in Taiwan -- this is a classification problem.\n\nTo demonstrate the RFMTC marketing model (a modified version of RFM), this study adopted the donor database of Blood Transfusion Service Center in Hsin-Chu City in Taiwan. The center passes their blood transfusion service bus to one university in Hsin-Chu City to gather blood donated about every three months. To build an FRMTC model, we selected 748 donors at random from the donor database. \n\n### Attribute Information  \n* V1: Recency - months since last donation\n* V2: Frequency - total number of donation\n* V3: Monetary - total blood donated in c.c.\n* V4: Time - months since first donation), and a binary variable representing whether he/she donated blood in March 2007 (1 stand for donating blood; 0 stands for not donating blood).\n\nThe target attribute is a binary variable representing whether he/she donated blood in March 2007 (2 stands for donating blood; 1 stands for not donating blood).", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1464_blood_transfusion_service_center_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1464-blood-transfusion-service-center"}, "LL0_1466_cardiotocography": {"pipeline": {"_id": "ea74f0f4-0933-462d-a1f2-fd914bd3fd4d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 31}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 867, "max_depth": 5, "learning_rate": 0.32939875308433597, "gamma": 0.9946768602063646, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "ea74f0f4-0933-462d-a1f2-fd914bd3fd4d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 4.706129417291205e-16, "metric": "f1Macro", "ts": "2018-10-25T00:12:01.899000", "dataset": "LL0_1466_cardiotocography_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1466_cardiotocography", "about": {"problemID": "LL0_1466_cardiotocography_problem", "problemName": "LL0_1466_cardiotocography_problem", "problemDescription": "**Author**: J. P. Marques de S\u00e1, J. Bernardes, D. Ayers de Campos.  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Cardiotocography)  \n**Please cite**: Ayres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318, [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n\n2126 fetal cardiotocograms (CTGs) were automatically processed and the respective diagnostic features measured. The CTGs were also classified by three expert obstetricians and a consensus classification label assigned to each of them. Classification was both with respect to a morphologic pattern (A, B, C. ...) and to a fetal state (N, S, P). Therefore the dataset can be used either for 10-class or 3-class experiments.\n\n### Attribute Information:  \nLB - FHR baseline (beats per minute)  \nAC - # of accelerations per second  \nFM - # of fetal movements per second  \nUC - # of uterine contractions per second  \nDL - # of light decelerations per second  \nDS - # of severe decelerations per second  \nDP - # of prolongued decelerations per second  \nASTV - percentage of time with abnormal short term variability  \nMSTV - mean value of short term variability  \nALTV - percentage of time with abnormal long term variability  \nMLTV - mean value of long term variability  \nWidth - width of FHR histogram  \nMin - minimum of FHR histogram  \nMax - Maximum of FHR histogram  \nNmax - # of histogram peaks  \nNzeros - # of histogram zeros  \nMode - histogram mode  \nMean - histogram mean  \nMedian - histogram median  \nVariance - histogram variance  \nTendency - histogram tendency  \nCLASS - FHR pattern class code (1 to 10)  \nNSP - fetal state class code (N=normal; S=suspect; P=pathologic)  \n\n### Relevant Papers:\nAyres de Campos et al. (2000) SisPorto 2.0 A Program for Automated Analysis of Cardiotocograms. J Matern Fetal Med 5:311-318", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1466_cardiotocography_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 36, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1466-cardiotocography"}, "LL0_1467_climate_model_simulation_crashes": {"pipeline": {"_id": "f29130f5-1124-4d4b-aa23-cf996b5c25d0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 15}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 23, "min_samples_split": 0.01637193106429882, "min_samples_leaf": 0.02721011003307278, "n_estimators": 337, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "f29130f5-1124-4d4b-aa23-cf996b5c25d0", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7405201707449284, "rank": 0.25947982925522306, "metric": "f1Macro", "ts": "2018-10-25T04:48:29.248000", "dataset": "LL0_1467_climate_model_simulation_crashes_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1467_climate_model_simulation_crashes", "about": {"problemID": "LL0_1467_climate_model_simulation_crashes_problem", "problemName": "LL0_1467_climate_model_simulation_crashes_problem", "problemDescription": "**Author**: D. Lucas, R. Klein, J. Tannahill, D. Ivanova, S. Brandon, D. Domyancic, Y. Zhang.\n\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/climate+model+simulation+crashes)\n\n**Please Cite**:\nLucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link](http://www.geosci-model-dev-discuss.net/6/585/2013/gmdd-6-585-2013.html), 2013.\n\n\nSource:\n\nD. Lucas (ddlucas .at. alum.mit.edu), Lawrence Livermore National Laboratory; R. Klein (rklein .at. astron.berkeley.edu), Lawrence Livermore National Laboratory & U.C. Berkeley; J. Tannahill (tannahill1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Ivanova (ivanova2 .at. llnl.gov), Lawrence Livermore National Laboratory; S. Brandon (brandon1 .at. llnl.gov), Lawrence Livermore National Laboratory; D. Domyancic (domyancic1 .at. llnl.gov), Lawrence Livermore National Laboratory; Y. Zhang (zhang24 .at. llnl.gov), Lawrence Livermore National Laboratory .\n\nThis data was constructed using LLNL's UQ Pipeline, was created under the auspices of the US Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344, was funded by LLNL's Uncertainty Quantification Strategic Initiative Laboratory Directed Research and Development Project under tracking code 10-SI-013, and is released under UCRL number LLNL-MISC-633994.\n\n\nData Set Information:\n\nThis dataset contains records of simulation crashes encountered during climate model uncertainty quantification (UQ) ensembles. Ensemble members were constructed using a Latin hypercube method in LLNL's UQ Pipeline software system to sample the uncertainties of 18 model parameters within the Parallel Ocean Program (POP2) component of the Community Climate System Model (CCSM4). Three separate Latin hypercube ensembles were conducted, each containing 180 ensemble members. 46 out of the 540 simulations failed for numerical reasons at combinations of parameter values. The goal is to use classification to predict simulation outcomes (fail or succeed) from input parameter values, and to use sensitivity analysis and feature selection to determine the causes of simulation crashes. Further details about the data and methods are given in the publication 'Failure Analysis of Parameter-Induced Simulation Crashes in Climate Models,' Geoscientific Model Development [(Web Link)](doi:10.5194/gmdd-6-585-2013).\n\n\nAttribute Information:\n\nThe goal is to predict climate model simulation outcomes (column 21, fail or succeed) given scaled values of climate model input parameters (columns 3-20). \n\n- Column 1: Latin hypercube study ID (study 1 to study 3) \n\n- Column 2: simulation ID (run 1 to run 180) \n\n- Columns 3-20: values of 18 climate model parameters scaled in the interval [0, 1] \n\n- Column 21: simulation outcome (0 = failure, 1 = success)\n\nRelevant Papers:\n\nLucas, D. D., Klein, R., Tannahill, J., Ivanova, D., Brandon, S., Domyancic, D., and Zhang, Y.: Failure analysis of parameter-induced simulation crashes in climate models, Geosci. Model Dev. Discuss., 6, 585-623, [Web Link](http://www.geosci-model-dev-discuss.net/6/585/2013/gmdd-6-585-2013.html), 2013.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1467_climate_model_simulation_crashes_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1467-climate-model-simulation-crashes"}, "LL0_1468_cnae_9": {"pipeline": {"_id": "2c248093-4088-49e1-8adc-418b462e2554", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 34}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 274, "max_depth": 5, "learning_rate": 0.8572723832129601, "gamma": 0.34873527163065554, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "2c248093-4088-49e1-8adc-418b462e2554", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9170634810172679, "rank": 0.0829365189831045, "metric": "f1Macro", "ts": "2018-10-25T01:49:22.347000", "dataset": "LL0_1468_cnae_9_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1468_cnae_9", "about": {"problemID": "LL0_1468_cnae_9_problem", "problemName": "LL0_1468_cnae_9_problem", "problemDescription": "**Author**: Patrick Marques Ciarelli, Elias Oliviera   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/CNAE-9) - 2010  \n**Please cite**:   \n\n### Description\n\nThis is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a subset of 9 categories.\n\n### Source\n```\nPatrick Marques Ciarelli, pciarelli '@' lcad.inf.ufes.br, Department of Electrical Engineering, Federal University of Espirito Santo \nElias Oliveira, elias '@' lcad.inf.ufes.br, Department of Information Science, Federal University of Espirito Santo\n```\n\n### Data Set Information\n\nThis is a data set containing 1080 documents of free text business descriptions of Brazilian companies categorized into a \nsubset of 9 categories cataloged in a table called National Classification of Economic Activities (Classifica\u00e7\u00e3o Nacional de \nAtividade Econ\u00f4micas - CNAE). The original texts were preprocessed to obtain the current data set: initially, it was kept only letters and then it was removed prepositions of the texts. Next, the words were transformed to their canonical form. Finally, \neach document was represented as a vector, where the weight of each word is its frequency in the document. \nThis data set is highly sparse (99.22% of the matrix is filled with zeros).\n\n### Attribute Information\n\nIn the dataset there are 857 attributes, 1 attributes with the class of instance and 856 with word frequency:\n ```\n1. category: range 1 - 9 (integer)   \n2. 857. word frequency: (integer)\n```\n\n### Relevant Papers\n\nPatrick Marques Ciarelli, Elias Oliveira, 'Agglomeration and Elimination of Terms for Dimensionality Reduction', \nNinth International Conference on Intelligent Systems Design and Applications, pp.547-552, 2009 \n\nPatrick Marques Ciarelli, Elias Oliveira, Evandro O. T. Salles, 'An Evolving System Based on Probabilistic Neural Network', \nBrazilian Symposium on Artificial Neural Network, 2010", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1468_cnae_9_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 857, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1468-cnae-9"}, "LL0_1470_dresses_sales": {"pipeline": {"_id": "6bc0134d-9a4b-4acb-80f1-7510ef194b6d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 21}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 15, "min_samples_split": 0.2892891766387222, "min_samples_leaf": 0.00898936303454971, "n_estimators": 339, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "6bc0134d-9a4b-4acb-80f1-7510ef194b6d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6240763326930034, "rank": 0.37592366730718274, "metric": "f1Macro", "ts": "2018-10-25T06:06:43.551000", "dataset": "LL0_1470_dresses_sales_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1470_dresses_sales", "about": {"problemID": "LL0_1470_dresses_sales_problem", "problemName": "LL0_1470_dresses_sales_problem", "problemDescription": "**Author**: Muhammad Usman, Adeel Ahmed  \n**Source**: UCI \n\n**Please cite**:   \n\nSource:\n\nMuhammad Usman & Adeel Ahmed, usman.madspot '@' gmail.com adeel.ahmed92 '@' gmail.com, Air University, Students at Air University.\n\n\nData Set Information:\n\nStyle, Price, Rating, Size, Season, NeckLine, SleeveLength, waiseline, Material,  FabricType, Decoration, Pattern, Type, Recommendation are Attributes in dataset. \n\n\nAttribute Information:\n\nStyle: Bohemia,brief,casual,cute,fashion,flare,novelty,OL,party,sexy,vintage,work. \nPrice:Low,Average,Medium,High,Very-High \nRating:1-5 \nSize:S,M,L,XL,Free \nSeason:Autumn,winter,Spring,Summer \nNeckLine:O-neck,backless,board-neck,Bowneck,halter,mandarin-collor,open,peterpan-collor,ruffled,scoop,slash-neck,square-collar,sweetheart,turndowncollar,V-neck. \nSleeveLength:full,half,halfsleeves,butterfly,sleveless,short,threequarter,turndown,null \nwaiseline:dropped,empire,natural,princess,null. \nMaterial:wool,cotton,mix etc \nFabricType:shafoon,dobby,popline,satin,knitted,jersey,flannel,corduroy etc \nDecoration:applique,beading,bow,button,cascading,crystal,draped,embroridary,feathers,flowers etc \nPattern type: solid,animal,dot,leapard etc \nRecommendation:0,1", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1470_dresses_sales_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1470-dresses-sales"}, "LL0_1471_eeg_eye_state": {"pipeline": {"_id": "3da5fafa-746c-499a-801c-419da97e0032", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 68}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 504, "max_depth": 10, "learning_rate": 0.18381233695862165, "gamma": 0.004645232180811254, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "3da5fafa-746c-499a-801c-419da97e0032", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9461483981376636, "rank": 0.05385160186254133, "metric": "f1Macro", "ts": "2018-10-25T01:29:21.471000", "dataset": "LL0_1471_eeg_eye_state_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1471_eeg_eye_state", "about": {"problemID": "LL0_1471_eeg_eye_state_problem", "problemName": "LL0_1471_eeg_eye_state_problem", "problemDescription": "**Author**: Oliver Roesler  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State), Baden-Wuerttemberg, Cooperative State University (DHBW), Stuttgart, Germany  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\nAll data is from one continuous EEG measurement with the Emotiv EEG Neuroheadset. The duration of the measurement was 117 seconds. The eye state was detected via a camera during the EEG measurement and added later manually to the file after analyzing the video frames. '1' indicates the eye-closed and '0' the eye-open state. All values are in chronological order with the first measured value at the top of the data.\n\nThe features correspond to 14 EEG measurements from the headset, originally labeled AF3, F7, F3, FC5, T7, P, O1, O2, P8, T8, FC6, F4, F8, AF4, in that order.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1471_eeg_eye_state_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 15, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1471-eeg-eye-state"}, "LL0_1475_first_order_theorem_proving": {"pipeline": {"_id": "35f42e64-6893-4ec4-8e03-b4f6ef9a5187", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 302, "max_depth": 8, "learning_rate": 0.2474333142498093, "gamma": 0.24280694395254387, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "35f42e64-6893-4ec4-8e03-b4f6ef9a5187", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5124056921439243, "rank": 0.48759430785628777, "metric": "f1Macro", "ts": "2018-10-31T05:30:42.432000", "dataset": "LL0_1475_first_order_theorem_proving_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1475_first_order_theorem_proving", "about": {"problemID": "LL0_1475_first_order_theorem_proving_problem", "problemName": "LL0_1475_first_order_theorem_proving_problem", "problemDescription": "**Author**: James P Bridge, Sean B Holden and Lawrence C Paulson \n  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/First-order+theorem+proving)  \n\n**Please cite**: James P Bridge, Sean B Holden and Lawrence C Paulson . Machine learning for first-order theorem proving: learning to select a good heuristic. Journal of Automated Reasoning, Springer 2012/13. \n\nSource:\n\nJames P Bridge, Sean B Holden and Lawrence C Paulson \n\nUniversity of Cambridge \nComputer Laboratory \nWilliam Gates Building \n15 JJ Thomson Avenue \nCambridge CB3 0FD \nUK \n\n+44 (0)1223 763500 \nforename.surname '@' cl.cam.ac.uk\n\n\nData Set Information:\n\nSee the file dataset file.\n\n\nAttribute Information:\n\nThe attributes are a mixture of static and dynamic features derived from theorems to be proved. See the paper for full details.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1475_first_order_theorem_proving_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 52, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1475-first-order-theorem-proving"}, "LL0_1476_gas_drift": {"pipeline": {"_id": "a4eadb01-9d55-4f21-af4f-96b2e3d13b59", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "a4eadb01-9d55-4f21-af4f-96b2e3d13b59", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9932710750706457, "rank": 0.006728924929855013, "metric": "f1Macro", "ts": "2018-10-31T04:18:14.049000", "dataset": "LL0_1476_gas_drift_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1476_gas_drift", "about": {"problemID": "LL0_1476_gas_drift_problem", "problemName": "LL0_1476_gas_drift_problem", "problemDescription": "**Author**: Alexander Vergara  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/gas+sensor+array+drift+dataset) - 2012    \n**Please cite**: Alexander Vergara, Shankar Vembu, Tuba Ayhan, Margaret A. Ryan, Margie L. Homer, Ram\u00f3n Huerta. Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074.   \n\n### Description\nGas Sensor Array Drift Dataset Data Set\n\n### Sources\n```\n(a) Creators: Alexander Vergara (vergara '@' ucsd.edu) \nBioCircutis Institute \nUniversity of California San Diego \nSan Diego, California, USA \n\n(b) Donors: Alexander Vergara (vergara '@' ucsd.edu) \nRamon Huerta (rhuerta '@' ucsd.edu) \n```\n\n### Dataset Information\n\nThis archive contains 13910 measurements from 16 chemical sensors utilized in simulations for drift compensation in a discrimination task of 6 gases at various levels of concentrations.  \nThe goal is to achieve good performance (or as low degradation as possible) over time, as reported in the paper mentioned below in Section 2: Data collection. \n\nThe primary purpose of providing this dataset is to make it freely accessible online to the chemo-sensor research community and artificial intelligence to develop strategies to cope with sensor/concept drift. The dataset can be used exclusively for research purposes. Commercial purposes are fully excluded.\n\nThe dataset was gathered within January 2007 to February 2011 (36 months) in a gas delivery platform facility situated at the ChemoSignals Laboratory in the BioCircuits Institute, University of California San Diego. \n\nBeing completely operated by a fully computerized environment controlled by a LabVIEW's National Instruments software on a PC fitted with the appropriate serial data acquisition boards. The measurement system platform provides versatility for obtaining the desired concentrations of the chemical substances of interest with high accuracy and in a highly reproducible manner, minimizing thereby the common mistakes caused by human intervention and making it possible to exclusively concentrate on the chemical sensors for compensating real drift.\n\nThe resulting dataset comprises recordings from six distinct pure gaseous substances, namely Ammonia, Acetaldehyde, Acetone, Ethylene, Ethanol, and Toluene, each dosed at a wide variety of concentration values ranging from 5 to 1000 ppmv. An extension of this dataset with the concentration values is available at [Gas Sensor Array Drift Dataset at Different Concentrations Data Set](http://archive.ics.uci.edu/ml/datasets/Gas+Sensor+Array+Drift+Dataset+at+Different+Concentrations).\n\n\n### Attribute Information\n\nThe response of the said sensors is read-out in the form of the resistance across the active layer of each sensor. Hence each measurement produced a 16-channel time series, each of which represented by an aggregate of features reflecting all the dynamic processes occurring at the sensor surface in reaction to the chemical substance being evaluated. \n\nIn particular, two distinct types of features were considered in the creation of this dataset: \n(i) The so-called steady-state feature (\u00ce\u201dR), defined as the difference of the maximal resistance change and the baseline and its normalized version expressed by the ratio of the maximal resistance and the baseline values when the chemical vapor is present in the test chamber; and \n(ii) an aggregate of features reflecting the sensor dynamics of the increasing/decaying transient portion of the sensor response during the entire measurement procedure under controlled conditions, namely the exponential moving average (ema\u00ce\u00b1). These aggregate of features is a transform, borrowed from the field of econometrics originally introduced to the chemo-sensing community by Muezzinoglu et al. (2009), that converts the said transient portion into a real scalar, by estimating the maximum value \u00e2\u20ac\u201dminimum for the decaying portion of the sensor response\u00e2\u20ac\u201d of its exponential moving average (ema\u00ce\u00b1), with an initial condition set to zero and a scalar smoothing parameter of the operator, \u00ce\u00b1, that defines both the quality of the feature and the time of its occurrence along the time series the scalar, set to range between 0 and 1. In particular, three different values for \u00ce\u00b1 were set to obtain three different feature values from the pre-recorded rising portion of the sensor response and three additional features with the same \u00ce\u00b1 values but for the decaying portion of the sensor response, covering thus the entire sensor response dynamics. \n\nFor a more detailed analysis and discussion on these features as well as a graphical illustration of them please refer to Section 2.3 and Figure 2, respectively of the annotated manuscript.\n\nOnce the abovementioned features are calculated, one is to form a feature vector containing the 8 features extracted from each particular sensor multiplied by the 16 sensors considered here. In the end, there is a resulting 128-dimensional feature vector containing all the features indicated above.\n\nThere are six possible classes: \n```\n1: Ethanol \n2: Ethylene  \n3: Ammonia \n4: Acetaldehyde \n5: Acetone \n6: Toluene\n```\n### Relevant Papers\n\nAlexander Vergara, Shankar Vembu, Tuba Ayhan, Margaret A. Ryan, Margie L. Homer and Ram\u00f3n Huerta, Chemical gas sensor drift compensation using classifier ensembles, Sensors and Actuators B: Chemical (2012) doi: 10.1016/j.snb.2012.01.074.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1476_gas_drift_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 129, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1476-gas-drift"}, "LL0_1479_hill_valley": {"pipeline": {"_id": "01ca9495-ff61-444b-94eb-9be95f480a4a", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 66}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 987, "max_depth": 8, "learning_rate": 0.9691629511450297, "gamma": 0.5470277968962701, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "01ca9495-ff61-444b-94eb-9be95f480a4a", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5943658973350684, "rank": 0.40563410266588623, "metric": "f1Macro", "ts": "2018-10-25T01:10:43.257000", "dataset": "LL0_1479_hill_valley_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1479_hill_valley", "about": {"problemID": "LL0_1479_hill_valley_problem", "problemName": "LL0_1479_hill_valley_problem", "problemDescription": "**Author**: Lee Graham, Franz Oppacher  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/hill-valley)  \n**Please cite**:   \n\nEach record represents 100 points on a two-dimensional graph. When plotted in order (from 1 through 100) as the Y coordinate, the points will create either a Hill (a \u201cbump\u201d in the terrain) or a Valley (a \u201cdip\u201d in the terrain). \nSee the original source for some examples of these graphs. \n\nIn the original form, there are six files. This is the non-noisy version, with training and test sets merged. \n\n### Attribute Information:\n\n1-100: Labeled \u201cX##\u201d. Floating point values (numeric), the Y-values of the graphs.  \n101: Labeled \u201cclass\u201d. Binary {0, 1} representing {valley, hill}", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1479_hill_valley_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 101, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1479-hill-valley"}, "LL0_1480_ilpd": {"pipeline": {"_id": "70cfd7f5-af9d-4d9e-9727-fb94c2a713c9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 88}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 517, "max_depth": 6, "learning_rate": 0.2790296103832197, "gamma": 0.5150147838534425, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "70cfd7f5-af9d-4d9e-9727-fb94c2a713c9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6946582887560139, "rank": 0.30534171124431864, "metric": "f1Macro", "ts": "2018-10-24T23:57:51.035000", "dataset": "LL0_1480_ilpd_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1480_ilpd", "about": {"problemID": "LL0_1480_ilpd_problem", "problemName": "LL0_1480_ilpd_problem", "problemDescription": "**Author**: Bendi Venkata Ramana, M. Surendra Prasad Babu, N. B. Venkateswarlu  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ILPD+(Indian+Liver+Patient+Dataset)) - 2012  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**Indian Liver Patient Dataset**  \nThis data set contains 416 liver patient records and 167 non liver patient records.The data set was collected from north east of Andhra Pradesh, India. The class label divides the patients into 2 groups (liver patient or not). This data set contains 441 male patient records and 142 female patient records. \n\n### Attribute Information  \nV1. Age of the patient. Any patient whose age exceeded 89 is listed as being of age \"90\".  \nV2. Gender of the patient  \nV3. Total Bilirubin  \nV4. Direct Bilirubin  \nV5. Alkphos Alkaline Phosphatase  \nV6. Sgpt Alanine Aminotransferase  \nV7. Sgot Aspartate Aminotransferase   \nV8. Total Proteins  \nV9. Albumin  \nV10. A/G Ratio Albumin and Globulin Ratio  \n\nA feature indicating a train-test split has been removed.  \n\n### Relevant Papers  \n1. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, A Critical Comparative Study of Liver Patients from USA and INDIA: An Exploratory Analysis\u009d, International Journal of Computer Science Issues, ISSN:1694-0784, May 2012. \n2. Bendi Venkata Ramana, Prof. M. S. Prasad Babu and Prof. N. B. Venkateswarlu, A Critical Study of Selected Classification Algorithms for Liver Disease Diagnosis, International Journal of Database Management Systems (IJDMS), Vol.3, No.2, ISSN : 0975-5705, PP 101-114, May 2011.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1480_ilpd_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1480-ilpd"}, "LL0_1481_kr_vs_k": {"pipeline": {"_id": "ad6f7a3f-4dd0-4977-812c-c0d56690fd80", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 9}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 983, "max_depth": 10, "learning_rate": 0.030697576360745327, "gamma": 0.14346438404944362, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "ad6f7a3f-4dd0-4977-812c-c0d56690fd80", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8712358627483981, "rank": 0.12876413725251992, "metric": "f1Macro", "ts": "2018-10-25T01:47:08.772000", "dataset": "LL0_1481_kr_vs_k_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1481_kr_vs_k", "about": {"problemID": "LL0_1481_kr_vs_k_problem", "problemName": "LL0_1481_kr_vs_k_problem", "problemDescription": "**Author**:   \n**Source**: KEEL \n**Please cite**:   \n\nAbstract:\n\nA chess endgame data set representing the positions on the board of the white king, the white rook, and the black king. The task is to determine the optimum number of turn required for white to win the game, which can be a draw if it takes more than sixteen turns.\n\nAttributes Details:\n\n\n1. White_king_col {a, b, c, d, e, f, g, h}\n2. White_king_row {1, 2, 3, 4, 5, 6, 7, 8}\n3. White_rook_col {a, b, c, d, e, f, g, h}\n4. White_rook_row {1, 2, 3, 4, 5, 6, 7, 8}\n5. Black_king_col {a, b, c, d, e, f, g, h}\n6. Black_king_row {1, 2, 3, 4, 5, 6, 7, 8}\n7. Class - Game {draw, zero, one, two, three, four, five, six, seven, eight, nine, ten, eleven, twelve, thirteen, fourteen, fifteen, sixteen}", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1481_kr_vs_k_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1481-kr-vs-k"}, "LL0_1485_madelon": {"pipeline": {"_id": "46d4662e-5e01-45d4-be85-5364cc1a8c53", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 864, "max_depth": 8, "learning_rate": 0.05376021674599951, "gamma": 0.43979934718568126, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "46d4662e-5e01-45d4-be85-5364cc1a8c53", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.817764714730625, "rank": 0.18223528526980448, "metric": "f1Macro", "ts": "2018-10-25T01:42:32.143000", "dataset": "LL0_1485_madelon_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1485_madelon", "about": {"problemID": "LL0_1485_madelon_problem", "problemName": "LL0_1485_madelon_problem", "problemDescription": "**Author**: Isabelle Guyon  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/madelon)  \n**Please cite**: Isabelle Guyon, Steve R. Gunn, Asa Ben-Hur, Gideon Dror, 2004. Result analysis of the NIPS 2003 feature selection challenge.\n\n#### Abstract: \n\nMADELON is an artificial dataset, which was part of the NIPS 2003 feature selection challenge. This is a two-class classification problem with continuous input variables. The difficulty is that the problem is multivariate and highly non-linear.\n\n#### Source:\n\nIsabelle Guyon \nClopinet \n955 Creston Road \nBerkeley, CA 90708 \nisabelle '@' clopinet.com \n\n#### Data Set Information:\n\nMADELON is an artificial dataset containing data points grouped in 32 clusters placed on the vertices of a five-dimensional hypercube and randomly labeled +1 or -1. The five dimensions constitute 5 informative features. 15 linear combinations of those features were added to form a set of 20 (redundant) informative features. Based on those 20 features one must separate the examples into the 2 classes (corresponding to the +-1 labels). It was added a number of distractor feature called 'probes' having no predictive power. The order of the features and patterns were randomized. \n\nThis dataset is one of five datasets used in the NIPS 2003 feature selection challenge. The original data was split into training, validation and test set. Target values are provided only for two first sets (not for the test set). So, this dataset version contains all the examples from training and validation partitions. \n\nThere is no attribute information provided to avoid biasing the feature selection process.\n\n#### Relevant Papers:\n\nThe best challenge entrants wrote papers collected in the book: \nIsabelle Guyon, Steve Gunn, Masoud Nikravesh, Lofti Zadeh (Eds.), Feature Extraction, Foundations and Applications. Studies in Fuzziness and Soft Computing. Physica-Verlag, Springer.\n\nIsabelle Guyon, et al, 2007. Competitive baseline methods set new standards for the NIPS 2003 feature selection benchmark. Pattern Recognition Letters 28 (2007) 1438\u20131444. \n\nIsabelle Guyon, et al. 2006. Feature selection with the CLOP package. Technical Report.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1485_madelon_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 501, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1485-madelon"}, "LL0_1487_ozone_level_8hr": {"pipeline": {"_id": "a2cefb51-ed04-4cfc-981c-5d3ca6b5fa46", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 51}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 454, "max_depth": 10, "learning_rate": 0.7195954481747882, "gamma": 0.27807412236123674, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "a2cefb51-ed04-4cfc-981c-5d3ca6b5fa46", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7166385897994775, "rank": 0.28336141020059924, "metric": "f1Macro", "ts": "2018-10-25T00:50:56.576000", "dataset": "LL0_1487_ozone_level_8hr_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1487_ozone_level_8hr", "about": {"problemID": "LL0_1487_ozone_level_8hr_problem", "problemName": "LL0_1487_ozone_level_8hr_problem", "problemDescription": "**Author**: Kun Zhang, Wei Fan, XiaoJing Yuan\n\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ozone+level+detection)\n\n**Please cite**:   \n\nForecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. \n\n\n1 . Abstract: \nTwo ground ozone level data sets are included in this collection. One is the eight hour peak set (eighthr.data), the other is the one hour peak set (onehr.data). Those data were collected from 1998 to 2004 at the Houston, Galveston and Brazoria area.\n\n2. Source:\n\nKun Zhang, zhang.kun05 '@' gmail.com, Department of Computer Science, Xavier University of Lousiana \nWei Fan, wei.fan '@' gmail.com, IBM T.J.Watson Research \nXiaoJing Yuan, xyuan '@' uh.edu, Engineering Technology Department, College of Technology, University of Houston \n\n\n3. Data Set Information:\n\nAll the attribute start with T means the temperature measured at different time throughout the day; and those starts with WS indicate the wind speed at various time. \n\nWSR_PK: continuous. peek wind speed -- resultant (meaning average of wind vector) \nWSR_AV: continuous. average wind speed \nT_PK: continuous. Peak T \nT_AV: continuous. Average T \nT85: continuous. T at 850 hpa level (or about 1500 m height) \nRH85: continuous. Relative Humidity at 850 hpa \nU85: continuous. (U wind - east-west direction wind at 850 hpa) \nV85: continuous. V wind - N-S direction wind at 850 \nHT85: continuous. Geopotential height at 850 hpa, it is about the same as height at low altitude \nT70: continuous. T at 700 hpa level (roughly 3100 m height) \n\nRH70: continuous. \nU70: continuous. \nV70: continuous. \nHT70: continuous. \n\nT50: continuous. T at 500 hpa level (roughly at 5500 m height) \n\nRH50: continuous. \nU50: continuous. \nV50: continuous. \nHT50: continuous. \n\nKI: continuous. K-Index [Web Link] \nTT: continuous. T-Totals [Web Link] \nSLP: continuous. Sea level pressure \nSLP_: continuous. SLP change from previous day \n\nPrecp: continuous. -- precipitation\n\n\n4. Attribute Information:\n\nThe following are specifications for several most important attributes that are highly valued by Texas Commission on Environmental Quality (TCEQ). More details can be found in the two relevant papers. \n\nO 3 - Local ozone peak prediction \nUpwind - Upwind ozone background level \nEmFactor - Precursor emissions related factor \nTmax - Maximum temperature in degrees F \nTb - Base temperature where net ozone production begins (50 F) \nSRd - Solar radiation total for the day \nWSa - Wind speed near sunrise (using 09-12 UTC forecast mode) \nWSp - Wind speed mid-day (using 15-21 UTC forecast mode) \n\n\n5. Relevant Papers:\n\nForecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008. \n\nIt Discusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods. \nA shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in: \nForecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1487_ozone_level_8hr_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 73, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1487-ozone-level-8hr"}, "LL0_1488_parkinsons": {"pipeline": {"_id": "41b68a15-e4d5-442e-8d84-a00f1409a317", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 20}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 20, "max_depth": 6, "learning_rate": 0.8170163002618728, "gamma": 0.15864250911902356, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "41b68a15-e4d5-442e-8d84-a00f1409a317", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8741277786605929, "rank": 0.12587222133974868, "metric": "f1Macro", "ts": "2018-10-25T00:18:17.816000", "dataset": "LL0_1488_parkinsons_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1488_parkinsons", "about": {"problemID": "LL0_1488_parkinsons_problem", "problemName": "parkinsons_problem", "problemDescription": "**Author**:   \n**Source**: UCI\n**Please cite**: 'Exploiting Nonlinear Recurrence and Fractal Scaling Properties for Voice Disorder Detection', Little MA, McSharry PE, Roberts SJ, Costello DAE, Moroz IM. BioMedical Engineering OnLine 2007, 6:23 (26 June 2007) \n\n* Abstract: \n\nOxford Parkinson's Disease Detection Dataset\n\n* Source:\n\nThe dataset was created by Max Little of the University of Oxford, in collaboration with the National Centre for Voice and Speech, Denver, Colorado, who recorded the speech signals. The original study published the feature extraction methods for general voice disorders.\n\n* Data Set Information:\nThis dataset is composed of a range of biomedical voice measurements from 31 people, 23 with Parkinson's disease (PD). Each column in the table is a particular voice measure, and each row corresponds one of 195 voice recording from these individuals (\"name\" column). The main aim of the data is to discriminate healthy people from those with PD, according to \"status\" column which is set to 0 for healthy and 1 for PD. \n\nFurther details are contained in the following reference -- if you use this dataset, please cite: \nMax A. Little, Patrick E. McSharry, Eric J. Hunter, Lorraine O. Ramig (2008), 'Suitability of dysphonia measurements for telemonitoring of Parkinson's disease', IEEE Transactions on Biomedical Engineering (to appear).\n\n\n* Attribute Information:\n\nMatrix column entries (attributes): \nname - ASCII subject name and recording number \nMDVP:Fo(Hz) - Average vocal fundamental frequency \nMDVP:Fhi(Hz) - Maximum vocal fundamental frequency \nMDVP:Flo(Hz) - Minimum vocal fundamental frequency \nMDVP:Jitter(%),MDVP:Jitter(Abs),MDVP:RAP,MDVP:PPQ,Jitter:DDP - Several measures of variation in fundamental frequency \nMDVP:Shimmer,MDVP:Shimmer(dB),Shimmer:APQ3,Shimmer:APQ5,MDVP:APQ,Shimmer:DDA - Several measures of variation in amplitude \nNHR,HNR - Two measures of ratio of noise to tonal components in the voice \nstatus - Health status of the subject (one) - Parkinson's, (zero) - healthy \nRPDE,D2 - Two nonlinear dynamical complexity measures \nDFA - Signal fractal scaling exponent \nspread1,spread2,PPE - Three nonlinear measures of fundamental frequency variation", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1488_parkinsons_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 23, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1488-parkinsons"}, "LL0_1489_phoneme": {"pipeline": {"_id": "d7a911b9-4d3f-47ce-abd1-dc53a622da4d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 60}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 431, "max_depth": 9, "learning_rate": 0.3384323412219786, "gamma": 0.08065870355035876, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d7a911b9-4d3f-47ce-abd1-dc53a622da4d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8801222217885432, "rank": 0.11987777821231127, "metric": "f1Macro", "ts": "2018-10-25T01:43:46.507000", "dataset": "LL0_1489_phoneme_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1489_phoneme", "about": {"problemID": "LL0_1489_phoneme_problem", "problemName": "LL0_1489_phoneme_problem", "problemDescription": "**Author**: Dominique Van Cappel, THOMSON-SINTRA  \n**Source**: [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=105#sub2), [ELENA](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/databases/REAL/phoneme/) - 1993  \n**Please cite**: None  \n\nThe aim of this dataset is to distinguish between nasal (class 0) and oral sounds (class 1). Five different attributes were chosen to characterize each vowel: they are the amplitudes of the five first harmonics AHi, normalised by the total energy Ene (integrated on all the frequencies): AHi/Ene. The phonemes are transcribed as follows: sh as in she, dcl as in dark, iy as the vowel in she, aa as the vowel in dark, and ao as the first vowel in water.  \n\n### Source\n\nThe current dataset was formatted by the KEEL repository, but originally hosted by the [ELENA Project](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/elena.htm#stuff). The dataset originates from the European ESPRIT 5516 project: ROARS. The aim of this project was the development and the implementation of a real time analytical system for French and Spanish speech recognition.  \n\n### Relevant information\n\nMost of the already existing speech recognition systems are global systems (typically Hidden Markov Models and Time Delay Neural Networks) which recognizes signals and do not really use the speech\nspecificities.  On the contrary, analytical systems take into account the articulatory process leading to the different phonemes of a given language, the idea being to deduce the presence of each of the\nphonetic features from the acoustic observation.\n\nThe main difficulty of analytical systems is to obtain acoustical parameters sufficiantly reliable. These acoustical measurements must :\n\n   - contain all the information relative to the concerned phonetic feature.\n   - being speaker independent.\n   - being context independent.\n   - being more or less robust to noise.\n\nThe primary acoustical observation is always voluminous (spectrum x N different observation moments) and classification cannot been processed directly.\n\nIn ROARS, the initial database is provided by cochlear spectra, which may be seen as the output of a filters bank having a constant DeltaF/F0, where the central frequencies are distributed on a\nlogarithmic scale (MEL type) to simulate the frequency answer of the auditory nerves.  The filters outputs are taken every 2 or 8 msec (integration on 4 or 16 msec) depending on the type of phoneme\nobserved (stationary or transitory).  \n\nThe aim of the present database is to distinguish between nasal and\noral vowels. There are thus two different classes:\n\n- Class 0 : Nasals  \n- Class 1 : Orals        \n\nThis database contains vowels coming from 1809 isolated syllables (for example: pa, ta, pan,...). Five different attributes were chosen to characterize each vowel: they are the amplitudes of the five first harmonics AHi, normalised by the total energy Ene (integrated on all the frequencies): AHi/Ene. Each harmonic is signed: positive when it corresponds to a local maximum of the spectrum and negative otherwise.\n\nThree observation moments have been kept for each vowel to obtain 5427 different instances: \n\n - the observation corresponding to the maximum total energy Ene. \n   \n - the observations taken 8 msec before and 8 msec after the observation corresponding to this maximum total energy.\n\nFrom these 5427 initial values, 23 instances for which the amplitude of the 5 first harmonics was zero were removed, leading to the 5404 instances of the present database. The patterns are presented in a random order.\n\n### Past Usage  \n\nAlinat, P., Periodic Progress Report 4, ROARS Project ESPRIT II- Number 5516, February 1993, Thomson report TS. ASM 93/S/EGS/NC/079  \n    \nGuerin-Dugue, A. and others, Deliverable R3-B4-P - Task B4: Benchmarks, Technical report, Elena-NervesII \"Enhanced Learning for Evolutive Neural Architecture\", ESPRIT-Basic Research Project  Number 6891, June 1995  \n\nVerleysen, M. and Voz, J.L. and Thissen, P. and Legat, J.D., A statistical Neural Network for high-dimensional vector classification, ICNN'95 - IEEE International Conference on Neural Networks, November 1995, Perth, Western Australia.  \n    \nVoz J.L., Verleysen M., Thissen P. and Legat J.D., Suboptimal Bayesian classification by vector quantization with small clusters. ESANN95-European Symposium on Artificial Neural Networks, April 1995, M. Verleysen editor, D facto publications, Brussels, Belgium.  \n    \nVoz J.L., Verleysen M., Thissen P. and Legat J.D., A practical view of  suboptimal Bayesian classification, IWANN95-Proceedings of the International Workshop on Artificial Neural Networks, June 1995, Mira, Cabestany, Prieto editors, Springer-Verlag Lecture Notes in Computer Sciences, Malaga, Spain", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1489_phoneme_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1489-phoneme"}, "LL0_1490_planning_relax": {"pipeline": {"_id": "f7182c05-6f86-4cad-b030-fd5e67c9704e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 68}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 251, "max_depth": 8, "learning_rate": 0.5132794029818697, "gamma": 0.7884356283499707, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f7182c05-6f86-4cad-b030-fd5e67c9704e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5570443349753694, "rank": 0.44295566502528627, "metric": "f1Macro", "ts": "2018-10-25T01:37:58.218000", "dataset": "LL0_1490_planning_relax_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1490_planning_relax", "about": {"problemID": "LL0_1490_planning_relax_problem", "problemName": "planning_relax_problem", "problemDescription": "**Author**: Rajen Bhatt  \n\n**Source**: UCI \n\n**Please cite**: Rajen Bhatt, 'Planning-Relax Dataset for Automatic Classification of EEG Signals', UCI Machine Learning Repository\n\n\n* Title:\n\nPlanning Relax Data Set \n\n\n* Abstract: \n\nThe dataset concerns with the classification of two mental stages from recorded EEG signals: Planning (during imagination of motor act) and Relax state.\n\n* Data Set Characteristics:  \n\nUnivariate\nNumber of Instances: 182\nArea: Computer\nAttribute Characteristics: Real\nNumber of Attributes: 13\nAssociated Tasks: Classification\nMissing Values? N/A\n\n* Source:\n\nRajen Bhatt, rajen.bhatt '@' gmail.com, IIT Delhi\n\n\n* Data Set Information:\n\nEEG record contains many regular oscillations, which are believed to reflect synchronized rhythmic activity in a group of neurons. Most activity related EEG patterns occur within the following frequency bands. Delta (0.5 \u00e2\u20ac\u201c 4 Hz.), Theta (4 \u00e2\u20ac\u201c 8 Hz), Alpha (8 \u00e2\u20ac\u201c 13 Hz), Beta (13 \u00e2\u20ac\u201c 22 Hz), and Gamma (30 \u00e2\u20ac\u201c 40 Hz). The waves with the frequency of 7 \u00e2\u20ac\u201c 13 Hz over motor processing areas are called mu rhythm and reflect idling activity in motor areas. It is more pronounced when the subjects are at rest and at least a second before subjects initiate voluntary movement, the mu activity over the hemisphere contralateral to the region moved shows a decrease in amplitude and is called Event Related Desynchronization (ERD). \nFor the current study, EEG data was collected for 5 times on various days from a healthy right-handed subject of 25 years of age. The data was recorded on a Medelec Profile Digital EEG machine. The settings of high frequency filter 50 Hz, low frequency filter 1.6 Hz, notch filter 50 Hz, sensitivity 70 micro volts/mm, and a sampling rate of 256 Hz were used for the basic signal processing. \nEight EEG electrodes (C3, C4, P3, P4, F3, F4, T3, and T4) were placed according to the international standard 10-20 system of electrode placement. Bipolar and unipolar EEG was recorded from eight Ag/AgCI scalp electrodes, which were placed 2.5 cm anterior and posterior to the central electrodes C3 and C4 (left and right side of the hemisphere). A1 and A2 are reference electrodes. The reference electrodes are placed on the left and right ears and the ground electrode on the forehead. EOG (Electrooculogram) being a noise artifact, was derived from two electrodes, placed on the outer cantus of left and right eye in order to detect eye movement. These EOG signals are then used to eliminate eye movement artifacts. \nThe subject was asked to lie down comfortably in a relaxed position with eyes closed and advised to minimize eye movements. The EEG was recorded for the relaxed state for 5 minutes. Following this, an audio beep of 60 db and 0.91 sec. duration was given at the start and end of a 5 second epoch where the subject was asked to mentally plan lifting of the right hand thumb. This activity is collected as a 5 second epoch data corresponding to \u00e2\u20ac\u02dcmovement imagery\u00e2\u20ac\u2122 state. After a gap of 5 minutes, the same cue is given to repeat the experiment. The whole experiment lasts for approximately 30 minutes, collecting data for 5 trials of 5 second epoch each for normal relaxed state and 5 trials of 5 second epoch each for movement imagery. No actual movement is performed during the session. All data sets were visually checked for artifacts before final selection.\n\n\n* Attribute Information:\n\nWavelet transform has been applied for feature extraction for EEG classification. However, wavelet transforms pyramidal algorithm work only on approximation coefficients. So it can not identify 7-13 Hz frequency band. We have extended the methodology by applying wavelet packet analysis, which also decompose detail coefficients. Wavelet packet analysis has been used for signal decomposition with equal frequency bandwidth at each level of decomposition, which leads to an equal number of the approximation and detail coefficients. By applying wavelet packet analysis on the original signal, we have obtained twelve wavelet coefficients in the 7-13 Hz frequency band at the 6th level node (6,2). The signal is reconstructed at node (6,2) and its FFT plot gave the frequency band 7-13 Hz as the most discriminating, in conjunction with the wavelet Daubechies#6 (db6).\n\n\n* Relevant Papers:\n\n1. Rajen B. Bhatt and M. Gopal, 2008, \u00e2\u20ac\u0153FRCT: Fuzzy-Rough Classification Trees\u00e2\u20ac\u009d, Pattern Analysis and Applications, 11(1), pp. 73-88. \n2. Shweta Sahu and Rajen B. Bhatt, \u00e2\u20ac\u0153Automatic classification of Electroencephalography Signals using Wavelet Packet Analysis and Fuzzy Decision Trees\u00e2\u20ac\u009d, in Proc. of 28th National Systems Conference (NSC-2004), Dec. 16-18, Vellore, India. \n3. Rajen Bhatt, 'Fuzzy-Rough Approach to Pattern Classification:Hybrid Algorithms and Optimization', Ph.D. Thesis, IIT Delhi, 2006.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1490_planning_relax_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1490-planning-relax"}, "LL0_1493_one_hundred_plants_texture": {"pipeline": {"_id": "9aa467c4-6a33-4739-ab41-5e8c49a95165", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 59}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 23, "min_samples_split": 0.013374357576781069, "min_samples_leaf": 0.00560788580854162, "n_estimators": 270, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "9aa467c4-6a33-4739-ab41-5e8c49a95165", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7306369408369409, "rank": 0.2693630591639762, "metric": "f1Macro", "ts": "2018-10-25T04:43:32.103000", "dataset": "LL0_1493_one_hundred_plants_texture_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1493_one_hundred_plants_texture", "about": {"problemID": "LL0_1493_one_hundred_plants_texture_problem", "problemName": "LL0_1493_one_hundred_plants_texture_problem", "problemDescription": "**Author**: James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/One-hundred+plant+species+leaves+data+set) - 2010   \n**Please cite**: Charles Mallah, James Cope, James Orwell. Plant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. Signal Processing, Pattern Recognition and Applications, in press. 2013.     \n\n### Description\n\nOne-hundred plant species leaves dataset (Class = Texture).\n \n### Sources\n```\n   (a) Original owners of colour Leaves Samples:\n\n James Cope, Thibaut Beghin, Paolo Remagnino, Sarah Barman.  \n The colour images are not included.  \n The Leaves were collected in the Royal Botanic Gardens, Kew, UK.  \n email: james.cope@kingston.ac.uk  \n   \n   (b) This dataset consists of work carried out by James Cope, Charles Mallah, and James Orwell.  \n Donor of database Charles Mallah: charles.mallah@kingston.ac.uk; James Cope:  james.cope@kingston.ac.uk  \n```\n\n### Dataset Information\n\nThe original data directory contains the binary images (masks) of the leaf samples (colour images not included).\nThere are three features for each image: Shape, Margin and Texture.\nFor each feature, a 64 element vector is given per leaf sample.\nThese vectors are taken as a contiguous descriptor (for shape) or histograms (for texture and margin).\nSo, there are three different files, one for each feature problem:  \n * 'data_Sha_64.txt' -> prediction based on shape\n * 'data_Tex_64.txt' -> prediction based on texture [**dataset provided here**] \n * 'data_Mar_64.txt' -> prediction based on margin \n\nEach row has a 64-element feature vector followed by the Class label.\nThere is a total of 1600 samples with 16 samples per leaf class (100 classes), and no missing values.\n\n### Attributes Information\n\nThree 64 element feature vectors per sample.\n\n### Relevant Papers\n\nCharles Mallah, James Cope, James Orwell. \nPlant Leaf Classification Using Probabilistic Integration of Shape, Texture and Margin Features. \nSignal Processing, Pattern Recognition and Applications, in press.\n\nJ. Cope, P. Remagnino, S. Barman, and P. Wilkin.\nPlant texture classification using gabor co-occurrences.\nAdvances in Visual Computing,\npages 699-677, 2010.\n\nT. Beghin, J. Cope, P. Remagnino, and S. Barman.\nShape and texture based plant leaf classification. \nIn: Advanced Concepts for Intelligent Vision Systems,\npages 345-353. Springer, 2010.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1493_one_hundred_plants_texture_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 65, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1493-one-hundred-plants-texture"}, "LL0_1494_qsar_biodeg": {"pipeline": {"_id": "a8e50b38-73fc-440f-9bbe-9a030fe86157", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 566, "max_depth": 5, "learning_rate": 0.0872598112114722, "gamma": 0.9013542404550332, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "a8e50b38-73fc-440f-9bbe-9a030fe86157", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8658264587483572, "rank": 0.13417354125198738, "metric": "f1Macro", "ts": "2018-10-25T01:28:38.325000", "dataset": "LL0_1494_qsar_biodeg_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1494_qsar_biodeg", "about": {"problemID": "LL0_1494_qsar_biodeg_problem", "problemName": "LL0_1494_qsar_biodeg_problem", "problemDescription": "**Author**:   \n**Source**: UCI  \n**Please cite**: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878 \n\n\nQSAR biodegradation Data Set \n\n* Abstract: \n\nData set containing values for 41 attributes (molecular descriptors) used to classify 1055 chemicals into 2 classes (ready and not ready biodegradable).\n\n\n* Source:\n\nKamel Mansouri, Tine Ringsted, Davide Ballabio (davide.ballabio '@' unimib.it), Roberto Todeschini, Viviana Consonni, Milano Chemometrics and QSAR Research Group (http://michem.disat.unimib.it/chm/), Universit\u00c3  degli Studi Milano \u00e2\u20ac\u201c Bicocca, Milano (Italy)\n\n\n* Data Set Information:\n\nThe QSAR biodegradation dataset was built in the Milano Chemometrics and QSAR Research Group (Universit\u00c3  degli Studi Milano \u00e2\u20ac\u201c Bicocca, Milano, Italy). The research leading to these results has received funding from the European Community\u00e2\u20ac\u2122s Seventh Framework Programme [FP7/2007-2013] under Grant Agreement n. 238701 of Marie Curie ITN Environmental Chemoinformatics (ECO) project. \nThe data have been used to develop QSAR (Quantitative Structure Activity Relationships) models for the study of the relationships between chemical structure and biodegradation of molecules. Biodegradation experimental values of 1055 chemicals were collected from the webpage of the National Institute of Technology and Evaluation of Japan (NITE). Classification models were developed in order to discriminate ready (356) and not ready (699) biodegradable molecules by means of three different modelling methods: k Nearest Neighbours, Partial Least Squares Discriminant Analysis and Support Vector Machines. Details on attributes (molecular descriptors) selected in each model can be found in the quoted reference: Mansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878.\n\n\n* Attribute Information:\n\n41 molecular descriptors and 1 experimental class: \n1) SpMax_L: Leading eigenvalue from Laplace matrix \n2) J_Dz(e): Balaban-like index from Barysz matrix weighted by Sanderson electronegativity \n3) nHM: Number of heavy atoms \n4) F01[N-N]: Frequency of N-N at topological distance 1 \n5) F04[C-N]: Frequency of C-N at topological distance 4 \n6) NssssC: Number of atoms of type ssssC \n7) nCb-: Number of substituted benzene C(sp2) \n8) C%: Percentage of C atoms \n9) nCp: Number of terminal primary C(sp3) \n10) nO: Number of oxygen atoms \n11) F03[C-N]: Frequency of C-N at topological distance 3 \n12) SdssC: Sum of dssC E-states \n13) HyWi_B(m): Hyper-Wiener-like index (log function) from Burden matrix weighted by mass \n14) LOC: Lopping centric index \n15) SM6_L: Spectral moment of order 6 from Laplace matrix \n16) F03[C-O]: Frequency of C - O at topological distance 3 \n17) Me: Mean atomic Sanderson electronegativity (scaled on Carbon atom) \n18) Mi: Mean first ionization potential (scaled on Carbon atom) \n19) nN-N: Number of N hydrazines \n20) nArNO2: Number of nitro groups (aromatic) \n21) nCRX3: Number of CRX3 \n22) SpPosA_B(p): Normalized spectral positive sum from Burden matrix weighted by polarizability \n23) nCIR: Number of circuits \n24) B01[C-Br]: Presence/absence of C - Br at topological distance 1 \n25) B03[C-Cl]: Presence/absence of C - Cl at topological distance 3 \n26) N-073: Ar2NH / Ar3N / Ar2N-Al / R..N..R \n27) SpMax_A: Leading eigenvalue from adjacency matrix (Lovasz-Pelikan index) \n28) Psi_i_1d: Intrinsic state pseudoconnectivity index - type 1d \n29) B04[C-Br]: Presence/absence of C - Br at topological distance 4 \n30) SdO: Sum of dO E-states \n31) TI2_L: Second Mohar index from Laplace matrix \n32) nCrt: Number of ring tertiary C(sp3) \n33) C-026: R--CX--R \n34) F02[C-N]: Frequency of C - N at topological distance 2 \n35) nHDon: Number of donor atoms for H-bonds (N and O) \n36) SpMax_B(m): Leading eigenvalue from Burden matrix weighted by mass \n37) Psi_i_A: Intrinsic state pseudoconnectivity index - type S average \n38) nN: Number of Nitrogen atoms \n39) SM6_B(m): Spectral moment of order 6 from Burden matrix weighted by mass \n40) nArCOOR: Number of esters (aromatic) \n41) nX: Number of halogen atoms \n42) experimental class: ready biodegradable (RB) and not ready biodegradable (NRB)\n\n\n* Relevant Papers:\n\nMansouri, K., Ringsted, T., Ballabio, D., Todeschini, R., Consonni, V. (2013). Quantitative Structure - Activity Relationship models for ready biodegradability of chemicals. Journal of Chemical Information and Modeling, 53, 867-878", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1494_qsar_biodeg_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 42, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1494-qsar-biodeg"}, "LL0_1496_ringnorm": {"pipeline": {"_id": "0d6cf769-b8ea-48a0-a1b5-372b6317efe3", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 655, "max_depth": 3, "learning_rate": 0.08250896735603319, "gamma": 0.9058426699387727, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "0d6cf769-b8ea-48a0-a1b5-372b6317efe3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9716108280144338, "rank": 0.028389171985660516, "metric": "f1Macro", "ts": "2018-10-31T04:49:19.552000", "dataset": "LL0_1496_ringnorm_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1496_ringnorm", "about": {"problemID": "LL0_1496_ringnorm_problem", "problemName": "LL0_1496_ringnorm_problem", "problemDescription": "**Author**: Michael Revow     \n**Source**: http://www.cs.toronto.edu/~delve/data/ringnorm/desc.html   \n**Please cite**:     \n\n1: Abstract: \n\nThis is a 20 dimensional, 2 class classification problem. Each class is drawn from a multivariate normal distribution. Class 1 has mean zero and covariance 4 times the identity. Class 2 has mean (a,a,..a) and unit covariance. a = 2/sqrt(20). \n\n2: Data set description.\n\nThis is an implementation of Leo Breiman's ringnorm example[1]. It is a 20 dimensional, 2 class classification example. Each class is drawn from a multivariate normal distribution. Class 1 has mean zero and covariance 4 times the identity. Class 2 has mean (a,a,..a) and unit covariance. a = 2/sqrt(20). Breiman reports the theoretical expected misclassification rate as 1.3%. He used 300 training examples with CART and found an error of 21.4%.\n\n\n- Type.          Classification \n- Origin.  Laboratory\n- Instances.  7400\n- Features.  20\n- Classes.  2 \n- Missing values. No\n\n3: Attributes information\n\n@relation ring\n@attribute A1 real [-6879.0, 6285.0]\n@attribute A2 real [-7141.0, 6921.0]\n@attribute A3 real [-7734.0, 7611.0]\n@attribute A4 real [-6627.0, 7149.0]\n@attribute A5 real [-7184.0, 6383.0]\n@attribute A6 real [-6946.0, 6743.0]\n@attribute A7 real [-7781.0, 6285.0]\n@attribute A8 real [-6882.0, 6357.0]\n@attribute A9 real [-7184.0, 7487.0]\n@attribute A10 real [-7232.0, 6757.0]\n@attribute A11 real [-7803.0, 7208.0]\n@attribute A12 real [-7395.0, 6791.0]\n@attribute A13 real [-7096.0, 6403.0]\n@attribute A14 real [-7472.0, 7261.0]\n@attribute A15 real [-7342.0, 7372.0]\n@attribute A16 real [-7121.0, 6905.0]\n@attribute A17 real [-7163.0, 7175.0]\n@attribute A18 real [-8778.0, 6896.0]\n@attribute A19 real [-7554.0, 5726.0]\n@attribute A20 real [-6722.0, 7627.0]\n@attribute Class {0, 1}\n@inputs A1, A2, A3, A4, A5, A6, A7, A8, A9, A10, A11, A12, A13, A14, A15, A16, A17, A18, A19, A20\n@outputs Class", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1496_ringnorm_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1496-ringnorm"}, "LL0_1497_wall_robot_navigation": {"pipeline": {"_id": "19ad38ec-3d03-4974-ba3c-4c8cd8b4fa30", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 80}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 355, "max_depth": 10, "learning_rate": 0.4139012107089586, "gamma": 0.38449516647469684, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "19ad38ec-3d03-4974-ba3c-4c8cd8b4fa30", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9976686456915097, "rank": 0.002331354309381405, "metric": "f1Macro", "ts": "2018-10-25T00:45:28.260000", "dataset": "LL0_1497_wall_robot_navigation_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1497_wall_robot_navigation", "about": {"problemID": "LL0_1497_wall_robot_navigation_problem", "problemName": "LL0_1497_wall_robot_navigation_problem", "problemDescription": "**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Wall-Following+Robot+Navigation+Data) - 2010  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n\n**Wall-Following Robot Navigation Data Data Set**  \nThe data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.\n\nThe data consists of raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second.\n\nThe class labels are:  \n1. Move-Forward,  \n2. Slight-Right-Turn,  \n3. Sharp-Right-Turn,  \n4. Slight-Left-Turn  \n\nIt is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). \n\nThe wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. \n\n### Attribute Information:\n\n1. US1: ultrasound sensor at the front of the robot (reference angle: 180\u00b0) \n2. US2: ultrasound reading (reference angle: -165\u00b0)\n3. US3: ultrasound reading (reference angle: -150\u00b0)\n4. US4: ultrasound reading (reference angle: -135\u00b0)\n5. US5: ultrasound reading (reference angle: -120\u00b0)\n6. US6: ultrasound reading (reference angle: -105\u00b0)\n7. US7: ultrasound reading (reference angle: -90\u00b0)\n8. US8: ultrasound reading (reference angle: -75\u00b0) \n9. US9: ultrasound reading (reference angle: -60\u00b0) \n10. US10: ultrasound reading (reference angle: -45\u00b0)\n11. US11: ultrasound reading (reference angle: -30\u00b0) \n12. US12: ultrasound reading (reference angle: -15\u00b0)\n13. US13: reading of ultrasound sensor situated at the back of the robot (reference angle: 0\u00b0) \n14. US14: ultrasound reading (reference angle: 15\u00b0)\n15. US15: ultrasound reading (reference angle: 30\u00b0)\n16. US16: ultrasound reading (reference angle: 45\u00b0)\n17. US17: ultrasound reading (reference angle: 60\u00b0)\n18. US18: ultrasound reading (reference angle: 75\u00b0)\n19. US19: ultrasound reading (reference angle: 90\u00b0)\n20. US20: ultrasound reading (reference angle: 105\u00b0)\n21. US21: ultrasound reading (reference angle: 120\u00b0)\n22. US22: ultrasound reading (reference angle: 135\u00b0)\n23. US23: ultrasound reading (reference angle: 150\u00b0)\n24. US24: ultrasound reading (reference angle: 165\u00b0)\n\n\n### Relevant Papers\n\nAnanda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), 'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation Tasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), pages 1-6", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1497_wall_robot_navigation_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 25, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1497-wall-robot-navigation"}, "LL0_1498_sa_heart": {"pipeline": {"_id": "ddcdd6b4-a2a5-482d-9f03-65ee7d90cbd2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 56}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 24, "max_depth": 7, "learning_rate": 0.36680481171609314, "gamma": 0.27188290608688215, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "ddcdd6b4-a2a5-482d-9f03-65ee7d90cbd2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7036357970530156, "rank": 0.2963642029476188, "metric": "f1Macro", "ts": "2018-10-24T23:56:40.811000", "dataset": "LL0_1498_sa_heart_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1498_sa_heart", "about": {"problemID": "LL0_1498_sa_heart_problem", "problemName": "LL0_1498_sa_heart_problem", "problemDescription": "**Author**:   \n**Source**: http://statweb.stanford.edu/~tibs/ElemStatLearn/data.html   \n**Please cite**:   \n\n* Title:\n\nSouth Africa Heart Disease Dataset\n\n* Description\n\nA retrospective sample of males in a heart-disease high-risk region of the Western Cape, South Africa. There are roughly two controls per case of CHD. Many of the CHD positive men have undergone blood pressure reduction treatment and other programs to reduce their risk factors after their CHD event. In some cases the measurements were made after these treatments. These data are taken from a larger dataset, described in  Rousseauw et al, 1983, South African Medical\nJournal. \n\n* Attributes:\n\nsbp  systolic blood pressure   \ntobacco  cumulative tobacco (kg)   \nldl  low densiity lipoprotein cholesterol   \nadiposity  \nfamhist  family history of heart disease (Present, Absent)   \ntypea  type-A behavior   \nobesity   \nalcohol  current alcohol consumption   \nage  age at onset   \nchd  response, coronary heart disease", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1498_sa_heart_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1498-sa-heart"}, "LL0_1499_seeds": {"pipeline": {"_id": "dae63026-8562-413a-aca1-d31f6273a39f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 16}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 531, "max_depth": 7, "learning_rate": 0.8982086383788104, "gamma": 0.05589629858242051, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "dae63026-8562-413a-aca1-d31f6273a39f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9406164985112355, "rank": 0.05938350148889415, "metric": "f1Macro", "ts": "2018-10-24T23:54:14.512000", "dataset": "LL0_1499_seeds_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1499_seeds", "about": {"problemID": "LL0_1499_seeds_problem", "problemName": "seeds_problem", "problemDescription": "**Author**: M. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak  \n**Source**: UCI     \n**Please cite**:  Contributors gratefully acknowledge support of their work by the Institute of Agrophysics of the Polish Academy of Sciences in Lublin.   \n\n* Title:\n\nseeds Data Set \n\n* Abstract: \n\nMeasurements of geometrical properties of kernels belonging to three different varieties of wheat. A soft X-ray technique and GRAINS package were used to construct all seven, real-valued attributes.\n\n* Source:\n\nMa\u00c5\u201agorzata Charytanowicz, Jerzy Niewczas \nInstitute of Mathematics and Computer Science, \nThe John Paul II Catholic University of Lublin, Konstantyn\u00c3\u00b3w 1 H, \nPL 20-708 Lublin, Poland \ne-mail: {mchmat,jniewczas}@kul.lublin.pl \n\nPiotr Kulczycki, Piotr A. Kowalski, Szymon Lukasik, Slawomir Zak \nDepartment of Automatic Control and Information Technology, \nCracow University of Technology, Warszawska 24, PL 31-155 Cracow, Poland \nand \nSystems Research Institute, Polish Academy of Sciences, Newelska 6, \nPL 01-447 Warsaw, Poland \ne-mail: {kulczycki,pakowal,slukasik,slzak}@ibspan.waw.pl\n\n\n* Data Set Information:\n\nThe examined group comprised kernels belonging to three different varieties of wheat: Kama, Rosa and Canadian, 70 elements each, randomly selected for the experiment. High quality visualization of the internal kernel structure was detected using a soft X-ray technique. It is non-destructive and considerably cheaper than other more sophisticated imaging techniques like scanning microscopy or laser technology. The images were recorded on 13x18 cm X-ray KODAK plates. Studies were conducted using combine harvested wheat grain originating from experimental fields, explored at the Institute of Agrophysics of the Polish Academy of Sciences in Lublin. The data set can be used for the tasks of classification and cluster analysis.\n\n* Attribute Information:\n\nTo construct the data, seven geometric parameters of wheat kernels were measured: \n1. area A, \n2. perimeter P, \n3. compactness C = 4*pi*A/P^2, \n4. length of kernel, \n5. width of kernel, \n6. asymmetry coefficient \n7. length of kernel groove. \nAll of these parameters were real-valued continuous.\n\n\n* Relevant Papers:\n\nM. Charytanowicz, J. Niewczas, P. Kulczycki, P.A. Kowalski, S. Lukasik, S. Zak, 'A Complete Gradient Clustering Algorithm for Features Analysis of X-ray Images', in: Information Technologies in Biomedicine, Ewa Pietka, Jacek Kawa (eds.), Springer-Verlag, Berlin-Heidelberg, 2010, pp. 15-24.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1499_seeds_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1499-seeds"}, "LL0_14_mfeat_fourier": {"pipeline": {"_id": "ebcf1c97-a990-44a3-b89e-5c324e6c4ba9", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "ebcf1c97-a990-44a3-b89e-5c324e6c4ba9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8293543580236717, "rank": 0.17064564197704205, "metric": "f1Macro", "ts": "2018-10-31T04:09:37.045000", "dataset": "LL0_14_mfeat_fourier_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_14_mfeat_fourier", "about": {"problemID": "LL0_14_mfeat_fourier_problem", "problemName": "mfeat_fourier_problem", "problemDescription": "**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**Multiple Features Dataset: Fourier**  \nOne of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. \n\n### Attribute Information  \nThe attributes represent 76 Fourier coefficients of the character shapes.\n\n### Relevant Papers  \nA slightly different version of the database is used in  \nM. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.\n \nThe database as is is used in:  \nA.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_14_mfeat_fourier_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 77, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-14-mfeat-fourier"}, "LL0_1500_seismic_bumps": {"pipeline": {"_id": "ec2416ae-4b13-4ad3-92ef-66bbaf3f37c3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 18}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 398, "max_depth": 4, "learning_rate": 0.9278757301387611, "gamma": 0.14305774414643824, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "ec2416ae-4b13-4ad3-92ef-66bbaf3f37c3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9406164985112355, "rank": 0.05938350148887701, "metric": "f1Macro", "ts": "2018-10-25T00:19:43.789000", "dataset": "LL0_1500_seismic_bumps_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1500_seismic_bumps", "about": {"problemID": "LL0_1500_seismic_bumps_problem", "problemName": "seismic_bumps_problem", "problemDescription": "**Author**: Sikora M., Wrobel L.     \n**Source**: UCI   \n**Please cite**:  Sikora M., Wrobel L.: Application of rule induction algorithms for analysis of data collected by seismic hazard monitoring systems in coal mines. Archives of Mining Sciences, 55(1), 2010, 91-114.  \n\n* Title: \n\nseismic-bumps Data Set \n\n* Abstract: \n\nThe data describe the problem of high energy (higher than 10^4 J) seismic bumps forecasting in a coal mine. Data come from two of longwalls located in a Polish coal mine.\n\n* Source:\n\nMarek Sikora^{1,2} (marek.sikora '@' polsl.pl), Lukasz Wrobel^{1} (lukasz.wrobel '@' polsl.pl) \n(1) Institute of Computer Science, Silesian University of Technology, 44-100 Gliwice, Poland \n(2) Institute of Innovative Technologies EMAG, 40-189 Katowice, Poland\n\n\n* Data Set Information:\n\nMining activity was and is always connected with the occurrence of dangers which are commonly called mining hazards. A special case of such threat is a seismic hazard which frequently occurs in many underground mines. Seismic hazard is the hardest detectable and predictable of natural hazards and in this respect it is comparable to an earthquake. More and more advanced seismic and seismoacoustic monitoring systems allow a better understanding rock mass processes and definition of seismic hazard \nprediction methods. Accuracy of so far created methods is however far from perfect. Complexity of seismic processes and big disproportion between the number of low-energy seismic events and the number of high-energy phenomena (e.g. > 10^4J) causes the statistical techniques to be insufficient to predict seismic hazard. Therefore, it is essential to search for new opportunities of better hazard prediction, also using machine learning methods. In seismic hazard assessment data clustering techniques can be \napplied (Lesniak A., Isakow Z.: Space-time clustering of seismic events and hazard assessment in the Zabrze-Bielszowice coal mine, Poland. Int. Journal of Rock Mechanics and Mining Sciences, 46(5), 2009, 918-928), and for prediction of seismic tremors artificial neural networks are used (Kabiesz, J.: Effect of the form of data on the quality of mine tremors hazard forecasting using neural networks. Geotechnical and Geological Engineering, 24(5), 2005, 1131-1147). In the majority of applications, the results obtained by mentioned methods are reported in the form of two states which are interpreted as 'hazardous' and 'non-hazardous'. Unbalanced distribution of positive ('hazardous state') and negative ('non-hazardous state') examples is a serious problem in seismic hazard prediction. Currently used methods are still insufficient to achieve good sensitivity and specificity of predictions. In the paper \n(Bukowska M.: The probability of rockburst occurrence in the Upper Silesian Coal Basin area dependent on natural mining conditions. Journal of Mining Sciences, 42(6), 2006, 570-577) a number of factors having an effect on seismic hazard occurrence was proposed, among other factors, the occurrence of tremors with energy > 10^4J was listed. The task of seismic prediction can be defined in different ways, but the main aim of all seismic hazard assessment methods is to predict (with given precision relating to time and \ndate) of increased seismic activity which can cause a rockburst. In the data set each row contains a summary statement about seismic activity in the rock mass within one shift (8 hours). If decision attribute has the value 1, then in the next shift any seismic bump with an energy higher than 10^4 J was registered. That task of hazards prediction bases on the relationship between the energy of recorded tremors and seismoacoustic activity with the possibility of rockburst occurrence. Hence, such hazard prognosis is not connected with accurate rockburst prediction. Moreover, with the information about the possibility of hazardous situation occurrence, an appropriate supervision service can reduce a risk of rockburst (e.g. by distressing shooting) or withdraw workers from the threatened area. Good prediction of increased seismic activity is therefore a matter of great practical importance. The presented data set is characterized by unbalanced distribution of positive and negative examples. In the data set there \nare only 170 positive examples representing class 1. \n\n\n* Attribute Information:\n\n1. seismic: result of shift seismic hazard assessment in the mine working obtained by the seismic \nmethod (a - lack of hazard, b - low hazard, c - high hazard, d - danger state); \n2. seismoacoustic: result of shift seismic hazard assessment in the mine working obtained by the \nseismoacoustic method; \n3. shift: information about type of a shift (W - coal-getting, N -preparation shift); \n4. genergy: seismic energy recorded within previous shift by the most active geophone (GMax) out of \ngeophones monitoring the longwall; \n5. gpuls: a number of pulses recorded within previous shift by GMax; \n6. gdenergy: a deviation of energy recorded within previous shift by GMax from average energy recorded \nduring eight previous shifts; \n7. gdpuls: a deviation of a number of pulses recorded within previous shift by GMax from average number \nof pulses recorded during eight previous shifts; \n8. ghazard: result of shift seismic hazard assessment in the mine working obtained by the \nseismoacoustic method based on registration coming form GMax only; \n9. nbumps: the number of seismic bumps recorded within previous shift; \n10. nbumps2: the number of seismic bumps (in energy range [10^2,10^3)) registered within previous shift; \n11. nbumps3: the number of seismic bumps (in energy range [10^3,10^4)) registered within previous shift; \n12. nbumps4: the number of seismic bumps (in energy range [10^4,10^5)) registered within previous shift; \n13. nbumps5: the number of seismic bumps (in energy range [10^5,10^6)) registered within the last shift; \n14. nbumps6: the number of seismic bumps (in energy range [10^6,10^7)) registered within previous shift; \n15. nbumps7: the number of seismic bumps (in energy range [10^7,10^8)) registered within previous shift; \n16. nbumps89: the number of seismic bumps (in energy range [10^8,10^10)) registered within previous shift; \n17. energy: total energy of seismic bumps registered within previous shift; \n18. maxenergy: the maximum energy of the seismic bumps registered within previous shift; \n19. class: the decision attribute - '1' means that high energy seismic bump occurred in the next shift \n('hazardous state'), '0' means that no high energy seismic bumps occurred in the next shift \n('non-hazardous state').", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1500_seismic_bumps_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1500-seismic-bumps"}, "LL0_1501_semeion": {"pipeline": {"_id": "e61b177e-13bd-458d-aba9-96989c35d7d9", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "e61b177e-13bd-458d-aba9-96989c35d7d9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9215377815244828, "rank": 0.07846221847605282, "metric": "f1Macro", "ts": "2018-10-31T04:09:36.129000", "dataset": "LL0_1501_semeion_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1501_semeion", "about": {"problemID": "LL0_1501_semeion_problem", "problemName": "LL0_1501_semeion_problem", "problemDescription": "**Author**: Semeion Research Center of Sciences of Communication     \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit)     \n**Please cite**: Semeion Research Center of Sciences of Communication, via Sersale 117, 00128 Rome, Italy \nTattile Via Gaetano Donizetti, 1-3-5,25030 Mairano (Brescia), Italy.    \n\n### Dataset Description\n\nSemeion Handwritten Digit Data Set, where 1593 handwritten digits from around 80 persons were scanned and documented.\n\n### Sources\n\nThe dataset was created by Tactile Srl, Brescia, Italy (http://www.tattile.it) and donated in 1994 to Semeion Research Center of Sciences of Communication, Rome, Italy (http://www.semeion.it), for machine learning research. \n\nFor any questions, e-mail Massimo Buscema (m.buscema '@' semeion.it) or Stefano Terzi (s.terzi '@' semeion.it)\n\n### DataSet Information\n\nA total of 1593 handwritten digits from around 80 persons were scanned, stretched in a rectangular box 16x16 in a gray scale of 256 values. Then each pixel of each image was scaled into a boolean (1/0) value using a fixed threshold. \n\nEach person wrote in a paper all the digits from 0 to 9, twice. The commitment was to write the digit the first time in the normal way (trying to write each digit accurately) and the second time in a fast way (with no accuracy). \n\nThe best validation protocol for this dataset seems to be a 5x2CV, 50% Tune (Train +Test) and completely blind 50% Validation\n\n### Attribute Information\n\nThis dataset consists of 1593 records (rows) and 256 attributes (columns). \nEach record represents a handwritten digit, originally scanned with a resolution of 256 grays scale (28). \nEach pixel of the each original scanned image was first stretched, and after scaled between 0 and 1 (setting to 0 every pixel whose value was under the value 127 of the grey scale (127 included) and setting to 1 each pixel whose original value in the grey scale was over 127). \nFinally, each binary image was scaled again into a 16x16 square box (the final 256 binary attributes).\n\n### Relevant Papers\n\nM Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse 33(2)1998, pp 439-461.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1501_semeion_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 257, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1501-semeion"}, "LL0_1504_steel_plates_fault": {"pipeline": {"_id": "5919c32a-7b1a-47bd-bec6-c1621fb5471d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 19}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 110, "max_depth": 7, "learning_rate": 0.26902281363992375, "gamma": 0.6617969053108405, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "5919c32a-7b1a-47bd-bec6-c1621fb5471d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 4.7684199116271306e-17, "metric": "f1Macro", "ts": "2018-10-25T01:03:23.742000", "dataset": "LL0_1504_steel_plates_fault_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1504_steel_plates_fault", "about": {"problemID": "LL0_1504_steel_plates_fault_problem", "problemName": "LL0_1504_steel_plates_fault_problem", "problemDescription": "**Author**: Semeion, Research Center of Sciences of Communication, Rome, Italy.     \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/steel+plates+faults)     \n**Please cite**: Dataset provided by Semeion, Research Center of Sciences of Communication, Via Sersale 117, 00128, Rome, Italy.  \n\n**Steel Plates Faults Data Set**  \nA dataset of steel plates' faults, classified into 7 different types. The goal was to train machine learning for automatic pattern recognition.\n\nThe dataset consists of 27 features describing each fault (location, size, ...) and 7 binary features indicating the type of fault (on of 7: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults). The latter is commonly used as a binary classification target ('common' or 'other' fault.)\n\n### Attribute Information  \n* V1: X_Minimum  \n* V2: X_Maximum  \n* V3: Y_Minimum  \n* V4: Y_Maximum  \n* V5: Pixels_Areas  \n* V6: X_Perimeter  \n* V7: Y_Perimeter  \n* V8: Sum_of_Luminosity  \n* V9: Minimum_of_Luminosity  \n* V10: Maximum_of_Luminosity  \n* V11: Length_of_Conveyer  \n* V12: TypeOfSteel_A300  \n* V13: TypeOfSteel_A400  \n* V14: Steel_Plate_Thickness  \n* V15: Edges_Index  \n* V16: Empty_Index  \n* V17: Square_Index  \n* V18: Outside_X_Index  \n* V19: Edges_X_Index  \n* V20: Edges_Y_Index  \n* V21: Outside_Global_Index  \n* V22: LogOfAreas  \n* V23: Log_X_Index  \n* V24: Log_Y_Index  \n* V25: Orientation_Index  \n* V26: Luminosity_Index  \n* V27: SigmoidOfAreas  \n* V28: Pastry  \n* V29: Z_Scratch  \n* V30: K_Scatch  \n* V31: Stains  \n* V32: Dirtiness  \n* V33: Bumps  \n* Class: Other_Faults  \n\n### Relevant Papers  \n1.M Buscema, S Terzi, W Tastle, A New Meta-Classifier,in NAFIPS 2010, Toronto (CANADA),26-28 July 2010, 978-1-4244-7858-6/10 \u00c2\u00a92010 IEEE  \n2.M Buscema, MetaNet: The Theory of Independent Judges, in Substance Use & Misuse, 33(2), 439-461,1998", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1504_steel_plates_fault_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 34, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1504-steel-plates-fault"}, "LL0_1505_tamilnadu_electricity": {"pipeline": {"_id": "7f95cd55-7793-4b81-a230-35c86729fd16", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 934, "max_depth": 7, "learning_rate": 0.9651398446169219, "gamma": 0.9733664977531153, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "7f95cd55-7793-4b81-a230-35c86729fd16", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 1.0084153070821999e-14, "metric": "f1Macro", "ts": "2018-10-31T05:27:19.788000", "dataset": "LL0_1505_tamilnadu_electricity_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1505_tamilnadu_electricity", "about": {"problemID": "LL0_1505_tamilnadu_electricity_problem", "problemName": "LL0_1505_tamilnadu_electricity_problem", "problemDescription": "**Author**: K.Kalyani.    \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Tamilnadu+Electricity+Board+Hourly+Readings) - 2013  \n**Please cite**:   \n\n### Description\n\nTamilnadu Electricity Board Hourly Readings dataset. \n\n### Source\n```\nK.Kalyani ,kkalyanims '@' gmail.com,  \nT.U.K Arts College,Karanthai,Thanjavur.\n```\n\n### Data Set Information\n\nReal-time readings were collected from residential, commercial, industrial and agriculture to find the accuracy consumption in Tamil Nadu, around Thanajvur. \n\n**Note**: the attribute Sector was removed from original source since it was constant to all instances.\n\n### Attribute Information:\n```\n1 - ForkVA (V1) : real\n2 - ForkW (V2) : real\n3 - ServiceID (V3): factor\n\n4 - Type (Class): \n- Bank  \n- AutomobileIndustry \n- BpoIndustry   \n- CementIndustry   \n- Farmers1   \n- Farmers2   \n- HealthCareResources \n- TextileIndustry \n- PoultryIndustry \n- Residential(individual)  \n- Residential(Apartments)    \n- FoodIndustry   \n- ChemicalIndustry   \n- Handlooms   \n- FertilizerIndustry   \n- Hostel   \n- Hospital   \n- Supermarket   \n- Theatre   \n- University", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1505_tamilnadu_electricity_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1505-tamilnadu-electricity"}, "LL0_1506_thoracic_surgery": {"pipeline": {"_id": "013bf81c-8a55-4076-905e-8250163f670f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 63}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 683, "max_depth": 8, "learning_rate": 0.9907001604531296, "gamma": 0.13813654503712658, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "013bf81c-8a55-4076-905e-8250163f670f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6147714824925139, "rank": 0.3852285175082094, "metric": "f1Macro", "ts": "2018-10-25T01:35:23.877000", "dataset": "LL0_1506_thoracic_surgery_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1506_thoracic_surgery", "about": {"problemID": "LL0_1506_thoracic_surgery_problem", "problemName": "LL0_1506_thoracic_surgery_problem", "problemDescription": "**Author**:   \n**Source**: UCI    \n**Please cite**: Zikeba, M., Tomczak, J. M., Lubicz, M., & Swikatek, J. (2013). Boosted SVM for extracting rules from imbalanced data in application to prediction of the post-operative life expectancy in the lung cancer patients. Applied Soft Computing.   \n\n  \n* Title: \nThoracic Surgery Data Data Set \n\n* Abstract: \nThe data is dedicated to classification problem related to the post-operative life expectancy in the lung cancer patients: class 1 - death within one year after surgery, class 2 - survival.\n\n* Source:\nCreators: Marek Lubicz (1), Konrad Pawelczyk (2), Adam Rzechonek (2), Jerzy Kolodziej (2) \n-- (1) Wroclaw University of Technology, wybrzeze Wyspianskiego 27, 50-370, Wroclaw, Poland \n-- (2) Wroclaw Medical University, wybrzeze L. Pasteura 1, 50-367 Wroclaw, Poland \n\nDonor: Maciej Zieba (maciej.zieba '@' pwr.wroc.pl), Jakub M. Tomczak (jakub.tomczak '@' pwr.wroc.pl), (+48) 71 320 44 53 \n\n* Data Set Information:\n\nThe data was collected retrospectively at Wroclaw Thoracic Surgery Centre for patients who underwent major lung resections for primary lung cancer in the years 2007\u00e2\u20ac\u201c2011. The Centre is associated with the Department of Thoracic Surgery of the Medical University of Wroclaw and Lower-Silesian Centre for Pulmonary Diseases, Poland, while the research database constitutes a part of the National Lung Cancer Registry, administered by the Institute of Tuberculosis and Pulmonary Diseases in Warsaw, Poland.\n\n\n* Attribute Information:\n\n1. DGN: Diagnosis - specific combination of ICD-10 codes for primary and secondary as well multiple tumours if any (DGN3,DGN2,DGN4,DGN6,DGN5,DGN8,DGN1) \n2. PRE4: Forced vital capacity - FVC (numeric) \n3. PRE5: Volume that has been exhaled at the end of the first second of forced expiration - FEV1 (numeric) \n4. PRE6: Performance status - Zubrod scale (PRZ2,PRZ1,PRZ0) \n5. PRE7: Pain before surgery (T,F) \n6. PRE8: Haemoptysis before surgery (T,F) \n7. PRE9: Dyspnoea before surgery (T,F) \n8. PRE10: Cough before surgery (T,F) \n9. PRE11: Weakness before surgery (T,F) \n10. PRE14: T in clinical TNM - size of the original tumour, from OC11 (smallest) to OC14 (largest) (OC11,OC14,OC12,OC13) \n11. PRE17: Type 2 DM - diabetes mellitus (T,F) \n12. PRE19: MI up to 6 months (T,F) \n13. PRE25: PAD - peripheral arterial diseases (T,F) \n14. PRE30: Smoking (T,F) \n15. PRE32: Asthma (T,F) \n16. AGE: Age at surgery (numeric) \n17. Risk1Y: 1 year survival period - (T)rue value if died (T,F) \n\nClass Distribution: the class value (Risk1Y) is binary valued.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1506_thoracic_surgery_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 17, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1506-thoracic-surgery"}, "LL0_1507_twonorm": {"pipeline": {"_id": "236cb91e-18d9-48f5-bd6d-9e219fd585e3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 50}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 363, "max_depth": 4, "learning_rate": 0.18829597651898722, "gamma": 0.14524160577946799, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "236cb91e-18d9-48f5-bd6d-9e219fd585e3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9741586429784028, "rank": 0.025841357022167884, "metric": "f1Macro", "ts": "2018-10-25T00:10:03.851000", "dataset": "LL0_1507_twonorm_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1507_twonorm", "about": {"problemID": "LL0_1507_twonorm_problem", "problemName": "LL0_1507_twonorm_problem", "problemDescription": "**Author**: Michael Revow     \n**Source**: http://www.cs.toronto.edu/~delve/data/twonorm/desc.html  \n**Please cite**:     \n\n* Twonorm dataset\n\nThis is an implementation of Leo Breiman's twonorm example[1]. It is a 20 dimensional, 2 class classification example. Each class is drawn from a multivariate normal distribution with unit variance. Class 1 has mean (a,a,..a) while Class 2 has mean (-a,-a,..-a). Where a = 2/sqrt(20). Breiman reports the theoretical expected misclassification rate as 2.3%. He used 300 training examples with CART and found an error of 22.1%.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1507_twonorm_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1507-twonorm"}, "LL0_1508_user_knowledge": {"pipeline": {"_id": "43248482-41c7-4dd4-ac9c-2f21daad107f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 15}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 163, "max_depth": 4, "learning_rate": 0.28411929212431686, "gamma": 0.22040326012283074, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "43248482-41c7-4dd4-ac9c-2f21daad107f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8864770602506322, "rank": 0.11352293974998989, "metric": "f1Macro", "ts": "2018-10-25T01:42:27.266000", "dataset": "LL0_1508_user_knowledge_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1508_user_knowledge", "about": {"problemID": "LL0_1508_user_knowledge_problem", "problemName": "LL0_1508_user_knowledge_problem", "problemDescription": "**Author**:   \n**Source**: UCI    \n**Please cite**:  H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, Knowledge Based Systems, vol. 37, pp. 283-295, 2013.   \n\n* Title:  \n\nUser Knowledge Modeling Data Set \n\n* Abstract: \n\nIt is the real dataset about the students' knowledge status about the subject of Electrical DC Machines. The dataset had been obtained from Ph.D. Thesis.\n\n* Source:\n\n-- Creators: Hamdi Tolga Kahraman (htolgakahraman '@' yahoo.com) \n-- Institution: Faculty of Technology, Department of Software Engineering, Karadeniz Technical University, Trabzon, Turkiye \n-- Creators: Ilhami Colak (icolak '@' gazi.edu.tr) \n-- Institution: Faculty of Technology, Department of Electrical and Electronics Engineering, Gazi University, Ankara, Turkiye \n-- Creators: Seref Sagiroglu (ss '@' gazi.edu.tr) \n-- Institution: Faculty of Technology, Department of Computer Engineering, Gazi University, Ankara, Turkiye \n\n-- Donor: undergraduate students of Department of Electrical Education of Gazi University in the 2009 semester \n-- Date: October, 2009\n\n\n* Data Set Information:\n\n-- The users' knowledge class were classified by the authors \nusing intuitive knowledge classifier (a hybrid ML technique of k-NN and meta-heuristic exploring methods), k-nearest neighbor algorithm. See article for more details on how the users' data was collected and evaluated by the user modeling server. \n\nH. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, Knowledge Based Systems, vol. 37, pp. 283-295, 2013.\n\n\n* Attribute Information:\n\nSTG (The degree of study time for goal object materails), (input value) \nSCG (The degree of repetition number of user for goal object materails) (input value) \nSTR (The degree of study time of user for related objects with goal object) (input value) \nLPR (The exam performance of user for related objects with goal object) (input value) \nPEG (The exam performance of user for goal objects) (input value) \nUNS (The knowledge level of user) (target value)\n\n\n* Relevant Papers:\n\n1. H. T. Kahraman, Sagiroglu, S., Colak, I., Developing intuitive knowledge classifier and modeling of users' domain dependent data in web, \nKnowledge Based Systems, vol. 37, pp. 283-295, 2013. \n2. Kahraman, H. T. (2009). Designing and Application of Web-Based Adaptive Intelligent Education System. Gazi University Ph. D. Thesis, Turkey, 1-156.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1508_user_knowledge_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1508-user-knowledge"}, "LL0_1510_wdbc": {"pipeline": {"_id": "34770c19-9743-4bab-8b6b-3d3b388d203b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 48}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 981, "max_depth": 7, "learning_rate": 0.6971783162789565, "gamma": 0.3198835899811301, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "34770c19-9743-4bab-8b6b-3d3b388d203b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9672422157671633, "rank": 0.03275778423356781, "metric": "f1Macro", "ts": "2018-10-25T00:05:48.169000", "dataset": "LL0_1510_wdbc_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1510_wdbc", "about": {"problemID": "LL0_1510_wdbc_problem", "problemName": "LL0_1510_wdbc_problem", "problemDescription": "**Author**: William H. Wolberg, W. Nick Street, Olvi L. Mangasarian    \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), [University of Wisconsin](http://pages.cs.wisc.edu/~olvi/uwmp/cancer.html) - 1995  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)     \n\n**Breast Cancer Wisconsin (Diagnostic) Data Set (WDBC).** Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The target feature records the prognosis (benign (1) or malignant (2)). [Original data available here](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/) \n\nCurrent dataset was adapted to ARFF format from the UCI version. Sample code ID's were removed.  \n\n! Note that there is also a related Breast Cancer Wisconsin (Original) Data Set with a different set of features, better known as [breast-w](https://www.openml.org/d/15).\n\n\n### Feature description  \n\nTen real-valued features are computed for each of 3 cell nuclei, yielding a total of 30 descriptive features. See the papers below for more details on how they were computed. The 10 features (in order) are:  \n\na) radius (mean of distances from center to points on the perimeter)  \nb) texture (standard deviation of gray-scale values)  \nc) perimeter  \nd) area  \ne) smoothness (local variation in radius lengths)  \nf) compactness (perimeter^2 / area - 1.0)  \ng) concavity (severity of concave portions of the contour)  \nh) concave points (number of concave portions of the contour)  \ni) symmetry  \nj) fractal dimension (\"coastline approximation\" - 1)  \n\n### Relevant Papers   \n\nW.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. \n\nO.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1510_wdbc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 31, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1510-wdbc"}, "LL0_1511_wholesale_customers": {"pipeline": {"_id": "982b9777-8f8c-4115-a9db-e01371c8bc5d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 58}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 666, "max_depth": 7, "learning_rate": 0.5530635844436306, "gamma": 0.274876910269758, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "982b9777-8f8c-4115-a9db-e01371c8bc5d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9271176428233998, "rank": 0.07288235717690143, "metric": "f1Macro", "ts": "2018-10-25T00:20:11.877000", "dataset": "LL0_1511_wholesale_customers_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1511_wholesale_customers", "about": {"problemID": "LL0_1511_wholesale_customers_problem", "problemName": "LL0_1511_wholesale_customers_problem", "problemDescription": "**Author**: Margarida G. M. S. Cardoso      \n**Source**: UCI     \n**Please cite**: Abreu, N. (2011). Analise do perfil do cliente Recheio e desenvolvimento de um sistema promocional. Mestrado em Marketing, ISCTE-IUL, Lisbon.  \n\n* Title:   \nWholesale customers Data Set \n\n* Abstract:   \nThe data set refers to clients of a wholesale distributor. It includes the annual spending in monetary units (m.u.) on diverse product categories\n\n* Source:  \nMargarida G. M. S. Cardoso, margarida.cardoso '@' iscte.pt, ISCTE-IUL, Lisbon, Portugal\n\n* Attribute Information:\n\n1) FRESH: annual spending (m.u.) on fresh products (Continuous); \n2) MILK: annual spending (m.u.) on milk products (Continuous); \n3) GROCERY: annual spending (m.u.)on grocery products (Continuous); \n4) FROZEN: annual spending (m.u.)on frozen products (Continuous) \n5) DETERGENTS_PAPER: annual spending (m.u.) on detergents and paper products (Continuous) \n6) DELICATESSEN: annual spending (m.u.)on and delicatessen products (Continuous); \n7) CHANNEL: customers' Channel - Horeca (Hotel/Restaurant/Caf\u00e9) or Retail channel (Nominal) \n8) REGION: customers' Region - Lisbon, Porto or Other (Nominal) \n\nDescriptive Statistics: \n\n(Minimum, Maximum, Mean, Std. Deviation) \nFRESH ( 3, 112151, 12000.30, 12647.329) \nMILK (55, 73498, 5796.27, 7380.377) \nGROCERY (3, 92780, 7951.28, 9503.163) \nFROZEN (25, 60869, 3071.93, 4854.673) \nDETERGENTS_PAPER (3, 40827, 2881.49, 4767.854) \nDELICATESSEN (3, 47943, 1524.87, 2820.106) \n\nREGION Frequency \nLisbon 77 \nOporto 47 \nOther Region 316 \nTotal 440 \n\nCHANNEL Frequency \nHoreca 298 \nRetail 142 \nTotal 440 \n\n\n* Relevant Papers:\n\nCardoso, Margarida G.M.S. (2013). Logical discriminant models \u00e2\u20ac\u201c Chapter 8 in Quantitative Modeling in Marketing and Management Edited by Luiz Moutinho and Kun-Huang Huarng. World Scientific. p. 223-253. ISBN 978-9814407717 \n\nJean-Patrick Baudry, Margarida Cardoso, Gilles Celeux, Maria Jos\u00c3\u00a9 Amorim, Ana Sousa Ferreira (2012). Enhancing the selection of a model-based clustering with external qualitative variables. RESEARCH REPORT N\u00c2\u00b0 8124, October 2012, Project-Team SELECT. INRIA Saclay - \u00c3\u017dle-de-France, Projet select, Universit\u00c3\u00a9 Paris-Sud 11", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1511_wholesale_customers_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Channel"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1511-wholesale-customers"}, "LL0_1515_micro_mass": {"pipeline": {"_id": "16bacfb4-5f94-4f2e-9919-da9fe187205b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 10}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 91, "max_depth": 9, "learning_rate": 0.2255119754796746, "gamma": 0.3005806250207498, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "16bacfb4-5f94-4f2e-9919-da9fe187205b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8639807629590912, "rank": 0.1360192370416981, "metric": "f1Macro", "ts": "2018-10-25T01:40:07.785000", "dataset": "LL0_1515_micro_mass_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1515_micro_mass", "about": {"problemID": "LL0_1515_micro_mass_problem", "problemName": "LL0_1515_micro_mass_problem", "problemDescription": "**Author**: Pierre Mah\u00e9, Jean-Baptiste Veyrieras  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MicroMass) - 2014  \n**Please cite**:   \n\n### Description\n\nMicroMass (pure spectra version) is a dataset to explore machine learning approaches for the identification of microorganisms from mass-spectrometry data.  \n\n### Source\n```\nPierre Mah\u00e9, pierre.mahe '@' biomerieux.com, bioM\u00e9rieux\nJean-Baptiste Veyrieras, jean-baptiste.veyrieras '@' biomerieux.com, bioM\u00e9rieux\n```\n\n### Data Set Information\n\nThis MALDI-TOF dataset consists in:\n\na) A reference panel of 20 Gram positive and negative bacterial species covering 9 genera among which several species are known to be hard to discriminate by mass spectrometry (MALDI-TOF). Each species was represented by 11 to 60 mass spectra obtained from 7 to 20 bacterial strains, constituting altogether a dataset of 571 spectra obtained from 213 strains. The spectra were obtained according to the standard culture-based workflow used in clinical routine in which the microorganism was first grown on an agar plate for 24 to 48 hours before a portion of the colony was picked, spotted on a MALDI slide and a mass spectrum was acquired. \n\nb) Based on this reference panel, a dedicated in vitro mock-up mixture dataset was constituted. For that purpose we considered 10 pairs of species of various taxonomic proximity:\n* 4 mixtures, labeled A, B, C and D, involved species that belong to the same genus,  \n* 2 mixtures, labeled E and F, involved species that belong to distinct genera, but to the same Gram type,  \n* 4 mixtures, labeled G, H, I and J, involved species that belong to distinct Gram types.  \nEach mixture was represented by 2 pairs of strains, which were mixed according to the following 9 concentration ratios : 1:0, 10:1, 5:1, 2:1, 1:1, 1:2, 1:5, 1:10, 0:1. Two replicate spectra were acquired for each concentration ratio and each couple of strains, leading altogether to a dataset of 360 spectra, among which 80 are actually pure sample spectra.\n\n### Relevant Papers\n\nMah\u00e9 et al. (2014). Automatic identification of mixed bacterial species fingerprints in a MALDI-TOF mass-spectrum. Bioinformatics.\n\nVervier et al., A benchmark of support vector machines strategies for microbial identification by mass-spectrometry data, submitted", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1515_micro_mass_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1301, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1515-micro-mass"}, "LL0_1520_robot_failures_lp5": {"pipeline": {"_id": "85550e14-1251-4b94-a4ef-246eab84c33e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 50}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 3, "min_samples_split": 0.005560168164316936, "min_samples_leaf": 0.1171456486984502, "n_estimators": 148, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "85550e14-1251-4b94-a4ef-246eab84c33e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.724031746031746, "rank": 0.2759682539683649, "metric": "f1Macro", "ts": "2018-10-25T05:30:23.330000", "dataset": "LL0_1520_robot_failures_lp5_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1520_robot_failures_lp5", "about": {"problemID": "LL0_1520_robot_failures_lp5_problem", "problemName": "robot_failures_lp5_problem", "problemDescription": "**Author**: Luis Seabra Lope, Luis M. Camarinha-Matos    \n**Source**: UCI   \n**Please cite**:   \n\n* Dataset Title:   \nRobot Execution Failures Data Set \n\n* Abstract:   \nThis dataset contains force and torque measurements on a robot after failure detection. Each failure is characterized by 15 force/torque samples collected at regular time intervals\n\n\n* Source:  \n\nOriginal Owner and Donor\n\nLuis Seabra Lopes and Luis M. Camarinha-Matos, Universidade Nova de Lisboa, Monte da Caparica, Portugal \n\n\n* Data Set Information:\n\nThe donation includes 5 datasets, each of them defining a different learning problem: \n\n* LP1: failures in approach to grasp position   \n* LP2: failures in transfer of a part   \n* LP3: position of part after a transfer failure   \n* LP4: failures in approach to ungrasp position   \n* LP5 (This dataset): failures in motion with part   \n\nIn order to improve classification accuracy, a set of five feature transformation strategies (based on statistical summary features, discrete Fourier transform, etc.) was defined and evaluated. This enabled an average improvement of 20% in accuracy. The most accessible reference is [Seabra Lopes and Camarinha-Matos, 1998].\n\n\n* Attribute Information:\n\nAll features are numeric although they are integer valued only. Each feature represents a force or a torque measured after failure detection; each failure instance is characterized in terms of 15 force/torque samples collected at regular time intervals starting immediately after failure detection; The total observation window for each failure instance was of 315 ms. \n\nEach example is described as follows: \n\nclass    \nFx1 Fy1 Fz1 Tx1 Ty1 Tz1    \nFx2 Fy2 Fz2 Tx2 Ty2 Tz2    \n......    \nFx15 Fy15 Fz15 Tx15 Ty15 Tz15   \n\nwhere Fx1 ... Fx15 is the evolution of force Fx in the observation window, the same for Fy, Fz and the torques; there is a total of 90 features.\n\n\n* Relevant Papers:\n\nSeabra Lopes, L. (1997) \"Robot Learning at the Task Level: a Study in the Assembly Domain\", Ph.D. thesis, Universidade Nova de Lisboa, Portugal. \n\nSeabra Lopes, L. and L.M. Camarinha-Matos (1998) Feature Transformation Strategies for a Robot Learning Problem, \"Feature Extraction, Construction and Selection. A Data Mining Perspective\", H. Liu and H. Motoda (edrs.), Kluwer Academic Publishers. \n\nCamarinha-Matos, L.M., L. Seabra Lopes, and J. Barata (1996) Integration and Learning in Supervision of Flexible Assembly Systems, \"IEEE Transactions on Robotics and Automation\", 12 (2), 202-219.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1520_robot_failures_lp5_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 91, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1520-robot-failures-lp5"}, "LL0_1523_vertebra_column": {"pipeline": {"_id": "561b08f2-3f54-485e-b946-104627ee1b31", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 886, "max_depth": 9, "learning_rate": 0.6782376882215508, "gamma": 0.4391690890008748, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "561b08f2-3f54-485e-b946-104627ee1b31", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8309029926187055, "rank": 0.16909700738174074, "metric": "f1Macro", "ts": "2018-10-24T23:53:37.857000", "dataset": "LL0_1523_vertebra_column_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1523_vertebra_column", "about": {"problemID": "LL0_1523_vertebra_column_problem", "problemName": "LL0_1523_vertebra_column_problem", "problemDescription": "**Author**: Guilherme de Alencar Barreto, Ajalmar R. da Rocha Neto, Henrique Antonio Fonseca da Mota Filho       \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title: Vertebra Column - 3 classes\n\n* Abstract:   \nData set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).\n\n* Source:\n\nGuilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar R. da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of Cear\u00e1, Fortaleza, Cear\u00e1, Brazil. \n\nHenrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Cear\u00e1, Brazil.\n\n\nData Set Information:\n\nBiomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre M\u00e9dico-Chirurgical de R\u00e9adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.\n\n\nAttribute Information:\n\nEach patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).\n\n\n* Relevant Papers:\n\n(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40\u00e2\u20ac\u201c47. \n\n(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496. \n\n(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Option\u00e2\u20ac\u009d, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1523_vertebra_column_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1523-vertebra-column"}, "LL0_1524_vertebra_column": {"pipeline": {"_id": "e6722141-a0ad-4231-bee0-526368fe725d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 54}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 22, "min_samples_split": 0.10884282254782232, "min_samples_leaf": 0.053055977115310245, "n_estimators": 10, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "e6722141-a0ad-4231-bee0-526368fe725d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8138681502134835, "rank": 0.18613184978711744, "metric": "f1Macro", "ts": "2018-10-25T04:34:27.325000", "dataset": "LL0_1524_vertebra_column_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1524_vertebra_column", "about": {"problemID": "LL0_1524_vertebra_column_problem", "problemName": "LL0_1524_vertebra_column_problem", "problemDescription": "**Author**: Guilherme de Alencar Barreto, Ajalmar R. da Rocha Neto, Henrique Antonio Fonseca da Mota Filho       \n**Source**: [original](http://www.openml.org/d/1523) - UCI   \n**Please cite**:   \n\n* Dataset Title: Vertebra Column - 2 classes\n\n* Abstract:   \nData set containing values for six biomechanical features used to classify orthopaedic patients into 3 classes (normal, disk hernia or spondilolysthesis) or 2 classes (normal or abnormal).\n\n* Source:\n\nGuilherme de Alencar Barreto (guilherme '@' deti.ufc.br) & Ajalmar R. da Rocha Neto (ajalmar '@' ifce.edu.br), Department of Teleinformatics Engineering, Federal University of Cear\u00e1, Fortaleza, Cear\u00e1, Brazil. \n\nHenrique Antonio Fonseca da Mota Filho (hdamota '@' gmail.com), Hospital Monte Klinikum, Fortaleza, Cear\u00e1, Brazil.\n\n\n* Data Set Information:\n\nBiomedical data set built by Dr. Henrique da Mota during a medical residence period in the Group of Applied Research in Orthopaedics (GARO) of the Centre M\u00e9dico-Chirurgical de R\u00e9adaptation des Massues, Lyon, France. The data have been organized in two different but related classification tasks. The first task consists in classifying patients as belonging to one out of three categories: Normal (100 patients), Disk Hernia (60 patients) or Spondylolisthesis (150 patients). For the second task, the categories Disk Hernia and Spondylolisthesis were merged into a single category labelled as 'abnormal'. Thus, the second task consists in classifying patients as belonging to one out of two categories: Normal (100 patients) or Abnormal (210 patients). We provide files also for use within the WEKA environment.\n\n\n* Attribute Information:\n\nEach patient is represented in the data set by six biomechanical attributes derived from the shape and orientation of the pelvis and lumbar spine (in this order): pelvic incidence, pelvic tilt, lumbar lordosis angle, sacral slope, pelvic radius and grade of spondylolisthesis. The following convention is used for the class labels: DH (Disk Hernia), Spondylolisthesis (SL), Normal (NO) and Abnormal (AB).\n\n\n* Relevant Papers:\n\n(1) Berthonnaud, E., Dimnet, J., Roussouly, P. & Labelle, H. (2005). 'Analysis of the sagittal balance of the spine and pelvis using shape and orientation parameters', Journal of Spinal Disorders & Techniques, 18(1):40\u00e2\u20ac\u201c47. \n\n(2) Rocha Neto, A. R. & Barreto, G. A. (2009). 'On the Application of Ensembles of Classifiers to the Diagnosis of Pathologies of the Vertebral Column: A Comparative Analysis', IEEE Latin America Transactions, 7(4):487-496. \n\n(3) Rocha Neto, A. R., Sousa, R., Barreto, G. A. & Cardoso, J. S. (2011). 'Diagnostic of Pathology on the Vertebral Column with Embedded Reject Option\u00e2\u20ac\u009d, Proceedings of the 5th Iberian Conference on Pattern Recognition and Image Analysis (IbPRIA'2011), Gran Canaria, Spain, Lecture Notes on Computer Science, vol. 6669, p. 588-595.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1524_vertebra_column_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1524-vertebra-column"}, "LL0_1525_wall_robot_navigation": {"pipeline": {"_id": "c81d0a21-1899-43f2-be8b-ced1a29bb25e", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 3, "min_samples_split": 0.19782199063783543, "min_samples_leaf": 0.012740382833380293, "n_estimators": 338, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "c81d0a21-1899-43f2-be8b-ced1a29bb25e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 8.811642363636407e-16, "metric": "f1Macro", "ts": "2018-10-25T04:50:41.472000", "dataset": "LL0_1525_wall_robot_navigation_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1525_wall_robot_navigation", "about": {"problemID": "LL0_1525_wall_robot_navigation_problem", "problemName": "LL0_1525_wall_robot_navigation_problem", "problemDescription": "**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     \n**Source**: [original](http://www.openml.org/d/1497) - UCI  \n**Please cite**:   \n\n* Dataset Title: \n\nWall-Following Robot Navigation Data Data Set (version with 2 Attributes)\n\n* Abstract:  \n\nThe data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.\n\n* Source:\n\n(a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto \nDepartment of Teleinformatics Engineering \nFederal University of Cear\u00c3\u00a1 \nFortaleza, Cear\u00c3\u00a1, Brazil \n\n(b) Donors of database: Ananda Freire (anandalf '@' gmail.com) \nGuilherme Barreto (guilherme '@' deti.ufc.br)\n\n* Data Set Information:\n\nThe provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second. \n\nIt is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). \n\nThe wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. \n\nIf some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. \n\n* Attribute Information:\n\nNumber of Attributes: sensor_readings_2.data: 2 numeric attributes and the class. \n\nFor Each Attribute: \n-- File sensor_readings_2.data: \n1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real) \n2. SD_left: minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real) \n3. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn}     \n\n\n* Relevant Papers:\n\nAnanda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), \n'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation \nTasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), \nValpara\u00c3\u00adso-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1525_wall_robot_navigation_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1525-wall-robot-navigation"}, "LL0_1526_wall_robot_navigation": {"pipeline": {"_id": "d010a785-0819-4f85-87ce-492ea3ba0d8c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 20, "min_samples_split": 0.04824384828098666, "min_samples_leaf": 0.0042549489377354185, "n_estimators": 48, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "d010a785-0819-4f85-87ce-492ea3ba0d8c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 4.8778035439943526e-14, "metric": "f1Macro", "ts": "2018-10-25T06:24:03.295000", "dataset": "LL0_1526_wall_robot_navigation_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1526_wall_robot_navigation", "about": {"problemID": "LL0_1526_wall_robot_navigation_problem", "problemName": "LL0_1526_wall_robot_navigation_problem", "problemDescription": "**Author**: Ananda Freire, Marcus Veloso and Guilherme Barreto     \n**Source**: [original](http://www.openml.org/d/1497) - UCI     \n**Please cite**:   \n\n* Dataset Title: \n\nWall-Following Robot Navigation Data Data Set (version with 4 Attributes)\n\n* Abstract:  \n\nThe data were collected as the SCITOS G5 robot navigates through the room following the wall in a clockwise direction, for 4 rounds, using 24 ultrasound sensors arranged circularly around its 'waist'.\n\n* Source:\n\n(a) Creators: Ananda Freire, Marcus Veloso and Guilherme Barreto \nDepartment of Teleinformatics Engineering \nFederal University of Cear\u00c3\u00a1 \nFortaleza, Cear\u00c3\u00a1, Brazil \n\n(b) Donors of database: Ananda Freire (anandalf '@' gmail.com) \nGuilherme Barreto (guilherme '@' deti.ufc.br)\n\n* Data Set Information:\n\nThe provided file contain the raw values of the measurements of all 24 ultrasound sensors and the corresponding class label. Sensor readings are sampled at a rate of 9 samples per second. \n\nIt is worth mentioning that the 24 ultrasound readings and the simplified distances were collected at the same time step, so each file has the same number of rows (one for each sampling time step). \n\nThe wall-following task and data gathering were designed to test the hypothesis that this apparently simple navigation task is indeed a non-linearly separable classification task. Thus, linear classifiers, such as the Perceptron network, are not able to learn the task and command the robot around the room without collisions. Nonlinear neural classifiers, such as the MLP network, are able to learn the task and command the robot successfully without collisions. \n\nIf some kind of short-term memory mechanism is provided to the neural classifiers, their performances are improved in general. For example, if past inputs are provided together with current sensor readings, even the Perceptron becomes able to learn the task and command the robot successfully. If a recurrent neural network, such as the Elman network, is used to learn the task, the resulting dynamical classifier is able to learn the task using less hidden neurons than the MLP network. \n\n* Attribute Information:\n\nNumber of Attributes: sensor_readings_24.data: 24 numeric attributes and the class. \n\nFor Each Attribute: \n-- File sensor_readings_4.data: \n1. SD_front: minimum sensor reading within a 60 degree arc located at the front of the robot - (numeric: real) \n2. SD_left: minimum sensor reading within a 60 degree arc located at the left of the robot - (numeric: real) \n3. SD_right: minimum sensor reading within a 60 degree arc located at the right of the robot - (numeric: real) \n4. SD_back: minimum sensor reading within a 60 degree arc located at the back of the robot - (numeric: real) \n5. Class: {Move-Forward, Slight-Right-Turn, Sharp-Right-Turn, Slight-Left-Turn}   \n\n\n* Relevant Papers:\n\nAnanda L. Freire, Guilherme A. Barreto, Marcus Veloso and Antonio T. Varela (2009), \n'Short-Term Memory Mechanisms in Neural Network Learning of Robot Navigation \nTasks: A Case Study'. Proceedings of the 6th Latin American Robotics Symposium (LARS'2009), \nValpara\u00c3\u00adso-Chile, pages 1-6, DOI: 10.1109/LARS.2009.5418323", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1526_wall_robot_navigation_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1526-wall-robot-navigation"}, "LL0_1527_volcanoes_a1": {"pipeline": {"_id": "b18d6eb2-44ad-4eb0-95fb-343f1ceda3f6", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 41}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 618, "max_depth": 7, "learning_rate": 0.5277035504810665, "gamma": 0.059127580360902154, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "b18d6eb2-44ad-4eb0-95fb-343f1ceda3f6", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8022027036185253, "rank": 0.19779729638147858, "metric": "f1Macro", "ts": "2018-10-25T01:03:22.013000", "dataset": "LL0_1527_volcanoes_a1_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1527_volcanoes_a1", "about": {"problemID": "LL0_1527_volcanoes_a1_problem", "problemName": "LL0_1527_volcanoes_a1_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: A1        \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n[Web Link] \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n[Web Link] \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n[Web Link] \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995). \n[Web Link]", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1527_volcanoes_a1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1527-volcanoes-a1"}, "LL0_1528_volcanoes_a2": {"pipeline": {"_id": "f4cb57d4-2567-42be-af58-13266c05fd9c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 99}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 174, "max_depth": 6, "learning_rate": 0.031798832750832506, "gamma": 0.8038405684589063, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f4cb57d4-2567-42be-af58-13266c05fd9c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.40206319929849343, "rank": 0.5979368007016499, "metric": "f1Macro", "ts": "2018-10-25T01:29:41.738000", "dataset": "LL0_1528_volcanoes_a2_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1528_volcanoes_a2", "about": {"problemID": "LL0_1528_volcanoes_a2_problem", "problemName": "LL0_1528_volcanoes_a2_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: A2        \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1528_volcanoes_a2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1528-volcanoes-a2"}, "LL0_1529_volcanoes_a3": {"pipeline": {"_id": "e73246b5-0bc9-42bd-9aef-3b0b385dc06f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 88}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 465, "max_depth": 10, "learning_rate": 0.6357001707919645, "gamma": 0.32760618619606974, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "e73246b5-0bc9-42bd-9aef-3b0b385dc06f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.4095393584997451, "rank": 0.5904606415004032, "metric": "f1Macro", "ts": "2018-10-25T01:10:22.814000", "dataset": "LL0_1529_volcanoes_a3_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1529_volcanoes_a3", "about": {"problemID": "LL0_1529_volcanoes_a3_problem", "problemName": "LL0_1529_volcanoes_a3_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: A3       \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1529_volcanoes_a3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1529-volcanoes-a3"}, "LL0_1530_volcanoes_a4": {"pipeline": {"_id": "82be6a83-d8c2-4721-baad-bbe1fa4faaa3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 55}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 339, "max_depth": 7, "learning_rate": 0.9297145511330555, "gamma": 0.7196110708867842, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "82be6a83-d8c2-4721-baad-bbe1fa4faaa3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.40023289449054067, "rank": 0.5997671055094992, "metric": "f1Macro", "ts": "2018-10-25T01:09:51.339000", "dataset": "LL0_1530_volcanoes_a4_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1530_volcanoes_a4", "about": {"problemID": "LL0_1530_volcanoes_a4_problem", "problemName": "LL0_1530_volcanoes_a4_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: A4       \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1530_volcanoes_a4_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1530-volcanoes-a4"}, "LL0_1531_volcanoes_b1": {"pipeline": {"_id": "9e20da6c-e384-4e75-90c1-abdeb757b7c9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 23}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 791, "max_depth": 5, "learning_rate": 0.9624534811158214, "gamma": 0.1693625918756908, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9e20da6c-e384-4e75-90c1-abdeb757b7c9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.3347852769899251, "rank": 0.6652147230104245, "metric": "f1Macro", "ts": "2018-10-25T00:38:50.463000", "dataset": "LL0_1531_volcanoes_b1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1531_volcanoes_b1", "about": {"problemID": "LL0_1531_volcanoes_b1_problem", "problemName": "LL0_1531_volcanoes_b1_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: B1        \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1531_volcanoes_b1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1531-volcanoes-b1"}, "LL0_1534_volcanoes_b4": {"pipeline": {"_id": "f0839e9f-1f41-411e-aa7e-677b277db735", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 600, "max_depth": 9, "learning_rate": 0.6415942336794379, "gamma": 0.5989779498490703, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "f0839e9f-1f41-411e-aa7e-677b277db735", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.35420077638456926, "rank": 0.6457992236164148, "metric": "f1Macro", "ts": "2018-10-31T05:10:39.313000", "dataset": "LL0_1534_volcanoes_b4_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1534_volcanoes_b4", "about": {"problemID": "LL0_1534_volcanoes_b4_problem", "problemName": "LL0_1534_volcanoes_b4_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: B4        \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1534_volcanoes_b4_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1534-volcanoes-b4"}, "LL0_1538_volcanoes_d1": {"pipeline": {"_id": "6533d881-78cd-4cd4-ae33-c615f9b1855c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 55}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 597, "max_depth": 10, "learning_rate": 0.5181602377698546, "gamma": 0.0904985264432947, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6533d881-78cd-4cd4-ae33-c615f9b1855c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.2865297003761341, "rank": 0.7134702996239896, "metric": "f1Macro", "ts": "2018-10-25T01:34:25.398000", "dataset": "LL0_1538_volcanoes_d1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1538_volcanoes_d1", "about": {"problemID": "LL0_1538_volcanoes_d1_problem", "problemName": "LL0_1538_volcanoes_d1_problem", "problemDescription": "**Author**: Michael C. Burl \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \nVolcanoes on Venus - JARtool experiment Data Set  \nExperiment: D1        \n\n* Source:\n\nMichael C. Burl \nMS 126-347, JPL \n4800 Oak Grove Drive \nPasadena, CA 91109 \n(818) 393-5345 \nMichael.C.Burl '@' jpl.nasa.gov \nhttp://www-aig.jpl.nasa.gov/mls/home/burl/\n\n\n* Data Set Information:  \n\nThe data was collected by the Magellan spacecraft over an approximately four year period from 1990--1994. The objective of the mission was to obtain global mapping of the surface of Venus using synthetic aperture radar (SAR). A more detailed discussion of the mission and objectives is available at JPL's Magellan webpage. \n\nThere are some spatial dependencies. For example, background patches from with in a single image are likely to be more similar than background patches taken across different images. \n\nIn addition to the images, there are \"ground truth\" files that specify the locations of volcanoes within the images. The quotes around \"ground truth\" are intended as a reminder that there is no absolute ground truth for this data set. No one has been to Venus and the image quality does not permit 100%, unambiguous identification of the volcanoes, even by human experts. There are labels that provide some measure of subjective uncertainty (1 = definitely a volcano, 2 = probably, 3 = possibly, 4 = only a pit is visible). See reference [Smyth95] for more information on the labeling uncertainty problem. \n\nThere are also files that specify the exact set of experiments using in the published evaluations of the JARtool system. \n\n* Attribute Information:\n\nThe images are 1024X1024 pixels. The pixel values are in the range [0,255]. The pixel value is related to the amount of energy backscattered to the radar from a given spatial location. Higher pixel values indicate greater backscatter. Lower pixel values indicate lesser backscatter. Both topography and surface roughness relative to the radar wavelength affect the amount of backscatter.\n\n\n* Relevant Papers:\n\nG.H. Pettengill, P.G. Ford, W.T.K. Johnson, R.K. Raney, L.A. Soderblom, \"Magellan: Radar Performance and Data Products\", Science, 252:260-265 (1991). \n\nR.S. Saunders, A.J. Spear, P.C. Allin, R.S. Austin, A.L. Berman, R.C. Chandlee, J. Clark, A.V. Decharon, E.M. Dejong, \"Magellan Mission Summary\", J. of Geophysical Research Planets, 97(E8):13067-13090, (1992). \n\nM.C. Burl, L. Asker, P. Smyth, U. Fayyad, P. Perona, L. Crumpler, and J. Aubele, \"Learning to Recognize Volcanoes on Venus\", Machine Learning, (March 1998). \n\nP. Smyth, M.C. Burl, U.M. Fayyad, and P. Perona, Chapter: \"Knowledge Discovery in Large Image Databases: Dealing with Uncertainties in Ground Truth\", In Advances in Knowledge Discovery and Data Mining, AAAI/MIT Press, Menlo Park, CA, (1995).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1538_volcanoes_d1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1538-volcanoes-d1"}, "LL0_1547_autouniv_au1_1000": {"pipeline": {"_id": "f3d78422-a9ca-48e0-917c-701bd49a6b2f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 90}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 67, "max_depth": 5, "learning_rate": 0.015890623000160975, "gamma": 0.7814080478804399, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f3d78422-a9ca-48e0-917c-701bd49a6b2f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6850822414460265, "rank": 0.3149177585541466, "metric": "f1Macro", "ts": "2018-10-24T23:52:51.823000", "dataset": "LL0_1547_autouniv_au1_1000_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1547_autouniv_au1_1000", "about": {"problemID": "LL0_1547_autouniv_au1_1000_problem", "problemName": "LL0_1547_autouniv_au1_1000_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au1-1000   \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1547_autouniv_au1_1000_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1547-autouniv-au1-1000"}, "LL0_1548_autouniv_au4_2500": {"pipeline": {"_id": "06d6a361-4b07-44ee-b365-77b1daa01b99", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 68}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 986, "max_depth": 6, "learning_rate": 0.27447375788573436, "gamma": 0.11940262238698085, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "06d6a361-4b07-44ee-b365-77b1daa01b99", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.4537374781787508, "rank": 0.5462625218216492, "metric": "f1Macro", "ts": "2018-10-25T01:08:28.808000", "dataset": "LL0_1548_autouniv_au4_2500_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1548_autouniv_au4_2500", "about": {"problemID": "LL0_1548_autouniv_au4_2500_problem", "problemName": "LL0_1548_autouniv_au4_2500_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au4-2500    \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1548_autouniv_au4_2500_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 101, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1548-autouniv-au4-2500"}, "LL0_1549_autouniv_au6_750": {"pipeline": {"_id": "7311aea5-e1ce-46d7-a3bd-842077cee180", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 11}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 569, "max_depth": 8, "learning_rate": 0.38361785727253805, "gamma": 0.5134140176923415, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "7311aea5-e1ce-46d7-a3bd-842077cee180", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.19717928024112114, "rank": 0.8028207197591725, "metric": "f1Macro", "ts": "2018-10-25T06:28:46.050000", "dataset": "LL0_1549_autouniv_au6_750_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1549_autouniv_au6_750", "about": {"problemID": "LL0_1549_autouniv_au6_750_problem", "problemName": "LL0_1549_autouniv_au6_750_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au6-250-drift-au6-cd1-500     \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1549_autouniv_au6_750_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1549-autouniv-au6-750"}, "LL0_1551_autouniv_au6_400": {"pipeline": {"_id": "53245678-b61e-4d30-a91a-57904eec38e2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 12}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 98, "max_depth": 7, "learning_rate": 0.9779679152724843, "gamma": 0.6590239761372828, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "53245678-b61e-4d30-a91a-57904eec38e2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.23982601224735092, "rank": 0.7601739877528703, "metric": "f1Macro", "ts": "2018-10-25T01:09:53.775000", "dataset": "LL0_1551_autouniv_au6_400_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1551_autouniv_au6_400", "about": {"problemID": "LL0_1551_autouniv_au6_400_problem", "problemName": "LL0_1551_autouniv_au6_400_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au6-cd1-400    \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1551_autouniv_au6_400_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1551-autouniv-au6-400"}, "LL0_1552_autouniv_au7_1100": {"pipeline": {"_id": "8de0b1ca-2972-4b84-9113-7ec85cdfe8ba", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 63}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 961, "max_depth": 5, "learning_rate": 0.004977214778666972, "gamma": 0.8286222664031353, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "8de0b1ca-2972-4b84-9113-7ec85cdfe8ba", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.42538937556852474, "rank": 0.5746106244317942, "metric": "f1Macro", "ts": "2018-10-25T00:03:36.234000", "dataset": "LL0_1552_autouniv_au7_1100_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1552_autouniv_au7_1100", "about": {"problemID": "LL0_1552_autouniv_au7_1100_problem", "problemName": "LL0_1552_autouniv_au7_1100_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au7-300-drift-au7-cpd1-800 \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1552_autouniv_au7_1100_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1552-autouniv-au7-1100"}, "LL0_1553_autoUniv_au7_700": {"pipeline": {"_id": "d07ba7ef-0288-44f5-92f7-d99e4ee02b6e", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 818, "max_depth": 10, "learning_rate": 0.17322237621821213, "gamma": 0.5192590268088897, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "d07ba7ef-0288-44f5-92f7-d99e4ee02b6e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5256105688822907, "rank": 0.4743894311181327, "metric": "f1Macro", "ts": "2018-10-25T01:56:06.703000", "dataset": "LL0_1553_autoUniv_au7_700_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1553_autoUniv_au7_700", "about": {"problemID": "LL0_1553_autoUniv_au7_700_problem", "problemName": "autoUniv_au7_700_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au7-700     \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1553_autoUniv_au7_700_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1553-autoUniv-au7-700"}, "LL0_1554_autouniv_au7_500": {"pipeline": {"_id": "e52c6a58-6005-4f38-b486-45dfff0d433b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 28}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 326, "max_depth": 4, "learning_rate": 0.5347512475907272, "gamma": 0.6134927385696273, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "e52c6a58-6005-4f38-b486-45dfff0d433b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.40888810259212266, "rank": 0.5911118974084463, "metric": "f1Macro", "ts": "2018-10-25T00:53:27.490000", "dataset": "LL0_1554_autouniv_au7_500_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1554_autouniv_au7_500", "about": {"problemID": "LL0_1554_autouniv_au7_500_problem", "problemName": "LL0_1554_autouniv_au7_500_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au7-cpd1-500    \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1554_autouniv_au7_500_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1554-autouniv-au7-500"}, "LL0_1555_autoUniv_au6_1000": {"pipeline": {"_id": "b5bb5faa-09a2-4836-9f12-78e100dea318", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 15, "min_samples_split": 0.029412812158553358, "min_samples_leaf": 0.020542408689985286, "n_estimators": 450, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "b5bb5faa-09a2-4836-9f12-78e100dea318", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.21659634547286988, "rank": 0.7834036545274907, "metric": "f1Macro", "ts": "2018-10-25T04:40:10.402000", "dataset": "LL0_1555_autoUniv_au6_1000_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1555_autoUniv_au6_1000", "about": {"problemID": "LL0_1555_autoUniv_au6_1000_problem", "problemName": "autoUniv_au6_1000_problem", "problemDescription": "**Author**: Ray. J. Hickey   \n**Source**: UCI  \n**Please cite**:   \n\n* Dataset Title:  \n\nAutoUniv Dataset  \ndata problem: autoUniv-au6-1000    \n\n* Abstract:   \n\nAutoUniv is an advanced data generator for classifications tasks. The aim is to reflect the nuances and heterogeneity of real data. Data can be generated in .csv, ARFF or C4.5 formats.\n\n* Source:  \n\nAutoUniv was developed by Ray. J. Hickey. Email: ray.j.hickey '@' gmail.com \nAutoUniv web-site: http://sites.google.com/site/autouniv/.\n\n\n* Data Set Information:\n\nThe user first creates a classification model and then generates classified examples from it. To create a model, the following are specified: the number of attributes (up to 1000) and their type (discrete or continuous), the number of classes (up to 10), the complexity of the underlying rules and the noise level. AutoUniv then produces a model through a process of constrained randomised search to satisfy the user's requirements. A model can have up to 3000 rules. Rare class models can be designed. A sequence of models can be designed to reflect concept and/or population drift. \n\nAutoUniv creates three text files for a model: a Prolog specification of the model used to generate examples (.aupl); a user-friendly statement of the classification rules in an 'if ... then' format (.aurules); a statistical summary of the main properties of the model, including its Bayes rate (.auprops).\n\n\n* Attribute Information: \n\nAttributes may be discrete with up to 10 values or continuous. A discrete attribute can be nominal with values v1, v2, v3 ... or integer with values 0, 1, 2 , ... .\n\n\n* Relevant Papers:\n\nMarrs, G, Hickey, RJ and Black, MM (2010) Modeling the example life-cycle in an online classification learner. In Proceedings of HaCDAIS 2010: International Workshop on Handling Concept Drift in Adaptive Information Systems. \n[Web Link]#proc . \n\nMarrs, G, Hickey, RJ and Black, MM (2010) The Impact of Latency on Online Classification Learning with Concept Drift. In Y. Bi and M.A. Williams (Eds.): KSEM 2010, LNAI 6291, Springer-Verlag, Berlin, pp. 459\u00e2\u20ac\u201c469. \n\nHickey, RJ (2007) Structure and Majority Classes in Decision Tree Learning. Journal of Machine Learning Research, 8, pp. 1747-1768.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1555_autoUniv_au6_1000_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1555-autoUniv-au6-1000"}, "LL0_1557_abalone": {"pipeline": {"_id": "fd829a15-0045-42a3-bf5f-434d2ee79885", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 10}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 7, "min_samples_split": 0.00837683487143447, "min_samples_leaf": 0.0003949933237880684, "n_estimators": 405, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "fd829a15-0045-42a3-bf5f-434d2ee79885", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6604789258049262, "rank": 0.3395210741956149, "metric": "f1Macro", "ts": "2018-10-25T06:08:32.027000", "dataset": "LL0_1557_abalone_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1557_abalone", "about": {"problemID": "LL0_1557_abalone_problem", "problemName": "LL0_1557_abalone_problem", "problemDescription": "**Author**:   \n**Source**: [original](http://www.openml.org/d/183) - UCI    \n**Please cite**:   \n\n* Abstract: \n\nA 3-class version of abalone dataset.\n\n* Sources:  \n\n(a) Original owners of database: Marine Resources Division Marine Research Laboratories - Taroona Department of Primary Industry and Fisheries, Tasmania GPO Box 619F, Hobart, Tasmania 7001, Australia (contact: Warwick Nash +61 02 277277, wnash@dpi.tas.gov.au)\n\n(b) Donor of database: Sam Waugh (Sam.Waugh@cs.utas.edu.au) Department of Computer Science, University of Tasmania GPO Box 252C, Hobart, Tasmania 7001, Australia", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1557_abalone_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1557-abalone"}, "LL0_155_pokerhand": {"pipeline": {"_id": "fb09371f-fa11-4fa5-bd30-1bd239e8ac29", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 80, "max_depth": 6, "learning_rate": 0.8247720401037858, "gamma": 0.6107283173481408, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "fb09371f-fa11-4fa5-bd30-1bd239e8ac29", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7647020995692613, "rank": 0.2352979004310309, "metric": "f1Macro", "ts": "2018-10-31T05:17:43.511000", "dataset": "LL0_155_pokerhand_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_155_pokerhand", "about": {"problemID": "LL0_155_pokerhand_problem", "problemName": "LL0_155_pokerhand_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nNormalized version of the pokerhand data set.\n\nAutomated file upload of pokerhand-normalized.arff", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_155_pokerhand_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-155-pokerhand"}, "LL0_1560_cardiotocography": {"pipeline": {"_id": "b45878b4-4749-4f37-bf3a-215278d1c0a1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 51}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 132, "max_depth": 4, "learning_rate": 0.4816296725895064, "gamma": 0.8675938869315322, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "b45878b4-4749-4f37-bf3a-215278d1c0a1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9861475130639608, "rank": 0.013852486936086582, "metric": "f1Macro", "ts": "2018-10-25T00:04:28.234000", "dataset": "LL0_1560_cardiotocography_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1560_cardiotocography", "about": {"problemID": "LL0_1560_cardiotocography_problem", "problemName": "LL0_1560_cardiotocography_problem", "problemDescription": "**Author**: J. P. Marques de S\u00e1, J. Bernardes, D. Ayers de Campos.  \n**Source**: [original](http://www.openml.org/d/1466) - UCI   \n**Please cite**:     \n\nA 3-class version of Cardiotocography dataset.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1560_cardiotocography_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 36, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1560-cardiotocography"}, "LL0_1569_poker_hand": {"pipeline": {"_id": "9593d814-6fcd-465e-a56e-d2d836f1cde6", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 6}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 392, "max_depth": 6, "learning_rate": 0.8681331637873516, "gamma": 0.19617083158703563, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "9593d814-6fcd-465e-a56e-d2d836f1cde6", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5747183808298458, "rank": 0.42528161917023766, "metric": "f1Macro", "ts": "2018-10-25T10:05:42.934000", "dataset": "LL0_1569_poker_hand_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1569_poker_hand", "about": {"problemID": "LL0_1569_poker_hand_problem", "problemName": "LL0_1569_poker_hand_problem", "problemDescription": "**Author**: Robert Cattral, Franz Oppacher    \n**Source**: [original](http://www.openml.org/d/1567) - UCI    \n**Please cite**:   \n\n* Abstract:\n9-class version of poker-hand dataset, it was removed the minority class.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1569_poker_hand_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1569-poker-hand"}, "LL0_1570_wilt": {"pipeline": {"_id": "49e6a971-a245-4d67-b2be-80b60648b2ba", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 19}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 901, "max_depth": 3, "learning_rate": 0.9288926069350657, "gamma": 0.44783408713273654, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "49e6a971-a245-4d67-b2be-80b60648b2ba", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9334837129012268, "rank": 0.06651628709912391, "metric": "f1Macro", "ts": "2018-10-25T01:24:35.367000", "dataset": "LL0_1570_wilt_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1570_wilt", "about": {"problemID": "LL0_1570_wilt_problem", "problemName": "LL0_1570_wilt_problem", "problemDescription": "**Author**: Brian Johnson     \n**Source**: [UCI] (https://archive.ics.uci.edu/ml/datasets/Wilt)  \n**Please cite**: Johnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.   \n\nHigh-resolution Remote Sensing data set (Quickbird). Small number of training samples of diseased trees, large number for other land cover.\n\n* Source:\n  \nBrian Johnson; \nInstitute for Global Environmental Strategies; \n2108-11 Kamiyamaguchi, Hayama, Kanagawa,240-0115 Japan; \nEmail: Johnson '@' iges.or.jp \n\n\n* Data Set Information:  \n\nThis data set contains some training and testing data from a remote sensing study by Johnson et al. (2013) that involved detecting diseased trees in Quickbird imagery. There are few training samples for the 'diseased trees' class (74) and many for 'other land cover' class (4265). \n\nThe data set consists of image segments, generated by segmenting the pansharpened image. The segments contain spectral information from the Quickbird multispectral image bands and texture information from the panchromatic (Pan) image band. The testing data set is for the row with \u00e2\u20ac\u0153Segmentation scale 15\u00e2\u20ac\u009d segments and \u00e2\u20ac\u0153original multi-spectral image\u00e2\u20ac\u009d Spectral information in Table 2 of the reference (i.e. row 5). Please see the reference below for more information on the data set, and please cite the reference if you use this data set. Enjoy! \n\n* Attribute Information:\n\nclass: 'w' (diseased trees), 'n' (all other land cover)   \nGLCM_Pan: GLCM mean texture (Pan band)   \nMean_G: Mean green value   \nMean_R: Mean red value   \nMean_NIR: Mean NIR value   \nSD_Pan: Standard deviation (Pan band)   \n\n\n* Relevant Papers:\n\nJohnson, B., Tateishi, R., Hoan, N., 2013. A hybrid pansharpening approach and multiscale object-based image analysis for mapping diseased pine and oak trees. International Journal of Remote Sensing, 34 (20), 6969-6982.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1570_wilt_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1570-wilt"}, "LL0_1571_fourclass_scale": {"pipeline": {"_id": "065a860e-a903-4162-8bbd-6070c7f2324e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 93}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 304, "max_depth": 5, "learning_rate": 0.13237857588200708, "gamma": 0.004391006353977378, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "065a860e-a903-4162-8bbd-6070c7f2324e", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.027197430520371168, "rank": 0.027197430521186318, "metric": "meanSquaredError", "ts": "2018-10-24T20:18:35.912000", "dataset": "LL0_1571_fourclass_scale_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1571_fourclass_scale", "about": {"problemID": "LL0_1571_fourclass_scale_problem", "problemName": "fourclass_scale_problem", "problemDescription": "**Author**: Tin Kam Ho and Eugene M. Kleinberg.  \nlibSVM\",\"AAD group  \n**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  \n**Please cite**:   \n\n#Dataset from the LIBSVM data repository.\n\nPreprocessing: transform to two-class", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1571_fourclass_scale_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1571-fourclass-scale"}, "LL0_1589_svmguide3": {"pipeline": {"_id": "5c9da2b3-3651-441e-a1fd-81007b231977", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 70}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 615, "max_depth": 6, "learning_rate": 0.08621832066959245, "gamma": 0.6138623630667461, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "5c9da2b3-3651-441e-a1fd-81007b231977", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.4373841681480185, "rank": 0.43738416814839676, "metric": "meanSquaredError", "ts": "2018-10-24T21:21:36.095000", "dataset": "LL0_1589_svmguide3_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1589_svmguide3", "about": {"problemID": "LL0_1589_svmguide3_problem", "problemName": "svmguide3_problem", "problemDescription": "**Author**: Chih-Wei Hsu\",\"Chih-Chung Chang\",\"and Chih-Jen Lin.  \nlibSVM\",\"AAD group  \n**Source**: [original](http://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html) - Date unknown  \n**Please cite**:   \n\n#Dataset from the LIBSVM data repository.\n\nPreprocessing: Original data: someone from Germany working with the car industry.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_1589_svmguide3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 23, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1589-svmguide3"}, "LL0_15_breast_w": {"pipeline": {"_id": "acb418fb-df38-4588-b8be-21c34d604a6c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 6}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 177, "max_depth": 7, "learning_rate": 0.4352728097722639, "gamma": 0.27202273231232943, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "acb418fb-df38-4588-b8be-21c34d604a6c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9746039339799604, "rank": 0.025396066020258193, "metric": "f1Macro", "ts": "2018-10-24T23:51:52.508000", "dataset": "LL0_15_breast_w_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_15_breast_w", "about": {"problemID": "LL0_15_breast_w_problem", "problemName": "breast_w_problem", "problemDescription": "**Author**: Dr. William H. Wolberg, University of Wisconsin  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)), [University of Wisconsin](http://pages.cs.wisc.edu/~olvi/uwmp/cancer.html) - 1995  \n**Please cite**: See below, plus [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**Breast Cancer Wisconsin (Original) Data Set.** Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. The target feature records the prognosis (malignant or benign). [Original data available here](ftp://ftp.cs.wisc.edu/math-prog/cpo-dataset/machine-learn/cancer/)  \n\nCurrent dataset was adapted to ARFF format from the UCI version. Sample code ID's were removed.  \n\n! Note that there is also a related Breast Cancer Wisconsin (Diagnosis) Data Set with a different set of features, better known as [wdbc](https://www.openml.org/d/1510).\n\n### Relevant Papers  \n\nW.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on Electronic Imaging: Science and Technology, volume 1905, pages 861-870, San Jose, CA, 1993. \n\nO.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and prognosis via linear programming. Operations Research, 43(4), pages 570-577, July-August 1995.  \n\n### Citation request  \n\nThis breast cancer database was obtained from the University of Wisconsin Hospitals, Madison from Dr. William H. Wolberg.  If you publish results when using this database, then please include this information in your acknowledgments.  Also, please cite one or more of:\n\n   1. O. L. Mangasarian and W. H. Wolberg: \"Cancer diagnosis via linear \n      programming\", SIAM News, Volume 23, Number 5, September 1990, pp 1 & 18.\n\n   2. William H. Wolberg and O.L. Mangasarian: \"Multisurface method of \n      pattern separation for medical diagnosis applied to breast cytology\", \n      Proceedings of the National Academy of Sciences, U.S.A., Volume 87, \n      December 1990, pp 9193-9196.\n\n   3. O. L. Mangasarian, R. Setiono, and W.H. Wolberg: \"Pattern recognition \n      via linear programming: Theory and application to medical diagnosis\", \n      in: \"Large-scale numerical optimization\", Thomas F. Coleman and Yuying\n      Li, editors, SIAM Publications, Philadelphia 1990, pp 22-30.\n\n   4. K. P. Bennett & O. L. Mangasarian: \"Robust linear programming \n      discrimination of two linearly inseparable sets\", Optimization Methods\n      and Software 1, 1992, 23-34 (Gordon & Breach Science Publishers).", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_15_breast_w_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-15-breast-w"}, "LL0_16_mfeat_karhunen": {"pipeline": {"_id": "4f02d966-00d9-4fc9-aff2-1167e0204398", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "4f02d966-00d9-4fc9-aff2-1167e0204398", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.944783445491684, "rank": 0.055216554508525556, "metric": "f1Macro", "ts": "2018-10-31T04:09:27.091000", "dataset": "LL0_16_mfeat_karhunen_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_16_mfeat_karhunen", "about": {"problemID": "LL0_16_mfeat_karhunen_problem", "problemName": "mfeat_karhunen_problem", "problemDescription": "**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**Multiple Features Dataset: Karhunen**  \nOne of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. \n\n### Attribute Information  \nThe attributes represent 64 descriptors from the Karhunen-Loeve Transform, a linear transform that corresponds to the projection of the images on the eigenvectors of a covariant matrix. Also see:  \nM.D. Garris et al: NIST Form-Based Handprint Recognition System. Internal Report. National Institute of Standards and Technology, NISTIR 5469, 1994.\n\n### Relevant Papers  \nA slightly different version of the database is used in  \nM. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.\n \nThe database as is is used in:  \nA.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_16_mfeat_karhunen_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 65, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-16-mfeat-karhunen"}, "LL0_179_adult": {"pipeline": {"_id": "3cf35161-12db-4ba2-b361-0b62c092b169", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 250, "max_depth": 4, "learning_rate": 0.09040483196058202, "gamma": 0.07669732309731847, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "3cf35161-12db-4ba2-b361-0b62c092b169", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7928584454926618, "rank": 0.20714155450787675, "metric": "f1Macro", "ts": "2018-10-25T00:29:39.430000", "dataset": "LL0_179_adult_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_179_adult", "about": {"problemID": "LL0_179_adult_problem", "problemName": "LL0_179_adult_problem", "problemDescription": "**Author**: Ronny Kohavi and Barry Becker  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Adult) - 1996-05-01  \n**Please cite**: Ron Kohavi, \"Scaling Up the Accuracy of Naive-Bayes Classifiers: a Decision-Tree Hybrid\", Proceedings of the Second International Conference on Knowledge Discovery and Data Mining, 1996  \n\n**Note: This dataset is not the original UCI dataset. It has some discretized features. See version 2 for the original.**\n\nPrediction task is to determine whether a person makes over 50K a year. Extraction was done by Barry Becker from the 1994 Census database. A set of reasonably clean records was extracted using the following conditions: ((AAGE>16) && (AGI>100) && (AFNLWGT>1)&& (HRSWK>0))\n\nRonny Kohavi and Barry Becker. Data Mining and Visualization, Silicon Graphics.  \ne-mail: ronnyk '@' live.com for questions.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_179_adult_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 15, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-179-adult"}, "LL0_180_covertype": {"pipeline": {"_id": "ad521765-f775-42f6-988a-527d6ac8dd56", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 958, "max_depth": 3, "learning_rate": 0.9123873884522489, "gamma": 0.09506846065225971, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "ad521765-f775-42f6-988a-527d6ac8dd56", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6838816469157278, "rank": 0.3161183530847783, "metric": "f1Macro", "ts": "2018-10-25T01:52:25.165000", "dataset": "LL0_180_covertype_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_180_covertype", "about": {"problemID": "LL0_180_covertype_problem", "problemName": "LL0_180_covertype_problem", "problemDescription": "**Author**: Jock A. Blackard, Dr. Denis J. Dean, Dr. Charles W. Anderson  \n**Source**: Unknown\n\n**Note: This is a 19% subsample from the original UCI dataset (see version 4). The origin is currently not clear.**\n\n**Covertype**  \nPredicting forest cover type from cartographic variables only (no remotely sensed data). The actual forest cover type for a given observation (30 x 30 meter cell) was determined from US Forest Service (USFS) Region 2 Resource Information System &#40;RIS&#41; data. Independent variables were derived from data originally obtained from US Geological Survey (USGS) and USFS data. Data is in raw form (not scaled) and contains binary (0 or 1) columns of data for qualitative independent variables (wilderness areas and soil types). \n\nThis study area includes four wilderness areas located in the Roosevelt National Forest of northern Colorado. These areas represent forests with minimal human-caused disturbances, so that existing forest cover types are more a result of ecological processes rather than forest management practices. \n\nSome background information for these four wilderness areas: Neota (area 2) probably has the highest mean elevational value of the 4 wilderness areas. Rawah (area 1) and Comanche Peak (area 3) would have a lower mean elevational value, while Cache la Poudre (area 4) would have the lowest mean elevational value. \n\nAs for primary major tree species in these areas, Neota would have spruce/fir (type 1), while Rawah and Comanche Peak would probably have lodgepole pine (type 2) as their primary species, followed by spruce/fir and aspen (type 5). Cache la Poudre would tend to have Ponderosa pine (type 3), Douglas-fir (type 6), and cottonwood/willow (type 4). \n\nThe Rawah and Comanche Peak areas would tend to be more typical of the overall dataset than either the Neota or Cache la Poudre, due to their assortment of tree species and range of predictive variable values (elevation, etc.) Cache la Poudre would probably be more unique than the others, due to its relatively low elevation range and species composition.\n\nAttribute Information:  \nGiven is the attribute name, attribute type, the measurement unit and a brief description. The forest cover type is the classification problem. The order of this listing corresponds to the order of numerals along the rows of the database. \n>\nName / Data Type / Measurement / Description  \nElevation / quantitative /meters / Elevation in meters  \nAspect / quantitative / azimuth / Aspect in degrees azimuth  \nSlope / quantitative / degrees / Slope in degrees  \nHorizontal_Distance_To_Hydrology / quantitative / meters / Horz Dist to nearest surface water features  \nVertical_Distance_To_Hydrology / quantitative / meters / Vert Dist to nearest surface water features  \nHorizontal_Distance_To_Roadways / quantitative / meters / Horz Dist to nearest roadway  \nHillshade_9am / quantitative / 0 to 255 index / Hillshade index at 9am, summer solstice  \nHillshade_Noon / quantitative / 0 to 255 index / Hillshade index at noon, summer solstice  \nHillshade_3pm / quantitative / 0 to 255 index / Hillshade index at 3pm, summer solstice  \nHorizontal_Distance_To_Fire_Points / quantitative / meters / Horz Dist to nearest wildfire ignition points  \nWilderness_Area (4 binary columns) / qualitative / 0 (absence) or 1 (presence) / Wilderness area designation  \nSoil_Type (40 binary columns) / qualitative / 0 (absence) or 1 (presence) / Soil Type designation  \nCover_Type (7 types) / integer / 1 to 7 / Forest Cover Type designation \n\n\nRelevant Papers:  \n- Blackard, Jock A. and Denis J. Dean. 2000. \"Comparative Accuracies of Artificial Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables.\" Computers and Electronics in Agriculture 24(3):131-151. \n- Blackard, Jock A. and Denis J. Dean. 1998. \"Comparative Accuracies of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types from Cartographic Variables.\" Second Southern Forestry GIS Conference. University of Georgia. Athens, GA. Pages 189-199. \n- Blackard, Jock A. 1998. \"Comparison of Neural Networks and Discriminant Analysis in Predicting Forest Cover Types.\" Ph.D. dissertation. Department of Forest Sciences. Colorado State University. Fort Collins, Colorado. 165 pages.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_180_covertype_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 55, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-180-covertype"}, "LL0_186_braziltourism": {"pipeline": {"_id": "e9e17e90-4c8b-48df-a850-667cffa882d0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 50}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 223, "max_depth": 8, "learning_rate": 0.6045313137991024, "gamma": 0.19572783716347797, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "e9e17e90-4c8b-48df-a850-667cffa882d0", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.374479496221358, "rank": 0.6255205037790118, "metric": "f1Macro", "ts": "2018-10-24T23:57:42.301000", "dataset": "LL0_186_braziltourism_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_186_braziltourism", "about": {"problemID": "LL0_186_braziltourism_problem", "problemName": "LL0_186_braziltourism_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\n                by Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\n                consists of a zip file containing two versions of each of 84 data sets, \n                plus this README file. Each data set is given in comma-delimited ASCII\n                (.csv) form, and Microsoft Excel (.xls) form.\n \n NOTICE: These data sets may be used freely for scientific, educational and/or\n         noncommercial purposes, provided suitable acknowledgment is given (by citing\n         the above-named reference).\n \n Further details concerning the book, including information on statistical software\n (including sample S-PLUS/R and SAS code), are available at the web site\n \n             http://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last\n\n\n Note: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\n       with Underscores", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_186_braziltourism_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "Trips"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-186-braziltourism"}, "LL0_188_eucalyptus": {"pipeline": {"_id": "bcacbaeb-33c5-45bc-b30c-20a7ad6b79b5", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 45}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 632, "max_depth": 4, "learning_rate": 0.8037473819564962, "gamma": 0.8399841659119017, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "bcacbaeb-33c5-45bc-b30c-20a7ad6b79b5", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6666147362880166, "rank": 0.3333852637128938, "metric": "f1Macro", "ts": "2018-10-25T00:38:26.685000", "dataset": "LL0_188_eucalyptus_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_188_eucalyptus", "about": {"problemID": "LL0_188_eucalyptus_problem", "problemName": "LL0_188_eucalyptus_problem", "problemDescription": "**Author**: Bruce Bulloch  \n**Source**: [WEKA Dataset Collection](http://www.cs.waikato.ac.nz/ml/weka/datasets.html) - part of the agridatasets archive.  \n**Please cite**:   \n\n**Eucalyptus Soil Conservation**  \nThe objective was to determine which seedlots in a species are best for soil conservation in seasonally dry hill country. Determination is found by measurement of height, diameter by height, survival, and other contributing factors. \n \nIt is important to note that eucalypt trial methods changed over time; earlier trials included mostly 15 - 30cm tall seedling grown in peat plots and the later trials have included mostly three replications of eight trees grown. This change may contribute to less significant results.\n\nExperimental data recording procedures which require noting include:\n - instances with no data recorded due to experimental recording procedures\n   require that the absence of a species from one replicate at a site was\n   treated as a missing value, but if absent from two or more replicates at a\n   site the species was excluded from the site's analyses.\n - missing data for survival, vigour, insect resistance, stem form, crown form\n   and utility especially for the data recorded at the Morea Station; this \n   could indicate the death of species in these areas or a lack in collection\n   of data.  \n\n### Attribute Information  \n \n  1.  Abbrev - site abbreviation - enumerated\n  2.  Rep - site rep - integer\n  3.  Locality - site locality in the North Island - enumerated\n  4.  Map_Ref - map location in the North Island - enumerated\n  5.  Latitude - latitude approximation - enumerated\n  6.  Altitude - altitude approximation - integer\n  7.  Rainfall - rainfall (mm pa) - integer\n  8.  Frosts - frosts (deg. c) - integer\n  9.  Year - year of planting - integer\n  10. Sp - species code - enumerated\n  11. PMCno - seedlot number - integer\n  12. DBH - best diameter base height (cm) - real\n  13. Ht - height (m) - real\n  14. Surv - survival - integer\n  15. Vig - vigour - real\n  16. Ins_res - insect resistance - real\n  17. Stem_Fm - stem form - real\n  18. Crown_Fm - crown form - real\n  19. Brnch_Fm - branch form - real\n  Class:\n  20. Utility - utility rating - enumerated\n\n### Relevant papers\n\nBulluch B. T., (1992) Eucalyptus Species Selection for Soil Conservation in Seasonally Dry Hill Country - Twelfth Year Assessment  New Zealand Journal of Forestry Science 21(1): 10 - 31 (1991)  \n\nKirsten Thomson and Robert J. McQueen (1996) Machine Learning Applied to Fourteen Agricultural Datasets. University of Waikato Research Report  \nhttps://www.cs.waikato.ac.nz/ml/publications/1996/Thomson-McQueen-96.pdf + the original publication:", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_188_eucalyptus_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 20, "colName": "Utility"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-188-eucalyptus"}, "LL0_189_kin8nm": {"pipeline": {"_id": "337cb4ed-f5e7-4ef3-af45-75371bfd7e8d", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 694, "max_depth": 6, "learning_rate": 0.15530554215400227, "gamma": 0.005983613944788968, "min_child_weight": 7}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "337cb4ed-f5e7-4ef3-af45-75371bfd7e8d", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.015680552479263237, "rank": 0.01568055247946963, "metric": "meanSquaredError", "ts": "2018-10-31T05:50:12.689000", "dataset": "LL0_189_kin8nm_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_189_kin8nm", "about": {"problemID": "LL0_189_kin8nm_problem", "problemName": "LL0_189_kin8nm_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is data set is concerned with the forward kinematics of an 8 link\n robot arm. Among the existing variants of this data set we have used\n the variant 8nm, which is known to be highly non-linear and medium\n noisy.\n\n Original source: DELVE repository of data. \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 8192 cases, 9 attributes (0 nominal, 9 continuous).", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_189_kin8nm_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "y"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-189-kin8nm"}, "LL0_191_wisconsin": {"pipeline": {"_id": "453ccbe7-d20e-46a9-91c5-bd6fafbf7709", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 17}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 22, "min_samples_split": 0.3890267297217612, "min_samples_leaf": 0.12902706971130737, "n_estimators": 38}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "453ccbe7-d20e-46a9-91c5-bd6fafbf7709", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 1007.9691055277575, "rank": 1007.9691055277577, "metric": "meanSquaredError", "ts": "2018-10-24T22:00:00.344000", "dataset": "LL0_191_wisconsin_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_191_wisconsin", "about": {"problemID": "LL0_191_wisconsin_problem", "problemName": "wisconsin_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Wisconsin Prognostic Breast Cancer (WPBC)\n \n 2. Source Information\n \n a) Creators: \n \n \tDr. William H. Wolberg, General Surgery Dept., University of\n \tWisconsin,  Clinical Sciences Center, Madison, WI 53792\n \twolberg@eagle.surgery.wisc.edu\n \n \tW. Nick Street, Computer Sciences Dept., University of\n \tWisconsin, 1210 West Dayton St., Madison, WI 53706\n \tstreet@cs.wisc.edu  608-262-6619\n \n \tOlvi L. Mangasarian, Computer Sciences Dept., University of\n \tWisconsin, 1210 West Dayton St., Madison, WI 53706\n \tolvi@cs.wisc.edu \n \n b) Donor: Nick Street\n \n c) Date: December 1995\n \n 3. Past Usage:\n \n \tVarious versions of this data have been used in the following\n \tpublications: \n \n \t(i) W. N. Street, O. L. Mangasarian, and W.H. Wolberg. \n \tAn inductive learning approach to prognostic prediction. \n \tIn A. Prieditis and S. Russell, editors, Proceedings of the\n \tTwelfth International Conference on Machine Learning, pages\n \t522--530, San Francisco, 1995. Morgan Kaufmann.\n \n \t(ii) O.L. Mangasarian, W.N. Street and W.H. Wolberg. \n \tBreast cancer diagnosis and prognosis via linear programming. \n \tOperations Research, 43(4), pages 570-577, July-August 1995. \n \n \t(iii) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n \tComputerized breast cancer diagnosis and prognosis from fine\n \tneedle aspirates.  Archives of Surgery 1995;130:511-516. \n \n \t(iv) W.H. Wolberg, W.N. Street, and O.L. Mangasarian. \n \tImage analysis and machine learning applied to breast cancer\n \tdiagnosis and prognosis. Analytical and Quantitative Cytology\n \tand Histology, Vol. 17 No. 2, pages 77-87, April 1995.\n \n \t(v) W.H. Wolberg, W.N. Street, D.M. Heisey, and O.L. Mangasarian. \n \tComputer-derived nuclear ``grade'' and breast cancer prognosis. \n \tAnalytical and Quantitative Cytology and Histology, Vol. 17,\n \tpages 257-264, 1995. \n \n See also:\n \thttp://www.cs.wisc.edu/~olvi/uwmp/mpml.html\n \thttp://www.cs.wisc.edu/~olvi/uwmp/cancer.html\n \n Results:\n \n \tTwo possible learning problems:\n \n \t1) Predicting field 2, outcome: R = recurrent, N = nonrecurrent\n \t- Dataset should first be filtered to reflect a particular\n \tendpoint; e.g., recurrences before 24 months = positive,\n \tnonrecurrence beyond 24 months = negative.\n \t- 86.3% accuracy estimated accuracy on 2-year recurrence using\n \tprevious version of this data.  Learning method: MSM-T (see\n \tbelow) in the 4-dimensional space of Mean Texture, Worst Area,\n \tWorst Concavity, Worst Fractal Dimension.\n \n \t2) Predicting Time To Recur (field 3 in recurrent records)\n \t- Estimated mean error 13.9 months using Recurrence Surface\n \tApproximation. (See references (i) and (ii) above)\n \n 4. Relevant information\n \n \tEach record represents follow-up data for one breast cancer\n \tcase.  These are consecutive patients seen by Dr. Wolberg\n \tsince 1984, and include only those cases exhibiting invasive\n \tbreast cancer and no evidence of distant metastases at the\n \ttime of diagnosis. \n \n \tThe first 30 features are computed from a digitized image of a\n \tfine needle aspirate (FNA) of a breast mass.  They describe\n \tcharacteristics of the cell nuclei present in the image.\n \tA few of the images can be found at\n \thttp://www.cs.wisc.edu/~street/images/\n \n \tThe separation described above was obtained using\n \tMultisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n \tConstruction Via Linear Programming.\" Proceedings of the 4th\n \tMidwest Artificial Intelligence and Cognitive Science Society,\n \tpp. 97-101, 1992], a classification method which uses linear\n \tprogramming to construct a decision tree.  Relevant features\n \twere selected using an exhaustive search in the space of 1-4\n \tfeatures and 1-3 separating planes.\n \n \tThe actual linear program used to obtain the separating plane\n \tin the 3-dimensional space is that described in:\n \t[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n \tProgramming Discrimination of Two Linearly Inseparable Sets\",\n \tOptimization Methods and Software 1, 1992, 23-34].\n \n \tThe Recurrence Surface Approximation (RSA) method is a linear\n \tprogramming model which predicts Time To Recur using both\n \trecurrent and nonrecurrent cases.  See references (i) and (ii)\n \tabove for details of the RSA method. \n \n \tThis database is also available through the UW CS ftp server:\n \n \tftp ftp.cs.wisc.edu\n \tcd math-prog/cpo-dataset/machine-learn/WPBC/\n \n 5. Number of instances: 198\n \n 6. Number of attributes: 34 (ID, outcome, 32 real-valued input features)\n \n 7. Attribute information\n \n 1) ID number\n 2) Outcome (R = recur, N = nonrecur)\n 3) Time (recurrence time if field 2 = R, disease-free time if \n \tfield 2\t= N)\n 4-33) Ten real-valued features are computed for each cell nucleus:\n \n \ta) radius (mean of distances from center to points on the perimeter)\n \tb) texture (standard deviation of gray-scale values)\n \tc) perimeter\n \td) area\n \te) smoothness (local variation in radius lengths)\n \tf) compactness (perimeter^2 / area - 1.0)\n \tg) concavity (severity of concave portions of the contour)\n \th) concave points (number of concave portions of the contour)\n \ti) symmetry \n \tj) fractal dimension (\"coastline approximation\" - 1)\n \n Several of the papers listed above contain detailed descriptions of\n how these features are computed. \n \n The mean, standard error, and \"worst\" or largest (mean of the three\n largest values) of these features were computed for each image,\n resulting in 30 features.  For instance, field 4 is Mean Radius, field\n 14 is Radius SE, field 24 is Worst Radius.\n \n Values for features 4-33 are recoded with four significant digits.\n \n 34) Tumor size - diameter of the excised tumor in centimeters\n 35) Lymph node status - number of positive axillary lymph nodes\n observed at time of surgery\n \n 8. Missing attribute values: \n \tLymph node status is missing in 4 cases.\n \n 9. Class distribution: 151 nonrecur, 47 recur\n\n-----------------------------------------------------------------------------------------------------------\n Luis Torgo's version: (reconstructed)\n - removed the four instances with unknown values of the last attribute\n - exchanged the attribute position of attributes n.3 (Time) and n.35\n   (Lymph node).\n - removed the attribute outcome as it is the class attribute if the\n   problem is treated as a classification one\n-----------------------------------------------------------------------------------------------------------", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_191_wisconsin_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "time"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-191-wisconsin"}, "LL0_194_cleveland": {"pipeline": {"_id": "f7569bf3-c5ca-47e6-b9a9-3a8264a8f025", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 84}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 12, "min_samples_split": 0.02850108280845964, "min_samples_leaf": 0.00910879382804552, "n_estimators": 65}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "f7569bf3-c5ca-47e6-b9a9-3a8264a8f025", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.7695211506812342, "rank": 0.7695211506821535, "metric": "meanSquaredError", "ts": "2018-10-24T21:28:47.587000", "dataset": "LL0_194_cleveland_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_194_cleveland", "about": {"problemID": "LL0_194_cleveland_problem", "problemName": "LL0_194_cleveland_problem", "problemDescription": "**Author**: Andras Janosi, M.D.  \nDonor: David W. Aha (aha@ics.uci.edu)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Heart+Disease) - July 1988  \n**Please cite**: The author request that any publications resulting from the use of the data include the name of the author.\n\n**Heart Disease Databases: Cleveland**  \nThis database contains 76 attributes, but all published experiments refer to using a subset of 14 of them.  In particular, the Cleveland database is the only one that has been used by ML researchers to this date.  The \"goal\" field refers to the presence of heart disease in the patient.  It is integer valued from 0 (no presence) to 4. Experiments with the Cleveland database have concentrated on simply attempting to distinguish presence (values 1,2,3,4) from absence (value 0).  \n    \nThe names and social security numbers of the patients were recently removed from the database, replaced with dummy values.\nOne file has been \"processed\", that one containing the Cleveland database. \n     \nAttribute documentation:  \n>\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_194_cleveland_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "num"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-194-cleveland"}, "LL0_195_auto_price": {"pipeline": {"_id": "0a307b9f-49db-472e-956c-25ca1d1a625a", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 11}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 903, "max_depth": 9, "learning_rate": 0.5481987414482525, "gamma": 0.1285862974710682, "min_child_weight": 3}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "0a307b9f-49db-472e-956c-25ca1d1a625a", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 7648536.487502481, "rank": 7648536.487502481, "metric": "meanSquaredError", "ts": "2018-10-24T21:34:56.545000", "dataset": "LL0_195_auto_price_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_195_auto_price", "about": {"problemID": "LL0_195_auto_price_problem", "problemName": "auto_price_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis data set consists of three types of entities:\n (a) the specification of an auto in terms of various characteristics;\n (b) its assigned insurance risk rating,;\n (c) its normalized losses in use as compared to other cars. \n The second rating corresponds to the degree to which the auto is more risky than its price indicates. Cars are initially\n assigned a risk factor symbol associated with its price. Then, if it is more risky (or less), this symbol is adjusted by\n moving it up (or down) the scale. Actuarians call this process \"symboling\". A value of +3 indicates that the auto is\n risky, -3 that it is probably pretty safe.The third factor is the relative average loss payment per insured vehicle year.\n This value is normalized for all autos within a particular size classification (two-door small, station wagons,\n sports/speciality, etc...), and represents the average loss per car per year.\n - Note: Several of the attributes in the database could be used as a \"class\" attribute.\n The original data (from the UCI repository) (http://www.ics.uci.edu/~mlearn/MLSummary.html) has 205 instances\n described by 26 attributes :\n - 15 continuous\n - 1 integer\n - 10 nominal\n The following provides more information on these attributes:\n \n   1. symboling:                 -3, -2, -1, 0, 1, 2, 3.\n   2. normalized-losses:        continuous from 65 to 256.\n   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n                                mitsubishi, nissan, peugot, plymouth, porsche,\n                                renault, saab, subaru, toyota, volkswagen, volvo\n   4. fuel-type:                diesel, gas.\n   5. aspiration:               std, turbo.\n   6. num-of-doors:             four, two.\n   7. body-style:               hardtop, wagon, sedan, hatchback,convertible.\n   8. drive-wheels:             4wd, fwd, rwd.\n   9. engine-location:          front, rear.\n  10. wheel-base:               continuous from 86.6 120.9.\n  11. length:                   continuous from 141.1 to 208.1.\n  12. width:                    continuous from 60.3 to 72.3.\n  13. height:                   continuous from 47.8 to 59.8.\n  14. curb-weight:              continuous from 1488 to 4066.\n  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n  17. engine-size:              continuous from 61 to 326.\n  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n  19. bore:                     continuous from 2.54 to 3.94.\n  20. stroke:                   continuous from 2.07 to 4.17.\n  21. compression-ratio:        continuous from 7 to 23.\n  22. horsepower:               continuous from 48 to 288.\n  23. peak-rpm:                 continuous from 4150 to 6600.\n  24. city-mpg:                 continuous from 13 to 49.\n  25. highway-mpg:              continuous from 16 to 54.\n  26. price:                    continuous from 5118 to 45400.\n \n The original data also has some missing attribute values denoted by \"?\" : \n \n    Attribute #:   Number of instances missing a value:\n    2.             41\n    6.             2\n    19.            4\n    20.            4\n    22.            2\n    23.            2\n    26.            4\n \n I've changed the original data in the following way :\n - All instances with unknowns were removed giving 159 instances.\n - The goal variable is \"price\"\n - All nominal attributes (10) were removed.\n \n Original source: UCI machine learning repository. (http://www.ics.uci.edu/~mlearn/MLSummary.html). \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 159 cases; 14 continuous variables; 1 nominal vars..", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_195_auto_price_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 16, "colName": "price"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-195-auto-price"}, "LL0_197_cpu_act": {"pipeline": {"_id": "9feff0e9-ea6f-40e5-a7c1-0c28d2188991", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 50}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 895, "max_depth": 3, "learning_rate": 0.10001767453956212, "gamma": 0.5130686330232757, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "9feff0e9-ea6f-40e5-a7c1-0c28d2188991", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 5.4338153434263, "rank": 5.433815343426334, "metric": "meanSquaredError", "ts": "2018-10-24T21:00:06.856000", "dataset": "LL0_197_cpu_act_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_197_cpu_act", "about": {"problemID": "LL0_197_cpu_act_problem", "problemName": "LL0_197_cpu_act_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe Computer Activity databases are a collection of computer systems\n activity measures. The data was collected from a Sun Sparcstation\n 20/712 with 128 Mbytes of memory running in a multi-user university\n department. Users would typically be doing a large variety of tasks\n ranging from accessing the internet, editing files or running very\n cpu-bound programs.  The data was collected continuously on two\n separate occasions. On both occassions, system activity was gathered\n every 5 seconds. The final dataset is taken from both occasions with\n equal numbers of observations coming from each collection epoch.\n \n System measures used:\n 1. lread - Reads (transfers per second ) between system memory and user memory.\n 2. lwrite - writes (transfers per second) between system memory and user memory.\n 3. scall - Number of system calls of all types per second.\n 4. sread - Number of system read calls per second.\n 5. swrite - Number of system write calls per second . \n 6. fork - Number of system fork calls per second. \n 7. exec - Number of system exec calls per second. \n 8. rchar - Number of characters transferred per second by system read calls.\n 9. wchar - Number of characters transfreed per second by system write calls. \n 10. pgout - Number of page out requests per second.\n 11. ppgout - Number of pages, paged out per second. \n 12. pgfree - Number of pages per second placed on the free list. \n 13. pgscan - Number of pages checked if they can be freed per second.\n 14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.\n 15. pgin - Number of page-in requests per second.\n 16. ppgin - Number of pages paged in per second.\n 17. pflt - Number of page faults caused by protection errors (copy-on-writes). \n 18. vflt - Number of page faults caused by address translation. \n 19. runqsz - Process run queue size.\n 20. freemem - Number of memory pages available to user processes.\n 21. freeswap - Number of disk blocks available for page swapping. \n 22. usr - Portion of time (%) that cpus run in user mode.\n 23. sys - Portion of time (%) that cpus run in system mode.\n 24. wio - Portion of time (%) that cpus are idle waiting for block IO.\n 25. idle - Portion of time (%) that cpus are otherwise idle.\n \n The two different regression tasks obtained from these databases are:\n \n CompAct \n Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.\n \n CompAct(s) \n Predict usr using a restricted number (excluding the paging information (10-18)\n \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original source: DELVE repository of data. \n Characteristics: 8192 cases, 22 continuous attributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_197_cpu_act_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "usr"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-197-cpu-act"}, "LL0_198_delta_elevators": {"pipeline": {"_id": "20371d68-0a27-4e68-bd9c-a1ea2bc14e69", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "20371d68-0a27-4e68-bd9c-a1ea2bc14e69", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.032445550952055e-06, "rank": 2.0324456214741225e-06, "metric": "meanSquaredError", "ts": "2018-10-31T04:09:06.242000", "dataset": "LL0_198_delta_elevators_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_198_delta_elevators", "about": {"problemID": "LL0_198_delta_elevators_problem", "problemName": "LL0_198_delta_elevators_problem", "problemDescription": "**Author**: Rui Camacho (rcamacho@garfield.fe.up.pt)  \n**Source**: [Regression datasets collection Luis Torgo](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html)  \n**Please cite**:   \n\nThis data set is also obtained from the task of controlling the ailerons of a F16 aircraft, although the target variable and attributes are different from the ailerons domain. The target variable here is a variation instead of an absolute value, and there was some pre-selection of the attributes.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_198_delta_elevators_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "Se"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-198-delta-elevators"}, "LL0_1_anneal": {"pipeline": {"_id": "f2f7c654-ccb9-4af9-b60e-837bb8dd02c1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 28}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 203, "max_depth": 5, "learning_rate": 0.9806157505277122, "gamma": 0.36656681270893887, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f2f7c654-ccb9-4af9-b60e-837bb8dd02c1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9308657318391402, "rank": 0.06913426816086095, "metric": "f1Macro", "ts": "2018-10-25T00:03:45.272000", "dataset": "LL0_1_anneal_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_1_anneal", "about": {"problemID": "LL0_1_anneal_problem", "problemName": "LL0_1_anneal_problem", "problemDescription": "**Author**: donated by David Sterling and Wray Buntine  \n**Source**: [original (UCI)](http://www.openml.org/d/2) -   \n**Please cite**:   \n\nThis is a preprocessed version of the <a href=\"d/2\">anneal</a> dataset (version 1). All missing values are treated as a nominal value with label '?'. (Quotes for clarity). Because this is not good practice, this dataset is deactivated. Use version 1 instead\n\n1. Title of Database: Annealing Data\n \n 2. Source Information: donated by David Sterling and Wray Buntine.\n \n 3. Past Usage: unknown\n \n 4. Relevant Information:\n    -- Explanation: I suspect this was left by Ross Quinlan in 1987 at the\n       4th Machine Learning Workshop.  I'd have to check with Jeff Schlimmer\n       to double check this.\n \n 5. Number of Instances: 898\n \n 6. Number of Attributes: 38\n    -- 6 continuously-valued\n    -- 3 integer-valued\n    -- 29 nominal-valued\n \n 7. Attribute Information:\n     1. family:          --,GB,GK,GS,TN,ZA,ZF,ZH,ZM,ZS\n     2. product-type:    C, H, G\n     3. steel:           -,R,A,U,K,M,S,W,V\n     4. carbon:          continuous\n     5. hardness:        continuous\n     6. temper_rolling:  -,T\n     7. condition:       -,S,A,X\n     8. formability:     -,1,2,3,4,5\n     9. strength:        continuous\n    10. non-ageing:      -,N\n    11. surface-finish:  P,M,-\n    12. surface-quality: -,D,E,F,G\n    13. enamelability:   -,1,2,3,4,5\n    14. bc:              Y,-\n    15. bf:              Y,-\n    16. bt:              Y,-\n    17. bw/me:           B,M,-\n    18. bl:              Y,-\n    19. m:               Y,-\n    20. chrom:           C,-\n    21. phos:            P,-\n    22. cbond:           Y,-\n    23. marvi:           Y,-\n    24. exptl:           Y,-\n    25. ferro:           Y,-\n    26. corr:            Y,-\n    27. blue/bright/varn/clean:          B,R,V,C,-\n    28. lustre:          Y,-\n    29. jurofm:          Y,-\n    30. s:               Y,-\n    31. p:               Y,-\n    32. shape:           COIL, SHEET\n    33. thick:           continuous\n    34. width:           continuous\n    35. len:             continuous\n    36. oil:             -,Y,N\n    37. bore:            0000,0500,0600,0760\n    38. packing: -,1,2,3\n    classes:        1,2,3,4,5,U\n  \n    -- The '-' values are actually 'not_applicable' values rather than\n       'missing_values' (and so can be treated as legal discrete\n       values rather than as showing the absence of a discrete value).\n \n 8. Missing Attribute Values: Signified with \"?\"\n    Attribute:  Number of instances missing its value:\n    1           0\n    2           0\n    3           70\n    4           0\n    5           0\n    6           675\n    7           271\n    8           283\n    9           0\n   10           703\n   11           790\n   12           217\n   13           785\n   14           797\n   15           680\n   16           736\n   17           609\n   18           662\n   19           798\n   20           775\n   21           791\n   22           730\n   23           798\n   24           796\n   25           772\n   26           798\n   27           793\n   28           753\n   29           798\n   30           798\n   31           798\n   32           0\n   33           0\n   34           0\n   35           0\n   36           740\n   37           0\n   38           789\n   39           0\n \n 9. Distribution of Classes\n      Class Name:   Number of Instances:\n      1               8\n      2              88\n      3             608\n      4               0\n      5              60\n      U              34\n                    ---\n                    798", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_1_anneal_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 39, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-1-anneal"}, "LL0_200_pbc": {"pipeline": {"_id": "aa627950-dc3c-4c2d-8d3d-97ed7876c9e0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 77, "max_depth": 10, "learning_rate": 0.3915648079159766, "gamma": 0.14643900880736815, "min_child_weight": 8}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "aa627950-dc3c-4c2d-8d3d-97ed7876c9e0", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 720531.2463610303, "rank": 720531.2463610303, "metric": "meanSquaredError", "ts": "2018-10-24T20:13:48.095000", "dataset": "LL0_200_pbc_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_200_pbc", "about": {"problemID": "LL0_200_pbc_problem", "problemName": "LL0_200_pbc_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Case number deleted. X treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n NAME:  PBC Data\n SIZE:  418 observations, 20 variables\n \n \n \n DESCRIPTIVE ABSTRACT:\n \n Below is a description of the variables recorded from the Mayo Clinic trial \n in primary biliary cirrhosis (PBC) of the liver conducted between 1974 and \n 1984.  A total of 424 PBC patients, referred to Mayo Clinic during\n that ten-year interval, met eligibility criteria for the randomized placebo \n controlled trial of the drug D-penicillamine. The first 312 cases in the data \n set participated in the randomized trial, and contain largely complete data. \n The additional 112 cases did not participate in the clinical trial, but \n consented to have basic measurements recorded and to be followed for survival.\n Six of those cases were lost to follow-up shortly after diagnosis, so there \n are data here on an additional 106 cases as well as the 312 randomized \n participants. Missing data items are denoted by \".\".  At least one space \n separates each variable in the .DAT file.  Censoring was due to liver \n transplantation for twenty-five subjects with the following case numbers: \n 5, 105, 111, 120, 125, 158, 183, 241, 246, 247, 254, 263, 264, 265, 274, \n 288, 291, 295, 297, 345, 361, 362, 375, 380, 383.\n \n \n \n SOURCE:  Counting Processes and Survival Analysis by T. Fleming & \n          D. Harrington, (1991),  published by John Wiley & Sons.\n \n \n \n VARIABLE DESCRIPTIONS:\n \n The data are in free format.  That is, at least one blank space separates\n each variable.  The variables contained in the .DAT are:\n \n \n N:   Case number.\n X:   The number of days between registration and the earlier of\n      death, liver transplantation, or study analysis time in July, 1986.\n D:   1 if X is time to death, 0 if time to censoring\n Z1:  Treatment Code, 1 = D-penicillamine, 2 = placebo.\n Z2:  Age in years. For the first 312 cases, age was calculated by\n      dividing the number of days between birth and study registration by 365.\n Z3:  Sex, 0 = male, 1 = female.\n Z4:  Presence of ascites, 0 = no, 1 = yes.\n Z5:  Presence of hepatomegaly, 0 = no, 1 = yes.\n Z6:  Presence of spiders 0 = no, 1 = Yes.\n Z7:  Presence of edema, 0 = no edema and no diuretic therapy for\n      edema; 0.5 = edema present for which no diuretic therapy was given, or \n      edema resolved with diuretic therapy; 1 = edema despite diuretic therapy\n Z8:  Serum bilirubin, in mg/dl.\n Z9:  Serum cholesterol, in mg/dl.\n Z10: Albumin, in gm/dl.\n Z11: Urine copper, in mg/day.\n Z12: Alkaline phosphatase, in U/liter.\n Z13: SGOT, in U/ml.\n Z14: Triglycerides, in mg/dl.\n Z15: Platelet count; coded value is number of platelets\n      per-cubic-milliliter of blood divided by 1000.\n Z16: Prothrombin time, in seconds.\n Z17: Histologic stage of disease, graded 1, 2, 3, or 4.\n \n \n \n \n STORY BEHIND THE DATA:\n \n Between January, 1974 and May, 1984, the Mayo Clinic conducted a\n double-blinded randomized trial in primary biliary cirrhosis of the liver\n (PBC), comparing the drug D-penicillamine (DPCA) with a placebo. There\n were 424 patients who met the eligibility criteria seen at the Clinic while\n the trial was open for patient registration. Both the treating physician and\n the patient agreed to participate in the randomized trial in 312 of the 424\n cases. The date of randomization and a large number of clinical, biochemical,\n serologic, and histologic parameters were recorded for each of the 312\n clinical trial patients. The data from the trial were analyzed in 1986 for\n presentation in the clinical literature. For that analysis, disease and \n survival status as of July, 1986, were recorded for as many patients as \n possible.  By that date, 125 of the 312 patients had died, with only 11 \n not attributable to PBC.  Eight patients had been lost to follow up, and 19 \n had undergone liver transplantation. \n \n PBC is a rare but fatal chronic liver disease of unknown cause,\n with a prevalence of about 50-cases-per-million population. The primary\n pathologic event appears to be the destruction of interlobular bile ducts,\n which may be mediated by immunologic mechanisms. The data discussed here are\n important in two respects. First, controlled clinical trials are difficult to\n complete in rare diseases, and this case series of patients uniformly\n diagnosed, treated, and followed is the largest existing for PBC. The\n treatment comparison in this trial is more precise than in similar trials\n having fewer participants and avoids the bias that may arise in comparing\n a case series to historical controls. Second, the data present an\n opportunity to study the natural history of the disease. We will see that, \n despite the immunosuppressive properties of DPCA, there are no detectable\n differences between the distributions of survival times for the DPCA and\n placebo treatment groups. This suggests that these groups can be combined\n in studying the association between survival time from randomization and\n clinical and other measurements. In the early to mid 1980s, the rate of \n successful liver transplant increased substantially, and transplant has \n become an effective therapy for PBC. The Mayo Clinic data set is therefore \n one of the last allowing a study of the natural history of PBC in patients \n who were treated with only supportive care or its equivalent. The PBC data \n can be used to: estimate a survival distribution; test for differences \n between two groups; and estimate covariate effects via a regression\n model.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_200_pbc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 19, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-200-pbc"}, "LL0_201_pol": {"pipeline": {"_id": "579e4669-5d29-4e38-9e66-f8d74621152d", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 99}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 459, "max_depth": 8, "learning_rate": 0.18978532677806403, "gamma": 0.5420275911409405, "min_child_weight": 3}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "579e4669-5d29-4e38-9e66-f8d74621152d", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 20.467742044082257, "rank": 20.467742044083124, "metric": "meanSquaredError", "ts": "2018-10-24T22:08:46.815000", "dataset": "LL0_201_pol_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_201_pol", "about": {"problemID": "LL0_201_pol_problem", "problemName": "LL0_201_pol_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is a commercial application described in Weiss & Indurkhya (1995). \n The data describes a telecommunication problem. No further information\n is available.\n \n Characteristics: (10000+5000) cases, 49 continuous attributes \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original Source: The data in the original format can be obtained \n from http://www.cs.su.oz.au/~nitin", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_201_pol_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 49, "colName": "foo"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-201-pol"}, "LL0_204_cholesterol": {"pipeline": {"_id": "af98fe5e-1df3-4687-b3b1-4b703945dff6", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 79}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 29, "min_samples_split": 0.03589706652308239, "min_samples_leaf": 0.10466594791382462, "n_estimators": 61}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "af98fe5e-1df3-4687-b3b1-4b703945dff6", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2173.3864944017337, "rank": 2173.3864944017346, "metric": "meanSquaredError", "ts": "2018-10-24T20:30:01.756000", "dataset": "LL0_204_cholesterol_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_204_cholesterol", "about": {"problemID": "LL0_204_cholesterol_problem", "problemName": "LL0_204_cholesterol_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Cholesterol treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n Publication Request: \n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    This file describes the contents of the heart-disease directory.\n \n    This directory contains 4 databases concerning heart disease diagnosis.\n    All attributes are numeric-valued.  The data was collected from the\n    four following locations:\n \n      1. Cleveland Clinic Foundation (cleveland.data)\n      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n      4. University Hospital, Zurich, Switzerland (switzerland.data)\n \n    Each database has the same instance format.  While the databases have 76\n    raw attributes, only 14 of them are actually used.  Thus I've taken the\n    liberty of making 2 copies of each database: one with all the attributes\n    and 1 with the 14 attributes actually used in past experiments.\n \n    The authors of the databases have requested:\n \n       ...that any publications resulting from the use of the data include the \n       names of the principal investigator responsible for the data collection\n       at each institution.  They would be:\n \n        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n           Robert Detrano, M.D., Ph.D.\n \n    Thanks in advance for abiding by this request.\n \n    David Aha\n    July 22, 1988\n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n \n 1. Title: Heart Disease Databases\n \n 2. Source Information:\n    (a) Creators: \n        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n              Robert Detrano, M.D., Ph.D.\n    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n    (c) Date: July, 1988\n \n 3. Past Usage:\n     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,\n        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it \n        International application of a new probability algorithm for the \n        diagnosis of coronary artery disease.}  {it American Journal of \n        Cardiology}, {it 64},304--310.\n        -- International Probability Analysis \n        -- Address: Robert Detrano, M.D.\n                    Cardiology 111-C\n                    V.A. Medical Center\n                    5901 E. 7th Street\n                    Long Beach, CA 90028\n        -- Results in percent accuracy: (for 0.5 probability threshold)\n              Data Name:  CDF    CADENZA\n           -- Hungarian   77     74\n              Long beach  79     77\n              Swiss       81     81\n           -- Approximately a 77% correct classification accuracy with a\n              logistic-regression-derived discriminant function\n     2. David W. Aha & Dennis Kibler\n        -- \n           \n           \n           -- Instance-based prediction of heart-disease presence with the \n              Cleveland database\n              -- NTgrowth: 77.0% accuracy\n              --       C4: 74.8% accuracy\n     3. John Gennari\n        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of\n           incremental concept formation. {it Artificial Intelligence, 40},\n           11--61.\n        -- Results: \n           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy\n              on the Cleveland database.\n \n 4. Relevant Information:\n      This database contains 76 attributes, but all published experiments\n      refer to using a subset of 14 of them.  In particular, the Cleveland\n      database is the only one that has been used by ML researchers to \n      this date.  The \"goal\" field refers to the presence of heart disease\n      in the patient.  It is integer valued from 0 (no presence) to 4.\n      Experiments with the Cleveland database have concentrated on simply\n      attempting to distinguish presence (values 1,2,3,4) from absence (value\n      0).  \n    \n      The names and social security numbers of the patients were recently \n      removed from the database, replaced with dummy values.\n \n      One file has been \"processed\", that one containing the Cleveland \n      database.  All four unprocessed files also exist in this directory.\n     \n 5. Number of Instances: \n         Database:    # of instances:\n           Cleveland: 303\n           Hungarian: 294\n         Switzerland: 123\n       Long Beach VA: 200\n \n 6. Number of Attributes: 76 (including the predicted attribute)\n \n 7. Attribute Information:\n    -- Only 14 used\n       -- 1. #3  (age)       \n       -- 2. #4  (sex)       \n       -- 3. #9  (cp)        \n       -- 4. #10 (trestbps)  \n       -- 5. #12 (chol)      \n       -- 6. #16 (fbs)       \n       -- 7. #19 (restecg)   \n       -- 8. #32 (thalach)   \n       -- 9. #38 (exang)     \n       -- 10. #40 (oldpeak)   \n       -- 11. #41 (slope)     \n       -- 12. #44 (ca)        \n       -- 13. #51 (thal)      \n       -- 14. #58 (num)       (the predicted attribute)\n \n    -- Complete attribute documentation:\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")\n \n 9. Missing Attribute Values: Several.  Distinguished with value -9.0.\n \n 10. Class Distribution:\n         Database:      0   1   2   3   4 Total\n           Cleveland: 164  55  36  35  13   303\n           Hungarian: 188  37  26  28  15   294\n         Switzerland:   8  48  32  30   5   123\n       Long Beach VA:  51  56  41  42  10   200", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_204_cholesterol_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "chol"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-204-cholesterol"}, "LL0_207_autoPrice": {"pipeline": {"_id": "ff96febc-4e9c-46af-a109-8ec362157594", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 40}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 334, "max_depth": 10, "learning_rate": 0.5461744490182447, "gamma": 0.15492111521118246, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "ff96febc-4e9c-46af-a109-8ec362157594", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 7640597.329526359, "rank": 7640597.329526359, "metric": "meanSquaredError", "ts": "2018-10-24T20:17:14.916000", "dataset": "LL0_207_autoPrice_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_207_autoPrice", "about": {"problemID": "LL0_207_autoPrice_problem", "problemName": "autoPrice_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n All nominal attributes and instances with missing values are deleted.\n Price treated as the class attribute.\n\n As used by Kilpatrick, D. & Cameron-Jones, M. (1998). Numeric prediction\n using instance-based learning with encoding length selection. In Progress\n in Connectionist-Based Information Systems. Singapore: Springer-Verlag.\n\n !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n\n 1. Title: 1985 Auto Imports Database\n \n 2. Source Information:\n    -- Creator/Donor: Jeffrey C. Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n    -- Date: 19 May 1987\n    -- Sources:\n      1) 1985 Model Import Car and Truck Specifications, 1985 Ward's\n         Automotive Yearbook.\n      2) Personal Auto Manuals, Insurance Services Office, 160 Water\n         Street, New York, NY 10038 \n      3) Insurance Collision Report, Insurance Institute for Highway\n         Safety, Watergate 600, Washington, DC 20037\n\n 3. Past Usage:\n    -- Kibler,~D., Aha,~D.~W., & Albert,~M. (1989).  Instance-based prediction\n       of real-valued attributes.  {it Computational Intelligence}, {it 5},\n       51--57.\n          -- Predicted price of car using all numeric and Boolean attributes\n          -- Method: an instance-based learning (IBL) algorithm derived from a\n             localized k-nearest neighbor algorithm.  Compared with a\n             linear regression prediction...so all instances\n             with missing attribute values were discarded.  This resulted with\n             a training set of 159 instances, which was also used as a test\n             set (minus the actual instance during testing).\n          -- Results: Percent Average Deviation Error of Prediction from Actual\n             -- 11.84% for the IBL algorithm\n             -- 14.12% for the resulting linear regression equation\n \n 4. Relevant Information:\n    -- Description\n       This data set consists of three types of entities: (a) the\n       specification of an auto in terms of various characteristics, (b)\n       its assigned insurance risk rating, (c) its normalized losses in use\n       as compared to other cars.  The second rating corresponds to the\n       degree to which the auto is more risky than its price indicates.\n       Cars are initially assigned a risk factor symbol associated with its\n       price.   Then, if it is more risky (or less), this symbol is\n       adjusted by moving it up (or down) the scale.  Actuarians call this\n       process \"symboling\".  A value of +3 indicates that the auto is\n       risky, -3 that it is probably pretty safe.\n \n       The third factor is the relative average loss payment per insured\n       vehicle year.  This value is normalized for all autos within a\n       particular size classification (two-door small, station wagons,\n       sports/speciality, etc...), and represents the average loss per car\n       per year.\n \n    -- Note: Several of the attributes in the database could be used as a\n             \"class\" attribute.\n \n 5. Number of Instances: 205\n \n 6. Number of Attributes: 26 total\n    -- 15 continuous\n    -- 1 integer\n    -- 10 nominal\n \n 7. Attribute Information:     \n      Attribute:                Attribute Range:\n      ------------------        -----------------------------------------------\n   1. symboling:                -3, -2, -1, 0, 1, 2, 3.\n   2. normalized-losses:        continuous from 65 to 256.\n   3. make:                     alfa-romero, audi, bmw, chevrolet, dodge, honda,\n                                isuzu, jaguar, mazda, mercedes-benz, mercury,\n                                mitsubishi, nissan, peugot, plymouth, porsche,\n                                renault, saab, subaru, toyota, volkswagen, volvo\n   4. fuel-type:                diesel, gas.\n   5. aspiration:               std, turbo.\n   6. num-of-doors:             four, two.\n   7. body-style:               hardtop, wagon, sedan, hatchback, convertible.\n   8. drive-wheels:             4wd, fwd, rwd.\n   9. engine-location:          front, rear.\n  10. wheel-base:               continuous from 86.6 120.9.\n  11. length:                   continuous from 141.1 to 208.1.\n  12. width:                    continuous from 60.3 to 72.3.\n  13. height:                   continuous from 47.8 to 59.8.\n  14. curb-weight:              continuous from 1488 to 4066.\n  15. engine-type:              dohc, dohcv, l, ohc, ohcf, ohcv, rotor.\n  16. num-of-cylinders:         eight, five, four, six, three, twelve, two.\n  17. engine-size:              continuous from 61 to 326.\n  18. fuel-system:              1bbl, 2bbl, 4bbl, idi, mfi, mpfi, spdi, spfi.\n  19. bore:                     continuous from 2.54 to 3.94.\n  20. stroke:                   continuous from 2.07 to 4.17.\n  21. compression-ratio:        continuous from 7 to 23.\n  22. horsepower:               continuous from 48 to 288.\n  23. peak-rpm:                 continuous from 4150 to 6600.\n  24. city-mpg:                 continuous from 13 to 49.\n  25. highway-mpg:              continuous from 16 to 54.\n  26. price:                    continuous from 5118 to 45400.\n \n 8. Missing Attribute Values: (denoted by \"?\")\n    Attribute #:   Number of instances missing a value:\n    2.             41\n    6.             2\n    19.            4\n    20.            4\n    22.            2\n    23.            2\n    26.            4%", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_207_autoPrice_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 16, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-207-autoPrice"}, "LL0_216_elevators": {"pipeline": {"_id": "6c1ed7fb-1aea-4794-b59d-32dc1f033036", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "6c1ed7fb-1aea-4794-b59d-32dc1f033036", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 5.74954708736328e-06, "rank": 5.749547329001273e-06, "metric": "meanSquaredError", "ts": "2018-10-31T04:09:07.585000", "dataset": "LL0_216_elevators_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_216_elevators", "about": {"problemID": "LL0_216_elevators_problem", "problemName": "LL0_216_elevators_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis data set is also obtained from the task of controlling a F16\n aircraft, although the target variable and attributes are different\n from the ailerons domain. In this case the goal variable is related to\n an action taken on the elevators of the aircraft.\n\n Characteristics: 8752 cases, 19 continuous attributes \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original source: Experiments of Rui Camacho (rcamacho@garfield.fe.up.pt).", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_216_elevators_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 19, "colName": "Goal"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-216-elevators"}, "LL0_21_car": {"pipeline": {"_id": "6528ced4-b131-461c-abcb-a8e437f8497f", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 433, "max_depth": 9, "learning_rate": 0.3574889329369094, "gamma": 0.19131682294027308, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "6528ced4-b131-461c-abcb-a8e437f8497f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9588839295237055, "rank": 0.04111607047640447, "metric": "f1Macro", "ts": "2018-10-31T04:28:11.960000", "dataset": "LL0_21_car_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_21_car", "about": {"problemID": "LL0_21_car_problem", "problemName": "LL0_21_car_problem", "problemDescription": "**Author**: Marko Bohanec, Blaz Zupan  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/car+evaluation) - 1997   \n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**Car Evaluation Database**\nThis database was derived from a simple hierarchical decision model originally developed for the demonstration of DEX (M. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.).\n\nThe model evaluates cars according to the following concept structure:\n \n    CAR                      car acceptability\n    . PRICE                  overall price\n    . . buying               buying price\n    . . maint                price of the maintenance\n    . TECH                   technical characteristics\n    . . COMFORT              comfort\n    . . . doors              number of doors\n    . . . persons            capacity in terms of persons to carry\n    . . . lug_boot           the size of luggage boot\n    . . safety               estimated safety of the car\n \nInput attributes are printed in lowercase. Besides the target concept (CAR), the model includes three intermediate concepts: PRICE, TECH, COMFORT. Every concept is in the original model related to its lower level descendants by a set of examples (for\nthese examples sets see http://www-ai.ijs.si/BlazZupan/car.html).\n \nThe Car Evaluation Database contains examples with the structural information removed, i.e., directly relates CAR to the six input attributes: buying, maint, doors, persons, lug_boot, safety. Because of known underlying concept structure, this database may be particularly useful for testing constructive induction and structure discovery methods.\n\n### Relevant papers:  \nM. Bohanec and V. Rajkovic: Knowledge acquisition and explanation for multi-attribute decision making. In 8th Intl Workshop on Expert Systems and their Applications, Avignon, France. pages 59-78, 1988.  \n\nM. Bohanec, V. Rajkovic: Expert system for decision making. Sistemica 1(1), pp. 145-157, 1990.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_21_car_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-21-car"}, "LL0_223_stock": {"pipeline": {"_id": "a98389a2-8d50-4cc0-9e23-12938b8d5989", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 34}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 920, "max_depth": 8, "learning_rate": 0.07759982006543109, "gamma": 0.09207644672274362, "min_child_weight": 4}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "a98389a2-8d50-4cc0-9e23-12938b8d5989", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.7494291284681183, "rank": 0.7494291284685592, "metric": "meanSquaredError", "ts": "2018-10-24T21:16:16.515000", "dataset": "LL0_223_stock_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_223_stock", "about": {"problemID": "LL0_223_stock_problem", "problemName": "LL0_223_stock_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is a dataset obtained from the StatLib repository. Here is the included description:\n\n The data provided are daily stock prices from January 1988 through October 1991, for ten aerospace companies.\n\n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original source: StatLib repository. \n Characteristics: 950 cases, 10 continuous attributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_223_stock_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "company10"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-223-stock"}, "LL0_225_puma8nh": {"pipeline": {"_id": "364abb75-c0dc-49fb-ac7f-4b0532e1ed08", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 145, "max_depth": 5, "learning_rate": 0.030001328730314802, "gamma": 0.6529918247148802, "min_child_weight": 4}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "364abb75-c0dc-49fb-ac7f-4b0532e1ed08", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 10.070551454930982, "rank": 10.070551454931254, "metric": "meanSquaredError", "ts": "2018-10-31T05:53:51.307000", "dataset": "LL0_225_puma8nh_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_225_puma8nh", "about": {"problemID": "LL0_225_puma8nh_problem", "problemName": "LL0_225_puma8nh_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is a family of datasets synthetically generated from a realistic\n simulation of the dynamics of a Unimation Puma 560 robot arm. There\n are eight datastets in this family . In this repository we only have\n two of them. They are all variations on the same model; a realistic\n simulation of the dynamics of a Puma 560 robot arm. The task in these\n datasets is to predict the angular accelaration of one of the robot\n arm's links. The inputs include angular positions, velocities and\n torques of the robot arm. The family has been specifically generated\n for the delve environment and so the individual datasets span the\n corners of a cube whose dimensions represent:\n \n Number of inputs 8. \n degree of non-linearity (fairly linear or non-linear) \n amount of noise in the output (moderate or high). \n \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Original Source: DELVE repository of data. \n Characteristics: 8192 (4500+3692) cases, 9 continuous variables.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_225_puma8nh_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "thetadd3"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-225-puma8nh"}, "LL0_227_cpu_small": {"pipeline": {"_id": "2f21a10e-036c-463e-9768-7ad612873129", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 5}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 255, "max_depth": 9, "learning_rate": 0.05573851205792457, "gamma": 0.139144554841228, "min_child_weight": 8}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "2f21a10e-036c-463e-9768-7ad612873129", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 7.32436479232859, "rank": 7.324364792328717, "metric": "meanSquaredError", "ts": "2018-10-24T21:17:24.629000", "dataset": "LL0_227_cpu_small_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_227_cpu_small", "about": {"problemID": "LL0_227_cpu_small_problem", "problemName": "LL0_227_cpu_small_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nThe Computer Activity databases are a collection of computer systems\n activity measures. The data was collected from a Sun Sparcstation\n 20/712 with 128 Mbytes of memory running in a multi-user university\n department. Users would typically be doing a large variety of tasks\n ranging from accessing the internet, editing files or running very\n cpu-bound programs.  The data was collected continuously on two\n separate occasions. On both occassions, system activity was gathered\n every 5 seconds. The final dataset is taken from both occasions with\n equal numbers of observations coming from each collection epoch.\n \n System measures used:\n 1. lread - Reads (transfers per second ) between system memory and user memory.\n 2. lwrite - writes (transfers per second) between system memory and user memory.\n 3. scall - Number of system calls of all types per second.\n 4. sread - Number of system read calls per second.\n 5. swrite - Number of system write calls per second . \n 6. fork - Number of system fork calls per second. \n 7. exec - Number of system exec calls per second. \n 8. rchar - Number of characters transferred per second by system read calls.\n 9. wchar - Number of characters transfreed per second by system write calls. \n 10. pgout - Number of page out requests per second.\n 11. ppgout - Number of pages, paged out per second. \n 12. pgfree - Number of pages per second placed on the free list. \n 13. pgscan - Number of pages checked if they can be freed per second.\n 14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.\n 15. pgin - Number of page-in requests per second.\n 16. ppgin - Number of pages paged in per second.\n 17. pflt - Number of page faults caused by protection errors (copy-on-writes). \n 18. vflt - Number of page faults caused by address translation. \n 19. runqsz - Process run queue size.\n 20. freemem - Number of memory pages available to user processes.\n 21. freeswap - Number of disk blocks available for page swapping. \n 22. usr - Portion of time (%) that cpus run in user mode.\n 23. sys - Portion of time (%) that cpus run in system mode.\n 24. wio - Portion of time (%) that cpus are idle waiting for block IO.\n 25. idle - Portion of time (%) that cpus are otherwise idle.\n \n The two different regression tasks obtained from these databases are:\n \n CompAct \n Predict usr, the portion of time that cpus run in user mode from all attributes 1-21.\n \n CompAct(s) \n Predict usr using a restricted number (excluding the paging information (10-18)\n \n Original source: DELVE repository of data. \n Source: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\n http://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\n Characteristics: 8192 cases, 13 continuous attributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_227_cpu_small_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "usr"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-227-cpu-small"}, "LL0_228_breast_cancer_wisconsin_diagnostic": {"pipeline": {"_id": "0d307612-facf-4215-8ca9-97105c7609a8", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 102, "max_depth": 7, "learning_rate": 0.16280162979016466, "gamma": 0.8462468877959978, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "0d307612-facf-4215-8ca9-97105c7609a8", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9694430726603496, "rank": 0.030556927340025044, "metric": "f1Macro", "ts": "2018-10-25T00:15:31.603000", "dataset": "LL0_228_breast_cancer_wisconsin_diagnostic_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_228_breast_cancer_wisconsin_diagnostic", "about": {"problemID": "LL0_228_breast_cancer_wisconsin_diagnostic_problem", "problemName": "breast_cancer_wisconsin_diagnostic_problem", "problemDescription": "Dataset to diagnose breast cancer.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_228_breast_cancer_wisconsin_diagnostic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "diagnosis_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-228-breast-cancer-wisconsin-diagnostic"}, "LL0_22_mfeat_zernike": {"pipeline": {"_id": "28030e19-f8ec-4ad1-9960-d2e02b497c88", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 6}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 101, "max_depth": 3, "learning_rate": 0.32469276461324714, "gamma": 0.0936955834968013, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "28030e19-f8ec-4ad1-9960-d2e02b497c88", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7946406764116236, "rank": 0.20535932358866835, "metric": "f1Macro", "ts": "2018-10-25T00:43:48.922000", "dataset": "LL0_22_mfeat_zernike_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_22_mfeat_zernike", "about": {"problemID": "LL0_22_mfeat_zernike_problem", "problemName": "mfeat_zernike_problem", "problemDescription": "**Author**: Robert P.W. Duin, Department of Applied Physics, Delft University of Technology  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Multiple+Features) - 1998  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**Multiple Features Dataset: Zernike**  \nOne of a set of 6 datasets describing features of handwritten numerals (0 - 9) extracted from a collection of Dutch utility maps. Corresponding patterns in different datasets correspond to the same original character. 200 instances per class (for a total of 2,000 instances) have been digitized in binary images. \n\nIn this dataset, these digits are represented in terms of 47 Zernike moments. \n\n### Attribute Information  \nThe attributes represent 47 rotation invariant Zernike moments. They can't distinguish samples of class '6' from those of class '9'. More information on Zernike moments can be found in:  \nA. Khotanzad and Y.H. Hong: Rotation invariant pattern recognition using Zernike moments. Int. Conf. on Pattern Recognition, Rome 1998, pp. 326-328.\n\n### Relevant Papers  \nA slightly different version of the database is used in  \nM. van Breukelen, R.P.W. Duin, D.M.J. Tax, and J.E. den Hartog, Handwritten digit recognition by combined classifiers, Kybernetika, vol. 34, no. 4, 1998, 381-386.\n \nThe database as is is used in:  \nA.K. Jain, R.P.W. Duin, J. Mao, Statistical Pattern Recognition: A Review, IEEE Transactions on Pattern Analysis and Machine Intelligence archive, Volume 22 Issue 1, January 2000", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_22_mfeat_zernike_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 48, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-22-mfeat-zernike"}, "LL0_231_hungarian": {"pipeline": {"_id": "72f72da3-5cc2-4f08-9c19-5a23b3509be3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 101, "max_depth": 6, "learning_rate": 0.5798599866034765, "gamma": 0.7827437058793029, "min_child_weight": 4}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "72f72da3-5cc2-4f08-9c19-5a23b3509be3", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.12541267936712738, "rank": 0.12541267936723263, "metric": "meanSquaredError", "ts": "2018-10-24T21:07:49.643000", "dataset": "LL0_231_hungarian_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_231_hungarian", "about": {"problemID": "LL0_231_hungarian_problem", "problemName": "hungarian_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nPublication Request: \n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    This file describes the contents of the heart-disease directory.\n \n    This directory contains 4 databases concerning heart disease diagnosis.\n    All attributes are numeric-valued.  The data was collected from the\n    four following locations:\n \n      1. Cleveland Clinic Foundation (cleveland.data)\n      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n      4. University Hospital, Zurich, Switzerland (switzerland.data)\n \n    Each database has the same instance format.  While the databases have 76\n    raw attributes, only 14 of them are actually used.  Thus I've taken the\n    liberty of making 2 copies of each database: one with all the attributes\n    and 1 with the 14 attributes actually used in past experiments.\n \n    The authors of the databases have requested:\n \n       ...that any publications resulting from the use of the data include the \n       names of the principal investigator responsible for the data collection\n       at each institution.  They would be:\n \n        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n           Robert Detrano, M.D., Ph.D.\n \n    Thanks in advance for abiding by this request.\n \n    David Aha\n    July 22, 1988\n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n \n 1. Title: Heart Disease Databases\n \n 2. Source Information:\n    (a) Creators: \n        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n              Robert Detrano, M.D., Ph.D.\n    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n    (c) Date: July, 1988\n \n 3. Past Usage:\n     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,\n        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it \n        International application of a new probability algorithm for the \n        diagnosis of coronary artery disease.}  {it American Journal of \n        Cardiology}, {it 64},304--310.\n        -- International Probability Analysis \n        -- Address: Robert Detrano, M.D.\n                    Cardiology 111-C\n                    V.A. Medical Center\n                    5901 E. 7th Street\n                    Long Beach, CA 90028\n        -- Results in percent accuracy: (for 0.5 probability threshold)\n              Data Name:  CDF    CADENZA\n           -- Hungarian   77     74\n              Long beach  79     77\n              Swiss       81     81\n           -- Approximately a 77% correct classification accuracy with a\n              logistic-regression-derived discriminant function\n     2. David W. Aha & Dennis Kibler\n        -- \n           \n           \n           -- Instance-based prediction of heart-disease presence with the \n              Cleveland database\n              -- NTgrowth: 77.0% accuracy\n              --       C4: 74.8% accuracy\n     3. John Gennari\n        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of\n           incremental concept formation. {it Artificial Intelligence, 40},\n           11--61.\n        -- Results: \n           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy\n              on the Cleveland database.\n \n 4. Relevant Information:\n      This database contains 76 attributes, but all published experiments\n      refer to using a subset of 14 of them.  In particular, the Cleveland\n      database is the only one that has been used by ML researchers to \n      this date.  The \"goal\" field refers to the presence of heart disease\n      in the patient.  It is integer valued from 0 (no presence) to 4.\n      Experiments with the Cleveland database have concentrated on simply\n      attempting to distinguish presence (values 1,2,3,4) from absence (value\n      0).  \n    \n      The names and social security numbers of the patients were recently \n      removed from the database, replaced with dummy values.\n \n      One file has been \"processed\", that one containing the Cleveland \n      database.  All four unprocessed files also exist in this directory.\n     \n 5. Number of Instances: \n         Database:    # of instances:\n           Cleveland: 303\n           Hungarian: 294\n         Switzerland: 123\n       Long Beach VA: 200\n \n 6. Number of Attributes: 76 (including the predicted attribute)\n \n 7. Attribute Information:\n    -- Only 14 used\n       -- 1. #3  (age)       \n       -- 2. #4  (sex)       \n       -- 3. #9  (cp)        \n       -- 4. #10 (trestbps)  \n       -- 5. #12 (chol)      \n       -- 6. #16 (fbs)       \n       -- 7. #19 (restecg)   \n       -- 8. #32 (thalach)   \n       -- 9. #38 (exang)     \n       -- 10. #40 (oldpeak)   \n       -- 11. #41 (slope)     \n       -- 12. #44 (ca)        \n       -- 13. #51 (thal)      \n       -- 14. #58 (num)       (the predicted attribute)\n \n    -- Complete attribute documentation:\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")\n \n 9. Missing Attribute Values: Several.  Distinguished with value -9.0.\n \n 10. Class Distribution:\n         Database:      0   1   2   3   4 Total\n           Cleveland: 164  55  36  35  13   303\n           Hungarian: 188  37  26  28  15   294\n         Switzerland:   8  48  32  30   5   123\n       Long Beach VA:  51  56  41  42  10   200", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_231_hungarian_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "num"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-231-hungarian"}, "LL0_23395_comet_mc_sample": {"pipeline": {"_id": "10923719-d015-43dc-8b0e-ac146d40277b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 364, "max_depth": 10, "learning_rate": 0.18523009233683307, "gamma": 0.3868023370352305, "min_child_weight": 10}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "10923719-d015-43dc-8b0e-ac146d40277b", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.005052489684190426, "rank": 0.005052489684327963, "metric": "meanSquaredError", "ts": "2018-10-24T20:40:55.879000", "dataset": "LL0_23395_comet_mc_sample_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_23395_comet_mc_sample", "about": {"problemID": "LL0_23395_comet_mc_sample_problem", "problemName": "LL0_23395_comet_mc_sample_problem", "problemDescription": "Another sample of COMET_MC", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_23395_comet_mc_sample_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-23395-comet-mc-sample"}, "LL0_23397_comet_mc_sample": {"pipeline": {"_id": "6dc272d2-02b1-44f7-9a46-0285395f8a59", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 86}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 896, "max_depth": 5, "learning_rate": 0.5595696669488571, "gamma": 0.005201248819348359, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "6dc272d2-02b1-44f7-9a46-0285395f8a59", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.0035562771704425547, "rank": 0.0035562771706530165, "metric": "meanSquaredError", "ts": "2018-10-24T21:13:39.251000", "dataset": "LL0_23397_comet_mc_sample_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_23397_comet_mc_sample", "about": {"problemID": "LL0_23397_comet_mc_sample_problem", "problemName": "LL0_23397_comet_mc_sample_problem", "problemDescription": "Sample with OpenML metadata.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_23397_comet_mc_sample_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-23397-comet-mc-sample"}, "LL0_238_drivface": {"pipeline": {"_id": "551a63b9-df88-4d47-a57b-65d3d6cbaa28", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 324, "max_depth": 4, "learning_rate": 0.989374541427544, "gamma": 0.30169332615026057, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "551a63b9-df88-4d47-a57b-65d3d6cbaa28", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 3.7067750605757064e-16, "metric": "f1Macro", "ts": "2018-10-25T01:11:46.941000", "dataset": "LL0_238_drivface_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_238_drivface", "about": {"problemID": "LL0_238_drivface_problem", "problemName": "drivface_problem", "problemDescription": "Dataset to predict head pose of subjects while driving.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_238_drivface_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "label_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-238-drivface"}, "LL0_23_cmc": {"pipeline": {"_id": "115b9a07-306a-45c3-83d6-34e903715b9e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 16}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 10, "min_samples_split": 0.01621355179787197, "min_samples_leaf": 0.02496280366439616, "n_estimators": 480, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "115b9a07-306a-45c3-83d6-34e903715b9e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5484956744435869, "rank": 0.45150432555702774, "metric": "f1Macro", "ts": "2018-10-25T05:53:40.375000", "dataset": "LL0_23_cmc_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_23_cmc", "about": {"problemID": "LL0_23_cmc_problem", "problemName": "LL0_23_cmc_problem", "problemDescription": "**Author**:   \n**Source**: [As obtained from UCI](https://archive.ics.uci.edu/ml/datasets/Contraceptive+Method+Choice)\n**Please cite**:   \n\n1. Title: Contraceptive Method Choice\n \n 2. Sources:\n    (a) Origin:  This dataset is a subset of the 1987 National Indonesia\n                 Contraceptive Prevalence Survey\n    (b) Creator: Tjen-Sien Lim (limt@stat.wisc.edu)\n    (c) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)\n    (c) Date:    June 7, 1997\n \n 3. Past Usage:\n    Lim, T.-S., Loh, W.-Y. & Shih, Y.-S. (1999). A Comparison of\n    Prediction Accuracy, Complexity, and Training Time of Thirty-three\n    Old and New Classification Algorithms. Machine Learning. Forthcoming.\n    (ftp://ftp.stat.wisc.edu/pub/loh/treeprogs/quest1.7/mach1317.pdf or\n    (http://www.stat.wisc.edu/~limt/mach1317.pdf)\n \n 4. Relevant Information:\n    This dataset is a subset of the 1987 National Indonesia Contraceptive\n    Prevalence Survey. The samples are married women who were either not \n    pregnant or do not know if they were at the time of interview. The \n    problem is to predict the current contraceptive method choice \n    (no use, long-term methods, or short-term methods) of a woman based \n    on her demographic and socio-economic characteristics.\n \n 5. Number of Instances: 1473\n \n 6. Number of Attributes: 10 (including the class attribute)\n \n 7. Attribute Information:\n \n    1. Wife's age                     (numerical)\n    2. Wife's education               (categorical)      1=low, 2, 3, 4=high\n    3. Husband's education            (categorical)      1=low, 2, 3, 4=high\n    4. Number of children ever born   (numerical)\n    5. Wife's religion                (binary)           0=Non-Islam, 1=Islam\n    6. Wife's now working?            (binary)           0=Yes, 1=No\n    7. Husband's occupation           (categorical)      1, 2, 3, 4\n    8. Standard-of-living index       (categorical)      1=low, 2, 3, 4=high\n    9. Media exposure                 (binary)           0=Good, 1=Not good\n    10. Contraceptive method used     (class attribute)  1=No-use \n                                                         2=Long-term\n                                                         3=Short-term\n \n 8. Missing Attribute Values: None\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_23_cmc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Contraceptive_method_used"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-23-cmc"}, "LL0_255_breast_cancer_wisconsin_original": {"pipeline": {"_id": "0bc76f0c-72ef-48c1-ad48-eb3d564739a4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 35}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 55, "max_depth": 4, "learning_rate": 0.7168457698650161, "gamma": 0.06856784447144693, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "0bc76f0c-72ef-48c1-ad48-eb3d564739a4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9745926002387322, "rank": 0.025407399761372546, "metric": "f1Macro", "ts": "2018-10-24T23:49:52.733000", "dataset": "LL0_255_breast_cancer_wisconsin_original_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_255_breast_cancer_wisconsin_original", "about": {"problemID": "LL0_255_breast_cancer_wisconsin_original_problem", "problemName": "breast_cancer_wisconsin_original_problem", "problemDescription": "Dataset to diagnose breast cancer from a set of pre-extracted features.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_255_breast_cancer_wisconsin_original_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-255-breast-cancer-wisconsin-original"}, "LL0_25_colic": {"pipeline": {"_id": "d7407d41-ad87-4f4f-82a2-a344d189ccad", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 79}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 279, "max_depth": 5, "learning_rate": 0.973394132437963, "gamma": 0.909764842270249, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d7407d41-ad87-4f4f-82a2-a344d189ccad", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8895189286437756, "rank": 0.11048107135674738, "metric": "f1Macro", "ts": "2018-10-25T01:36:42.403000", "dataset": "LL0_25_colic_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_25_colic", "about": {"problemID": "LL0_25_colic_problem", "problemName": "LL0_25_colic_problem", "problemDescription": "**Author**: Mary McLeish & Matt Cecile, University of Guelph  \nDonor: Will Taylor (taylor@pluto.arc.nasa.gov)   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Horse+Colic) - 8/6/89   \n\n**Horse Colic database**  \nDatabase of surgeries on horses. Possible class attributes: 24 (whether lesion is surgical), others include: 23, 25, 26, and 27\n\nNotes:\n* Hospital_Number is an identifier and should be ignored when modelling\n\nAttribute Information:\n> \n   1:  surgery?\n           1 = Yes, it had surgery\n           2 = It was treated without surgery  \n   2:  Age \n           1 = Adult horse\n           2 = Young (< 6 months)  \n   3:  Hospital Number \n           - numeric id\n           - the case number assigned to the horse\n             (may not be unique if the horse is treated > 1 time)  \n   4:  rectal temperature\n           - linear\n           - in degrees celsius.\n           - An elevated temp may occur due to infection.\n           - temperature may be reduced when the animal is in late shock\n           - normal temp is 37.8\n           - this parameter will usually change as the problem progresses\n                eg. may start out normal, then become elevated because of\n                    the lesion, passing back through the normal range as the\n                    horse goes into shock  \n   5:  pulse \n           - linear\n           - the heart rate in beats per minute\n           - is a reflection of the heart condition: 30 -40 is normal for adults\n           - rare to have a lower than normal rate although athletic horses\n             may have a rate of 20-25\n           - animals with painful lesions or suffering from circulatory shock\n             may have an elevated heart rate  \n   6:  respiratory rate\n           - linear\n           - normal rate is 8 to 10\n           - usefulness is doubtful due to the great fluctuations  \n   7:  temperature of extremities\n           - a subjective indication of peripheral circulation\n           - possible values:\n                1 = Normal\n                2 = Warm\n                3 = Cool\n                4 = Cold\n           - cool to cold extremities indicate possible shock\n           - hot extremities should correlate with an elevated rectal temp.  \n   8:  peripheral pulse\n           - subjective\n           - possible values are:\n                1 = normal\n                2 = increased\n                3 = reduced\n                4 = absent\n           - normal or increased p.p. are indicative of adequate circulation\n             while reduced or absent indicate poor perfusion  \n   9:  mucous membranes\n           - a subjective measurement of colour\n           - possible values are:\n                1 = normal pink\n                2 = bright pink\n                3 = pale pink\n                4 = pale cyanotic\n                5 = bright red / injected\n                6 = dark cyanotic\n           - 1 and 2 probably indicate a normal or slightly increased\n             circulation\n           - 3 may occur in early shock\n           - 4 and 6 are indicative of serious circulatory compromise\n           - 5 is more indicative of a septicemia  \n  10: capillary refill time\n           - a clinical judgement. The longer the refill, the poorer the\n             circulation\n           - possible values\n                1 = < 3 seconds\n                2 = >= 3 seconds  \n  11: pain - a subjective judgement of the horse's pain level\n           - possible values:\n                1 = alert, no pain\n                2 = depressed\n                3 = intermittent mild pain\n                4 = intermittent severe pain\n                5 = continuous severe pain\n           - should NOT be treated as a ordered or discrete variable!\n           - In general, the more painful, the more likely it is to require\n             surgery\n           - prior treatment of pain may mask the pain level to some extent  \n  12: peristalsis                              \n           - an indication of the activity in the horse's gut. As the gut\n             becomes more distended or the horse becomes more toxic, the\n             activity decreases\n           - possible values:\n                1 = hypermotile\n                2 = normal\n                3 = hypomotile\n                4 = absent  \n  13: abdominal distension\n           - An IMPORTANT parameter.\n           - possible values\n                1 = none\n                2 = slight\n                3 = moderate\n                4 = severe\n           - an animal with abdominal distension is likely to be painful and\n             have reduced gut motility.\n           - a horse with severe abdominal distension is likely to require\n             surgery just tio relieve the pressure  \n  14: nasogastric tube\n           - this refers to any gas coming out of the tube\n           - possible values:\n                1 = none\n                2 = slight\n                3 = significant\n           - a large gas cap in the stomach is likely to give the horse\n             discomfort  \n  15: nasogastric reflux\n           - possible values\n                1 = none\n                2 = > 1 liter\n                3 = < 1 liter\n           - the greater amount of reflux, the more likelihood that there is\n             some serious obstruction to the fluid passage from the rest of\n             the intestine  \n  16: nasogastric reflux PH\n           - linear\n           - scale is from 0 to 14 with 7 being neutral\n           - normal values are in the 3 to 4 range  \n  17: rectal examination - feces\n           - possible values\n                1 = normal\n                2 = increased\n                3 = decreased\n                4 = absent\n           - absent feces probably indicates an obstruction  \n  18: abdomen\n           - possible values\n                1 = normal\n                2 = other\n                3 = firm feces in the large intestine\n                4 = distended small intestine\n                5 = distended large intestine\n           - 3 is probably an obstruction caused by a mechanical impaction\n             and is normally treated medically\n           - 4 and 5 indicate a surgical lesion  \n  19: packed cell volume\n           - linear\n           - the # of red cells by volume in the blood\n           - normal range is 30 to 50. The level rises as the circulation\n             becomes compromised or as the animal becomes dehydrated.  \n  20: total protein\n           - linear\n           - normal values lie in the 6-7.5 (gms/dL) range\n           - the higher the value the greater the dehydration  \n  21: abdominocentesis appearance\n           - a needle is put in the horse's abdomen and fluid is obtained from\n             the abdominal cavity\n           - possible values:\n                1 = clear\n                2 = cloudy\n                3 = serosanguinous\n           - normal fluid is clear while cloudy or serosanguinous indicates\n             a compromised gut  \n  22: abdomcentesis total protein\n           - linear\n           - the higher the level of protein the more likely it is to have a\n             compromised gut. Values are in gms/dL  \n  23: outcome\n           - what eventually happened to the horse?\n           - possible values:\n                1 = lived\n                2 = died\n                3 = was euthanized  \n  24: surgical lesion?\n           - retrospectively, was the problem (lesion) surgical?\n           - all cases are either operated upon or autopsied so that\n             this value and the lesion type are always known\n           - possible values:\n                1 = Yes\n                2 = No  \n  25, 26, 27: type of lesion\n           - first number is site of lesion\n                1 = gastric\n                2 = sm intestine\n                3 = lg colon\n                4 = lg colon and cecum\n                5 = cecum\n                6 = transverse colon\n                7 = retum/descending colon\n                8 = uterus\n                9 = bladder\n                11 = all intestinal sites\n                00 = none\n           - second number is type\n                1 = simple\n                2 = strangulation\n                3 = inflammation\n                4 = other\n           - third number is subtype\n                1 = mechanical\n                2 = paralytic\n                0 = n/a\n           - fourth number is specific code\n                1 = obturation\n                2 = intrinsic\n                3 = extrinsic\n                4 = adynamic\n                5 = volvulus/torsion\n                6 = intussuption\n                7 = thromboembolic\n                8 = hernia\n                9 = lipoma/slenic incarceration\n                10 = displacement\n                0 = n/a\n  28: cp_data\n           - is pathology data present for this case?\n                1 = Yes\n                2 = No\n           - this variable is of no significance since pathology data\n             is not included or collected for these cases", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_25_colic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 24, "colName": "surgical_lesion"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-25-colic"}, "LL0_26_nursery": {"pipeline": {"_id": "b6b6dbfe-a3fb-4dd5-b4ae-c35165bd0468", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 67, "max_depth": 4, "learning_rate": 0.6068936075644088, "gamma": 0.3898132379516528, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "b6b6dbfe-a3fb-4dd5-b4ae-c35165bd0468", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9192452158433466, "rank": 0.08075478415666462, "metric": "f1Macro", "ts": "2018-10-25T00:59:29.817000", "dataset": "LL0_26_nursery_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_26_nursery", "about": {"problemID": "LL0_26_nursery_problem", "problemName": "LL0_26_nursery_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Nursery Database\n \n 2. Sources:\n    (a) Creator: Vladislav Rajkovic et al. (13 experts)\n    (b) Donors: Marko Bohanec   (marko.bohanec@ijs.si)\n                Blaz Zupan      (blaz.zupan@ijs.si)\n    (c) Date: June, 1997\n \n 3. Past Usage:\n \n    The hierarchical decision model, from which this dataset is\n    derived, was first presented in \n \n    M. Olave, V. Rajkovic, M. Bohanec: An application for admission in\n    public school systems. In (I. Th. M. Snellen and W. B. H. J. van de\n    Donk and J.-P. Baquiast, editors) Expert Systems in Public\n    Administration, pages 145-160. Elsevier Science Publishers (North\n    Holland)}, 1989.\n \n    Within machine-learning, this dataset was used for the evaluation\n    of HINT (Hierarchy INduction Tool), which was proved to be able to\n    completely reconstruct the original hierarchical model. This,\n    together with a comparison with C4.5, is presented in\n \n    B. Zupan, M. Bohanec, I. Bratko, J. Demsar: Machine learning by\n    function decomposition. ICML-97, Nashville, TN. 1997 (to appear)\n \n 4. Relevant Information Paragraph:\n \n    Nursery Database was derived from a hierarchical decision model\n    originally developed to rank applications for nursery schools. It\n    was used during several years in 1980's when there was excessive\n    enrollment to these schools in Ljubljana, Slovenia, and the\n    rejected applications frequently needed an objective\n    explanation. The final decision depended on three subproblems:\n    occupation of parents and child's nursery, family structure and\n    financial standing, and social and health picture of the family.\n    The model was developed within expert system shell for decision\n    making DEX (M. Bohanec, V. Rajkovic: Expert system for decision\n    making. Sistemica 1(1), pp. 145-157, 1990.).\n \n    The hierarchical model ranks nursery-school applications according\n    to the following concept structure:\n \n    NURSERY            Evaluation of applications for nursery schools\n    . EMPLOY           Employment of parents and child's nursery\n    . . parents        Parents' occupation\n    . . has_nurs       Child's nursery\n    . STRUCT_FINAN     Family structure and financial standings\n    . . STRUCTURE      Family structure\n    . . . form         Form of the family\n    . . . children     Number of children\n    . . housing        Housing conditions\n    . . finance        Financial standing of the family\n    . SOC_HEALTH       Social and health picture of the family\n    . . social         Social conditions\n    . . health         Health conditions\n \n    Input attributes are printed in lowercase. Besides the target\n    concept (NURSERY) the model includes four intermediate concepts:\n    EMPLOY, STRUCT_FINAN, STRUCTURE, SOC_HEALTH. Every concept is in\n    the original model related to its lower level descendants by a set\n    of examples (for these examples sets see \n    http://www-ai.ijs.si/BlazZupan/nursery.html).\n \n    The Nursery Database contains examples with the structural\n    information removed, i.e., directly relates NURSERY to the eight input\n    attributes: parents, has_nurs, form, children, housing, finance,\n    social, health.\n \n    Because of known underlying concept structure, this database may be\n    particularly useful for testing constructive induction and\n    structure discovery methods.\n \n 5. Number of Instances: 12960\n    (instances completely cover the attribute space)\n \n 6. Number of Attributes: 8\n \n 7. Attribute Values:\n \n    parents        usual, pretentious, great_pret\n    has_nurs       proper, less_proper, improper, critical, very_crit\n    form           complete, completed, incomplete, foster\n    children       1, 2, 3, more\n    housing        convenient, less_conv, critical\n    finance        convenient, inconv\n    social         non-prob, slightly_prob, problematic\n    health         recommended, priority, not_recom\n \n 8. Missing Attribute Values: none\n \n 9. Class Distribution (number of instances per class)\n \n    class        N         N[%]\n    ------------------------------\n    not_recom    4320   (33.333 %)\n    recommend       2   ( 0.015 %)\n    very_recom    328   ( 2.531 %)\n    priority     4266   (32.917 %)\n    spec_prior   4044   (31.204 %)\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_26_nursery_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-26-nursery"}, "LL0_285_flags": {"pipeline": {"_id": "381dcab3-ee81-4c24-95d7-22ac24a18330", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 5}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 8, "learning_rate": 0.9822624267542152, "gamma": 0.6138108569261527, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "381dcab3-ee81-4c24-95d7-22ac24a18330", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.544570707070707, "rank": 0.45542929292990303, "metric": "f1Macro", "ts": "2018-10-25T00:14:52.994000", "dataset": "LL0_285_flags_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_285_flags", "about": {"problemID": "LL0_285_flags_problem", "problemName": "flags_problem", "problemDescription": "**Author**: Richard S. Forsyth  \n**Source**: Unknown - 5/15/1990  \n**Please cite**:   \n\nARFF version of UCI dataset 'flags'.\n\nCreators: Collected primarily from the \"Collins Gem Guide to Flags\": Collins Publishers (1986). Donor: Richard S. Forsyth. Date 5/15/1990\n\nThis data file contains details of various nations and their flags.\nWith this data you can try things like predicting the religion of a country from its size and the colours in its flag. 10 attributes are numeric-valued.  The remainder are either Boolean-  or nominal-valued.\n\nNumber of Instances: 194. Number of attributes: 30 (overall). Missing values: none\n\nAttribute Information:\n1. name Name of the country concerned\n2. landmass 1=N.America, 2=S.America, 3=Europe, 4=Africa, 4=Asia, 6=Oceania\n3. zone Geographic quadrant, based on Greenwich and the Equator 1=NE, 2=SE, 3=SW, 4=NW\n4. area in thousands of square km\n5. population in round millions\n6. language 1=English, 2=Spanish, 3=French, 4=German, 5=Slavic, 6=Other Indo-European, 7=Chinese, 8=Arabic, 9=Japanese/Turkish/Finnish/Magyar, 10=Others\n7. religion 0=Catholic, 1=Other Christian, 2=Muslim, 3=Buddhist, 4=Hindu, 5=Ethnic, 6=Marxist, 7=Others\n8. bars     Number of vertical bars in the flag\n9. stripes  Number of horizontal stripes in the flag\n10. colours  Number of different colours in the flag\n11. red      0 if red absent, 1 if red present in the flag\n12. green    same for green\n13. blue     same for blue\n14. gold     same for gold (also yellow)\n15. white    same for white\n16. black    same for black\n17. orange   same for orange (also brown)\n18. mainhue  predominant colour in the flag (tie-breaks decided by taking the topmost hue, if that fails then the most central hue, and if that fails the leftmost hue)\n19. circles  Number of circles in the flag\n20. crosses  Number of (upright) crosses\n21. saltires Number of diagonal crosses\n22. quarters Number of quartered sections\n23. sunstars Number of sun or star symbols\n24. crescent 1 if a crescent moon symbol present, else 0\n25. triangle 1 if any triangles present, 0 otherwise\n26. icon     1 if an inanimate image present (e.g., a boat), otherwise 0\n27. animate  1 if an animate image (e.g., an eagle, a tree, a human hand) present, 0 otherwise\n28. text     1 if any letters or writing on the flag (e.g., a motto or slogan), 0 otherwise\n29. topleft  colour in the top-left corner (moving right to decide tie-breaks)\n30. botright Colour in the bottom-left corner (moving left to decide \ntie-breaks)", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_285_flags_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "religion"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-285-flags"}, "LL0_287_wine_quality": {"pipeline": {"_id": "2f3f0afe-a42d-4be1-971c-b14a3ae0e619", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 921, "max_depth": 9, "learning_rate": 0.09484983266084857, "gamma": 0.02078815136177825, "min_child_weight": 5}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "2f3f0afe-a42d-4be1-971c-b14a3ae0e619", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.39751322641065323, "rank": 0.3975132264114006, "metric": "meanSquaredError", "ts": "2018-10-24T20:13:07.637000", "dataset": "LL0_287_wine_quality_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_287_wine_quality", "about": {"problemID": "LL0_287_wine_quality_problem", "problemName": "LL0_287_wine_quality_problem", "problemDescription": "**Author**: Tobias Kuehn  \n**Source**: Unknown - 2009  \n**Please cite**:   \n\n1. Title: Wine Quality \n\n2. Sources\nCreated by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009\n    \n3. Past Usage:\nP. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \nModeling wine preferences by data mining from physicochemical properties.\nIn Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n\nIn the above reference, two datasets were created, using red and white wine samples.\nThe inputs include objective tests (e.g. PH values) and the output is based on sensory data (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model these datasets under a regression approach. The support vector machine model achieved the best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T), etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity analysis procedure).\n \n4. Relevant Information:\nThe two datasets are related to red and white variants of the Portuguese \"Vinho Verde\" wine. For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009]. Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables  are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\nThese datasets can be viewed as classification or regression tasks.\nThe classes are ordered and not balanced (e.g. there are munch more normal wines than excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent or poor wines. Also, we are not sure if all input variables are relevant. So it could be interesting to test feature selection methods. \n\n5. Number of Instances: red wine - first 1599 instances; white wine - instances 1600 to 6497. \n \n6. Number of Attributes: 11 + output attribute\nNote: several of the attributes may be correlated, thus it makes sense to apply some sort of feature selection.\n\n7. Attribute information:\nFor more information, read [Cortez et al., 2009].\nInput variables (based on physicochemical tests):\n1 - fixed acidity\n2 - volatile acidity\n3 - citric acid\n4 - residual sugar\n5 - chlorides\n6 - free sulfur dioxide\n7 - total sulfur dioxide\n8 - density\n9 - pH\n10 - sulphates\n11 - alcohol\nOutput variable (based on sensory data): \n12 - quality (score between 0 and 10)\n\n8. Missing Attribute Values: None", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_287_wine_quality_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 12, "colName": "quality"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-287-wine-quality"}, "LL0_28_optdigits": {"pipeline": {"_id": "47f51c17-27e4-42b0-8c12-ec952b32288d", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "47f51c17-27e4-42b0-8c12-ec952b32288d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.978682878531489, "rank": 0.02131712146930079, "metric": "f1Macro", "ts": "2018-10-31T04:09:39.222000", "dataset": "LL0_28_optdigits_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_28_optdigits", "about": {"problemID": "LL0_28_optdigits_problem", "problemName": "LL0_28_optdigits_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Optical Recognition of Handwritten Digits\n \n 2. Source:\n \tE. Alpaydin, C. Kaynak\n \tDepartment of Computer Engineering\n \tBogazici University, 80815 Istanbul Turkey\n \talpaydin@boun.edu.tr\n \tJuly 1998\n \n 3. Past Usage:\n \tC. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n \tApplications to Handwritten Digit Recognition, \n \tMSc Thesis, Institute of Graduate Studies in Science and \n \tEngineering, Bogazici University.\n \n \tE. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika,\n \tto appear. ftp://ftp.icsi.berkeley.edu/pub/ai/ethem/kyb.ps.Z\n \n 4. Relevant Information:\n \tWe used preprocessing programs made available by NIST to extract\n \tnormalized bitmaps of handwritten digits from a preprinted form. From\n \ta total of 43 people, 30 contributed to the training set and different\n \t13 to the test set. 32x32 bitmaps are divided into nonoverlapping \n \tblocks of 4x4 and the number of on pixels are counted in each block.\n \tThis generates an input matrix of 8x8 where each element is an \n \tinteger in the range 0..16. This reduces dimensionality and gives \n \tinvariance to small distortions.\n \n \tFor info on NIST preprocessing routines, see \n \tM. D. Garris, J. L. Blue, G. T. Candela, D. L. Dimmick, J. Geist, \n \tP. J. Grother, S. A. Janet, and C. L. Wilson, NIST Form-Based \n \tHandprint Recognition System, NISTIR 5469, 1994.\n \n 5. Number of Instances\n \toptdigits.tra\tTraining\t3823\n \toptdigits.tes\tTesting\t\t1797\n \t\n \tThe way we used the dataset was to use half of training for \n \tactual training, one-fourth for validation and one-fourth\n \tfor writer-dependent testing. The test set was used for \n \twriter-independent testing and is the actual quality measure.\n \n 6. Number of Attributes\n \t64 input+1 class attribute\n \n 7. For Each Attribute:\n \tAll input attributes are integers in the range 0..16.\n \tThe last attribute is the class code 0..9\n \n 8. Missing Attribute Values\n \tNone\n \n 9. Class Distribution\n \tClass:\tNo of examples in training set\n \t0:  376\n \t1:  389\n \t2:  380\n \t3:  389\n \t4:  387\n \t5:  376\n \t6:  377\n \t7:  387\n \t8:  380\n \t9:  382\n \n \tClass: No of examples in testing set\n \t0:  178\n \t1:  182\n \t2:  177\n \t3:  183\n \t4:  181\n \t5:  182\n \t6:  181\n \t7:  179\n \t8:  174\n \t9:  180\n \n Accuracy on the testing set with k-nn \n using Euclidean distance as the metric\n \n  k =  1   : 98.00\n  k =  2   : 97.38\n  k =  3   : 97.83\n  k =  4   : 97.61\n  k =  5   : 97.89\n  k =  6   : 97.77\n  k =  7   : 97.66\n  k =  8   : 97.66\n  k =  9   : 97.72\n  k = 10   : 97.55\n  k = 11   : 97.89", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_28_optdigits_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 65, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-28-optdigits"}, "LL0_294_satellite_image": {"pipeline": {"_id": "cacd6cc7-8560-444a-b92d-2591353ba403", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 59}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 424, "max_depth": 7, "learning_rate": 0.11044878022778737, "gamma": 0.005010564940707729, "min_child_weight": 9}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "cacd6cc7-8560-444a-b92d-2591353ba403", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.48124780078378304, "rank": 0.48124780078390894, "metric": "meanSquaredError", "ts": "2018-10-24T20:26:30.802000", "dataset": "LL0_294_satellite_image_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_294_satellite_image", "about": {"problemID": "LL0_294_satellite_image_problem", "problemName": "LL0_294_satellite_image_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - 1993  \n**Please cite**:   \n\nSource:\nAshwin Srinivasan\nDepartment of Statistics and Data Modeling\nUniversity of Strathclyde\nGlasgow\nScotland\nUK\nross '@' uk.ac.turing\n\nThe original Landsat data for this database was generated from data purchased from NASA by the Australian Centre for Remote Sensing, and used for research at: \nThe Centre for Remote Sensing\nUniversity of New South Wales\nKensington, PO Box 1\nNSW 2033\nAustralia.\n\nThe sample database was generated taking a small section (82 rows and 100 columns) from the original data. The binary values were converted to their present ASCII form by Ashwin Srinivasan. The classification for each pixel was performed on the basis of an actual site visit by Ms. Karen Hall, when working for Professor John A. Richards, at the Centre for Remote Sensing at the University of New South Wales, Australia. Conversion to 3x3 neighbourhoods and splitting into test and training sets was done by Alistair Sutherland.\n\nData Set Information:\nThe database consists of the multi-spectral values of pixels in 3x3 neighbourhoods in a satellite image, and the classification associated with the central pixel in each neighbourhood. The aim is to predict this classification, given the multi-spectral values. In the sample database, the class of a pixel is coded as a number. The Landsat satellite data is one of the many sources of information available for a scene. The interpretation of a scene by  integrating spatial data of diverse types and resolutions including multispectral and radar data, maps indicating topography, land use etc. is expected to assume significant importance with the onset of an era characterised by integrative approaches to remote sensing (for example, NASA's Earth Observing System commencing this decade). Existing statistical methods are ill-equipped for handling such diverse data types. Note that this is not true for Landsat MSS data considered in isolation (as in this sample database). This data satisfies the important requirements of being numerical and at a single resolution, and standard maximum-likelihood classification performs very well. Consequently, for this data, it should be interesting to compare the performance of other methods against the statistical approach. One frame of Landsat MSS imagery consists of four digital images of the same scene in different spectral bands. Two of these are in the visible region (corresponding approximately to green and red regions of the visible spectrum) and two are in the (near) infra-red. Each pixel is a 8-bit binary word, with 0 corresponding to black and 255 to white. The spatial resolution of a pixel is about 80m x 80m. Each image contains 2340 x 3380 such pixels. The database is a (tiny) sub-area of a scene, consisting of 82 x 100 pixels. Each line of data corresponds to a 3x3 square neighbourhood of pixels completely contained within the 82x100 sub-area. Each line contains the pixel values in the four spectral bands (converted to ASCII) of each of the 9 pixels in the 3x3 neighbourhood and a number indicating the classification label of the central pixel. The number is a code for the following classes:\n\nNumber Class\n1 red soil\n2 cotton crop\n3 grey soil\n4 damp grey soil\n5 soil with vegetation stubble\n6 mixture class (all types present)\n7 very damp grey soil\nNB. There are no examples with class 6 in this dataset.\n \nThe data is given in random order and certain lines of data have been removed so you cannot reconstruct the original image from this dataset. In each line of data the four spectral values for the top-left pixel are given first followed by the four spectral values for the top-middle pixel and then those for the top-right pixel, and so on with the pixels read out in sequence left-to-right and top-to-bottom. Thus, the four spectral values for the central pixel are given by attributes 17,18,19 and 20. If you like you can use only these four attributes, while ignoring the others. This avoids the problem which arises when a 3x3 neighbourhood straddles a boundary.\n\nAttribute Information:\nThe attributes are numerical, in the range 0 to 255.\n\nUCI: http://archive.ics.uci.edu/ml/datasets/Statlog+(Landsat+Satellite)", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_294_satellite_image_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 37, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-294-satellite-image"}, "LL0_296_ailerons": {"pipeline": {"_id": "c4a0ac7a-3714-407e-8777-5120b2eec2e7", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "c4a0ac7a-3714-407e-8777-5120b2eec2e7", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.8724278730675802e-08, "rank": 2.8724477322750717e-08, "metric": "meanSquaredError", "ts": "2018-10-31T04:09:07.781000", "dataset": "LL0_296_ailerons_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_296_ailerons", "about": {"problemID": "LL0_296_ailerons_problem", "problemName": "LL0_296_ailerons_problem", "problemDescription": "**Author**: Luis Torgo\",\"Rui Camacho  \n**Source**: Unknown - 2014-08-18  \n**Please cite**:   \n\nThis data set addresses a control problem, namely flying a F16 aircraft. The attributes describe the status of the aeroplane, while the goal is to predict the control action on the ailerons of the aircraft.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_296_ailerons_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "goal"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-296-ailerons"}, "LL0_298_coil2000": {"pipeline": {"_id": "d0aa3101-9b53-44f6-885e-db02abf41b72", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 33}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 944, "max_depth": 4, "learning_rate": 0.10577814628557569, "gamma": 0.24196492033089412, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "d0aa3101-9b53-44f6-885e-db02abf41b72", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.052004854062059944, "rank": 0.05200485406228691, "metric": "meanSquaredError", "ts": "2018-10-24T21:17:32.992000", "dataset": "LL0_298_coil2000_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_298_coil2000", "about": {"problemID": "LL0_298_coil2000_problem", "problemName": "coil2000_problem", "problemDescription": "**Author**: Peter van der Putten  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Insurance+Company+Benchmark+(COIL+2000))  \n**Please cite**: P. van der Putten and M. van Someren (eds) . CoIL Challenge 2000: The Insurance Company Case. Published by Sentient Machine Research, Amsterdam. Leiden Institute of Advanced Computer Science Technical Report 2000-09. June 22, 2000. [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n\n**Insurance Company Benchmark (COIL 2000)**\nInformation about customers consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was supplied by the Dutch data mining company Sentient Machine Research and is based on a real world business problem. The training set contains over 5000 descriptions of customers, including the information of whether or not they have a caravan insurance policy. A test set contains 4000 customers of whom only the organisers know if they have a caravan insurance policy.\n\nThe data dictionary describes the variables used and their values: TIC Benchmark Homepage: http://www.liacs.nl/~putten/library/cc2000/ \n\n### Attribute Information  \nEach record consists of 86 attributes, containing sociodemographic data (attribute 1-43) and product ownership (attributes 44-86).The sociodemographic data is derived from zip codes. All customers living in areas with the same zip code have the same sociodemographic attributes. Attribute \"CARAVAN\", the number of mobile home policies, is the target variable.\n\nAll the variables starting with M are zipcode variables. They give information on the distribution of that variable, e.g. Rented house, in the zipcode area of the customer. \n\n```\n1 MOSTYPE Customer Subtype see L0\n2 MAANTHUI Number of houses 1 \u0096 10\n3 MGEMOMV Avg size household 1 \u0096 6\n4 MGEMLEEF Avg age see L1\n5 MOSHOOFD Customer main type see L2\n6 MGODRK Roman catholic see L3\n7 MGODPR Protestant ...\n8 MGODOV Other religion\n9 MGODGE No religion\n10 MRELGE Married\n11 MRELSA Living together\n12 MRELOV Other relation\n13 MFALLEEN Singles\n14 MFGEKIND Household without children\n15 MFWEKIND Household with children\n16 MOPLHOOG High level education\n17 MOPLMIDD Medium level education\n18 MOPLLAAG Lower level education\n19 MBERHOOG High status\n20 MBERZELF Entrepreneur\n21 MBERBOER Farmer\n22 MBERMIDD Middle management\n23 MBERARBG Skilled labourers\n24 MBERARBO Unskilled labourers\n25 MSKA Social class A\n26 MSKB1 Social class B1\n27 MSKB2 Social class B2\n28 MSKC Social class C\n29 MSKD Social class D\n30 MHHUUR Rented house\n31 MHKOOP Home owners\n32 MAUT1 1 car\n33 MAUT2 2 cars\n34 MAUT0 No car\n35 MZFONDS National Health Service\n36 MZPART Private health insurance\n37 MINKM30 Income < 30>123.000\n42 MINKGEM Average income\n43 MKOOPKLA Purchasing power class\n44 PWAPART Contribution private third party insurance see L4\n45 PWABEDR Contribution third party insurance (firms) ...\n46 PWALAND Contribution third party insurane (agriculture)\n47 PPERSAUT Contribution car policies\n48 PBESAUT Contribution delivery van policies\n49 PMOTSCO Contribution motorcycle/scooter policies\n50 PVRAAUT Contribution lorry policies\n51 PAANHANG Contribution trailer policies\n52 PTRACTOR Contribution tractor policies\n53 PWERKT Contribution agricultural machines policies \n54 PBROM Contribution moped policies\n55 PLEVEN Contribution life insurances\n56 PPERSONG Contribution private accident insurance policies\n57 PGEZONG Contribution family accidents insurance policies\n58 PWAOREG Contribution disability insurance policies\n59 PBRAND Contribution fire policies\n60 PZEILPL Contribution surfboard policies\n61 PPLEZIER Contribution boat policies\n62 PFIETS Contribution bicycle policies\n63 PINBOED Contribution property insurance policies\n64 PBYSTAND Contribution social security insurance policies\n65 AWAPART Number of private third party insurance 1 - 12\n66 AWABEDR Number of third party insurance (firms) ...\n67 AWALAND Number of third party insurane (agriculture)\n68 APERSAUT Number of car policies\n69 ABESAUT Number of delivery van policies\n70 AMOTSCO Number of motorcycle/scooter policies\n71 AVRAAUT Number of lorry policies\n72 AAANHANG Number of trailer policies\n73 ATRACTOR Number of tractor policies\n74 AWERKT Number of agricultural machines policies\n75 ABROM Number of moped policies\n76 ALEVEN Number of life insurances\n77 APERSONG Number of private accident insurance policies\n78 AGEZONG Number of family accidents insurance policies\n79 AWAOREG Number of disability insurance policies\n80 ABRAND Number of fire policies\n81 AZEILPL Number of surfboard policies\n82 APLEZIER Number of boat policies\n83 AFIETS Number of bicycle policies\n84 AINBOED Number of property insurance policies\n85 ABYSTAND Number of social security insurance policies\n86 CARAVAN Number of mobile home policies 0 - 1\n\nL0: Value Label\n1 High Income, expensive child\n2 Very Important Provincials\n3 High status seniors\n4 Affluent senior apartments\n5 Mixed seniors\n6 Career and childcare\n7 Dinki's (double income no kids)\n8 Middle class families\n9 Modern, complete families\n10 Stable family\n11 Family starters\n12 Affluent young families\n13 Young all american family\n14 Junior cosmopolitan\n15 Senior cosmopolitans\n16 Students in apartments\n17 Fresh masters in the city\n18 Single youth\n19 Suburban youth\n20 Etnically diverse\n21 Young urban have-nots\n22 Mixed apartment dwellers\n23 Young and rising\n24 Young, low educated \n25 Young seniors in the city\n26 Own home elderly\n27 Seniors in apartments\n28 Residential elderly\n29 Porchless seniors: no front yard\n30 Religious elderly singles\n31 Low income catholics\n32 Mixed seniors\n33 Lower class large families \n34 Large family, employed child\n35 Village families\n36 Couples with teens 'Married with children'\n37 Mixed small town dwellers\n38 Traditional families\n39 Large religous families\n40 Large family farms\n41 Mixed rurals\n\nL1:\n1 20-30 years\n2 30-40 years\n3 40-50 years\n4 50-60 years\n5 60-70 years\n6 70-80 years\n\nL2:\n1 Successful hedonists\n2 Driven Growers\n3 Average Family\n4 Career Loners\n5 Living well\n6 Cruising Seniors\n7 Retired and Religeous\n8 Family with grown ups\n9 Conservative families\n10 Farmers\n\nL3:\n0 0%\n1 1 - 10%\n2 11 - 23%\n3 24 - 36%\n4 37 - 49%\n5 50 - 62%\n6 63 - 75%\n7 76 - 88%\n8 89 - 99%\n9 100%\n\nL4:\n0 f 0\n1 f 1 \u0096 49\n2 f 50 \u0096 99\n3 f 100 \u0096 99\n4 f 200 \u0096 499\n5 f 500 \u0096 999\n6 f 1000 \u0096 4999\n7 f 5000 \u0096 9999\n8 f 10.000 - 19.999\n9 f 20.000 - ?\n```", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_298_coil2000_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 86, "colName": "CARAVAN"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-298-coil2000"}, "LL0_29_credit_approval": {"pipeline": {"_id": "006df13c-ba41-433f-9940-2272828d73ad", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 41}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 19, "max_depth": 9, "learning_rate": 0.753968731817388, "gamma": 0.7321638617085713, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "006df13c-ba41-433f-9940-2272828d73ad", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8922411116357132, "rank": 0.10775888836484772, "metric": "f1Macro", "ts": "2018-10-25T00:20:30.580000", "dataset": "LL0_29_credit_approval_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_29_credit_approval", "about": {"problemID": "LL0_29_credit_approval_problem", "problemName": "LL0_29_credit_approval_problem", "problemDescription": "**Author**: Confidential - Donated by Ross Quinlan   \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/credit+approval) - 1987  \n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**Credit Approval**\nThis file concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data.  \n   \nThis dataset is interesting because there is a good mix of attributes -- continuous, nominal with small numbers of values, and nominal with larger numbers of values.  There are also a few missing values.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_29_credit_approval_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 16, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-29-credit-approval"}, "LL0_300_isolet": {"pipeline": {"_id": "bc166a8b-a0c9-49ee-870d-5378ac34d76d", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "bc166a8b-a0c9-49ee-870d-5378ac34d76d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9515551625983619, "rank": 0.0484448374026032, "metric": "f1Macro", "ts": "2018-10-31T05:08:19.422000", "dataset": "LL0_300_isolet_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_300_isolet", "about": {"problemID": "LL0_300_isolet_problem", "problemName": "LL0_300_isolet_problem", "problemDescription": "**Author**: Ron Cole and Mark Fanty (cole@cse.ogi.edu, fanty@cse.ogi.edu)  \n**Donor**: Tom Dietterich (tgd@cs.orst.edu)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/ISOLET)   \n**Please cite**: UCI  \n\n### Description\n\nISOLET (Isolated Letter Speech Recognition) dataset was generated as follows: 150 subjects spoke the name of each letter of the alphabet twice. Hence, there are 52 training examples from each speaker. The speakers are grouped into sets of 30 speakers each, 4 groups can serve as training set, the last group as the test set. A total of 3 examples are missing, the authors dropped them due to difficulties in recording. \n\nThis is a good domain for a noisy, perceptual task. It is also a very good domain for testing the scaling abilities of algorithms. For example, C4.5 on this domain is slower than backpropagation!\n\n### Source\n\n* Creators: \nRon Cole and Mark Fanty \nDepartment of Computer Science and Engineering, \nOregon Graduate Institute, Beaverton, OR 97006. \ncole '@' cse.ogi.edu, fanty '@' cse.ogi.edu \n\n* Donor: \nTom Dietterich \nDepartment of Computer Science \nOregon State University, Corvallis, OR 97331 \ntgd '@' cs.orst.edu\n\n### Attributes Information\n  \nAll attributes are continuous, real-valued attributes scaled into the range -1.0 to 1.0. The features are described in the paper by Cole and Fanty cited below. \nThe features include spectral coefficients; contour features, sonorant features, pre-sonorant features, and post-sonorant features. The exact order of appearance of the features is not known.\n\n### Relevant papers\n\nFanty, M., Cole, R. (1991).  Spoken letter recognition.  \nIn Lippman, R. P., Moody, J., and Touretzky, D. S. (Eds). Advances in Neural Information Processing Systems 3.  San Mateo, CA: Morgan Kaufmann.\n\nDietterich, T. G., Bakiri, G. (1991)  Error-correcting output codes: A general method for improving multiclass inductive learning programs.  \nProceedings of the Ninth National Conference on Artificial Intelligence (AAAI-91), Anaheim, CA: AAAI Press.\n\nDietterich, T. G., Bakiri, G. (1994) Solving Multiclass Learning Problems via Error-Correcting Output Codes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_300_isolet_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 618, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-300-isolet"}, "LL0_301_ozone_level": {"pipeline": {"_id": "a6fa8cab-bbd3-4022-b1e6-86d776e14615", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 0}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 10, "min_samples_split": 0.1, "min_samples_leaf": 0.1, "n_estimators": 30}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "a6fa8cab-bbd3-4022-b1e6-86d776e14615", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.029439760511244084, "rank": 0.02943976051198778, "metric": "meanSquaredError", "ts": "2018-10-24T20:15:47.067000", "dataset": "LL0_301_ozone_level_dataset_TRAIN", "test_id": "20181024201213536304"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_301_ozone_level", "about": {"problemID": "LL0_301_ozone_level_problem", "problemName": "ozone_level_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Ozone Level Detection\n2. Source:\nKun Zhang\nzhang.kun05 '@' gmail.com\nDepartment of Computer Science, \nXavier University of Lousiana\n\nWei Fan\nwei.fan '@' gmail.com\nIBM T.J.Watson Research\n\nXiaoJing Yuan\nxyuan '@' uh.edu\nEngineering Technology Department, \nCollege of Technology, University of Houston \n\n3. Past Usage:\nForecasting skewed biased stochastic ozone days: analyses, solutions and beyond, Knowledge and Information Systems, Vol. 14, No. 3, 2008.\nDiscusses details about the dataset, its use as well as various experiments (both cross-validation and streaming) using many state-of-the-art methods.\n\nA shorter version of the paper (does not contain some detailed experiments as the journal paper above) is in:\nForecasting Skewed Biased Stochastic Ozone Days: Analyses and Solutions. ICDM 2006: 753-764 \n\n4. Relevant Information:\nThe following are specifications for several most important attributes \nthat are highly valued by Texas Commission on Environmental Quality (TCEQ). \nMore details can be found in the two relevant papers.\n \n-- O 3 - Local ozone peak prediction\n-- Upwind - Upwind ozone background level\n-- EmFactor - Precursor emissions related factor\n-- Tmax - Maximum temperature in degrees F\n-- Tb - Base temperature where net ozone production begins (50 F)\n-- SRd - Solar radiation total for the day\n-- WSa - Wind speed near sunrise (using 09-12 UTC forecast mode)\n-- WSp - Wind speed mid-day (using 15-21 UTC forecast mode) \n\n5. Number of Instances: 2536\n\n6. Number of Attributes: 73\n\n7. Attribute Information:\n1,0 | two classes 1: ozone day, 0: normal day", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_301_ozone_level_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 73, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-301-ozone-level"}, "LL0_307_vowel": {"pipeline": {"_id": "9fb43618-f857-4a44-8873-143d130e46ee", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 80}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 24, "min_samples_split": 0.0029734106871196803, "min_samples_leaf": 0.0076255606107707204, "n_estimators": 212, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "9fb43618-f857-4a44-8873-143d130e46ee", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8993293185630096, "rank": 0.10067068143742351, "metric": "f1Macro", "ts": "2018-10-25T04:59:56.548000", "dataset": "LL0_307_vowel_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_307_vowel", "about": {"problemID": "LL0_307_vowel_problem", "problemName": "LL0_307_vowel_problem", "problemDescription": "**Author**: Peter Turney (peter@ai.iit.nrc.ca)   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/vowel/) - date unknown  \n**Please cite**:   \n\n# NAME: Vowel Recognition (Deterding data)\n\nSUMMARY: Speaker independent recognition of the eleven steady state vowels\nof British English using a specified training set of lpc derived log area\nratios.\n\nSOURCE: David Deterding  (data and non-connectionist analysis)\n        Mahesan Niranjan (first connectionist analysis)\n        Tony Robinson    (description, program, data, and results)\n\nTo contact Tony Robinson by electronic mail, use address\n\"tony@av-convex.ntt.jp\" until 1 June 1989, and \"ajr@dsl.eng.cam.ac.uk\"\nthereafter.\n\nMAINTAINER: Scott E. Fahlman, CMU\n\n## PROBLEM DESCRIPTION:\n\nThe problem is specified by the accompanying data file, \"vowel.data\".  This\nconsists of a three dimensional array: voweldata [speaker, vowel, input].\nThe speakers are indexed by integers 0-89.  (Actually, there are fifteen\nindividual speakers, each saying each vowel six times.)  The vowels are\nindexed by integers 0-10.  For each utterance, there are ten floating-point\ninput values, with array indices 0-9.\n\nThe problem is to train the network as well as possible using only on data\nfrom \"speakers\" 0-47, and then to test the network on speakers 48-89,\nreporting the number of correct classifications in the test set.\n\nFor a more detailed explanation of the problem, see the excerpt from Tony\nRobinson's Ph.D. thesis in the COMMENTS section.  In Robinson's opinion,\nconnectionist problems fall into two classes, the possible and the\nimpossible.  He is interested in the latter, by which he means problems\nthat have no exact solution.  Thus the problem here is not to see how fast\na network can be trained (although this is important), but to maximise a\nless than perfect performance.\n\n## METHODOLOGY:\n\nReport the number of test vowels classified correctly, (i.e. the number of\noccurences when distance of the correct output to the actual output was the\nsmallest of the set of distances from the actual output to all possible\ntarget outputs).\n\nThough this is not the focus of Robinson's study, it would also be useful\nto report how long the training took (measured in pattern presentations or\nwith a rough count of floating-point operations required) and what level of\nsuccess was achieved on the training and testing data after various amounts\nof training.  Of course, the network topology and algorithm used should be\nprecisely described as well.\n\n## VARIATIONS:\n\nThis benchmark is proposed to encourage the exploration of different node\ntypes.  Please theorise/experiment/hack.  The author (Robinson) will try to\ncorrespond by email if requested.  In particular there has been some\ndiscussion recently on the use of a cross-entropy distance measure, and it\nwould be interesting to see results for that.\n\n## RESULTS:\n\nHere is a summary of results obtained by Tony Robinson.  A more complete\nexplanation of this data is given in the exceprt from his thesis in the\nCOMMENTS section below.  The program used to obtain these results is in the\ncode directory, /afs/cs.cmu.edu/project as \"vowel.c\".\n\n+-------------------------+--------+---------+---------+\n|     | no. of | no.     | percent |\n| Classifier              | hidden | correct | correct |\n|     | units  |         |         | \n+-------------------------+--------+---------+---------+\n| Single-layer perceptron |  -     | 154     | 33      | \n| Multi-layer perceptron  | 88     | 234     | 51      |\n| Multi-layer perceptron  | 22     | 206     | 45      |\n| Multi-layer perceptron  | 11     | 203     | 44      | \n| Modified Kanerva Model  | 528    | 231     | 50      |\n| Modified Kanerva Model  | 88     | 197     | 43      | \n| Radial Basis Function   | 528    | 247     | 53      |\n| Radial Basis Function   | 88     | 220     | 48      | \n| Gaussian node network   | 528    | 252     | 55      |\n| Gaussian node network   | 88     | 247     | 53      |\n| Gaussian node network   | 22     | 250     | 54      |\n| Gaussian node network   | 11     | 211     | 47      | \n| Square node network     | 88     | 253     | 55      |\n| Square node network     | 22     | 236     | 51      |\n| Square node network     | 11     | 217     | 50      | \n| Nearest neighbour       |  -     | 260     | 56      | \n+-------------------------+--------+---------+---------+\n\n## Notes: \n\n1. Each of these numbers is based on a single trial with random starting\nweights.  More trials would of course be preferable, but the computational\nfacilities available to Robinson were limited.\n\n2. Graphs are given in Robinson's thesis showing test-set performance vs.\nepoch count for some of the training runs.  In most cases, performance\npeaks at around 250 correct, after which performance decays to different\ndegrees.  The numbers given above are final performance figures after about\n3000 trials, not the peak performance obtained during the run.\n\n## REFERENCES:\n\n[Deterding89] D. H. Deterding, 1989, University of Cambridge, \"Speaker\n Normalisation for Automatic Speech Recognition\", submitted for PhD.\n\n[NiranjanFallside88] M. Niranjan and F. Fallside, 1988, Cambridge University\n Engineering Department, \"Neural Networks and Radial Basis Functions in\n Classifying Static Speech Patterns\", CUED/F-INFENG/TR.22.\n\n[RenalsRohwer89-ijcnn] Steve Renals and Richard Rohwer, \"Phoneme\n Classification Experiments Using Radial Basis Functions\", Submitted to\n the International Joint Conference on Neural Networks, Washington,\n 1989.\n\n[RabinerSchafer78] L. R. Rabiner and R. W. Schafer, Englewood Cliffs, New\n Jersey, 1978, Prentice Hall, \"Digital Processing of Speech Signals\".\n\n[PragerFallside88] R. W. Prager and F. Fallside, 1988, Cambridge University\n Engineering Department, \"The Modified Kanerva Model for Automatic\n Speech Recognition\", CUED/F-INFENG/TR.6.\n\n[BroomheadLowe88] D. Broomhead and D. Lowe, 1988, Royal Signals and Radar\n Establishment, Malvern, \"Multi-variable Interpolation and Adaptive\n Networks\", RSRE memo, #4148.\n\n[RobinsonNiranjanFallside88-tr] A. J. Robinson and M. Niranjan and F. \n   Fallside, 1988, Cambridge University Engineering Department,\n \"Generalising the Nodes of the Error Propagation Network\",\n CUED/F-INFENG/TR.25.\n\n[Robinson89] A. J. Robinson, 1989, Cambridge University Engineering\n Department, \"Dynamic Error Propagation Networks\".\n\n[McCullochAinsworth88] N. McCulloch and W. A. Ainsworth, Proceedings of\n Speech'88, Edinburgh, 1988, \"Speaker Independent Vowel Recognition\n using a Multi-Layer Perceptron\".\n\n[RobinsonFallside88-neuro] A. J. Robinson and F. Fallside, 1988, Proceedings\n of nEuro'88, Paris, June, \"A Dynamic Connectionist Model for Phoneme\n Recognition.\n\n## COMMENTS:\n\n(By Tony Robinson)\n\nThe program supplied is slow.  I ran it on several MicroVaxII's for many\nnights.  I suspect that if I had spent more time on it, it would have been\npossible to get better results.  Indeed, my later code has a slightly\nbetter adaptive step size algotithm, but the old version is given here for\ncomatability with the stated performance values.  It is interesting that,\nfor this problem, the nearest neighbour clasification outperforms any of\nthe connectionist models.  This can be seen as a challange to improve the\nconnectionist performance.\n\nThe following problem description results and discussion is taken from my\nPhD thesis.  The aim was to demonstrate that many types of node can be\ntrained using gradient descent.  The full thesis will be available from me\nwhen it has been examined, say maybe July 1989.\n\n## Application to Vowel Recognition\n\nThis chapter describes the application of a variety of feed-forward networks\nto the task of recognition of vowel sounds from multiple speakers.  Single\nspeaker vowel recognition studies by Renals and Rohwer [RenalsRohwer89-ijcnn]\nshow that feed-forward networks compare favourably with vector-quantised\nhidden Markov models.  The vowel data used in this chapter was collected by\nDeterding [Deterding89], who recorded examples of the eleven steady state\nvowels of English spoken by fifteen speakers for a speaker normalisation\nstudy.  A range of node types are used, as described in the previous section,\nand some of the problems of the error propagation algorithm are discussed.\n\n## The Speech Data\n\n(An ascii approximation to) the International Phonetic Association (I.P.A.)\nsymbol and the word in which the eleven vowel sounds were recorded is given in\ntable 4.1.  The word was uttered once by each of the fifteen speakers.  Four\nmale and four female speakers were used to train the networks, and the other\nfour male and three female speakers were used for testing the performance.\n\n+-------+--------+-------+---------+\n| vowel |  word  | vowel |  word   | \n+-------+--------+-------+---------+\n|  i    |  heed  |  O    |  hod    |\n|  I    |  hid   |  C:   |  hoard  |\n|  E    |  head  |  U    |  hood   |\n|  A    |  had   |  u:   |  who'd  |\n|  a:   |  hard  |  3:   |  heard  |\n|  Y    |  hud   |       |         |\n+-------+--------+-------+---------+\n\nTable 4.1: Words used in Recording the Vowels\n\n## Front End Analysis\n\nThe speech signals were low pass filtered at 4.7kHz and then digitised to 12\nbits with a 10kHz sampling rate.  Twelfth order linear predictive analysis was\ncarried out on six 512 sample Hamming windowed segments from the steady part\nof the vowel.  The reflection coefficients were used to calculate 10 log area\nparameters, giving a 10 dimensional input space.  For a general introduction\nto speech processing and an explanation of this technique see Rabiner and\nSchafer [RabinerSchafer78].\n\nEach speaker thus yielded six frames of speech from eleven vowels.  This gave\n528 frames from the eight speakers used to train the networks and 462 frames\nfrom the seven speakers used to test the networks.\n\n## Details of the Models\n\nAll the models had common structure of one layer of hidden units and two\nlayers of weights.  Some of the models used fixed weights in the first layer\nto perform a dimensionality expansion [Robinson89:sect3.1], and the remainder\nmodified the first layer of weights using the error propagation algorithm for\ngeneral nodes described in [Robinson89:chap2].  In the second layer the hidden\nunits were mapped onto the outputs using the conventional weighted-sum type\nnodes with a linear activation function.  When Gaussian nodes were used the\nrange of influence of the nodes, w_ij1, was set to the standard deviation of\nthe training data for the appropriate input dimension.  If the locations of\nthese nodes, w_ij0, are placed randomly, then the model behaves like a\ncontinuous version of the modified Kanerva model [PragerFallside88].  If the\nlocations are placed at the points defined by the input examples then the\nmodel implements a radial basis function [BroomheadLowe88].  The first layer\nof weights remains constant in both of these models, but can be also trained\nusing the equations of [Robinson89:sect2.4].  Replacing the Gaussian nodes\nwith the conventional type gives a multilayer perceptron and replacing them\nwith conventional nodes with the activation function f(x) = x^2 gives a\nnetwork of square nodes.  Finally, dispensing with the first layer altogether\nyields a single layer perceptron.\n\nThe scaling factor between gradient of the energy and the change made to the\nweights (the `learning rate', `eta') was dynamically varied during training,\nas described in [Robinson89:sect2.5].  If the energy decreased this factor was\nincreased by 5%, if it increased the factor was halved.  The networks changed\nthe weights in the direction of steepest descent which is susceptible to\nfinding a local minimum.  A `momentum' term [RumelhartHintonWilliams86] is\noften used with error propagation networks to smooth the weight changes and\n`ride over' small local minima.  However, the optimal value of this term is\nlikely to be problem dependent, and in order to provide a uniform framework,\nthis additional term was not used.\n\n## Recognition Results\n\nThis experiment was originally carried out with only two frames of data from\neach word [RobinsonNiranjanFallside88-tr].  In the earlier experiment some\nproblems were encountered with a phenomena termed `overtraining' whereby the\nrecognition rate on the test data peaks part way through training then decays\nsignificantly.  The recognition rates for the six frames per word case are\ngiven in table 4.2 and are generally higher and show less variability than the\npreviously presented results.  However, the recognition rate on the test set\nstill displays large fluctuations during training, as shown by the plots in\n[Robinson89:fig3.2] Some fluctuations will arise from the fact that the\nminimum in weight space for the training set will not be coincident with the\nminima for the test set.  Thus, half the possible trajectories during learning\nwill approach the test set minimum and then move away from it again on the way\nto the training set minima [Mark Plumbley, personal communication].  In\naddition, continued training sharpens the class boundaries which makes the\nenergy insensitive to the class boundary position [Mahesan Niranjan, personal\ncommuniation].  For example, there are a large number planes defined with\nthreshold units which will separate two points in the input space, but only\none least squares solution for the case of linear units.\n\n+-------------------------+--------+---------+---------+\n|     | no. of | no.     | percent |\n| Classifier              | hidden | correct | correct |\n|     | units  |         |         | \n+-------------------------+--------+---------+---------+\n| Single-layer perceptron |  -     | 154     | 33      | \n| Multi-layer perceptron  | 88     | 234     | 51      |\n| Multi-layer perceptron  | 22     | 206     | 45      |\n| Multi-layer perceptron  | 11     | 203     | 44      | \n| Modified Kanerva Model  | 528    | 231     | 50      |\n| Modified Kanerva Model  | 88     | 197     | 43      | \n| Radial Basis Function   | 528    | 247     | 53      |\n| Radial Basis Function   | 88     | 220     | 48      | \n| Gaussian node network   | 528    | 252     | 55      |\n| Gaussian node network   | 88     | 247     | 53      |\n| Gaussian node network   | 22     | 250     | 54      |\n| Gaussian node network   | 11     | 211     | 47      | \n| Square node network     | 88     | 253     | 55      |\n| Square node network     | 22     | 236     | 51      |\n| Square node network     | 11     | 217     | 50      | \n| Nearest neighbour       |  -     | 260     | 56      | \n+-------------------------+--------+---------+---------+\n\nTable 4.2: Vowel classification with different non-linear classifiers\n\n## Discussion\n\nFrom these vowel classification results it can be seen that minimising the\nleast mean square error over a training set does not guarantee good\ngeneralisation to the test set.  The best results were achieved with nearest\nneighbour analysis which classifies an item as the class of the closest\nexample in the training set measured using the Euclidean distance.  It is\nexpected that the problem of overtraining could be overcome by using a larger\ntraining set taking data from more speakers.  The performance of the Gaussian\nand square node network was generally better than that of the multilayer\nperceptron.  In other speech recognition problems which attempt to classify\nsingle frames of speech, such as those described by McCulloch and Ainsworth\n[McCullochAinsworth88] and that of [Robinson89:chap7 and\nRobinsonFallside88-neuro], the nearest neighbour algorithm does not perform as\nwell as a multilayer perceptron.  It would be interesting to investigate this\ndifference and apply a network of Gaussian or square nodes to these problems.\n\nThe initial weights to the hidden units in the Gaussian network can be given a\nphysical interpretation in terms of matching to a template for a set of\nfeatures.  This gives an advantage both in shortening the training time and\nalso because the network starts at a point in weight space near a likely\nsolution, which avoids some possible local minima which represent poor\nsolutions.\n\nThe results of the experiments with Gaussian and square nodes are promising.\nHowever, it has not been the aim of this chapter to show that a particular\ntype of node is necessarily `better' for error propagation networks than the\nweighted sum node, but that the error propagation algorithm can be applied\nsuccessfully to many different types of node.\n\n\n# Notes:  \n* This is version 2. Version 1 is hidden because it includes a feature dividing the data in train and test set. In OpenML this information is explicitly available in the corresponding task.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_307_vowel_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-307-vowel"}, "LL0_308_puma32h": {"pipeline": {"_id": "9181dd3d-8649-4583-8cb9-dd95d306e0ed", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 62}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 834, "max_depth": 10, "learning_rate": 0.4943489464843669, "gamma": 0.00024208399891334498, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "9181dd3d-8649-4583-8cb9-dd95d306e0ed", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 7.460130424465986e-05, "rank": 7.460130427886694e-05, "metric": "meanSquaredError", "ts": "2018-10-24T22:05:28.046000", "dataset": "LL0_308_puma32h_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_308_puma32h", "about": {"problemID": "LL0_308_puma32h_problem", "problemName": "LL0_308_puma32h_problem", "problemDescription": "**Author**:   \n  \n**Source**: Unknown -   \n**Please cite**:   \n\nThis is one of a family of datasets synthetically generated from a realistic simulation of the dynamics of a Unimation Puma 560 robot arm. There are eight datastets in this family . In this repository we only have two of them. They are all variations on the same model; a realistic simulation of the dynamics of a Puma 560 robot arm. The task in these datasets is to predict the angular accelaration of one of the robot arm's links. The inputs include angular positions, velocities and torques of the robot arm. The family has been specifically generated for the delve environment and so the individual datasets span the corners of a cube whose dimensions represent:\n\nNumber of inputs 32 \ndegree of non-linearity (fairly linear or non-linear) \namount of noise in the output (moderate or high). \n\nSource: collection of regression datasets by Luis Torgo (torgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nOriginal Source: DELVE repository of data. \nCharacteristics: 8192 (4500+3692) cases, 33 continuous variables.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_308_puma32h_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "thetadd6"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-308-puma32h"}, "LL0_30_page_blocks": {"pipeline": {"_id": "15168508-9431-4c85-8bb0-e83a82de4e09", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 540, "max_depth": 10, "learning_rate": 0.7265692116098701, "gamma": 0.7999800523303852, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "15168508-9431-4c85-8bb0-e83a82de4e09", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8564156890242346, "rank": 0.14358431097634738, "metric": "f1Macro", "ts": "2018-10-31T04:48:17.593000", "dataset": "LL0_30_page_blocks_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_30_page_blocks", "about": {"problemID": "LL0_30_page_blocks_problem", "problemName": "LL0_30_page_blocks_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Blocks Classification\n 2. Sources:\n    (a) Donato Malerba\n        Dipartimento di Informatica\n        University of Bari\n        via Orabona 4\n        70126 Bari - Italy\n        phone: +39 - 80 - 5443269\n        fax: +39 - 80 - 5443196\n        malerbad@vm.csata.it\n    (b) Donor: Donato Malerba\n    (c) Date: July 1995\n 3. Past Usage:\n    This data set have been used to try different simplification methods\n    for decision trees. A summary of the results can be found in:\n \n    Malerba, D., Esposito, F., and Semeraro, G.\n    \"A Further Comparison of Simplification Methods for Decision-Tree Induction.\"\n    In D. Fisher and H. Lenz (Eds.), \"Learning  from Data: \n    Artificial Intelligence and Statistics V\", Lecture Notes in Statistics,\n    Springer Verlag, Berlin, 1995.\n \n    The problem consists in classifying all the blocks of the page\n    layout of a document that has been detected by a segmentation\n    process. This is an essential step in document analysis\n    in order to separate text from graphic areas. Indeed, \n    the five classes are: text (1), horizontal line (2),\n    picture (3), vertical line (4) and graphic (5).\n    For a detailed presentation of the problem see:\n \n     Esposito F., Malerba D., & Semeraro G.\n   Multistrategy Learning for Document Recognition\n          Applied Artificial Intelligence, 8, pp. 33-84, 1994\n \n    All instances have been personally checked so that\n    low noise is present in the data.\n \n 4. Relevant Information Paragraph:\n \n    The 5473 examples comes from 54 distinct documents. \n    Each observation concerns one block. \n    All attributes are numeric.\n    Data are in a format readable by C4.5.\n \n 5. Number of Instances: 5473.\n \n 6. Number of Attributes \n \n    height:   integer.         | Height of the block.\n    lenght:   integer.     | Length of the block. \n    area:     integer.    | Area of the block (height * lenght);\n    eccen:    continuous.  | Eccentricity of the block (lenght / height);\n    p_black:  continuous.  | Percentage of black pixels within the block (blackpix / area);\n    p_and:    continuous.        | Percentage of black pixels after the application of the Run Length Smoothing Algorithm (RLSA) (blackand / area);\n    mean_tr:  continuous.      | Mean number of white-black transitions (blackpix / wb_trans);\n    blackpix: integer.    | Total number of black pixels in the original bitmap of the block.\n    blackand: integer.        | Total number of black pixels in the bitmap of the block after the RLSA.\n    wb_trans: integer.          | Number of white-black transitions in the original bitmap of the block.\n \n \n \n 7. Missing Attribute Values:  No missing value.\n \n 8. Class Distribution: \n \n                                            Valid    Cum\n    Class               Frequency  Percent  Percent  Percent\n  \n text                      4913     89.8     89.8     89.8\n horiz. line                329      6.0      6.0     95.8\n graphic                     28       .5       .5     96.3\n vert. line                  88      1.6      1.6     97.9\n picture                    115      2.1      2.1    100.0\n                                 -------  -------  -------\n                         TOTAL      5473    100.0    100.0\n \n Summary Statistics:\n \n Variable      Mean    Std Dev   Minimum   Maximum   Correlation \n \n HEIGHT       10.47      18.96         1       804         .3510\n LENGTH       89.57     114.72         1       553        -.0045\n AREA       1198.41    4849.38         7    143993         .2343\n ECCEN        13.75      30.70      .007    537.00         .0992\n P_BLACK        .37        .18      .052      1.00         .2130\n P_AND          .79        .17      .062      1.00        -.1771\n MEAN_TR       6.22      69.08      1.00   4955.00         .0723\n BLACKPIX    365.93    1270.33         7     33017         .1656\n BLACKAND    741.11    1881.50         7     46133         .1565\n WB_TRANS    106.66     167.31         1      3212         .0337\n \n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_30_page_blocks_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-30-page-blocks"}, "LL0_312_scene": {"pipeline": {"_id": "49ee68d2-6f70-4e85-80df-d7f905112b56", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 982, "max_depth": 3, "learning_rate": 0.1544397128229521, "gamma": 0.6820255220551423, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "49ee68d2-6f70-4e85-80df-d7f905112b56", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.980968903694689, "rank": 0.01903109630623371, "metric": "f1Macro", "ts": "2018-10-31T05:26:24.687000", "dataset": "LL0_312_scene_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_312_scene", "about": {"problemID": "LL0_312_scene_problem", "problemName": "LL0_312_scene_problem", "problemDescription": "**Author**: Matthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown.  \n**Source**: [Mulan](http://mulan.sourceforge.net/datasets-mlc.html)     \n**Please cite**: \n\n### Description\n\nScene recognition dataset - It contains characteristics about images and their classes. \nThe original dataset is a multi-label classification problem with 6 different labels: {Beach, Sunset, FallFoliage, Field, Mountain, Urban}.\nThe current dataset is a binary classification problem considering just the 'Urban' label.\n\n### Sources\n\nMatthew R. Boutell, Jiebo Luo, Xipeng Shen, and Christopher M. Brown.\nLearning multi-label scene classification.\nPattern Recognition, 37(9):1757-1771, 2004. \n\n### Dataset Information\n\nMulti-label classification problem, based on real-world images.   \nInstances: 2407    \nFeatures: 294 numerical features with values between [0,1]   \nClasses/Labels: 2 {Urban, Nor Urban}   \nNo missing values", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_312_scene_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 300, "colName": "Urban"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-312-scene"}, "LL0_315_us_crime": {"pipeline": {"_id": "29b79451-3da2-4135-942d-c44cca9ac27b", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 898, "max_depth": 4, "learning_rate": 0.0767807714274793, "gamma": 0.052818554286952146, "min_child_weight": 6}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "29b79451-3da2-4135-942d-c44cca9ac27b", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.018236747502644146, "rank": 0.01823674750325841, "metric": "meanSquaredError", "ts": "2018-10-31T05:37:48.474000", "dataset": "LL0_315_us_crime_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_315_us_crime", "about": {"problemID": "LL0_315_us_crime_problem", "problemName": "us_crime_problem", "problemDescription": "**Author**:   \n  \n**Source**: Unknown - 2009  \n**Please cite**:   \n\nTitle: Communities and Crime\n \nAbstract: Communities within the United States. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.\n\nData Set Characteristics:  Multivariate\nAttribute Characteristics: Real\nAssociated Tasks: Regression\nNumber of Instances: 1994\nNumber of Attributes: 128\nMissing Values? Yes\nArea: Social\nDate Donated: 2009-07-13\n \nSource:\nCreator: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle \nUniversity; Philadelphia, PA, 19141, USA\n-- culled from 1990 US Census, 1995 US FBI Uniform Crime Report, 1990 US Law Enforcement Management and Administrative Statistics Survey, available from ICPSR at U of Michigan.\n-- Donor: Michael Redmond (redmond 'at' lasalle.edu); Computer Science; La Salle University; Philadelphia, PA, 19141, USA\n-- Date: July 2009\n\nData Set Information:\nMany variables are included so that algorithms that select or learn weights for attributes could be tested. However, clearly unrelated attributes were not included; attributes were picked if there was any plausible connection to crime (N=122), plus the attribute to be predicted (Per Capita Violent Crimes). The variables included in the dataset involve the community, such as the percent of the population considered urban, and the median family income, and involving law enforcement, such as per capita number of police officers, and percent of officers assigned to drug units. The per capita violent crimes variable was calculated using population and the sum of crime variables considered violent crimes in the United States: murder, rape, robbery, and assault. There was apparently some controversy in some states concerning the counting of rapes. These resulted in missing values for rape, which resulted in incorrect values for per capita violent crime. These cities are not included in the dataset. Many of these omitted communities were from the midwestern USA. Data is described below based on original values. All numeric data was normalized into the decimal range 0.00-1.00 using an Unsupervised, equal-interval binning method. \nAttributes retain their distribution and skew (hence for example the population \nattribute has a mean value of 0.06 because most communities are small). E.g. An attribute described as 'mean people per household' is actually the normalized (0-1) version of that value. The normalization preserves rough ratios of values WITHIN an attribute (e.g. double the value for double the population within the available precision - except for extreme values (all values more than 3 SD above the mean are normalized to 1.00; all values more than 3 SD below the mean are nromalized to 0.00)).\n\nHowever, the normalization does not preserve relationships between values BETWEEN attributes (e.g. it would not be meaningful to compare the value for whitePerCap with the value for blackPerCap for a community)\nA limitation was that the LEMAS survey was of the police departments with at least 100 officers, plus a random sample of smaller departments. For our purposes, communities not found in both census and crime datasets were omitted. Many communities are missing LEMAS data.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_315_us_crime_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 128, "colName": "ViolentCrimesPerPop"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-315-us-crime"}, "LL0_31_credit_g": {"pipeline": {"_id": "d2e511d8-e72e-4ea8-9e59-a13cc7e809dc", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 741, "max_depth": 3, "learning_rate": 0.12953649372142972, "gamma": 0.6811601759743834, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d2e511d8-e72e-4ea8-9e59-a13cc7e809dc", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7067914146291596, "rank": 0.2932085853710618, "metric": "f1Macro", "ts": "2018-10-25T00:31:32.132000", "dataset": "LL0_31_credit_g_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_31_credit_g", "about": {"problemID": "LL0_31_credit_g_problem", "problemName": "LL0_31_credit_g_problem", "problemDescription": "**Author**: Dr. Hans Hofmann  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)) - 1994    \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n\n**German Credit data**  \nThis dataset classifies people described by a set of attributes as good or bad credit risks.\n\nThis dataset comes with a cost matrix: \n``` \n      Good  Bad (predicted)  \nGood   0    1   (actual)  \nBad    5    0  \n```\n\nIt is worse to class a customer as good when they are bad (5), than it is to class a customer as bad when they are good (1).  \n\n### Attribute description  \n\n1. Status of existing checking account, in Deutsche Mark.  \n2. Duration in months  \n3. Credit history (credits taken, paid back duly, delays, critical accounts)  \n4. Purpose of the credit (car, television,...)  \n5. Credit amount  \n6. Status of savings account/bonds, in Deutsche Mark.  \n7. Present employment, in number of years.  \n8. Installment rate in percentage of disposable income  \n9. Personal status (married, single,...) and sex  \n10. Other debtors / guarantors  \n11. Present residence since X years  \n12. Property (e.g. real estate)  \n13. Age in years  \n14. Other installment plans (banks, stores)  \n15. Housing (rent, own,...)  \n16. Number of existing credits at this bank  \n17. Job  \n18. Number of people being liable to provide maintenance for  \n19. Telephone (yes,no)  \n20. Foreign worker (yes,no)", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_31_credit_g_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-31-credit-g"}, "LL0_329_hayes_roth": {"pipeline": {"_id": "c5d6df92-f5a3-467a-9730-6d8a0aff8f72", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 77}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 541, "max_depth": 4, "learning_rate": 0.8566543450013101, "gamma": 0.00040379032896309397, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "c5d6df92-f5a3-467a-9730-6d8a0aff8f72", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.852025012025012, "rank": 0.14797498797521708, "metric": "f1Macro", "ts": "2018-10-25T01:31:34.383000", "dataset": "LL0_329_hayes_roth_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_329_hayes_roth", "about": {"problemID": "LL0_329_hayes_roth_problem", "problemName": "hayes_roth_problem", "problemDescription": "**Author**: Barbara and Frederick Hayes-Roth  \n  \n**Source**: [original](https://archive.ics.uci.edu/ml/datasets/Hayes-Roth) -   \n**Please cite**:   \n\nHayes-Roth Database\n\nThis is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.\n\nSource Information: \n(a) Creators: Barbara and Frederick Hayes-Roth \n(b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779  \n(c) Date: March, 1989  \n\nAttribute Information: \n-- 1. name: distinct for each instance and represented numerically \n-- 2. hobby: nominal values ranging between 1 and 3 \n-- 3. age: nominal values ranging between 1 and 4 \n-- 4. educational level: nominal values ranging between 1 and 4 \n-- 5. marital status: nominal values ranging between 1 and 4 \n-- 6. class: nominal value between 1 and 3  \n\nDetailed description of the experiment: \n1. 3 categories (1, 2, and neither -- which I call 3) \n-- some of the instances could be classified in either class 1 or 2, and they have been evenly distributed between the two classes \n2. 5 Attributes \n-- A. name (a randomly-generated number between 1 and 132) \n-- B. hobby (a randomly-generated number between 1 and 3) \n-- C. age (a number between 1 and 4) \n-- D. education level (a number between 1 and 4) \n-- E. marital status (a number between 1 and 4) \n3. Classification:  \n-- only attributes C-E are diagnostic; values for A and B are ignored \n-- Class Neither: if a 4 occurs for any attribute C-E \n-- Class 1: Otherwise, if (# of 1's)>(# of 2's) for attributes C-E \n-- Class 2: Otherwise, if (# of 2's)>(# of 1's) for attributes C-E \n-- Either 1 or 2: Otherwise, if (# of 2's)=(# of 1's) for attributes C-E \n4. Prototypes: \n-- Class 1: 111 \n-- Class 2: 222 \n-- Class Either: 333 \n-- Class Neither: 444", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_329_hayes_roth_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-329-hayes-roth"}, "LL0_32_pendigits": {"pipeline": {"_id": "95111d0b-f263-4fff-b881-b6b472858306", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 14}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 414, "max_depth": 3, "learning_rate": 0.2928482842597604, "gamma": 0.019106053013407398, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "95111d0b-f263-4fff-b881-b6b472858306", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9913772580463471, "rank": 0.008622741954336077, "metric": "f1Macro", "ts": "2018-10-25T01:30:38.787000", "dataset": "LL0_32_pendigits_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_32_pendigits", "about": {"problemID": "LL0_32_pendigits_problem", "problemName": "LL0_32_pendigits_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Pen-Based Recognition of Handwritten Digits\n \n 2. Source:\n \tE. Alpaydin, F. Alimoglu\n \tDepartment of Computer Engineering\n \tBogazici University, 80815 Istanbul Turkey\n \talpaydin@boun.edu.tr\n \tJuly 1998\n \n 3. Past Usage:\n \tF. Alimoglu (1996) Combining Multiple Classifiers for Pen-Based\n \tHandwritten Digit Recognition, \n \tMSc Thesis, Institute of Graduate Studies in Science and \n \tEngineering, Bogazici University.\n \thttp://www.cmpe.boun.edu.tr/~alimoglu/alimoglu.ps.gz\n \n \tF. Alimoglu, E. Alpaydin, \"Methods of Combining Multiple Classifiers \n \tBased on Different Representations for Pen-based Handwriting\n \tRecognition,\" Proceedings of the Fifth Turkish Artificial \n \tIntelligence and Artificial Neural Networks Symposium (TAINN 96), \n \tJune 1996, Istanbul, Turkey.\n \thttp://www.cmpe.boun.edu.tr/~alimoglu/tainn96.ps.gz\n \n \t\n 4. Relevant Information:\n \n \tWe create a digit database by collecting 250 samples from 44 writers.\n \tThe samples written by 30 writers are used for training,\n \tcross-validation and writer dependent testing, and the digits \n \twritten by the other 14 are used for writer independent testing. This\n \tdatabase is also available in the UNIPEN format.\n \n \tWe use a WACOM PL-100V pressure sensitive tablet with an integrated \n \tLCD display and a cordless stylus. The input and display areas are\n \tlocated in the same place. Attached to the serial port of an Intel \n \t486 based PC, it allows us to collect handwriting samples. The tablet\n \tsends $x$ and $y$ tablet coordinates and pressure level values of the\n \tpen at fixed time intervals (sampling rate) of 100 miliseconds. \n \n \tThese writers are asked to write 250 digits in random order inside \n \tboxes of 500 by 500 tablet pixel resolution.  Subject are monitored \n \tonly during the first entry screens. Each screen contains five boxes\n \twith the digits to be written displayed above. Subjects are told to\n \twrite only inside these boxes.  If they make a mistake or are unhappy\n \twith their writing, they are instructed to clear the content of a box \n \tby using an on-screen button. The first ten digits are ignored \n \tbecause most writers are not familiar with this type of input devices,\n \tbut subjects are not aware of this. \n \n \tIn our study, we use only ($x, y$) coordinate information. The stylus\n \tpressure level values are ignored. First we apply normalization to \n \tmake our representation invariant to translations and scale \n \tdistortions. The raw data that we capture from the tablet consist of\n \tinteger values between 0 and 500 (tablet input box resolution). The \n \tnew coordinates are such that the coordinate which has the maximum \n \trange varies between 0 and 100. Usually $x$ stays in this range, since\n \tmost characters are taller than they are wide.  \n \n \tIn order to train and test our classifiers, we need to represent \n \tdigits as constant length feature vectors. A commonly used technique\n \tleading to good results is resampling the ( x_t, y_t) points. \n \tTemporal resampling (points regularly spaced in time) or spatial\n \tresampling (points regularly spaced in arc length) can be used here. \n \tRaw point data are already regularly spaced in time but the distance\n \tbetween them is variable. Previous research showed that spatial\n \tresampling to obtain a constant number of regularly spaced points \n \ton the trajectory yields much better performance, because it provides \n \ta better alignment between points. Our resampling algorithm uses \n \tsimple linear interpolation between pairs of points. The resampled\n \tdigits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T,\n \tregularly spaced in arc length, as opposed to the input sequence, \n \twhich is regularly spaced in time.\n \n \tSo, the input vector size is 2*T, two times the number of points\n \tresampled. We considered spatial resampling to T=8,12,16 points in our\n \texperiments and found that T=8 gave the best trade-off between \n \taccuracy and complexity.\n \n \n 5. Number of Instances\n \tpendigits.tra\tTraining\t7494\n \tpendigits.tes\tTesting\t\t3498\n \t\n \tThe way we used the dataset was to use first half of training for \n \tactual training, one-fourth for validation and one-fourth\n \tfor writer-dependent testing. The test set was used for \n \twriter-independent testing and is the actual quality measure.\n \n 6. Number of Attributes\n \t16 input+1 class attribute\n \n 7. For Each Attribute:\n \tAll input attributes are integers in the range 0..100.\n \tThe last attribute is the class code 0..9\n \n 8. Missing Attribute Values\n \tNone\n \n 9. Class Distribution\n \tClass: No of examples in training set\n \t0:  780\n \t1:  779\n \t2:  780\n \t3:  719\n \t4:  780\n \t5:  720\n \t6:  720\n \t7:  778\n \t8:  719\n \t9:  719\n \tClass: No of examples in testing set\n \t0:  363\n \t1:  364\n \t2:  364\n \t3:  336\n \t4:  364\n \t5:  335\n \t6:  336\n \t7:  364\n \t8:  336\n \t9:  336\n \n Accuracy on the testing set with k-nn \n using Euclidean distance as the metric\n \n  k =  1 : 97.74\n  k =  2 : 97.37\n  k =  3 : 97.80\n  k =  4 : 97.66\n  k =  5 : 97.60\n  k =  6 : 97.57\n  k =  7 : 97.54\n  k =  8 : 97.54\n  k =  9 : 97.46\n  k = 10 : 97.48\n  k = 11 : 97.34", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_32_pendigits_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 17, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-32-pendigits"}, "LL0_333_monks_problems_1": {"pipeline": {"_id": "44b441bc-4b28-4271-a608-ec188f16735a", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 80}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 344, "max_depth": 9, "learning_rate": 0.5419935120546946, "gamma": 0.30376994720276607, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "44b441bc-4b28-4271-a608-ec188f16735a", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 6.810390091369634e-16, "metric": "f1Macro", "ts": "2018-10-24T23:50:29.306000", "dataset": "LL0_333_monks_problems_1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_333_monks_problems_1", "about": {"problemID": "LL0_333_monks_problems_1_problem", "problemName": "LL0_333_monks_problems_1_problem", "problemDescription": "**Author**: Sebastian Thrun (Carnegie Mellon University)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MONK's+Problems) - October 1992  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**The Monk's Problems: Problem 1**  \nOnce upon a time, in July 1991, the monks of Corsendonk Priory were faced with a school held in their priory, namely the 2nd European Summer School on Machine Learning. After listening more than one week to a wide variety of learning algorithms, they felt rather confused: Which algorithm would be optimal? And which one to avoid? As a consequence of this dilemma, they created a simple task on which all learning algorithms ought to be compared: the three MONK's problems.\n\nThe target concept associated with the 1st Monk's problem is the binary outcome of the logical formula:  \nMONK-1: (a1 == a2) or (a5 == 1)\n\nIn this dataset, the original train and test sets were merged to allow other sampling procedures. However, the original train-test splits can be found as one of the OpenML tasks. \n\n### Attribute information: \n* attr1: 1, 2, 3 \n* attr2: 1, 2, 3 \n* attr3: 1, 2 \n* attr4: 1, 2, 3 \n* attr5: 1, 2, 3, 4 \n* attr6: 1, 2 \n\n### Relevant papers  \nThe MONK's Problems - A Performance Comparison of Different Learning Algorithms, by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. Technical Report CS-CMU-91-197, Carnegie Mellon University, Dec. 1991.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_333_monks_problems_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-333-monks-problems-1"}, "LL0_335_monks_problems_3": {"pipeline": {"_id": "67d98c62-fad2-423b-a5ed-5bfc68235a39", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 545, "max_depth": 6, "learning_rate": 0.8049654648941758, "gamma": 0.45079355490043127, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "67d98c62-fad2-423b-a5ed-5bfc68235a39", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9865063195750103, "rank": 0.013493680424989699, "metric": "f1Macro", "ts": "2018-10-24T23:52:39.687000", "dataset": "LL0_335_monks_problems_3_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_335_monks_problems_3", "about": {"problemID": "LL0_335_monks_problems_3_problem", "problemName": "LL0_335_monks_problems_3_problem", "problemDescription": "**Author**: Sebastian Thrun (Carnegie Mellon University)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/MONK's+Problems) - October 1992  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)   \n\n**The Monk's Problems: Problem 3**  \nOnce upon a time, in July 1991, the monks of Corsendonk Priory were faced with a school held in their priory, namely the 2nd European Summer School on Machine Learning. After listening more than one week to a wide variety of learning algorithms, they felt rather confused: Which algorithm would be optimal? And which one to avoid? As a consequence of this dilemma, they created a simple task on which all learning algorithms ought to be compared: the three MONK's problems.\n\nThe target concept associated with the 3rd Monk's problem is the binary outcome of the logical formula:  \nMONK-3: (a5 = 3 and a4 = 1) or (a5 /= 4 and a2 /= 3)  \nIn addition, 5% class noise was added to the training set\n\nIn this dataset, the original train and test sets were merged to allow other sampling procedures. However, the original train-test splits can be found as one of the OpenML tasks. \n\n### Attribute information: \n* attr1: 1, 2, 3 \n* attr2: 1, 2, 3 \n* attr3: 1, 2 \n* attr4: 1, 2, 3 \n* attr5: 1, 2, 3, 4 \n* attr6: 1, 2 \n\n### Relevant papers  \nThe MONK's Problems - A Performance Comparison of Different Learning Algorithms, by S.B. Thrun, J. Bala, E. Bloedorn, I. Bratko, B. Cestnik, J. Cheng, K. De Jong, S. Dzeroski, S.E. Fahlman, D. Fisher, R. Hamann, K. Kaufman, S. Keller, I. Kononenko, J. Kreuziger, R.S. Michalski, T. Mitchell, P. Pachowicz, Y. Reich H. Vafaie, W. Van de Welde, W. Wenzel, J. Wnek, and J. Zhang. Technical Report CS-CMU-91-197, Carnegie Mellon University, Dec. 1991.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_335_monks_problems_3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-335-monks-problems-3"}, "LL0_337_spectf": {"pipeline": {"_id": "9109dd3d-cdd1-463d-b1c4-2f29b09d405d", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 71}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 25, "min_samples_split": 0.04100142350803677, "min_samples_leaf": 0.0020026999751736473, "n_estimators": 404, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "9109dd3d-cdd1-463d-b1c4-2f29b09d405d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8618783405009861, "rank": 0.13812165949904223, "metric": "f1Macro", "ts": "2018-10-25T12:39:14.040000", "dataset": "LL0_337_spectf_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_337_spectf", "about": {"problemID": "LL0_337_spectf_problem", "problemName": "LL0_337_spectf_problem", "problemDescription": "**Author**: Krzysztof J. Cios\",\"Lukasz A.  \n**Source**: [original](https://archive.ics.uci.edu/ml/datasets/SPECTF+Heart) -   \n**Please cite**:   \n\nSPECTF heart data\n\nThis is a merged version of the separate train and test set which are usually distributed. On OpenML this train-test split can be found as one of the possible tasks.  \n\nNOTE: See the SPECT heart data for binary data for the same classification task.\n\nSources: \n-- Original owners: Krzysztof J. Cios, Lukasz A. Kurgan University of Colorado at Denver, Denver, CO 80217, U.S.A. Krys.Cios@cudenver.edu Lucy S. Goodenday Medical College of Ohio, OH, U.S.A. \n-- Donors: Lukasz A.Kurgan, Krzysztof J. Cios \n-- Date: 10/01/01  \n\nRelevant Information: The dataset describes diagnosing of cardiac Single Proton Emission Computed Tomography (SPECT) images. Each of the patients is classified into two categories: normal and abnormal. The database of 267 SPECT image sets (patients) was processed to extract features that summarize the original SPECT images. As a result, 44 continuous feature pattern was created for each patient. The CLIP3 algorithm was used to generate classification rules from these patterns. The CLIP3 algorithm generated rules that were 77.0% accurate (as compared with cardiologists' diagnoses).", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_337_spectf_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "OVERALL_DIAGNOSIS"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-337-spectf"}, "LL0_344_mv": {"pipeline": {"_id": "2e8bb62f-c2b1-4167-8846-e054253f9bf0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 52}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 991, "max_depth": 8, "learning_rate": 0.08491852506698039, "gamma": 0.05732927911886143, "min_child_weight": 10}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "2e8bb62f-c2b1-4167-8846-e054253f9bf0", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.026983687052635135, "rank": 0.026983687053193692, "metric": "meanSquaredError", "ts": "2018-10-24T21:27:46.015000", "dataset": "LL0_344_mv_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_344_mv", "about": {"problemID": "LL0_344_mv_problem", "problemName": "LL0_344_mv_problem", "problemDescription": "**Author**: Luis Torgo  \n**Source**: [original](http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html) -   \n**Please cite**:   \n\nThis is an artificial data set with dependencies between the attribute values. The cases are generated using the following method:\n\nX1 : uniformly distributed over [-5,5]\nX2 : uniformly distributed over [-15,-10]\nX3 : IF (X1 > 0) THEN X3 = green\n ELSE X3 = red with probability 0.4 and X4=brown with prob. 0.6\nX4 : IF (X3=green) THEN X4=X1+2X2\n ELSE X4=X1/2 with prob. 0.3, and X4=X2/2 with prob. 0.7\nX5 : uniformly distributed over [-1,1]\nX6 : X6=X4*[epsilon], where [epsilon] is uniformly distribute over [0,5]\nX7 : X7=yes with prob. 0.3 and X7=no with prob. 0.7\nX8 : IF (X5 < 0.5) THEN X8 = normal ELSE X8 = large\nX9 : uniformly distributed over [100,500]\nX10 : uniformly distributed integer over the interval [1000,1200]\n \nObtain the value of the target variable Y using the rules:\nIF (X2 > 2 ) THEN Y = 35 - 0.5 X4\n ELSE IF (-2 <= X4 <= 2) THEN Y = 10 - 2 X1\n ELSE IF (X7 = yes) THEN Y = 3 -X1/X4\n ELSE IF (X8 = normal) THEN Y = X6 + X1\n ELSE Y = X1/2\n\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at http://www.dcc.fc.up.pt/~ltorgo/Regression/DataSets.html", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_344_mv_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "y"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-344-mv"}, "LL0_35_dermatology": {"pipeline": {"_id": "40bce1fc-ab50-4deb-81b6-1844e56a7137", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 50}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 423, "max_depth": 10, "learning_rate": 0.7618423792086175, "gamma": 0.5874478921624935, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "40bce1fc-ab50-4deb-81b6-1844e56a7137", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9919270272211449, "rank": 0.00807297277929418, "metric": "f1Macro", "ts": "2018-10-25T01:59:34.088000", "dataset": "LL0_35_dermatology_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_35_dermatology", "about": {"problemID": "LL0_35_dermatology_problem", "problemName": "LL0_35_dermatology_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Dermatology Database\n \n 2. Source Information:\n    (a) Original owners:\n        -- 1. Nilsel Ilter, M.D., Ph.D., \n              Gazi University, \n              School of Medicine\n              06510 Ankara, Turkey\n              Phone: +90 (312) 214 1080\n \n        -- 2. H. Altay Guvenir, PhD., \n              Bilkent University,\n              Department of Computer Engineering and Information Science,\n              06533 Ankara, Turkey\n              Phone: +90 (312) 266 4133\n              Email: guvenir@cs.bilkent.edu.tr\n \n    (b) Donor: H. Altay Guvenir,\n               Bilkent University,\n               Department of Computer Engineering and Information Science,\n               06533 Ankara, Turkey\n               Phone: +90 (312) 266 4133\n               Email: guvenir@cs.bilkent.edu.tr\n \n    (c) Date:  January, 1998\n \n 3. Past Usage:\n    1. G. Demiroz, H. A. Govenir, and N. Ilter, \n       \"Learning Differential Diagnosis of Eryhemato-Squamous Diseases using\n        Voting Feature Intervals\", Aritificial Intelligence in Medicine,\n \n       The aim is to determine the type of Eryhemato-Squamous Disease.\n \n 4. Relevant Information:\n      This database contains 34 attributes, 33 of which are linear\n      valued and one of them is nominal. \n \n      The differential diagnosis of erythemato-squamous diseases is a real\n      problem in dermatology. They all share the clinical features of\n      erythema and scaling, with very little differences. The diseases in\n      this group are psoriasis, seboreic dermatitis, lichen planus, \n      pityriasis rosea, cronic dermatitis, and pityriasis rubra pilaris.\n      Usually a biopsy is necessary for the diagnosis but unfortunately\n      these diseases share many histopathological features as\n      well. Another difficulty for the differential diagnosis is that a\n      disease may show the features of another disease at the beginning\n      stage and may have the characteristic features at the following stages. \n      Patients were first evaluated clinically with 12 features.\n      Afterwards, skin samples were taken for the evaluation of 22\n      histopathological features. The values of the histopathological features\n      are determined by an analysis of the samples under a microscope. \n \n      In the dataset constructed for this domain, the family history feature\n      has the value 1 if any of these diseases has been observed in the\n      family, and 0 otherwise. The age feature simply represents the age of\n      the patient. Every other feature (clinical and histopathological) was\n      given a degree in the range of 0 to 3. Here, 0 indicates that the\n      feature was not present, 3 indicates the largest amount possible,\n      and 1, 2 indicate the relative intermediate values.\n \n      The names and id numbers of the patients were recently \n      removed from the database.\n \n 5. Number of Instances: 366\n \n 6. Number of Attributes: 34\n \n 7. Attribute Information:\n    -- Complete attribute documentation:\n       Clinical Attributes: (take values 0, 1, 2, 3, unless otherwise indicated)\n       1: erythema\n       2: scaling\n       3: definite borders\n       4: itching\n       5: koebner phenomenon\n       6: polygonal papules\n       7: follicular papules\n       8: oral mucosal involvement\n       9: knee and elbow involvement\n      10: scalp involvement\n      11: family history, (0 or 1)\n      34: Age (linear)\n \n      Histopathological Attributes: (take values 0, 1, 2, 3)\n      12: melanin incontinence\n      13: eosinophils in the infiltrate\n      14: PNL infiltrate\n      15: fibrosis of the papillary dermis\n      16: exocytosis\n      17: acanthosis\n      18: hyperkeratosis\n      19: parakeratosis\n      20: clubbing of the rete ridges\n      21: elongation of the rete ridges\n      22: thinning of the suprapapillary epidermis\n      23: spongiform pustule\n      24: munro microabcess\n      25: focal hypergranulosis\n      26: disappearance of the granular layer\n      27: vacuolisation and damage of basal layer\n      28: spongiosis\n      29: saw-tooth appearance of retes\n      30: follicular horn plug\n      31: perifollicular parakeratosis\n      32: inflammatory monoluclear inflitrate\n      33: band-like infiltrate\n       \n 8. Missing Attribute Values: 8 (in Age attribute). Distinguished with '?'.\n \n 9. Class Distribution:\n        Database:  Dermatology\n        \n        Class code:   Class:                  Number of instances:\n        1             psoriasis\t\t\t    112\n        2             seboreic dermatitis             61\n        3             lichen planus                   72\n        4             pityriasis rosea                49\n        5             cronic dermatitis               52    \n        6             pityriasis rubra pilaris        20\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_35_dermatology_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 35, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-35-dermatology"}, "LL0_36_segment": {"pipeline": {"_id": "c9317266-6869-46b2-ad32-01b2e05c544e", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 12}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 115, "max_depth": 5, "learning_rate": 0.2488608051882114, "gamma": 0.0794435486008015, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "c9317266-6869-46b2-ad32-01b2e05c544e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9842977209302299, "rank": 0.015702279070437346, "metric": "f1Macro", "ts": "2018-10-25T00:34:55.252000", "dataset": "LL0_36_segment_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_36_segment", "about": {"problemID": "LL0_36_segment_problem", "problemName": "LL0_36_segment_problem", "problemDescription": "**Author**: University of Massachusetts Vision Group, Carla Brodley  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/image+segmentation) - 1990  \n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**Image Segmentation Data Set**\nThe instances were drawn randomly from a database of 7 outdoor images. The images were hand-segmented to create a classification for every pixel. Each instance is a 3x3 region.\n \n### Attribute Information  \n\n1.  region-centroid-col:  the column of the center pixel of the region.\n2.  region-centroid-row:  the row of the center pixel of the region.\n3.  region-pixel-count:  the number of pixels in a region = 9.\n4.  short-line-density-5:  the results of a line extractoin algorithm that \n          counts how many lines of length 5 (any orientation) with\n          low contrast, less than or equal to 5, go through the region.\n5.  short-line-density-2:  same as short-line-density-5 but counts lines\n          of high contrast, greater than 5.\n6.  vedge-mean:  measure the contrast of horizontally\n          adjacent pixels in the region.  There are 6, the mean and \n          standard deviation are given.  This attribute is used as\n         a vertical edge detector.\n7.  vegde-sd:  (see 6)\n8.  hedge-mean:  measures the contrast of vertically adjacent\n           pixels. Used for horizontal line detection. \n9.  hedge-sd: (see 8).\n10. intensity-mean:  the average over the region of (R + G + B)/3\n11. rawred-mean: the average over the region of the R value.\n12. rawblue-mean: the average over the region of the B value.\n13. rawgreen-mean: the average over the region of the G value.\n14. exred-mean: measure the excess red:  (2R - (G + B))\n15. exblue-mean: measure the excess blue:  (2B - (G + R))\n16. exgreen-mean: measure the excess green:  (2G - (R + B))\n17. value-mean:  3-d nonlinear transformation\n          of RGB. (Algorithm can be found in Foley and VanDam, Fundamentals\n          of Interactive Computer Graphics)\n18. saturatoin-mean:  (see 17)\n19. hue-mean:  (see 17)", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_36_segment_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 20, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-36-segment"}, "LL0_375_japanesevowels": {"pipeline": {"_id": "a7aede44-3bd2-4451-8e77-6b7770cbcf90", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 522, "max_depth": 4, "learning_rate": 0.2597972719320937, "gamma": 0.0667843022719049, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "a7aede44-3bd2-4451-8e77-6b7770cbcf90", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9739185067763376, "rank": 0.02608149322440498, "metric": "f1Macro", "ts": "2018-10-31T04:58:09.802000", "dataset": "LL0_375_japanesevowels_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_375_japanesevowels", "about": {"problemID": "LL0_375_japanesevowels_problem", "problemName": "LL0_375_japanesevowels_problem", "problemDescription": "**Author**: Mineichi Kudo, Jun Toyama, Masaru Shimbo ({mine,jun,shimbo}@main.eng.hokudai.ac.jp)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Japanese+Vowels) - 2000  \n**Please cite**:   \n\n**Japanese vowels**  \nThis dataset records 640 time series of 12 LPC cepstrum coefficients taken from nine male speakers.\n\nThe data was collected for examining our newly developed classifier for multidimensional curves (multidimensional time series). Nine male speakers uttered two Japanese vowels /ae/ successively. For each utterance, with the analysis parameters described below, we applied 12-degree linear prediction analysis to it to obtain a discrete-time series with 12 LPC cepstrum coefficients. This means that one utterance by a speaker forms a time series whose length is in the range 7-29 and each point of a time series is of 12 features (12 coefficients).\n\nSimilar data are available for different utterances /ei/, /iu/, /uo/, /oa/ in addition to /ae/. Please contact the donor if you are interested in using this data.\n\nThe number of the time series is 640 in total. We used one set of 270 time series for training and the other set of 370 time series for testing.\n\nAnalysis parameters:  \n* Sampling rate : 10kHz\n* Frame length : 25.6 ms\n* Shift length : 6.4ms\n* Degree of LPC coefficients : 12\n\nEach line represents 12 LPC coefficients in the increasing order separated by spaces. This corresponds to one analysis\nframe. Lines are organized into blocks, which are a set of 7-29 lines separated by blank lines and corresponds to a single speech utterance of /ae/ with 7-29 frames.\n\nEach speaker is a set of consecutive blocks. In ae.train there are 30 blocks for each speaker. Blocks 1-30 represent speaker 1, blocks 31-60 represent speaker 2, and so on up to speaker 9. In ae.test, speakers 1 to 9 have the corresponding number of blocks: 31 35 88 44 29 24 40 50 29. Thus, blocks 1-31 represent speaker 1 (31 utterances of /ae/), blocks 32-66 represent speaker 2 (35 utterances of /ae/), and so on.\n\n**Past Usage**\n\nM. Kudo, J. Toyama and M. Shimbo. (1999). \"Multidimensional Curve Classification Using Passing-Through Regions\". Pattern Recognition Letters, Vol. 20, No. 11--13, pages 1103--1111.\n\nIf you publish any work using the dataset, please inform the donor. Use for commercial purposes requires donor permission.\n\nReferences  \n\n1. http://ips9.main.eng.hokudai.ac.jp/index_e.html\n2. mailto:mine@main.eng.hokudai.ac.jp\n3. mailto:jun@main.eng.hokudai.ac.jp\n4. mailto:shimbo@main.eng.hokudai.ac.jp\n5. http://kdd.ics.uci.edu/\n6. http://www.ics.uci.edu/\n7. http://www.uci.edu/", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_375_japanesevowels_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "speaker"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-375-japanesevowels"}, "LL0_377_synthetic_control": {"pipeline": {"_id": "3ad8217f-a643-4ee8-b86a-dea058a97202", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 21, "min_samples_split": 0.006489544846031635, "min_samples_leaf": 0.019521669853243634, "n_estimators": 277, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "3ad8217f-a643-4ee8-b86a-dea058a97202", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 5.845479947112843e-13, "metric": "f1Macro", "ts": "2018-10-25T04:39:07.641000", "dataset": "LL0_377_synthetic_control_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_377_synthetic_control", "about": {"problemID": "LL0_377_synthetic_control_problem", "problemName": "LL0_377_synthetic_control_problem", "problemDescription": "**Author**: Dr Robert Alcock (rob@skyblue.csd.auth.gr)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Synthetic+Control+Chart+Time+Series) - 1999  \n**Please cite**:   \n\n### Description\nSynthetic Control Chart Time Series\n\n### Sources\n```\n* Original Owner and Donor\nDr Robert Alcock \nrob@skyblue.csd.auth.gr\n```\n### Dataset Information\n  \nThis data consists of synthetically generated control charts. This dataset contains 600 examples of control charts synthetically generated by the process in Alcock and Manolopoulos (1999). There are six different classes of control charts:\n\n```\n1. Normal\n2. Cyclic\n3. Increasing trend\n4. Decreasing trend\n5. Upward shift\n6. Downward shift\n````\n\n### Relevante papers\n\nAlcock R.J. and Manolopoulos Y. Time-Series Similarity Queries Employing a Feature-Based Approach. 7th Hellenic Conference on\nInformatics. August 27-29. Ioannina,Greece 1999.\n\nD.T. Pham and A.B. Chan \"Control Chart Pattern Recognition using a New Type of Self Organizing Neural Network\" Proc. Instn, Mech, Engrs. Vol 212, No 1, pp 115-127 1998.\n\n### References  \n\n1. http://skyblue.csd.auth.gr/~rob/\n2. mailto:rob@skyblue.csd.auth.gr\n3. http://kdd.ics.uci.edu/\n4. http://www.ics.uci.edu/\n5. http://www.uci.edu/", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_377_synthetic_control_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 62, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-377-synthetic-control"}, "LL0_37_diabetes": {"pipeline": {"_id": "dec7ca0d-11f8-43c6-b16e-110d5bbb92df", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 94}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 996, "max_depth": 9, "learning_rate": 0.0464869005773364, "gamma": 0.7723377458882735, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "dec7ca0d-11f8-43c6-b16e-110d5bbb92df", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7536766097962276, "rank": 0.2463233902042523, "metric": "f1Macro", "ts": "2018-10-24T23:49:39.962000", "dataset": "LL0_37_diabetes_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_37_diabetes", "about": {"problemID": "LL0_37_diabetes_problem", "problemName": "LL0_37_diabetes_problem", "problemDescription": "**Author**:   \n**Source**: [Obtained from UCI](https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes) \n**Please cite**:   \n\n1. Title: Pima Indians Diabetes Database\n \n 2. Sources:\n    (a) Original owners: National Institute of Diabetes and Digestive and\n                         Kidney Diseases\n    (b) Donor of database: Vincent Sigillito (vgs@aplcen.apl.jhu.edu)\n                           Research Center, RMI Group Leader\n                           Applied Physics Laboratory\n                           The Johns Hopkins University\n                           Johns Hopkins Road\n                           Laurel, MD 20707\n                           (301) 953-6231\n    (c) Date received: 9 May 1990\n \n 3. Past Usage:\n     1. Smith,~J.~W., Everhart,~J.~E., Dickson,~W.~C., Knowler,~W.~C., &\n        Johannes,~R.~S. (1988). Using the ADAP learning algorithm to forecast\n        the onset of diabetes mellitus.  In {it Proceedings of the Symposium\n        on Computer Applications and Medical Care} (pp. 261--265).  IEEE\n        Computer Society Press.\n \n        The diagnostic, binary-valued variable investigated is whether the\n        patient shows signs of diabetes according to World Health Organization\n        criteria (i.e., if the 2 hour post-load plasma glucose was at least \n        200 mg/dl at any survey  examination or if found during routine medical\n        care).   The population lives near Phoenix, Arizona, USA.\n \n        Results: Their ADAP algorithm makes a real-valued prediction between\n        0 and 1.  This was transformed into a binary decision using a cutoff of \n        0.448.  Using 576 training instances, the sensitivity and specificity\n        of their algorithm was 76% on the remaining 192 instances.\n \n 4. Relevant Information:\n       Several constraints were placed on the selection of these instances from\n       a larger database.  In particular, all patients here are females at\n       least 21 years old of Pima Indian heritage.  ADAP is an adaptive learning\n       routine that generates and executes digital analogs of perceptron-like\n       devices.  It is a unique algorithm; see the paper for details.\n \n 5. Number of Instances: 768\n \n 6. Number of Attributes: 8 plus class \n \n 7. For Each Attribute: (all numeric-valued)\n    1. Number of times pregnant\n    2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n    3. Diastolic blood pressure (mm Hg)\n    4. Triceps skin fold thickness (mm)\n    5. 2-Hour serum insulin (mu U/ml)\n    6. Body mass index (weight in kg/(height in m)^2)\n    7. Diabetes pedigree function\n    8. Age (years)\n    9. Class variable (0 or 1)\n \n 8. Missing Attribute Values: None\n \n 9. Class Distribution: (class value 1 is interpreted as \"tested positive for\n    diabetes\")\n \n    Class Value  Number of instances\n    0            500\n    1            268\n \n 10. Brief statistical analysis:\n \n     Attribute number:    Mean:   Standard Deviation:\n     1.                     3.8     3.4\n     2.                   120.9    32.0\n     3.                    69.1    19.4\n     4.                    20.5    16.0\n     5.                    79.8   115.2\n     6.                    32.0     7.9\n     7.                     0.5     0.3\n     8.                    33.2    11.8\n \n \n\n\n\n\n Relabeled values in attribute 'class'\n    From: 0                       To: tested_negative     \n    From: 1                       To: tested_positive", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_37_diabetes_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-37-diabetes"}, "LL0_39_ecoli": {"pipeline": {"_id": "ed1b9434-0007-4760-9718-c18cbd8f3d32", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 56}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 26, "min_samples_split": 0.09472185221754967, "min_samples_leaf": 0.008180885456145339, "n_estimators": 82, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "ed1b9434-0007-4760-9718-c18cbd8f3d32", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8211105706691295, "rank": 0.17888942933120336, "metric": "f1Macro", "ts": "2018-10-25T05:12:06.293000", "dataset": "LL0_39_ecoli_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_39_ecoli", "about": {"problemID": "LL0_39_ecoli_problem", "problemName": "LL0_39_ecoli_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Protein Localization Sites\n \n \n 2. Creator and Maintainer:\n \t     Kenta Nakai\n              Institue of Molecular and Cellular Biology\n \t     Osaka, University\n \t     1-3 Yamada-oka, Suita 565 Japan\n \t     nakai@imcb.osaka-u.ac.jp\n              http://www.imcb.osaka-u.ac.jp/nakai/psort.html\n    Donor: Paul Horton (paulh@cs.berkeley.edu)\n    Date:  September, 1996\n    See also: yeast database\n \n 3. Past Usage.\n Reference: \"A Probablistic Classification System for Predicting the Cellular \n            Localization Sites of Proteins\", Paul Horton & Kenta Nakai,\n            Intelligent Systems in Molecular Biology, 109-115.\n \t   St. Louis, USA 1996.\n Results: 81% for E.coli with an ad hoc structured\n \t probability model. Also similar accuracy for Binary Decision Tree and\n \t Bayesian Classifier methods applied by the same authors in\n \t unpublished results.\n \n Predicted Attribute: Localization site of protein. ( non-numeric ).\n \n \n 4. The references below describe a predecessor to this dataset and its \n development. They also give results (not cross-validated) for classification \n by a rule-based expert system with that version of the dataset.\n \n Reference: \"Expert Sytem for Predicting Protein Localization Sites in \n            Gram-Negative Bacteria\", Kenta Nakai & Minoru Kanehisa,  \n            PROTEINS: Structure, Function, and Genetics 11:95-110, 1991.\n \n Reference: \"A Knowledge Base for Predicting Protein Localization Sites in\n \t   Eukaryotic Cells\", Kenta Nakai & Minoru Kanehisa, \n \t   Genomics 14:897-911, 1992.\n \n \n 5. Number of Instances:  336 for the E.coli dataset and \n \n \n 6. Number of Attributes.\n          for E.coli dataset:  8 ( 7 predictive, 1 name )\n \t     \n 7. Attribute Information.\n \n   1.  Sequence Name: Accession number for the SWISS-PROT database\n   2.  mcg: McGeoch's method for signal sequence recognition.\n   3.  gvh: von Heijne's method for signal sequence recognition.\n   4.  lip: von Heijne's Signal Peptidase II consensus sequence score.\n            Binary attribute.\n   5.  chg: Presence of charge on N-terminus of predicted lipoproteins.\n \t   Binary attribute.\n   6.  aac: score of discriminant analysis of the amino acid content of\n \t   outer membrane and periplasmic proteins.\n   7. alm1: score of the ALOM membrane spanning region prediction program.\n   8. alm2: score of ALOM program after excluding putative cleavable signal\n \t   regions from the sequence.\n \n NOTE - the sequence name has been removed\n \n 8. Missing Attribute Values: None.\n \n \n 9. Class Distribution. The class is the localization site. Please see Nakai &\n \t\t       Kanehisa referenced above for more details.\n \n   cp  (cytoplasm)                                    143\n   im  (inner membrane without signal sequence)        77               \n   pp  (perisplasm)                                    52\n   imU (inner membrane, uncleavable signal sequence)   35\n   om  (outer membrane)                                20\n   omL (outer membrane lipoprotein)                     5\n   imL (inner membrane lipoprotein)                     2\n   imS (inner membrane, cleavable signal sequence)      2", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_39_ecoli_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-39-ecoli"}, "LL0_3_kr_vs_kp": {"pipeline": {"_id": "9d4e42d2-5a5b-4b21-9f50-eb2ee45f91d1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 36}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 657, "max_depth": 7, "learning_rate": 0.11315338714064926, "gamma": 0.1360344153079216, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9d4e42d2-5a5b-4b21-9f50-eb2ee45f91d1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9937292816013452, "rank": 0.006270718399220169, "metric": "f1Macro", "ts": "2018-10-25T00:38:10.628000", "dataset": "LL0_3_kr_vs_kp_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_3_kr_vs_kp", "about": {"problemID": "LL0_3_kr_vs_kp_problem", "problemName": "kr_vs_kp_problem", "problemDescription": "**Author**: Alen Shapiro\n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Chess+(King-Rook+vs.+King-Pawn))    \n**Please cite**: [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\n1. Title: Chess End-Game -- King+Rook versus King+Pawn on a7\n    (usually abbreviated KRKPA7).  The pawn on a7 means it is one square\n    away from queening.  It is the King+Rook's side (white) to move.\n \n 2. Sources:\n     (a) Database originally generated and described by Alen Shapiro.\n     (b) Donor/Coder: Rob Holte (holte@uottawa.bitnet).  The database\n         was supplied to Holte by Peter Clark of the Turing Institute\n         in Glasgow (pete@turing.ac.uk).\n     (c) Date: 1 August 1989\n \n 3. Past Usage:\n      - Alen D. Shapiro (1983,1987), \"Structured Induction in Expert Systems\",\n        Addison-Wesley.  This book is based on Shapiro's Ph.D. thesis (1983)\n        at the University of Edinburgh entitled \"The Role of Structured\n        Induction in Expert Systems\".\n      - Stephen Muggleton (1987), \"Structuring Knowledge by Asking Questions\",\n        pp.218-229 in \"Progress in Machine Learning\", edited by I. Bratko\n        and Nada Lavrac, Sigma Press, Wilmslow, England  SK9 5BB.\n      - Robert C. Holte, Liane Acker, and Bruce W. Porter (1989),\n        \"Concept Learning and the Problem of Small Disjuncts\",\n        Proceedings of IJCAI.  Also available as technical report AI89-106,\n        Computer Sciences Department, University of Texas at Austin,\n        Austin, Texas 78712.\n \n 4. Relevant Information:\n       The dataset format is described below.  Note: the format of this\n     database was modified on 2/26/90 to conform with the format of all\n     the other databases in the UCI repository of machine learning databases.\n \n 5. Number of Instances: 3196 total\n \n 6. Number of Attributes: 36\n \n 7. Attribute Summaries:\n     Classes (2):  -- White-can-win (\"won\") and White-cannot-win (\"nowin\").\n           I believe that White is deemed to be unable to win if the Black pawn\n           can safely advance.\n     Attributes: see Shapiro's book.\n \n 8. Missing Attributes: --  none\n \n 9. Class Distribution:\n     In 1669 of the positions (52%), White can win.\n     In 1527 of the positions (48%), White cannot win.\n \n The format for instances in this database is a sequence of 37 attribute values.\n Each instance is a board-descriptions for this chess endgame.  The first\n 36 attributes describe the board.  The last (37th) attribute is the\n classification: \"win\" or \"nowin\".  There are 0 missing values.\n A typical board-description is\n \n f,f,f,f,f,f,f,f,f,f,f,f,l,f,n,f,f,t,f,f,f,f,f,f,f,t,f,f,f,f,f,f,f,t,t,n,won\n \n The names of the features do not appear in the board-descriptions.\n Instead, each feature correponds to a particular position in the\n feature-value list.  For example, the head of this list is the value\n for the feature \"bkblk\".  The following is the list of features, in\n the order in which their values appear in the feature-value list:\n \n [bkblk,bknwy,bkon8,bkona,bkspr,bkxbq,bkxcr,bkxwp,blxwp,bxqsq,cntxt,dsopp,dwipd,\n  hdchk,katri,mulch,qxmsq,r2ar8,reskd,reskr,rimmx,rkxwp,rxmsq,simpl,skach,skewr,\n  skrxp,spcop,stlmt,thrsk,wkcti,wkna8,wknck,wkovl,wkpos,wtoeg]\n \n In the file, there is one instance (board position) per line.\n \n \n Num Instances:     3196\n Num Attributes:    37\n Num Continuous:    0 (Int 0 / Real 0)\n Num Discrete:      37\n Missing values:    0 /  0.0%\n\n     name                      type enum ints real     missing    distinct  (1)\n   1 'bkblk'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   2 'bknwy'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   3 'bkon8'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   4 'bkona'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   5 'bkspr'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   6 'bkxbq'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   7 'bkxcr'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   8 'bkxwp'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n   9 'blxwp'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  10 'bxqsq'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  11 'cntxt'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  12 'dsopp'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  13 'dwipd'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  14 'hdchk'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  15 'katri'                   Enum 100%   0%   0%     0 /  0%     3 /  0%   0% \n  16 'mulch'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  17 'qxmsq'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  18 'r2ar8'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  19 'reskd'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  20 'reskr'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  21 'rimmx'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  22 'rkxwp'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  23 'rxmsq'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  24 'simpl'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  25 'skach'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  26 'skewr'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  27 'skrxp'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  28 'spcop'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  29 'stlmt'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  30 'thrsk'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  31 'wkcti'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  32 'wkna8'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  33 'wknck'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  34 'wkovl'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  35 'wkpos'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  36 'wtoeg'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0% \n  37 'class'                   Enum 100%   0%   0%     0 /  0%     2 /  0%   0%", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_3_kr_vs_kp_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 37, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-3-kr-vs-kp"}, "LL0_40474_thyroid_allbp": {"pipeline": {"_id": "462e7280-9339-40f9-8521-830e82800133", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 68}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 14, "max_depth": 5, "learning_rate": 0.4823714420895213, "gamma": 0.5349959201202826, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "462e7280-9339-40f9-8521-830e82800133", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5140215079824808, "rank": 0.48597849201771276, "metric": "f1Macro", "ts": "2018-10-25T00:57:52.777000", "dataset": "LL0_40474_thyroid_allbp_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40474_thyroid_allbp", "about": {"problemID": "LL0_40474_thyroid_allbp_problem", "problemName": "LL0_40474_thyroid_allbp_problem", "problemDescription": "UCI Thyroid allbp dataset.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40474_thyroid_allbp_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 27, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40474-thyroid-allbp"}, "LL0_40475_thyroid_allhyper": {"pipeline": {"_id": "a36fc86c-b346-4a18-aff3-896a66d9a32b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 116, "max_depth": 5, "learning_rate": 0.10484870979546201, "gamma": 0.4002006735135507, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "a36fc86c-b346-4a18-aff3-896a66d9a32b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5152836380344379, "rank": 0.48471636196599366, "metric": "f1Macro", "ts": "2018-10-25T00:48:51.890000", "dataset": "LL0_40475_thyroid_allhyper_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40475_thyroid_allhyper", "about": {"problemID": "LL0_40475_thyroid_allhyper_problem", "problemName": "LL0_40475_thyroid_allhyper_problem", "problemDescription": "General Description of Thyroid Disease Databases \n                        and Related Files\n\nThis directory contains 6 databases, corresponding test set, and \ncorresponding documentation.  They were left at the University of\nCalifornia at Irvine by Ross Quinlan during his visit in 1987 for\nthe 1987 Machine Learning Workshop.  \n\nThe documentation files (with file extension &quot;names&quot;) are formatted to\nbe read by Quinlan's C4 decision tree program.  Though briefer than\nthe other documentation files found in this database repository, they\nshould suffice to describe the database, specifically:\n\n    1. Source\n    2. Number and names of attributes (including class names)\n    3. Types of values that each attribute takes\n\nIn general, these databases are quite similar and can be characterized\nsomewhat as follows:\n\n    1. Many attributes (29 or so, mostly the same set over all the databases)\n    2. mostly numeric or Boolean valued attributes\n    3. thyroid disease domains (records provided by the Garavan Institute\n       of Sydney, Australia)\n    4. several missing attribute values (signified by &quot;?&quot;)\n    5. small number of classes (under 10, changes with each database)\n    7. 2800 instances in each data set\n    8. 972 instances in each test set (It seems that the test sets' instances\n       are disjoint with respect to the corresponding data sets, but this has \n       not been verified)\n\nSee the following for a discussion of relevant experiments and related work:\n   Quinlan,J.R., Compton,P.J., Horn,K.A., &amp; Lazurus,L. (1986).\n   Inductive knowledge acquisition: A case study.\n   In Proceedings of the Second Australian Conference on Applications\n   of Expert Systems.  Sydney, Australia.\n\n   Quinlan,J.R. (1986). Induction of decision trees. Machine Learning,\n   1, 81--106.\n\nNote that the instances in these databases are followed by a vertical\nbar and a number.  These appear to be a patient id number.  The vertical\nbar is interpreted by Quinlan's algorithms as &quot;ignore the remainder of\nthis line&quot;. \n\n======================================================================\n\nThis database now also contains an additional two data files, named \nhypothyroid.data and sick-euthyroid.data.  They have approximately the\nsame data format and set of attributes as the other 6 databases, but\ntheir integrity is questionable.  Ross Quinlan is concerned that they\nmay have been corrupted since they first arrived at UCI, but we have not\nyet established the validity of this possibility.  These 2 databases differ\nin terms of their number of instances (3163) and lack of corresponding \ntest files.  They each have 2 concepts (negative/hypothyroid and \nsick-euthyroid/negative respectively).  Their source also appears to\nbe the Garavan institute.  Each contains several missing values.\n\nAnother relatively recent file thyroid0387.data has been added that \ncontains the latest version of an archive of thyroid diagnoses obtained \nfrom the Garvan Institute, consisting of 9172 records from 1984 to early 1987.\n\nA domain theory related to thyroid disease has also been added recently \n(thyroid.theory).\n\nThe files new-thyroid.[names,data] were donated by Stefan Aberhard.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40475_thyroid_allhyper_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 27, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40475-thyroid-allhyper"}, "LL0_40478_thyroid_dis": {"pipeline": {"_id": "f82329f2-d27f-4e33-ac87-4ecfc7c6d651", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 152, "max_depth": 3, "learning_rate": 0.06069091777029223, "gamma": 0.678538675386114, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "f82329f2-d27f-4e33-ac87-4ecfc7c6d651", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5051830787569644, "rank": 0.49481692124308596, "metric": "f1Macro", "ts": "2018-10-25T01:17:28.164000", "dataset": "LL0_40478_thyroid_dis_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40478_thyroid_dis", "about": {"problemID": "LL0_40478_thyroid_dis_problem", "problemName": "thyroid_dis_problem", "problemDescription": "General Description of Thyroid Disease Databases \n                        and Related Files\n\nThis directory contains 6 databases, corresponding test set, and \ncorresponding documentation.  They were left at the University of\nCalifornia at Irvine by Ross Quinlan during his visit in 1987 for\nthe 1987 Machine Learning Workshop.  \n\nThe documentation files (with file extension &quot;names&quot;) are formatted to\nbe read by Quinlan's C4 decision tree program.  Though briefer than\nthe other documentation files found in this database repository, they\nshould suffice to describe the database, specifically:\n\n    1. Source\n    2. Number and names of attributes (including class names)\n    3. Types of values that each attribute takes\n\nIn general, these databases are quite similar and can be characterized\nsomewhat as follows:\n\n    1. Many attributes (29 or so, mostly the same set over all the databases)\n    2. mostly numeric or Boolean valued attributes\n    3. thyroid disease domains (records provided by the Garavan Institute\n       of Sydney, Australia)\n    4. several missing attribute values (signified by &quot;?&quot;)\n    5. small number of classes (under 10, changes with each database)\n    7. 2800 instances in each data set\n    8. 972 instances in each test set (It seems that the test sets' instances\n       are disjoint with respect to the corresponding data sets, but this has \n       not been verified)\n\nSee the following for a discussion of relevant experiments and related work:\n   Quinlan,J.R., Compton,P.J., Horn,K.A., &amp; Lazurus,L. (1986).\n   Inductive knowledge acquisition: A case study.\n   In Proceedings of the Second Australian Conference on Applications\n   of Expert Systems.  Sydney, Australia.\n\n   Quinlan,J.R. (1986). Induction of decision trees. Machine Learning,\n   1, 81--106.\n\nNote that the instances in these databases are followed by a vertical\nbar and a number.  These appear to be a patient id number.  The vertical\nbar is interpreted by Quinlan's algorithms as &quot;ignore the remainder of\nthis line&quot;. \n\n======================================================================\n\nThis database now also contains an additional two data files, named \nhypothyroid.data and sick-euthyroid.data.  They have approximately the\nsame data format and set of attributes as the other 6 databases, but\ntheir integrity is questionable.  Ross Quinlan is concerned that they\nmay have been corrupted since they first arrived at UCI, but we have not\nyet established the validity of this possibility.  These 2 databases differ\nin terms of their number of instances (3163) and lack of corresponding \ntest files.  They each have 2 concepts (negative/hypothyroid and \nsick-euthyroid/negative respectively).  Their source also appears to\nbe the Garavan institute.  Each contains several missing values.\n\nAnother relatively recent file thyroid0387.data has been added that \ncontains the latest version of an archive of thyroid diagnoses obtained \nfrom the Garvan Institute, consisting of 9172 records from 1984 to early 1987.\n\nA domain theory related to thyroid disease has also been added recently \n(thyroid.theory).\n\nThe files new-thyroid.[names,data] were donated by Stefan Aberhard.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40478_thyroid_dis_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 27, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40478-thyroid-dis"}, "LL0_40496_led_display_domain_7digit": {"pipeline": {"_id": "fca64bb4-cd66-4692-bf19-5bc04cef7692", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 41}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 80, "max_depth": 5, "learning_rate": 0.9931662994637102, "gamma": 0.43161573396515907, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "fca64bb4-cd66-4692-bf19-5bc04cef7692", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7581282662985449, "rank": 0.24187173370149573, "metric": "f1Macro", "ts": "2018-10-24T23:52:40.633000", "dataset": "LL0_40496_led_display_domain_7digit_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40496_led_display_domain_7digit", "about": {"problemID": "LL0_40496_led_display_domain_7digit_problem", "problemName": "LL0_40496_led_display_domain_7digit_problem", "problemDescription": "**Author**: Breiman,L., Friedman,J.H., Olshen,R.A., and Stone,C.J.  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/LED+Display+Domain), [KEEL](http://sci2s.ugr.es/keel/dataset.php?cod=63, https://archive.ics.uci.edu/ml/datasets/LED+Display+Domain) - 1988  \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)  \n\n**LED display data set**  \nThis simple domain contains 7 Boolean attributes and 10 classes, the set of decimal digits. Recall that LED displays contain 7 light-emitting diodes -- hence the reason for 7 attributes. The class attribute is an integer ranging between 0 and 9 inclusive, representing the possible digits show on the display.\n\nThe problem would be easy if not for the introduction of noise.  In this case, each attribute value has the 10% probability of having its value inverted.  \n\nIt's valuable to know the optimal Bayes rate for these databases. In this case, the misclassification rate is 26% (74% classification accuracy).\n        \n### Attribute Information  \n* V1-V7 represent each of the 7 LEDs, with values either 0 or 1, according to whether the corresponding light is on or not for the decimal digit. Each has a 10% percent chance of being inverted.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40496_led_display_domain_7digit_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40496-led-display-domain-7digit"}, "LL0_40497_thyroid_ann": {"pipeline": {"_id": "6739590e-6a1d-4f1a-ac89-fa176ba754d3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 0}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 93, "max_depth": 3, "learning_rate": 0.41089077167757104, "gamma": 0.17935141390208442, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6739590e-6a1d-4f1a-ac89-fa176ba754d3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.993160244283845, "rank": 0.0068397557162092615, "metric": "f1Macro", "ts": "2018-10-24T23:56:16.504000", "dataset": "LL0_40497_thyroid_ann_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40497_thyroid_ann", "about": {"problemID": "LL0_40497_thyroid_ann_problem", "problemName": "LL0_40497_thyroid_ann_problem", "problemDescription": "This directory contains Thyroid datasets. &quot;ann-train.data&quot; contains 3772 \nlearning examples and &quot;ann-test.data&quot; contains 3428 testing examples. I have \nobtained this data from Daimler-Benz. This are the informations I have got \ntogether with the dataset:\n\n-------------------------------------------------------------------------------\n1. Data setp summary\n\nNumber of attributes: 21 (15 attributes are binary,\n      6 attributes are continuous)\nNumber of classes: 3\nNumber of learning examples: 3772\nNumber of testing examples: 3428\nData set is availbale on ASCII-file\n\n2. Description\n\nThe problem is to determine whether a patient referred to the clinic is\nhypothyroid. Therefore three classes are built: normal (not hypothyroid),\nhyperfunction and subnormal functioning. Because 92 percent of the patients\nare not hyperthyroid a good classifier must be significant better than 92%.\n\nNote\n\nThese are the datas Quinlans used in the case study of his article\n&quot;Simplifying Decision Trees&quot; (International Journal of Man-Machine Studies \n(1987) 221-234)\n-------------------------------------------------------------------------------\n\n\nUnfortunately this data differ from the one Ross Quinlan placed in\n&quot;pub/machine-learning-databases/thyroid-disease&quot; on &quot;ics.uci.edu&quot;.\nI don't know any more details about the dataset. But it's hard to\ntrain Backpropagation ANNs with it. The dataset is used in two technical\nreports:\n\n-------------------------------------------------------------------------------\n&quot;Optimization of the Backpropagation Algorithm for Training Multilayer\nPerceptrons&quot;:\n\n        ftp archive.cis.ohio-state.edu  or  ftp 128.146.8.52\n        cd pub/neuroprose\n        binary\n        get schiff.bp_speedup.ps.Z\n        quit\n\nThe report is an overview of many different backprop speedup techniques.\n15 different algorithms are described in detail and compared by using\na big, very hard to solve, practical data set. Learning speed and network\nclassification performance with respect to the training data set and also\nwith respect to a testing data set are discussed.\nThese are the tested algorithms:\n\nbackprop\nbackprop (batch mode)\nbackprop + Learning rate calculated by Eaton and Oliver's formula\nbackprop + decreasing learning rate (Darken and Moody)\nbackprop + Learning rate adaptation for each training pattern (J. Schmidhuber)\nbackprop + evolutionarily learning rate adaptation (R. Salomon)\nbackprop + angle driven learning rate adaptation(Chan and Fallside)\nPolak-Ribiere + line search (Kramer and Vincentelli)\nConj. gradient + line search (Leonard and Kramer)\nbackprop + learning rate adaptation by sign changes (Silva and Almeida)\nSuperSAB (T. Tollenaere)\nDelta-Bar-Delta (Jacobs)\nRPROP (Riedmiller and Braun)\nQuickprop (Fahlman)\nCascade correlation (Fahlman)\n\n-------------------------------------------------------------------------------\n&quot;Synthesis and Performance Analysis of Multilayer eural Network Architectures&quot;:\n\n\n        ftp archive.cis.ohio-state.edu  or  ftp 128.146.8.52\n        cd pub/neuroprose\n        binary\n        get schiff.gann.ps.Z\n        quit\n\nIn this paper we present various approaches for automatic topology-optimization\nof backpropagation networks. First of all, we review the basics of genetic\nalgorithms which are our essential tool for a topology search. Then we give a\nsurvey of backprop and the topological properties of feedforward networks. We\nreport on pioneer work in the filed of topology--optimization. Our first\napproach was based on evolutions strategies which used only mutation to change\nthe parent's topologies. Now, we found a way to extend this approach by an\ncrossover operator which is essential to all genetic search methods.\nIn contrast to competing approaches it allows that two parent networks with\ndifferent number of units can mate and produce a (valid) child network, which\ninherits genes from both of the parents. We applied our genetic algorithm to a\nmedical classification problem which is extremly difficult to solve. The\nperformance with respect to the training set and a test set of pattern samples\nwas compared to fixed network topologies. Our results confirm that the topology\noptimization makes sense, because the generated networks outperform the fixed\ntopologies and reach classification performances near optimum.\n\n-------------------------------------------------------------------------------\n\nRandolf Werner (evol@infko.uni-koblenz.de)", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40497_thyroid_ann_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40497-thyroid-ann"}, "LL0_40498_wine_quality_white": {"pipeline": {"_id": "9f10c0fd-7a96-4009-9221-53d2135223fa", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 43}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 260, "max_depth": 10, "learning_rate": 0.9641397664279284, "gamma": 0.03445984462539031, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9f10c0fd-7a96-4009-9221-53d2135223fa", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.4302268557905258, "rank": 0.5697731442100835, "metric": "f1Macro", "ts": "2018-10-25T01:08:20.937000", "dataset": "LL0_40498_wine_quality_white_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40498_wine_quality_white", "about": {"problemID": "LL0_40498_wine_quality_white_problem", "problemName": "LL0_40498_wine_quality_white_problem", "problemDescription": "Citation Request:\n  This dataset is public available for research. The details are described in [Cortez et al., 2009]. \n  Please include this citation if you plan to use this database:\n\n  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n  Modeling wine preferences by data mining from physicochemical properties.\n  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n\n  Available at: [@Elsevier] http://dx.doi.org/10.1016/j.dss.2009.05.016\n                [Pre-press (pdf)] http://www3.dsi.uminho.pt/pcortez/winequality09.pdf\n                [bib] http://www3.dsi.uminho.pt/pcortez/dss09.bib\n\n1. Title: Wine Quality \n\n2. Sources\n   Created by: Paulo Cortez (Univ. Minho), Antonio Cerdeira, Fernando Almeida, Telmo Matos and Jose Reis (CVRVV) @ 2009\n   \n3. Past Usage:\n\n  P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n  Modeling wine preferences by data mining from physicochemical properties.\n  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n\n  In the above reference, two datasets were created, using red and white wine samples.\n  The inputs include objective tests (e.g. PH values) and the output is based on sensory data\n  (median of at least 3 evaluations made by wine experts). Each expert graded the wine quality \n  between 0 (very bad) and 10 (very excellent). Several data mining methods were applied to model\n  these datasets under a regression approach. The support vector machine model achieved the\n  best results. Several metrics were computed: MAD, confusion matrix for a fixed error tolerance (T),\n  etc. Also, we plot the relative importances of the input variables (as measured by a sensitivity\n  analysis procedure).\n \n4. Relevant Information:\n\n   The two datasets are related to red and white variants of the Portuguese &quot;Vinho Verde&quot; wine.\n   For more details, consult: http://www.vinhoverde.pt/en/ or the reference [Cortez et al., 2009].\n   Due to privacy and logistic issues, only physicochemical (inputs) and sensory (the output) variables \n   are available (e.g. there is no data about grape types, wine brand, wine selling price, etc.).\n\n   These datasets can be viewed as classification or regression tasks.\n   The classes are ordered and not balanced (e.g. there are munch more normal wines than\n   excellent or poor ones). Outlier detection algorithms could be used to detect the few excellent\n   or poor wines. Also, we are not sure if all input variables are relevant. So\n   it could be interesting to test feature selection methods. \n\n5. Number of Instances: red wine - 1599; white wine - 4898. \n\n6. Number of Attributes: 11 + output attribute\n  \n   Note: several of the attributes may be correlated, thus it makes sense to apply some sort of\n   feature selection.\n\n7. Attribute information:\n\n   For more information, read [Cortez et al., 2009].\n\n   Input variables (based on physicochemical tests):\n   1 - fixed acidity\n   2 - volatile acidity\n   3 - citric acid\n   4 - residual sugar\n   5 - chlorides\n   6 - free sulfur dioxide\n   7 - total sulfur dioxide\n   8 - density\n   9 - pH\n   10 - sulphates\n   11 - alcohol\n   Output variable (based on sensory data): \n   12 - quality (score between 0 and 10)\n\n8. Missing Attribute Values: None", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40498_wine_quality_white_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 12, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40498-wine-quality-white"}, "LL0_40499_texture": {"pipeline": {"_id": "9f43bbf5-29b3-481a-84d4-ba2acbd58f24", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "9f43bbf5-29b3-481a-84d4-ba2acbd58f24", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9834323271341386, "rank": 0.01656767286674297, "metric": "f1Macro", "ts": "2018-10-31T04:09:45.093000", "dataset": "LL0_40499_texture_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40499_texture", "about": {"problemID": "LL0_40499_texture_problem", "problemName": "LL0_40499_texture_problem", "problemDescription": "**Author**: Laboratory of Image Processing and Pattern Recognition (INPG-LTIRF), Grenoble - France.  \n**Source**: [original](https://www.elen.ucl.ac.be/neural-nets/Research/Projects/ELENA/databases/REAL/texture/) - ELENA project   \n**Please cite**:   \n\n####1. Summary\n\nThis database was generated by the Laboratory of Image Processing and Pattern Recognition (INPG-LTIRF) in the development of the Esprit project ELENA No. 6891 and the Esprit working group ATHOS No. 6620.\n```\n (a) Original source:\n\n   P. Brodatz \"Textures: A Photographic Album for Artists and Designers\",\n   Dover Publications,Inc.,New York, 1966.\n\n (b) Creation: Laboratory of Image Processing and Pattern Recognition\n\n   Institut National Polytechnique de Grenoble INPG\n   Laboratoire de Traitement d'Image et de Reconnaissance de Formes LTIRF\n   Av. Felix Viallet, 46\n   F-38031 Grenoble Cedex\n   France\n\n (c) Contact: Dr. A. Guerin-Dugue, INPG-LTIRF, guerin@tirf.inpg.fr\n```\n\n####2. Past Usage:\n\nThis database has a private usage at the TIRF laboratory. It has been created in order to study the textures discrimination with high order statistics.\n\n```\nA.Guerin-Dugue, C. Aviles-Cruz, \"High Order Statistics from Natural Textured Images\",\nIn ATHOS workshop on System Identification and High Order Statistics, Sophia-Antipolis, France, September 1993.\n\nGuerin-Dugue, A. and others, Deliverable R3-B4-P - Task B4: Benchmarks, Technical report,\nElena-NervesII \"Enhanced Learning for Evolutive Neural Architecture\", ESPRIT-Basic Research Project  Number 6891,\nJune 1995.\n```\n\n####3. Relevant Information:\n\nThe aim is to distinguish between 11 different textures (Grass lawn, Pressed calf leather, Handmade paper, Raffia looped to a high pile, Cotton canvas, ...), each pattern (pixel) being characterised by 40 attributes built by the estimation of fourth order modified moments in four orientations: 0, 45, 90 and 135 degrees.\n\nA statistical method based on the extraction of fourth order moments for the characterization of natural micro-textures was developed called \"fourth order modified moments\" (mm4) [Guerin93], this method measures the deviation from first-order Gauss-Markov process, for each texture. The features were estimated in four directions to take into account the possible orientations of the textures (0, 45, 90 and 135 degrees). Only correlation between the current pixel, the first neighbourhood and the second neighbourhood are taken into account. This small neighbourhood is adapted to the fine grain property of the textures.\n\nThe data set contains 11 classes of 500 instances and each class refers to a type of texture in the Brodatz album.\n\nThe database dimension is 40 plus one for the class label. The 40 attributes were build respectively by the estimation of the following fourth order modified moments in four orientations: 0, 45, 90 and 135 degrees: mm4(000), mm4(001), mm4(002), mm4(011), mm4(012), mm4(022), mm4(111), mm4(112), mm4(122) and mm4(222).\n\n!! Patterns are always sorted by class and are presented in the increasing order of their class label in each dataset relative to the texture database (texture.dat, texture_CR.dat, texture_PCA.dat, texture_DFA.dat)\n\n####4. Class:\n\nThe class label is a code for the following classes:\n```\n                Class         Class label\n  2   Grass lawn                      (D09)  \n  3   Pressed calf leather            (D24) \n  4   Handmade paper                  (D57) \n  6   Raffia looped to a high pile:   (D84) \n  7   Cotton canvas                   (D77) \n  8   Pigskin                         (D92) \n  9   Beach sand:                     (D28) \n  10  Beach sand                      (D29) \n  12  Oriental straw cloth            (D53) \n  13  Oriental straw cloth            (D78) \n  14  Oriental grass fiber cloth      (D79) \n```\n\n####5. Summary Statistics:\n\nTable here below provides for each attribute of the database the dynamic (Min and Max values), the mean value and the standard deviation.\n\n```\nAttribute  Min      Max       Mean     Standard    \n                                       deviation   \n\n    1   -1.4495    0.7741   -1.0983    0.2034\n    2   -1.2004    0.3297   -0.5867    0.2055\n    3   -1.3099    0.3441   -0.5838    0.3135\n    4   -1.1104    0.5878   -0.4046    0.2302\n    5   -1.0534    0.4387   -0.3307    0.2360\n    6   -1.0029    0.4515   -0.2422    0.2225\n    7   -1.2076    0.5246   -0.6026    0.2003\n    8   -1.0799    0.3980   -0.4322    0.2210\n    9   -1.0570    0.4369   -0.3317    0.2361\n   10   -1.2580    0.3546   -0.5978    0.3268\n   11   -1.4495    0.7741   -1.0983    0.2034\n   12   -1.0831    0.3715   -0.5929    0.2056\n   13   -1.1194    0.6347   -0.4019    0.3368\n   14   -1.0182    0.1573   -0.6270    0.1390\n   15   -0.9435    0.1642   -0.4482    0.1952\n   16   -0.9944    0.0357   -0.5763    0.1587\n   17   -1.1722    0.0201   -0.7331    0.1955\n   18   -1.0174    0.1155   -0.4919    0.2335\n   19   -1.0044    0.0833   -0.4727    0.2257\n   20   -1.1800    0.4392   -0.4831    0.3484\n   21   -1.4495    0.7741   -1.0983    0.2034\n   22   -1.2275    0.5963   -0.7363    0.2220\n   23   -1.3412    0.4464   -0.7771    0.3290\n   24   -1.1774    0.6882   -0.5770    0.2646\n   25   -1.1369    0.4098   -0.5085    0.2538\n   26   -1.1099    0.3725   -0.4038    0.2515\n   27   -1.2393    0.6120   -0.7279    0.2278\n   28   -1.1540    0.4221   -0.5863    0.2446\n   29   -1.1323    0.3916   -0.5090    0.2526\n   30   -1.4224    0.4718   -0.7708    0.3264\n   31   -1.4495    0.7741   -1.0983    0.2034\n   32   -1.1789    0.5647   -0.6463    0.1890\n   33   -1.1473    0.6755   -0.4919    0.3304\n   34   -1.1228    0.3132   -0.6435    0.1441\n   35   -1.0145    0.3396   -0.4918    0.1922\n   36   -1.0298    0.1560   -0.5934    0.1704\n   37   -1.2534    0.0899   -0.7795    0.1641\n   38   -1.0966    0.1944   -0.5541    0.2111\n   39   -1.0765    0.2019   -0.5230    0.2015\n   40   -1.2155    0.4647   -0.5677    0.3091\n```\n\nThe dynamic of the attributes is in [-1.45 - 0.775]. The database resulting from the centering and reduction by attribute of the Texture database is on the ftp server in the `REAL/texture/texture_CR.dat.Z' file.\n\n####6. Confusion matrix.\n\nThe following confusion matrix of the k_NN classifier was obtained with a Leave_One_Out error counting method on the texture_CR.dat database. k was set to 1 in order to reach the minimum mean error rate : 1.0 +/- 0.8%.\n\n```\n Class    2      3      4      6      7      8      9      10     12     13     14 \n 2      97.0    1.0    0.4    0.0    0.0    0.0    1.6    0.0    0.0    0.0    0.0   \n 3       0.2   99.0    0.0    0.0    0.0    0.0    0.4    0.0    0.0    0.0    0.4   \n 4       1.0    0.0   98.8    0.0    0.0    0.0    0.2    0.0    0.0    0.0    0.0   \n 6       0.0    0.0    0.0   99.4    0.0    0.0    0.0    0.6    0.0    0.0    0.0   \n 7       0.0    0.0    0.0    0.0  100.0    0.0    0.0    0.0    0.0    0.0    0.0   \n 8       0.0    0.0    0.0    0.0    0.0   98.6    0.0    1.4    0.0    0.0    0.0   \n 9       0.4    0.0    0.2    0.0    0.0    0.2   98.8    0.4    0.0    0.0    0.0   \n 10      0.0    0.0    0.0    0.0    0.0    1.4    0.0   98.6    0.0    0.0    0.0   \n 12      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0  100.0    0.0    0.0   \n 13      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   99.8    0.2   \n 14      0.0    0.4    0.0    0.0    0.0    0.4    0.0    0.0    0.2    0.0   99.0   \n```\n\n7. Result of the Principal Component Analysis:\n\nThe Principal Components Analysis is a very classical method in pattern recognition [Duda73]. PCA reduces the sample dimension in a linear way for the best representation in lower dimensions keeping the maximum of inertia. The best axe for the representation is however not necessary the best axe for the discrimination. After PCA, features are selected according to the percentage of initial inertia which is covered by the different axes and the number of features is determined according to the percentage of initial inertia to keep for the classification process.\n\nThis selection method has been applied on the texture_CR database. When quasi-linear correlations exists between some initial features, these redundant dimensions are removed by PCA and this preprocessing is then recommended. In this case, before a PCA, the determinant of the data covariance matrix is near zero; this database is thus badly conditioned for all process which use this information (the quadratic classifier for example).\n\nThe following file is available for the texture database: ''texture_PCA.dat.Z'', it is the projection of the ''texture_CR'' database on its principal components (sorted in a decreasing order of the related inertia percentage; so, if you desire to work on the database projected on its x first principal components you only have to keep the x first attributes of the texture_PCA.dat database and the class labels (last attribute)).\n\nTable here below provides the inertia percentages associated to the eigenvalues corresponding to the principal component axis sorted in the decreasing order of the associated inertia percentage. 99.85 percent of the total database inertia will remain if the 20 first principal components are kept.\n\n```\n       Eigen Value   Inertia      Cumulated\n         value      percentage      inertia\n\n  1   30.267500000 75.6687000000  75.6687000000 \n  2   3.6512500000  9.1281300000  84.7969000000 \n  3   2.2937000000  5.7342400000  90.5311000000 \n  4   1.7039700000  4.2599300000  94.7910000000 \n  5   0.6716540000  1.6791300000  96.4702000000 \n  6   0.5015290000  1.2538200000  97.7240000000 \n  7   0.1922830000  0.4807070000  98.2047000000 \n  8   0.1561070000  0.3902670000  98.5950000000 \n  9   0.1099570000  0.2748920000  98.8699000000 \n  10  0.0890891000  0.2227230000  99.0926000000 \n  11  0.0656016000  0.1640040000  99.2566000000 \n  12  0.0489988000  0.1224970000  99.3791000000 \n  13  0.0433819000  0.1084550000  99.4875000000 \n  14  0.0345022000  0.0862554000  99.5738000000 \n  15  0.0299203000  0.0748007000  99.6486000000 \n  16  0.0248857000  0.0622141000  99.7108000000 \n  17  0.0167901000  0.0419752000  99.7528000000 \n  18  0.0161633000  0.0404083000  99.7932000000 \n  19  0.0128898000  0.0322246000  99.8254000000 \n  20  0.0113884000  0.0284710000  99.8539000000 \n  21  0.0078481400  0.0196204000  99.8735000000 \n  22  0.0071527800  0.0178820000  99.8914000000 \n  23  0.0067661400  0.0169153000  99.9083000000 \n  24  0.0053149500  0.0132874000  99.9216000000 \n  25  0.0051102600  0.0127757000  99.9344000000 \n  26  0.0047116600  0.0117792000  99.9461000000 \n  27  0.0036193700  0.0090484300  99.9552000000 \n  28  0.0033222000  0.0083054900  99.9635000000 \n  29  0.0030722400  0.0076806100  99.9712000000 \n  30  0.0026373300  0.0065933300  99.9778000000 \n  31  0.0020996800  0.0052492000  99.9830000000 \n  32  0.0019376500  0.0048441200  99.9879000000 \n  33  0.0015642300  0.0039105700  99.9918000000 \n  34  0.0009679080  0.0024197700  99.9942000000 \n  35  0.0009578000  0.0023945000  99.9966000000 \n  36  0.0007379780  0.0018449400  99.9984000000 \n  37  0.0006280250  0.0015700600  100.000000000\n  38  0.0000000040  0.0000000099  100.000000000 \n  39  0.0000000001  0.0000000003  100.000000000 \n  40  0.0000000008  0.0000000019  100.000000000 \n\n```\n\nThis matrix can be found in the texture_EV.dat file.\n\nThe Discriminant Factorial Analysis (DFA) can be applied to a learning database where each learning sample belongs to a particular class [Duda73]. The number of discriminant features selected by DFA is fixed in function of the number of classes (c) and of the number of input dimensions (d); this number is equal to the minimum between d and c-1. In the usual case where d is greater than c, the output dimension is fixed equal to the number of classes minus one and the discriminant axes are selected in order to maximize the between-variance and to minimize the within-variance of the classes.\n\nThe discrimination power (ratio of the projected between-variance over the projected within-variance) is not the same for each discriminant axis: this ratio decreases for each axis. So for a problem with many classes, this preprocessing will not be always efficient as the last output features will not be so discriminant. This analysis uses the information of the inverse of the global covariance matrix, so the covariance matrix must be well conditioned (for example, a preliminary PCA must be applied to remove the linearly correlated dimensions).\n\nThe Discriminant Factorial Analysis (DFA) has been applied on the 18 first principal components of the texture_PCA database (thus by keeping only the 18 first attributes of these databases before to apply the DFA preprocessing) in order to build the texture_DFA.dat.Z database file, having 10 dimensions (the texture database having 11 classes). In the case of the texture database, experiments shown that a DFA preprocessing is very useful and most of the time improved the classifiers performances.\n\n[Duda73] Duda, R.O. and Hart, P.E.,Pattern Classification and Scene Analysis, John Wiley & Sons, 1973.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_40499_texture_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40499-texture"}, "LL0_40509_Australian": {"pipeline": {"_id": "547116b8-52b5-4982-a11b-be49cb3065c0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 9}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 82, "max_depth": 8, "learning_rate": 0.2811083178415873, "gamma": 0.8210858637291305, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "547116b8-52b5-4982-a11b-be49cb3065c0", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8975850273315771, "rank": 0.10241497266915238, "metric": "f1Macro", "ts": "2018-10-25T01:33:55.239000", "dataset": "LL0_40509_Australian_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40509_Australian", "about": {"problemID": "LL0_40509_Australian_problem", "problemName": "Australian_problem", "problemDescription": "**Author**: Confidential. Donated by Ross Quinlan  \n**Source**: [LibSVM] (https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html), [UCI](https://archive.ics.uci.edu/ml/datasets/Statlog+(Australian+Credit+Approval)) - 1987    \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html) \n\n**Australian Credit Approval**. This is the famous Australian Credit Approval dataset, originating from the StatLog project. It concerns credit card applications. All attribute names and values have been changed to meaningless symbols to protect the confidentiality of the data. \n\nThis dataset was retrieved 2014-11-14 from the libSVM site. It was normalized to [-1,1] and converted to the ARFF format.\n\n### Feature information\n\nThere are 6 numerical and 8 categorical attributes, all normalized to [-1,1]. The original formatting was as follows:  \n\nA1: 0,1 CATEGORICAL (formerly: a,b)  \nA2: continuous.  \nA3: continuous.  \nA4: 1,2,3 CATEGORICAL (formerly: p,g,gg)  \nA5: 1, 2,3,4,5, 6,7,8,9,10,11,12,13,14 CATEGORICAL (formerly: ff,d,i,k,j,aa,m,c,w, e, q, r,cc, x)  \nA6: 1, 2,3, 4,5,6,7,8,9 CATEGORICAL (formerly: ff,dd,j,bb,v,n,o,h,z)  \nA7: continuous.  \nA8: 1, 0 CATEGORICAL (formerly: t, f)  \nA9: 1, 0 CATEGORICAL (formerly: t, f)  \nA10: continuous.  \nA11: 1, 0 CATEGORICAL (formerly t, f)  \nA12: 1, 2, 3 CATEGORICAL (formerly: s, g, p)  \nA13: continuous.  \nA14: continuous.  \nA15: 1,2 class attribute (formerly: +,-)  \n\n### Relevant Papers\n\nRoss Quinlan. \"Simplifying decision trees\", Int J Man-Machine Studies 27, Dec 1987, pp. 221-234. \n\nRoss Quinlan. \"C4.5: Programs for Machine Learning\", Morgan Kaufmann, Oct 1992", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40509_Australian_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "Y"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40509-Australian"}, "LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1": {"pipeline": {"_id": "df27095c-a3c2-4b24-8b83-107637ba8f4b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 59}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 427, "max_depth": 5, "learning_rate": 0.24828248466365244, "gamma": 0.49415871742805206, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "df27095c-a3c2-4b24-8b83-107637ba8f4b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6489794499216767, "rank": 0.35102055007893984, "metric": "f1Macro", "ts": "2018-10-25T00:58:55.841000", "dataset": "LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1", "about": {"problemID": "LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1_problem", "problemName": "GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1_problem", "problemDescription": "GAMETES_Epistasis_2-Way_20atts_0.1H_EDM-1_1-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40646_GAMETES_Epistasis_2_Way_20atts_0.1H_EDM_1_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40646-GAMETES-Epistasis-2-Way-20atts-0.1H-EDM-1-1"}, "LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1": {"pipeline": {"_id": "88c9a6ad-65d7-41a5-b255-b696a9828372", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 97}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 813, "max_depth": 5, "learning_rate": 0.015669543006771924, "gamma": 0.1794227703778839, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "88c9a6ad-65d7-41a5-b255-b696a9828372", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7436485446302326, "rank": 0.25635145537015, "metric": "f1Macro", "ts": "2018-10-25T00:39:56.924000", "dataset": "LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1", "about": {"problemID": "LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1_problem", "problemName": "GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1_problem", "problemDescription": "GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40647_GAMETES_Epistasis_2_Way_20atts_0.4H_EDM_1_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40647-GAMETES-Epistasis-2-Way-20atts-0.4H-EDM-1-1"}, "LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1": {"pipeline": {"_id": "7f7c1587-c6dc-4274-8912-9304483f794e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 109, "max_depth": 9, "learning_rate": 0.42778589959213, "gamma": 0.5835128063367871, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "7f7c1587-c6dc-4274-8912-9304483f794e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6208806095294318, "rank": 0.37911939047120774, "metric": "f1Macro", "ts": "2018-10-25T00:18:10.700000", "dataset": "LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1", "about": {"problemID": "LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1_problem", "problemName": "GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1_problem", "problemDescription": "GAMETES_Epistasis_3-Way_20atts_0.2H_EDM-1_1-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40648_GAMETES_Epistasis_3_Way_20atts_0.2H_EDM_1_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40648-GAMETES-Epistasis-3-Way-20atts-0.2H-EDM-1-1"}, "LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001": {"pipeline": {"_id": "11fe2048-0760-4105-9f2e-e25a4bce901a", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 20}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 19, "max_depth": 5, "learning_rate": 0.38641290204464906, "gamma": 0.3574290658320105, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "11fe2048-0760-4105-9f2e-e25a4bce901a", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7133918035090184, "rank": 0.28660819649120856, "metric": "f1Macro", "ts": "2018-10-25T01:26:14.992000", "dataset": "LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001", "about": {"problemID": "LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001_problem", "problemName": "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001_problem", "problemDescription": "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM-2_001-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40649_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_50_EDM_2_001_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40649-GAMETES-Heterogeneity-20atts-1600-Het-0.4-0.2-50-EDM-2-001"}, "LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001": {"pipeline": {"_id": "8ea4c2fb-d56a-488f-a8fd-7ed011d4bdf1", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 95}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 50, "max_depth": 3, "learning_rate": 0.4846859521505391, "gamma": 0.5183935171409308, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "8ea4c2fb-d56a-488f-a8fd-7ed011d4bdf1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.712508831977116, "rank": 0.28749116802335456, "metric": "f1Macro", "ts": "2018-10-25T01:53:02.043000", "dataset": "LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001", "about": {"problemID": "LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001_problem", "problemName": "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001_problem", "problemDescription": "GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM-2_001-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40650_GAMETES_Heterogeneity_20atts_1600_Het_0.4_0.2_75_EDM_2_001_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 21, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40650-GAMETES-Heterogeneity-20atts-1600-Het-0.4-0.2-75-EDM-2-001"}, "LL0_40663_calendarDOW": {"pipeline": {"_id": "570dfd66-3bfd-4b03-bfe1-ad1467a298c5", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 486, "max_depth": 5, "learning_rate": 0.7665438309594242, "gamma": 0.7623466604433026, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "570dfd66-3bfd-4b03-bfe1-ad1467a298c5", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6119089644558089, "rank": 0.38809103554493934, "metric": "f1Macro", "ts": "2018-10-25T01:16:44.713000", "dataset": "LL0_40663_calendarDOW_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40663_calendarDOW", "about": {"problemID": "LL0_40663_calendarDOW_problem", "problemName": "calendarDOW_problem", "problemDescription": "calendarDOW-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40663_calendarDOW_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40663-calendarDOW"}, "LL0_40669_corral": {"pipeline": {"_id": "535c1992-21d2-4bcd-8946-1ba6cc88cd12", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 77}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 410, "max_depth": 4, "learning_rate": 0.4439730275947682, "gamma": 0.893710999245166, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "535c1992-21d2-4bcd-8946-1ba6cc88cd12", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 3.898286798342143e-15, "metric": "f1Macro", "ts": "2018-10-25T00:07:11.660000", "dataset": "LL0_40669_corral_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40669_corral", "about": {"problemID": "LL0_40669_corral_problem", "problemName": "corral_problem", "problemDescription": "corral-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40669_corral_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40669-corral"}, "LL0_40677_led24": {"pipeline": {"_id": "56f4c46c-2b95-4fe0-9e70-5b0e73782712", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 68}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 621, "max_depth": 3, "learning_rate": 0.09641882446112982, "gamma": 0.9980288800019755, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "56f4c46c-2b95-4fe0-9e70-5b0e73782712", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7270989058445035, "rank": 0.27290109415589103, "metric": "f1Macro", "ts": "2018-10-25T01:35:14.190000", "dataset": "LL0_40677_led24_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40677_led24", "about": {"problemID": "LL0_40677_led24_problem", "problemName": "led24_problem", "problemDescription": "led24-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40677_led24_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 25, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40677-led24"}, "LL0_40680_mofn_3_7_10": {"pipeline": {"_id": "4545bfe7-5a6f-41f9-a655-7b88fcd5ad94", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 49}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 639, "max_depth": 6, "learning_rate": 0.2773623522297193, "gamma": 0.644727076512565, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "4545bfe7-5a6f-41f9-a655-7b88fcd5ad94", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 1.9801685607001572e-17, "metric": "f1Macro", "ts": "2018-10-24T23:51:16.065000", "dataset": "LL0_40680_mofn_3_7_10_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40680_mofn_3_7_10", "about": {"problemID": "LL0_40680_mofn_3_7_10_problem", "problemName": "mofn_3_7_10_problem", "problemDescription": "mofn-3-7-10-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40680_mofn_3_7_10_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40680-mofn-3-7-10"}, "LL0_40682_thyroid_new": {"pipeline": {"_id": "661d6186-0b46-4ed5-9214-e25dfcef695e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 53}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 25, "min_samples_split": 0.0881276170208713, "min_samples_leaf": 0.1136086661437641, "n_estimators": 277, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "661d6186-0b46-4ed5-9214-e25dfcef695e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9787677077999659, "rank": 0.021232292200610466, "metric": "f1Macro", "ts": "2018-10-25T05:29:27.226000", "dataset": "LL0_40682_thyroid_new_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40682_thyroid_new", "about": {"problemID": "LL0_40682_thyroid_new_problem", "problemName": "thyroid_new_problem", "problemDescription": "new-thyroid-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40682_thyroid_new_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40682-thyroid-new"}, "LL0_40686_solar_flare_1": {"pipeline": {"_id": "b2d04ec1-e17d-4049-bb36-14d4bfc20807", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 666, "max_depth": 6, "learning_rate": 0.9259173041513037, "gamma": 0.07230841496536855, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "b2d04ec1-e17d-4049-bb36-14d4bfc20807", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6717069944548205, "rank": 0.32829300554573004, "metric": "f1Macro", "ts": "2018-10-31T05:28:15.068000", "dataset": "LL0_40686_solar_flare_1_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40686_solar_flare_1", "about": {"problemID": "LL0_40686_solar_flare_1_problem", "problemName": "solar_flare_1_problem", "problemDescription": "solar-flare_1-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40686_solar_flare_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40686-solar-flare-1"}, "LL0_40687_solar_flare_2": {"pipeline": {"_id": "d291f315-f154-4a77-9af6-8aa32c451570", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 97}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 608, "max_depth": 5, "learning_rate": 0.9155770381530989, "gamma": 0.23890225577915136, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d291f315-f154-4a77-9af6-8aa32c451570", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6661492703225215, "rank": 0.3338507296783331, "metric": "f1Macro", "ts": "2018-10-25T00:36:45.141000", "dataset": "LL0_40687_solar_flare_2_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40687_solar_flare_2", "about": {"problemID": "LL0_40687_solar_flare_2_problem", "problemName": "solar_flare_2_problem", "problemDescription": "solar-flare_2-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40687_solar_flare_2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40687-solar-flare-2"}, "LL0_40693_xd6": {"pipeline": {"_id": "09a086cd-a421-41ae-914d-23594f009962", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 60}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 495, "max_depth": 4, "learning_rate": 0.39503318472097215, "gamma": 0.38675060051448107, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "09a086cd-a421-41ae-914d-23594f009962", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 3.5455481937396446e-17, "metric": "f1Macro", "ts": "2018-10-25T00:14:53.668000", "dataset": "LL0_40693_xd6_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40693_xd6", "about": {"problemID": "LL0_40693_xd6_problem", "problemName": "xd6_problem", "problemDescription": "xd6-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40693_xd6_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40693-xd6"}, "LL0_40702_flare": {"pipeline": {"_id": "b7a3cba0-1f31-4a54-a4d0-b7e222044f9c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 15, "min_samples_split": 0.02336021354879688, "min_samples_leaf": 0.006537783996982131, "n_estimators": 34, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "b7a3cba0-1f31-4a54-a4d0-b7e222044f9c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6589434948414965, "rank": 0.3410565051587294, "metric": "f1Macro", "ts": "2018-10-25T06:24:12.011000", "dataset": "LL0_40702_flare_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40702_flare", "about": {"problemID": "LL0_40702_flare_problem", "problemName": "flare_problem", "problemDescription": "flare-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40702_flare_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40702-flare"}, "LL0_40704_titanic": {"pipeline": {"_id": "1a4cc652-ecb6-4788-ade8-5159d14f0676", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 17}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 19, "min_samples_split": 0.3224313334474357, "min_samples_leaf": 0.017304250492952086, "n_estimators": 475, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "1a4cc652-ecb6-4788-ade8-5159d14f0676", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7318341756924612, "rank": 0.26816582430770886, "metric": "f1Macro", "ts": "2018-10-25T06:08:05.511000", "dataset": "LL0_40704_titanic_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40704_titanic", "about": {"problemID": "LL0_40704_titanic_problem", "problemName": "titanic_problem", "problemDescription": "titanic-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40704_titanic_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40704-titanic"}, "LL0_40705_tokyo1": {"pipeline": {"_id": "70e65dc8-b32c-468e-bea8-3483158fc85e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 75}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 63, "max_depth": 3, "learning_rate": 0.1468864828811024, "gamma": 0.04667003739182218, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "70e65dc8-b32c-468e-bea8-3483158fc85e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9392295980912226, "rank": 0.06077040190938058, "metric": "f1Macro", "ts": "2018-10-25T00:10:45.914000", "dataset": "LL0_40705_tokyo1_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40705_tokyo1", "about": {"problemID": "LL0_40705_tokyo1_problem", "problemName": "tokyo1_problem", "problemDescription": "tokyo1-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40705_tokyo1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 45, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40705-tokyo1"}, "LL0_40706_parity5_plus_5": {"pipeline": {"_id": "a241cba6-306b-4ae1-ac6e-3450a4a590c1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 91}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 178, "max_depth": 6, "learning_rate": 0.8800940176552233, "gamma": 0.8495391195883095, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "a241cba6-306b-4ae1-ac6e-3450a4a590c1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9977899877899878, "rank": 0.0022100122100189154, "metric": "f1Macro", "ts": "2018-10-25T01:14:36.386000", "dataset": "LL0_40706_parity5_plus_5_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40706_parity5_plus_5", "about": {"problemID": "LL0_40706_parity5_plus_5_problem", "problemName": "parity5_plus_5_problem", "problemDescription": "parity5_plus_5-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40706_parity5_plus_5_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40706-parity5-plus-5"}, "LL0_40708_allrep": {"pipeline": {"_id": "4fd5a72a-2ac9-40dd-b720-24adaee8f9b2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 80}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 662, "max_depth": 3, "learning_rate": 0.9842310148676435, "gamma": 0.4502568001934114, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "4fd5a72a-2ac9-40dd-b720-24adaee8f9b2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8270279076690468, "rank": 0.17297209233194638, "metric": "f1Macro", "ts": "2018-10-25T01:42:40.566000", "dataset": "LL0_40708_allrep_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40708_allrep", "about": {"problemID": "LL0_40708_allrep_problem", "problemName": "allrep_problem", "problemDescription": "allrep-pmlb", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40708_allrep_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 30, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40708-allrep"}, "LL0_40712_crx": {"pipeline": {"_id": "6f735746-4a15-42fb-8aa5-88786dcd3d43", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 14}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 91, "max_depth": 6, "learning_rate": 0.4046666228770268, "gamma": 0.85237084783116, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6f735746-4a15-42fb-8aa5-88786dcd3d43", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.875632511732163, "rank": 0.1243674882682623, "metric": "f1Macro", "ts": "2018-10-25T00:28:57.741000", "dataset": "LL0_40712_crx_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40712_crx", "about": {"problemID": "LL0_40712_crx_problem", "problemName": "crx_problem", "problemDescription": "crx-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40712_crx_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 16, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40712-crx"}, "LL0_40715_pima": {"pipeline": {"_id": "74acc70b-9d37-49fe-8abb-83e9a9588d56", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 8, "min_samples_split": 0.06761244476985882, "min_samples_leaf": 0.052985294231628045, "n_estimators": 23, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "74acc70b-9d37-49fe-8abb-83e9a9588d56", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7541606155520564, "rank": 0.24583938444877879, "metric": "f1Macro", "ts": "2018-10-25T05:26:20.699000", "dataset": "LL0_40715_pima_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40715_pima", "about": {"problemID": "LL0_40715_pima_problem", "problemName": "pima_problem", "problemDescription": "pima-pmlb", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40715_pima_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40715-pima"}, "LL0_40_sonar": {"pipeline": {"_id": "cffc0f03-bef6-4006-a5a0-6aa5ebd91d64", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 40}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 507, "max_depth": 9, "learning_rate": 0.5916427586625409, "gamma": 0.4699756764398434, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "cffc0f03-bef6-4006-a5a0-6aa5ebd91d64", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8784635865024881, "rank": 0.12153641349759112, "metric": "f1Macro", "ts": "2018-10-25T01:47:33.111000", "dataset": "LL0_40_sonar_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_40_sonar", "about": {"problemID": "LL0_40_sonar_problem", "problemName": "sonar_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nNAME: Sonar, Mines vs. Rocks\n \n SUMMARY: This is the data set used by Gorman and Sejnowski in their study\n of the classification of sonar signals using a neural network [1].  The\n task is to train a network to discriminate between sonar signals bounced\n off a metal cylinder and those bounced off a roughly cylindrical rock.\n \n SOURCE: The data set was contributed to the benchmark collection by Terry\n Sejnowski, now at the Salk Institute and the University of California at\n San Deigo.  The data set was developed in collaboration with R. Paul\n Gorman of Allied-Signal Aerospace Technology Center.\n \n MAINTAINER: Scott E. Fahlman\n \n PROBLEM DESCRIPTION:\n \n The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar\n signals off a metal cylinder at various angles and under various\n conditions.  The file \"sonar.rocks\" contains 97 patterns obtained from\n rocks under similar conditions.  The transmitted sonar signal is a\n frequency-modulated chirp, rising in frequency.  The data set contains\n signals obtained from a variety of different aspect angles, spanning 90\n degrees for the cylinder and 180 degrees for the rock.\n \n Each pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number\n represents the energy within a particular frequency band, integrated over\n a certain period of time.  The integration aperture for higher frequencies\n occur later in time, since these frequencies are transmitted later during\n the chirp.\n \n The label associated with each record contains the letter \"R\" if the object\n is a rock and \"M\" if it is a mine (metal cylinder).  The numbers in the\n labels are in increasing order of aspect angle, but they do not encode the\n angle directly.\n \n METHODOLOGY: \n \n This data set can be used in a number of different ways to test learning\n speed, quality of ultimate learning, ability to generalize, or combinations\n of these factors.\n \n In [1], Gorman and Sejnowski report two series of experiments: an\n \"aspect-angle independent\" series, in which the whole data set is used\n without controlling for aspect angle, and an \"aspect-angle dependent\"\n series in which the training and testing sets were carefully controlled to\n ensure that each set contained cases from each aspect angle in\n appropriate proportions.\n \n For the aspect-angle independent experiments the combined set of 208 cases\n is divided randomly into 13 disjoint sets with 16 cases in each.  For each\n experiment, 12 of these sets are used as training data, while the 13th is\n reserved for testing.  The experiment is repeated 13 times so that every\n case appears once as part of a test set.  The reported performance is an\n average over the entire set of 13 different test sets, each run 10 times.\n \n It was observed that this random division of the sample set led to rather\n uneven performance.  A few of the splits gave poor results, presumably\n because the test set contains some samples from aspect angles that are\n under-represented in the corresponding training set.  This motivated Gorman\n and Sejnowski to devise a different set of experiments in which an attempt\n was made to balance the training and test sets so that each would have a\n representative number of samples from all aspect angles.  Since detailed\n aspect angle information was not present in the data base of samples, the\n 208 samples were first divided into clusters, using a 60-dimensional\n Euclidian metric; each of these clusters was then divided between the\n 104-member training set and the 104-member test set.  \n \n The actual training and testing samples used for the \"aspect angle\n dependent\" experiments are marked in the data files.  The reported\n performance is an average over 10 runs with this single division of the\n data set.\n \n A standard back-propagation network was used for all experiments.  The\n network had 60 inputs and 2 output units, one indicating a cylinder and the\n other a rock.  Experiments were run with no hidden units (direct\n connections from each input to each output) and with a single hidden layer\n with 2, 3, 6, 12, or 24 units.  Each network was trained by 300 epochs over\n the entire training set.\n \n The weight-update formulas used in this study were slightly different from\n the standard form.  A learning rate of 2.0 and momentum of 0.0 was used.\n Errors less than 0.2 were treated as zero.  Initial weights were uniform\n random values in the range -0.3 to +0.3.\n \n RESULTS: \n \n For the angle independent experiments, Gorman and Sejnowski report the\n following results for networks with different numbers of hidden units:\n \n Hidden\t% Right on\tStd.\t% Right on\tStd.\n Units\tTraining set\tDev.\tTest Set\tDev.\n ------\t------------\t----\t----------\t----\n 0\t89.4\t\t2.1\t77.1\t\t8.3\n 2\t96.5\t\t0.7\t81.9\t\t6.2\n 3\t98.8\t\t0.4\t82.0\t\t7.3\n 6\t99.7\t\t0.2\t83.5\t\t5.6\n 12\t99.8\t\t0.1\t84.7\t\t5.7\n 24\t99.8\t\t0.1\t84.5\t\t5.7\n \n For the angle-dependent experiments Gorman and Sejnowski report the\n following results:\n \n Hidden\t% Right on\tStd.\t% Right on\tStd.\n Units\tTraining set\tDev.\tTest Set\tDev.\n ------\t------------\t----\t----------\t----\n 0\t79.3\t\t3.4\t73.1\t\t4.8\n 2\t96.2\t\t2.2\t85.7\t\t6.3\n 3\t98.1\t\t1.5\t87.6\t\t3.0\n 6\t99.4\t\t0.9\t89.3\t\t2.4\n 12\t99.8\t\t0.6\t90.4\t\t1.8\n 24     100.0\t\t0.0\t89.2\t\t1.4\n \n Not surprisingly, the network's performance on the test set was somewhat\n better when the aspect angles in the training and test sets were balanced.\n \n Gorman and Sejnowski further report that a nearest neighbor classifier on\n the same data gave an 82.7% probability of correct classification.\n \n Three trained human subjects were each tested on 100 signals, chosen at\n random from the set of 208 returns used to create this data set.  Their\n responses ranged between 88% and 97% correct.  However, they may have been\n using information from the raw sonar signal that is not preserved in the\n processed data sets presented here.\n \n REFERENCES: \n \n 1. Gorman, R. P., and Sejnowski, T. J. (1988).  \"Analysis of Hidden Units\n in a Layered Network Trained to Classify Sonar Targets\" in Neural Networks,\n Vol. 1, pp. 75-89.\n\n\n\n\n Relabeled values in attribute 'Class'\n    From: R                       To: Rock                \n    From: M                       To: Mine", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_40_sonar_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 61, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-40-sonar"}, "LL0_4134_bioresponse": {"pipeline": {"_id": "76a66b71-40c9-42ef-9e48-8ef3ee96f96b", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 11}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 6, "learning_rate": 0.17382828986968646, "gamma": 0.6758064101049865, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "76a66b71-40c9-42ef-9e48-8ef3ee96f96b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8017516733273734, "rank": 0.19824832667295458, "metric": "f1Macro", "ts": "2018-10-25T00:53:38.144000", "dataset": "LL0_4134_bioresponse_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_4134_bioresponse", "about": {"problemID": "LL0_4134_bioresponse_problem", "problemName": "LL0_4134_bioresponse_problem", "problemDescription": "**Author**: Boehringer Ingelheim  \n**Source**: [Kaggle](https://www.kaggle.com/c/bioresponse) - 2011  \n**Please cite**: None  \n\nPredict a biological response of molecules from their chemical properties. Each row in this data set represents a molecule. The first column contains experimental data describing an actual biological response; the molecule was seen to elicit this response (1), or not (0). The remaining columns represent molecular descriptors (d1 through d1776), these are calculated properties that can capture some of the characteristics of the molecule - for example size, shape, or elemental constitution. The descriptor matrix has been normalized.\n\nThe original training and test set were merged.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_4134_bioresponse_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1777, "colName": "target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-4134-bioresponse"}, "LL0_4153_Smartphone_Based_Recognition_of_Human_Activities": {"pipeline": {"_id": "a475fbf0-cd07-44ac-a84e-60583911f1b9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 23, "min_samples_split": 0.019715235502725765, "min_samples_leaf": 0.16519217460683144, "n_estimators": 346, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "a475fbf0-cd07-44ac-a84e-60583911f1b9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9663492063492063, "rank": 0.03365079365130689, "metric": "f1Macro", "ts": "2018-10-25T06:00:28.598000", "dataset": "LL0_4153_Smartphone_Based_Recognition_of_Human_Activities_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_4153_Smartphone_Based_Recognition_of_Human_Activities", "about": {"problemID": "LL0_4153_Smartphone_Based_Recognition_of_Human_Activities_problem", "problemName": "Smartphone_Based_Recognition_of_Human_Activities_problem", "problemDescription": "Original data from UCI repository, http://archive.ics.uci.edu/ml/datasets/Smartphone-Based+Recognition+of+Human+Activities+and+Postural+Transitions.\n\nThe data was aggregated for each person and activity type (mean), train and test sets are joined.", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_4153_Smartphone_Based_Recognition_of_Human_Activities_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "Activity"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-4153-Smartphone-Based-Recognition-of-Human-Activities"}, "LL0_41_glass": {"pipeline": {"_id": "e7a2747f-5563-49a6-b58e-32e76976bcd3", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 100}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 14, "min_samples_split": 0.0069432626769727465, "min_samples_leaf": 0.005665157133340543, "n_estimators": 229, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "e7a2747f-5563-49a6-b58e-32e76976bcd3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7695611577964518, "rank": 0.23043884220371222, "metric": "f1Macro", "ts": "2018-10-25T06:33:29.774000", "dataset": "LL0_41_glass_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_41_glass", "about": {"problemID": "LL0_41_glass_problem", "problemName": "glass_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Glass Identification Database\n \n 2. Sources:\n     (a) Creator: B. German\n         -- Central Research Establishment\n            Home Office Forensic Science Service\n            Aldermaston, Reading, Berkshire RG7 4PN\n     (b) Donor: Vina Spiehler, Ph.D., DABFT\n                Diagnostic Products Corporation\n                (213) 776-0180 (ext 3014)\n     (c) Date: September, 1987\n \n 3. Past Usage:\n     -- Rule Induction in Forensic Science\n        -- Ian W. Evett and Ernest J. Spiehler\n        -- Central Research Establishment\n           Home Office Forensic Science Service\n           Aldermaston, Reading, Berkshire RG7 4PN\n        -- Unknown technical note number (sorry, not listed here)\n        -- General Results: nearest neighbor held its own with respect to the\n              rule-based system\n \n 4. Relevant Information:n\n       Vina conducted a comparison test of her rule-based system, BEAGLE, the\n       nearest-neighbor algorithm, and discriminant analysis.  BEAGLE is \n       a product available through VRS Consulting, Inc.; 4676 Admiralty Way,\n       Suite 206; Marina Del Ray, CA 90292 (213) 827-7890 and FAX: -3189.\n       In determining whether the glass was a type of \"float\" glass or not,\n       the following results were obtained (# incorrect answers):\n \n              Type of Sample                            Beagle   NN    DA\n              Windows that were float processed (87)     10      12    21\n              Windows that were not:            (76)     19      16    22\n \n       The study of classification of types of glass was motivated by \n       criminological investigation.  At the scene of the crime, the glass left\n       can be used as evidence...if it is correctly identified!\n \n 5. Number of Instances: 214\n \n 6. Number of Attributes: 10 (including an Id#) plus the class attribute\n    -- all attributes are continuously valued\n \n 7. Attribute Information:\n    1. Id number: 1 to 214\n    2. RI: refractive index\n    3. Na: Sodium (unit measurement: weight percent in corresponding oxide, as \n                   are attributes 4-10)\n    4. Mg: Magnesium\n    5. Al: Aluminum\n    6. Si: Silicon\n    7. K: Potassium\n    8. Ca: Calcium\n    9. Ba: Barium\n   10. Fe: Iron\n   11. Type of glass: (class attribute)\n       -- 1 building_windows_float_processed\n       -- 2 building_windows_non_float_processed\n       -- 3 vehicle_windows_float_processed\n       -- 4 vehicle_windows_non_float_processed (none in this database)\n       -- 5 containers\n       -- 6 tableware\n       -- 7 headlamps\n \n 8. Missing Attribute Values: None\n \n Summary Statistics:\n Attribute:   Min     Max      Mean     SD      Correlation with class\n  2. RI:       1.5112  1.5339   1.5184  0.0030  -0.1642\n  3. Na:      10.73   17.38    13.4079  0.8166   0.5030\n  4. Mg:       0       4.49     2.6845  1.4424  -0.7447\n  5. Al:       0.29    3.5      1.4449  0.4993   0.5988\n  6. Si:      69.81   75.41    72.6509  0.7745   0.1515\n  7. K:        0       6.21     0.4971  0.6522  -0.0100\n  8. Ca:       5.43   16.19     8.9570  1.4232   0.0007\n  9. Ba:       0       3.15     0.1750  0.4972   0.5751\n 10. Fe:       0       0.51     0.0570  0.0974  -0.1879\n \n 9. Class Distribution: (out of 214 total instances)\n     -- 163 Window glass (building windows and vehicle windows)\n        -- 87 float processed  \n           -- 70 building windows\n           -- 17 vehicle windows\n        -- 76 non-float processed\n           -- 76 building windows\n           -- 0 vehicle windows\n     -- 51 Non-window glass\n        -- 13 containers\n        -- 9 tableware\n        -- 29 headlamps\n \n \n \n\n\n\n\n Relabeled values in attribute 'Type'\n    From: '1'                     To: 'build wind float'    \n    From: '2'                     To: 'build wind non-float'\n    From: '3'                     To: 'vehic wind float'    \n    From: '4'                     To: 'vehic wind non-float'\n    From: '5'                     To: containers          \n    From: '6'                     To: tableware           \n    From: '7'                     To: headlamps", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_41_glass_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Type"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-41-glass"}, "LL0_42_soybean": {"pipeline": {"_id": "9aeab36c-72e2-4d31-9f7d-751b52200573", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 194, "max_depth": 7, "learning_rate": 0.6931016567188455, "gamma": 0.2649340161641991, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9aeab36c-72e2-4d31-9f7d-751b52200573", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9583783029998123, "rank": 0.04162169700022247, "metric": "f1Macro", "ts": "2018-10-25T01:08:33.538000", "dataset": "LL0_42_soybean_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_42_soybean", "about": {"problemID": "LL0_42_soybean_problem", "problemName": "LL0_42_soybean_problem", "problemDescription": "**Author**: R.S. Michalski and R.L. Chilausky (Donors: Ming Tan & Jeff Schlimmer)  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Soybean+(Large)) - 1988  \n**Please cite**: R.S. Michalski and R.L. Chilausky \"Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis\", International Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980.  \n\n### Description\n\nLarge Soybean Database - This is the large soybean database from the UCI repository, with its training and test database combined into a single file. \n\n### Sources\n\n(a) Origin \n\nR.S. Michalski and R.L. Chilausky \n\"Learning by Being Told and Learning from Examples: An Experimental Comparison of the Two Methods of Knowledge Acquisition in the Context of Developing an Expert System for Soybean Disease Diagnosis\", \nInternational Journal of Policy Analysis and Information Systems, Vol. 4, No. 2, 1980. \n\n(b) Donor\n\nMing Tan & Jeff Schlimmer (Jeff.Schlimmer%cs.cmu.edu)\n\n### Data Set Information\n\nThere are 19 classes, only the first 15 of which have been used in prior work. The folklore seems to be that the last four classes are unjustified by the data since they have so few examples. There are 35 categorical attributes, some nominal and some ordered. The value 'dna' means does not apply. The values for attributes are encoded numerically, with the first value encoded as \"0,'' the second as \"1,'' and so forth. An unknown value is encoded as \"?''.\n\n### Attribute Information\n\n1. date: april,may,june,july,august,september,october,?. \n2. plant-stand: normal,lt-normal,?. \n3. precip: lt-norm,norm,gt-norm,?. \n4. temp: lt-norm,norm,gt-norm,?. \n5. hail: yes,no,?. \n6. crop-hist: diff-lst-year,same-lst-yr,same-lst-two-yrs, \nsame-lst-sev-yrs,?. \n7. area-damaged: scattered,low-areas,upper-areas,whole-field,?. \n8. severity: minor,pot-severe,severe,?. \n9. seed-tmt: none,fungicide,other,?. \n10. germination: 90-100%,80-89%,lt-80%,?. \n11. plant-growth: norm,abnorm,?. \n12. leaves: norm,abnorm. \n13. leafspots-halo: absent,yellow-halos,no-yellow-halos,?. \n14. leafspots-marg: w-s-marg,no-w-s-marg,dna,?. \n15. leafspot-size: lt-1/8,gt-1/8,dna,?. \n16. leaf-shread: absent,present,?. \n17. leaf-malf: absent,present,?. \n18. leaf-mild: absent,upper-surf,lower-surf,?. \n19. stem: norm,abnorm,?. \n20. lodging: yes,no,?. \n21. stem-cankers: absent,below-soil,above-soil,above-sec-nde,?. \n22. canker-lesion: dna,brown,dk-brown-blk,tan,?. \n23. fruiting-bodies: absent,present,?. \n24. external decay: absent,firm-and-dry,watery,?. \n25. mycelium: absent,present,?. \n26. int-discolor: none,brown,black,?. \n27. sclerotia: absent,present,?. \n28. fruit-pods: norm,diseased,few-present,dna,?. \n29. fruit spots: absent,colored,brown-w/blk-specks,distort,dna,?. \n30. seed: norm,abnorm,?. \n31. mold-growth: absent,present,?. \n32. seed-discolor: absent,present,?. \n33. seed-size: norm,lt-norm,?. \n34. shriveling: absent,present,?. \n35. roots: norm,rotted,galls-cysts,?.\n\n### Classes \n\n-- 19 Classes = {diaporthe-stem-canker, charcoal-rot, rhizoctonia-root-rot, phytophthora-rot, brown-stem-rot, powdery-mildew, downy-mildew, brown-spot, bacterial-blight, bacterial-pustule, purple-seed-stain, anthracnose, phyllosticta-leaf-spot, alternarialeaf-spot, frog-eye-leaf-spot, diaporthe-pod-&-stem-blight, cyst-nematode, 2-4-d-injury, herbicide-injury} \n\n### Revelant papers\n\nTan, M., & Eshelman, L. (1988). Using weighted networks to represent classification knowledge in noisy domains. Proceedings of the Fifth International Conference on Machine Learning (pp. 121-134). Ann Arbor, Michigan: Morgan Kaufmann. \n\nFisher,D.H. & Schlimmer,J.C. (1988). Concept Simplification and Predictive Accuracy. Proceedings of the Fifth International Conference on Machine Learning (pp. 22-28). Ann Arbor, Michigan: Morgan Kaufmann.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_42_soybean_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 36, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-42-soybean"}, "LL0_4340_engine1": {"pipeline": {"_id": "0076db8d-b37f-4f16-a77e-71a666d82db3", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 640, "max_depth": 10, "learning_rate": 0.9890512777247497, "gamma": 0.4081667763650756, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "0076db8d-b37f-4f16-a77e-71a666d82db3", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8832073573872374, "rank": 0.11679264261316162, "metric": "f1Macro", "ts": "2018-10-25T01:55:52.642000", "dataset": "LL0_4340_engine1_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_4340_engine1", "about": {"problemID": "LL0_4340_engine1_problem", "problemName": "LL0_4340_engine1_problem", "problemDescription": "simple engine data", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_4340_engine1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "Pump_Status"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-4340-engine1"}, "LL0_434_benzo32": {"pipeline": {"_id": "2d88d105-04de-4595-bbe5-0a2a0cb12313", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 10}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 96, "max_depth": 9, "learning_rate": 0.42387423846369743, "gamma": 0.10373680268984586, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "2d88d105-04de-4595-bbe5-0a2a0cb12313", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.04560813936528133, "rank": 0.04560813936597547, "metric": "meanSquaredError", "ts": "2018-10-24T20:14:58.161000", "dataset": "LL0_434_benzo32_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_434_benzo32", "about": {"problemID": "LL0_434_benzo32_problem", "problemName": "benzo32_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis is one of 41 drug design datasets. The datasets with 1143 features are formed using Adriana.Code software  (www.molecular-networks.com/software/adrianacode).\nThe molecules and outputs are taken from the original studies (see below). The other datasets are taken exactly from the original studies. \n\nThe last attribute in each file is the target.\n\nOriginal studies:\n\ncarbolenes\n\"B. D. Silverman and Daniel. E. Platt, J. Med. Chem. 1996, 39, 2129-2140\"\n\nmtp2\n\"Bergstrom, C. A. S.; Norinder, U.; Luthman, K.; Artursson, P. Molecular Descriptors Influencing Melting Point and Their Role in Classification of Solid Drugs. J. Chem. Inf. Comput. Sci.; (Article); 2003; 43(4); 1177-1185\"\n\nchang, cristalli, depreux, doherty, garrat2, garrat, heyl, krystek, lewis, penning, rosowsky, siddiqi, stevenson, strupcz, svensson, thompson, tsutumi, uejling, yokoyama1, yokoyama2\t\n\"David E Patterson, Richard D Cramer, Allan M Ferguson, Robert D Clark, Laurence W Weinberger. Neighbourhood Behaviour: A Useful Concept for Validation of \"\"Molecular Diversity\"\" Descriptors. J. Med. Chem. 1996 (39) 3049 - 3059.\"\n\nmtp\n\"Karthikeyan, M.; Glen, R.C.; Bender, A. General melting point prediction based on a diverse compound dataset and artificial neural networks. J. Chem. Inf. Model.; 2005; 45(3); 581-590\"\n\nbenzo32\n\"Harrison,P.W. and Barlin,G.B. and Davies,L.P. and Ireland,S.J. and Matyus,P. and Wong,M.G., Syntheses, pharmacological evaluation and molecular modelling of substituted 6-alkoxyimidazo[1,2-b]pyridazines as new ligands for the benzodiazepine receptor, European Journal of Medicinal Chemistry, (31), 1996, 651-662\"\n\nPHENETYL1\t\n\"H. Kubinyi (Ed.): \"\"QSAR: Hansch Analysis and Related Approaches\"\", VCH, Weinhein (Ger), 1993, pp.57-68\"\n\npah\t\n\"Todeschini, R.; Gramatica, P.; Marengo, E.; Provenzani, R. Weighted Holistic  Invariant Molecular Descriptors. Part 2. Theory Development and Applications on Modeling Physico-Chemical Properties of PolyAromatic Hydrocarbons (PAH). Chemom. Intell. Lab. Syst. 1995, 27, 221-229.\"\n\npdgfr\t\n\"R. Guha and P. Jurs. The Development of Linear, Ensemble and Non-linear Models for the Prediction and Interpretation of the Biological Activity of a Set of PDGFR Inhibitors. J. Chem. Inf. Comput. Sci. 2004, 44 (6), 2179-2189\"\n\nPhen\t\n\"Cammarata, A. Interrelationship of the Regression Models Used for Structure-Activity Analyses. J. Med. Chem. 1972, 15, 573-577\"\n\ntopo_2_1, yprop_4_1\t\n\"Jun Feng et al, Predictive Toxicology: Benchmarking Molecular Descriptors and Statistical Methods, J. Chem. Inf Comput. Sci., 2003 (43) 1463-1470\"\n\nqsabr1, qsabr2\t\n\"Damborsky, J., Schultz, T.W., Comparison of the QSAR models for toxicity and biodegradability of anilines and phenols, Chemosphere 34: 429-446, 1997\"\n\nqsartox\t\n\"Blaha, L., Damborsky, J., Nemec, M., QSAR for acute toxicity of saturated and unsaturated halogenated aliphatic compounds, Chemosphere 36: 1345-1365, 1998\"\n\nqsbr_rw1\t\n\"Damborsky, J. et al., Structure-biodegradability relationships for chlorinated dibenzo-p-dioxins and dibenzofurans, In: Wittich, R.-M., Biodegradation of dioxins and furans, R.G. Landes Company, Austin, 1998\"\n\nqsbr_y2\t\n\"Damborsky, J. et al., A mechanistic approach to deriving QSBR- A case study: dehalogenation of haloaliphatic compounds, In: Peijnenburg, W.J.G.M., Damborsky, J., Biodegradability Prediction, Kluwer Academic Publishers\"\n\nqsbralks\t\n\"Damborsky, J. et al., Mechanism-based Quantitative Structure-Biodegradability Relationships for hydrolytic dehalogenation of chloro- and bromo-alkenes, Quantitative Structure-Activity Relationships 17: 450-458, 1998\"\n\nqsfrdhla\t\n\"Damborsky, J., Quantitative structure-function relationships of the single-point mutants of haloalkane dehalogenase: A multivariate approach, Qunatitative Structure-Activity Relationships 16: 126-135, 1997\"\n\nqsfsr1\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsfsr2\t\n\"Damborsky, J., Quantitative structure-function and structure-stability relationships of purposely modified proteins, Protein Engineering 11: 21-30, 1998\"\n\nqsprcmpx\t\n\"Cajan, M. et al., Stability of Aromatic Amides with Bromide Anion: Quantitative Structure-Property Relationships, Journal of Chemical Information and Computer Sciences, in press, 2000\"\n\nselwood\t\n\"Selwood, D. L.; Livingstone, D. J.; Comley, J. C.; O'Dowd, A. B.; Hudson, A. T.; Jackson, P.; Jandu, K. S.; Rose, V. S.; Stables, J. N. Structure-Activity Relationships of Antifilarial Antimycin Analogues: A Multivariate Pattern Recognition Study J. Med. Chem., 1990, 33, 136-142\"", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_434_benzo32_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "oz33"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-434-benzo32"}, "LL0_43_haberman": {"pipeline": {"_id": "3afc378e-8e72-494c-907c-68c68bb7257b", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 4}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 1, "min_samples_split": 0.1849465092612003, "min_samples_leaf": 0.05522629133492704, "n_estimators": 23, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "3afc378e-8e72-494c-907c-68c68bb7257b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7329963237318716, "rank": 0.2670036762684222, "metric": "f1Macro", "ts": "2018-10-25T04:39:38.050000", "dataset": "LL0_43_haberman_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_43_haberman", "about": {"problemID": "LL0_43_haberman_problem", "problemName": "LL0_43_haberman_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Haberman's Survival Data\n \n 2. Sources:\n    (a) Donor:   Tjen-Sien Lim (limt@stat.wisc.edu)\n    (b) Date:    March 4, 1999\n \n 3. Past Usage:\n    1. Haberman, S. J. (1976). Generalized Residuals for Log-Linear\n       Models, Proceedings of the 9th International Biometrics\n       Conference, Boston, pp. 104-122.\n    2. Landwehr, J. M., Pregibon, D., and Shoemaker, A. C. (1984),\n       Graphical Models for Assessing Logistic Regression Models (with\n       discussion), Journal of the American Statistical Association 79:\n       61-83.\n    3. Lo, W.-D. (1993). Logistic Regression Trees, PhD thesis,\n       Department of Statistics, University of Wisconsin, Madison, WI.\n \n 4. Relevant Information:\n    The dataset contains cases from a study that was conducted between\n    1958 and 1970 at the University of Chicago's Billings Hospital on\n    the survival of patients who had undergone surgery for breast\n    cancer.\n \n 5. Number of Instances: 306\n \n 6. Number of Attributes: 4 (including the class attribute)\n \n 7. Attribute Information:\n    1. Age of patient at time of operation (numerical)\n    2. Patient's year of operation (year - 1900, numerical)\n    3. Number of positive axillary nodes detected (numerical)\n    4. Survival status (class attribute)\n          1 = the patient survived 5 years or longer\n          2 = the patient died within 5 year\n \n 8. Missing Attribute Values: None\n\n Information about the dataset\n CLASSTYPE: nominal\n CLASSINDEX: last", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_43_haberman_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Survival_status"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-43-haberman"}, "LL0_446_prnn_crabs": {"pipeline": {"_id": "8d7cc676-947d-4caf-af41-ca1c62405c38", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "8d7cc676-947d-4caf-af41-ca1c62405c38", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9197478544846966, "rank": 0.08025214551612406, "metric": "f1Macro", "ts": "2018-10-31T04:08:59.697000", "dataset": "LL0_446_prnn_crabs_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_446_prnn_crabs", "about": {"problemID": "LL0_446_prnn_crabs_problem", "problemName": "prnn_crabs_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDatasets for `Pattern Recognition and Neural Networks' by B.D. Ripley\n=====================================================================\n\nCambridge University Press (1996)  ISBN  0-521-46086-7\n\nThe background to the datasets is described in section 1.4; this file\nrelates the computer-readable files to that description.\n\n\n\nCushing's syndrome\n------------------\n\nData from Aitchison & Dunsmore (1975, Tables 11.1-3).\n\nData file Cushings.dat has four columns,\n\nLabel of the patient\nTetrhydrocortisone  (mg/24hr)\nPregnanetriol  (mg/24hr)\nType\n\nThe type of the last six patients (u1 to u6) should be\nregarded as unknown.  (The code `o' indicates `other').\n\n\n\nsynthetic two-class problem\n---------------------------\n\nData from Ripley (1994a).\n\nThis has two real-valued co-ordinates (xs and ys) and a class (xc)\nwhich is 0 or 1.\n\nData file  synth.tr   has 250 rows of the training set\nsynth.te   has 1000 rows of the test set  (not used here)\n\n\n\nviruses\n-------\n\nThis is a dataset on 61 viruses with rod-shaped particles affecting\nvarious crops (tobacco, tomato, cucumber and others) described by\n{Fauquet et al. (1988) and analysed by Eslava-G\\'omez (1989).  There\nare 18 measurements on each virus,  the number of amino acid residues\nper molecule of coat protein.\n\nData file  viruses.dat  has 61 rows of 18 counts\nvirus3.dat   has 38 rows corresponding to the distinct\nTobamoviruses.\n\nThe whole dataset is in order Hordeviruses (3), Tobraviruses (6),\nTobamoviruses (39) and `furoviruses' (13).\n\n\n\nLeptograpsus crabs\n------------------\n\nData from Campbell & Mahon (1974) on the morphology of rock crabs of\ngenus Leptograpsus.\n\nThere are 50 specimens of each sex of each of two colour forms.\n\nData file  crabs.dat has rows\n\nsp\t`species', coded B (blue form) or O (orange form)\nsex\tcoded M or F\nindex\twithin each group of 50\nFL\tfrontal lip of carapace (mm)\nRW\trear width of carapace (mm)\nCL\tlength along the midline of carapace (mm)\nCW\tmaximum width of carapace (mm)\nBD\tbody depth (mm)\n\n\n\nForensic glass\n--------------\n\nThis example comes from forensic testing of glass collected by\nB. German on 214 fragments of glass.  It is also contained in the\nUCI machine-learning database collection (Murphy & Aha, 1995).\n\nData file fglass.dat has 214 rows with data for a single glass\nfragment.\n\nRI\trefractive index\nNa\t% weight of sodium oxide(s)\nMg\t% weight of magnesium oxide(s)\nAl\t% weight of aluminium oxide(s)\nSi\t% weight of silicon oxide(s)\nK\t% weight of potassium oxide(s)\nCa\t% weight of calcium oxide(s)\nBa\t% weight of barium oxide(s)\nFe\t% weight of iron oxide(s)\ntype\tcoded 1 to 7\n\nThe type codes are:\n\n1 (WinF) window float glass\n2 (WinNF) window non-float glass\n3 (Veh) vehicle glass\n5 (Con)  containers\n6 (Tabl) tableware\n7 (Head) vehicle headlamp glass\n\nThe ten groups used for the cross-validation experiments (I believe)\nare listed as row numbers in the file fglass.grp,\n\n\n\nDiabetes in Pima Indians\n------------------------\n\nA population of women who were at least 21 years old, of Pima Indian heritage\nand living near Phoenix, Arizona,  was tested for diabetes\naccording to World Health Organization criteria.  The data\nwere collected by the US National Institute of Diabetes and Digestive and\nKidney Diseases (Smith et al, 1988). This example is also contained in the\nUCI machine-learning database collection (Murphy & Aha, 1995).\n\nThe data files have rows containing\n\nnpreg \tnumber of pregnancies\nglu \tplasma glucose concentration in an oral glucose tolerance test\nbp \tdiastolic blood pressure (mm Hg)\nskin \ttriceps skin fold thickness (mm)\nins\tserum insulin (micro U/ml)\nbmi \tbody mass index (weight in kg/(height in m)^2)\nped \tdiabetes pedigree function\nage \tin years\ntype\tNo / Yes\n\nData file pima.tr   has 200 rows of complete training data.\npima.te   has 332 rows of complete test data.\npima.tr2  has the 200 rows of pima.tr plus 100 incomplete rows.\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: 1", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_446_prnn_crabs_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "sp"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-446-prnn-crabs"}, "LL0_44_spambase": {"pipeline": {"_id": "85b70b3a-8e17-472b-a395-7b919d23bb98", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 892, "max_depth": 6, "learning_rate": 0.07378613558273373, "gamma": 0.6227460657948826, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "85b70b3a-8e17-472b-a395-7b919d23bb98", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9546811991423807, "rank": 0.045318800857798686, "metric": "f1Macro", "ts": "2018-10-31T04:59:01.425000", "dataset": "LL0_44_spambase_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_44_spambase", "about": {"problemID": "LL0_44_spambase_problem", "problemName": "LL0_44_spambase_problem", "problemDescription": "**Author**: Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt    \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/spambase)   \n**Please cite**: [UCI](https://archive.ics.uci.edu/ml/citation_policy.html)\n\nSPAM E-mail Database  \nThe \"spam\" concept is diverse: advertisements for products/websites, make money fast schemes, chain letters, pornography... Our collection of spam e-mails came from our postmaster and individuals who had filed spam.  Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam.  These are useful when constructing a personalized spam filter.  One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\n \nFor background on spam:  \nCranor, Lorrie F., LaMacchia, Brian A.  Spam! Communications of the ACM, 41(8):74-83, 1998.  \n\n### Attribute Information:  \nThe last column denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occurring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters.  \n\nFor the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes:  \n\n48 continuous real [0,100] attributes of type  \nword_freq_WORD = percentage of words in the e-mail that match WORD,  i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail.  A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\n \n6 continuous real [0,100] attributes of type char_freq_CHAR = percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n \n1 continuous real [1,...] attribute of type capital_run_length_average\n = average length of uninterrupted sequences of capital letters\n \n1 continuous integer [1,...] attribute of type capital_run_length_longest\n = length of longest uninterrupted sequence of capital letters\n \n1 continuous integer [1,...] attribute of type capital_run_length_total\n = sum of length of uninterrupted sequences of capital letters\n = total number of capital letters in the e-mail\n \n1 nominal {0,1} class attribute of type spam\n = denotes whether the e-mail was considered spam (1) or not (0), \n i.e. unsolicited commercial e-mail.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_44_spambase_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 58, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-44-spambase"}, "LL0_450_analcatdata_lawsuit": {"pipeline": {"_id": "b6266ddb-fa29-4d98-a113-03d160528ae7", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 616, "max_depth": 7, "learning_rate": 0.3920697428605925, "gamma": 0.19860119948394672, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "b6266ddb-fa29-4d98-a113-03d160528ae7", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9433324071501342, "rank": 0.05666759284986728, "metric": "f1Macro", "ts": "2018-10-24T23:55:51.148000", "dataset": "LL0_450_analcatdata_lawsuit_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_450_analcatdata_lawsuit", "about": {"problemID": "LL0_450_analcatdata_lawsuit_problem", "problemName": "analcatdata_lawsuit_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_450_analcatdata_lawsuit_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Laid.off"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-450-analcatdata-lawsuit"}, "LL0_451_irish": {"pipeline": {"_id": "2a0bc4aa-8b85-42e6-b12d-fefe0fa570f2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 81}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 17, "min_samples_split": 0.06132496017580841, "min_samples_leaf": 0.0006052973540437402, "n_estimators": 178, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "2a0bc4aa-8b85-42e6-b12d-fefe0fa570f2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 3.3799359263215753e-15, "metric": "f1Macro", "ts": "2018-10-25T05:56:51.516000", "dataset": "LL0_451_irish_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_451_irish", "about": {"problemID": "LL0_451_irish_problem", "problemName": "LL0_451_irish_problem", "problemDescription": "**Author**: Vincent Greaney, Thomas Kelleghan (St. Patrick's College, Dublin)   \n**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/irish.ed) - 1984  \n**Please cite**: [StatLib](http://lib.stat.cmu.edu/datasets/)\n\n**Irish Educational Transitions Data**  \nData on educational transitions for a sample of 500 Irish schoolchildren aged 11 in 1967. The data were collected by Greaney and Kelleghan (1984), and reanalyzed by Raftery and Hout (1985, 1993). \n\n### Attribute information  \n\n* Sex: 1=male; 2=female.\n* DVRT (Drumcondra Verbal Reasoning Test Score).\n* Educational level attained\n* Leaving Certificate. 1 if Leaving Certificate not taken; 2 if taken.\n* Prestige score for father's occupation (calculated by Raftery and Hout, 1985).\n* Type of school: 1=secondary; 2=vocational; 9=primary terminal leaver.\n\n### Relevant papers  \n\nGreaney, V. and Kelleghan, T. (1984). Equality of Opportunity in Irish\nSchools. Dublin: Educational Company.\n\nKass, R.E. and Raftery, A.E. (1993). Bayes factors and model uncertainty.\nTechnical Report no. 254, Department of Statistics, University of Washington.\nRevised version to appear in Journal of the American Statistical\nAssociation.\n\nRaftery, A.E. (1988). Approximate Bayes factors for generalized linear models.\nTechnical Report no. 121, Department of Statistics, University of Washington.\n\nRaftery, A.E. and Hout, M. (1985). Does Irish education approach the\nmeritocratic ideal? A logistic analysis.\nEconomic and Social Review, 16, 115-140.\n\nRaftery, A.E. and Hout, M. (1993). Maximally maintained inequality:\nExpansion, reform and opportunity in Irish schools.\nSociology of Education, 66, 41-62.\n\n\n### Ownership Statement  \nThis data belongs to Vincent Greaney and Thomas Kelleghan, Educational Research Centre, St. Patrick's College, Drumcondra, Dublin 9, Ireland, who retain the copyright.\n\nIn the form given here, it may be used solely as an example for research on the development of statistical methods. For any other use of the data, permission must be obtained from the owners.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_451_irish_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Leaving_Certificate"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-451-irish"}, "LL0_452_analcatdata_broadwaymult": {"pipeline": {"_id": "627be352-220a-47af-adf7-1159927bd69d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 4}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 917, "max_depth": 4, "learning_rate": 0.567085792344681, "gamma": 0.5449895471675232, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "627be352-220a-47af-adf7-1159927bd69d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.41326195972034957, "rank": 0.5867380402802823, "metric": "f1Macro", "ts": "2018-10-25T00:57:24.768000", "dataset": "LL0_452_analcatdata_broadwaymult_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_452_analcatdata_broadwaymult", "about": {"problemID": "LL0_452_analcatdata_broadwaymult_problem", "problemName": "analcatdata_broadwaymult_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_452_analcatdata_broadwaymult_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Count"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-452-analcatdata-broadwaymult"}, "LL0_4541_diabetes130us": {"pipeline": {"_id": "89e1e2e2-6a63-4af8-8783-eb1c8ceaee07", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 48}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 382, "max_depth": 4, "learning_rate": 0.388097905111378, "gamma": 0.7755648905283664, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "89e1e2e2-6a63-4af8-8783-eb1c8ceaee07", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.4447335729237798, "rank": 0.5552664270765854, "metric": "f1Macro", "ts": "2018-10-25T01:40:22.303000", "dataset": "LL0_4541_diabetes130us_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_4541_diabetes130us", "about": {"problemID": "LL0_4541_diabetes130us_problem", "problemName": "LL0_4541_diabetes130us_problem", "problemDescription": "**Author**: Attila Reiss\",\"Department Augmented Vision\",\"DFKI\",\"Germany\",\"attila.reiss '@' dfki.de  Date: August 2012.  \n**Source**: UCI  \n**Please cite**: Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, &ldquo;Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,&rdquo; BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.  \n\nAbstract: This data has been prepared to analyze factors related to readmission as well as other outcomes pertaining to patients with diabetes.\nSource:\n\nThe data are submitted on behalf of the Center for Clinical and Translational Research, Virginia Commonwealth University, a recipient of NIH CTSA grant UL1 TR00058 and a recipient of the CERNER data. John Clore (jclore '@' vcu.edu), Krzysztof J. Cios (kcios '@' vcu.edu), Jon DeShazo (jpdeshazo '@' vcu.edu), and Beata Strack (strackb '@' vcu.edu). This data is a de-identified abstract of the Health Facts database (Cerner Corporation, Kansas City, MO).\n\n\nData Set Information:\n\nThe dataset represents 10 years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. It includes over 50 features representing patient and hospital outcomes. Information was extracted from the database for encounters that satisfied the following criteria.\n(1) It is an inpatient encounter (a hospital admission).\n(2) It is a diabetic encounter, that is, one during which any kind of diabetes was entered to the system as a diagnosis.\n(3) The length of stay was at least 1 day and at most 14 days.\n(4) Laboratory tests were performed during the encounter.\n(5) Medications were administered during the encounter.\nThe data contains such attributes as patient number, race, gender, age, admission type, time in hospital, medical specialty of admitting physician, number of lab test performed, HbA1c test result, diagnosis, number of medication, diabetic medications, number of outpatient, inpatient, and emergency visits in the year before the hospitalization, etc.\n\n\nAttribute Information:\n\nDetailed description of all the atrributes is provided in Table 1 Beata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, &ldquo;Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,&rdquo; BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.\n\n[Web Link]\n\n\nRelevant Papers:\n\nBeata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, &ldquo;Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,&rdquo; BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.\n\n[Web Link]\n\n\n\nCitation Request:\n\nPlease cite:\nBeata Strack, Jonathan P. DeShazo, Chris Gennings, Juan L. Olmo, Sebastian Ventura, Krzysztof J. Cios, and John N. Clore, &ldquo;Impact of HbA1c Measurement on Hospital Readmission Rates: Analysis of 70,000 Clinical Database Patient Records,&rdquo; BioMed Research International, vol. 2014, Article ID 781670, 11 pages, 2014.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_4541_diabetes130us_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 50, "colName": "readmitted"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-4541-diabetes130us"}, "LL0_454_analcatdata_halloffame": {"pipeline": {"_id": "eae1f8ab-90d7-45e5-90eb-d7af11da2ba4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 38}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 345, "max_depth": 9, "learning_rate": 0.5231687787806744, "gamma": 0.17088956334473349, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "eae1f8ab-90d7-45e5-90eb-d7af11da2ba4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6966586290830706, "rank": 0.3033413709170297, "metric": "f1Macro", "ts": "2018-10-25T01:47:13.164000", "dataset": "LL0_454_analcatdata_halloffame_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_454_analcatdata_halloffame", "about": {"problemID": "LL0_454_analcatdata_halloffame_problem", "problemName": "analcatdata_halloffame_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_454_analcatdata_halloffame_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 18, "colName": "Hall_of_Fame"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-454-analcatdata-halloffame"}, "LL0_455_cars": {"pipeline": {"_id": "4bbbd27e-b0cc-4d71-88c6-583ee6e7d7ce", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 33}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 550, "max_depth": 8, "learning_rate": 0.9849610794822495, "gamma": 0.4511431035545077, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "4bbbd27e-b0cc-4d71-88c6-583ee6e7d7ce", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8097491578347789, "rank": 0.19025084216527297, "metric": "f1Macro", "ts": "2018-10-25T00:38:33.045000", "dataset": "LL0_455_cars_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_455_cars", "about": {"problemID": "LL0_455_cars_problem", "problemName": "LL0_455_cars_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe Committee on Statistical Graphics of the American Statistical\nAssociation (ASA) invites you to participate in its Second (1983)\nExposition of Statistical Graphics Technology. The purposes of the\nExposition are (l) to provide a forum in which users and providers of\nstatistical graphics technology can exchange information and ideas and\n(2) to expose those members of the ASA community who are less familiar\nwith statistical graphics to its capabilities and potential benefits\nto them. The Exposition wil1 be held in conjunction with the Annual\nMeetings in Toronto, August 15-18, 1983 and is tentatively scheduled\nfor the afternoon of Wednesday, August 17.\n\nSeven providers of statistical graphics technology participated in the\nl982 Exposition. By all accounts, the Exposition was well received by\nthe ASA community and was a worthwhile experience for the\nparticipants. We hope to have those seven involved again this year,\nalong with as many new participants as we can muster. The 1982\nExposition was summarized in a paper to appear in the Proceeding of\nthe Statistical Computing Section. A copy of that paper is enclosed\nfor your information.\n\nThe basic format of the 1983 Exposition will be similar to that of\n1982. However, based upon comments received and experience gained,\nthere are some changes. The basic structure, intended to be simpler\nand more flexible than last year, is as follows:\n\nA fixed data set is to be analyzed. This data set is a version of the\nCRCARS data set of\n\nDonoho, David and Ramos, Ernesto (1982), ``PRIMDATA:\nData Sets for Use With PRIM-H'' (DRAFT).\n\nBecause of the Committee's limited (zero) budget for the Exposition,\nwe are forced to provide the data in hardcopy form only (enclosed).\n(Sorry!)\n\nThere are 406 observations on the following 8 variables: MPG (miles\nper gallon), # cylinders, engine displacement (cu. inches), horsepower,\nvehicle weight (lbs.), time to accelerate from O to 60 mph (sec.),\nmodel year (modulo 100), and origin of car (1. American, 2. European,\n3. Japanese). These data appear on seven pages. Also provided are the\ncar labels (types) in the same order as the 8 variables on seven\nseparate pages. Missing data values are marked by series of question\nmarks.\n\nYou are asked to analyze these data using your statistical graphics\nsoftware. Your objective should be to achieve graphical displays which\nwill be meaningful to the viewers and highlight relevant aspects of\nthe data. If you can best achieve this using simple graphical formats,\nfine. If you choose to illustrate some of the more sophisticated\ncapabilities of your software and can do so without losing relevancy\nto the data, that is fine, too. This year, there will be no Committee\ncommentary on the individual presentations, so you are not competing\nwith other presenters. The role of each presenter is to do his/her\nbest job of presenting their statistical graphics technology to the\nviewers.\n\nEach participant will be provided with a 6'(long) by 4'(tall)\nposterboard on which to display the results of their analyses. This is\nthe same format as last year. You are encouraged to remain by your\npresentation during the Exposition to answer viewers' questions. Three\ncopies of your presentation must be submitted to me by July 1. Movie\nor slide show presentations cannot be accommodated (sorry). The\nCommittee will prepare its own poster presentation which will orient\nthe viewers to the data and the purposes of the Exposition.\n\nThe ASA has asked us to remind all participants that the Exposition is\nintended for educational and scientific purposes and is not a\nmarketing activity. Even though last year's participants did an\nexcellent job of maintaining that distinction, a cautionary note at\nthis point is appropriate.\n\nThose of us who were involved with the 1982 Exposition found it\nworthwhile and fun to do. We would very much like to have you\nparticipate this year. For planning purposes, please RSVP (to me, in\nwriting please) by April 15 as to whether you plan to accept the\nCommittee's invitation.\n\nIf you have any questions about the Exposition, please call me on\n(301/763-5350). If you have specific questions about the data, or the\nanalysis, please call Karen Kafadar on (301/921-3651). If you cannot\nparticipate but know of another person or group in your organization\nwho can, please pass this invitation along to them.\n\nSincerely,\n\n\n\nLAWRENCE H. COX\nStatistical Research Division\nBureau of the Census\nRoom 3524-3\nWashington, DC 20233\n\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_455_cars_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "origin"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-455-cars"}, "LL0_458_analcatdata_authorship": {"pipeline": {"_id": "6f484fe9-01d5-43ef-bd91-0dd391f471dc", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 25}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 14, "min_samples_split": 0.062950232451738, "min_samples_leaf": 0.007228122238088391, "n_estimators": 360, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "6f484fe9-01d5-43ef-bd91-0dd391f471dc", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9946771307785035, "rank": 0.005322869222112972, "metric": "f1Macro", "ts": "2018-10-25T06:25:17.689000", "dataset": "LL0_458_analcatdata_authorship_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_458_analcatdata_authorship", "about": {"problemID": "LL0_458_analcatdata_authorship_problem", "problemName": "analcatdata_authorship_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_458_analcatdata_authorship_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 71, "colName": "Author"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-458-analcatdata-authorship"}, "LL0_463_backache": {"pipeline": {"_id": "18031214-766e-4d19-a4ca-33ca74483c37", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 20, "min_samples_split": 0.17880585493887957, "min_samples_leaf": 0.126968404679476, "n_estimators": 50, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "18031214-766e-4d19-a4ca-33ca74483c37", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5723973727422005, "rank": 0.42760262725870496, "metric": "f1Macro", "ts": "2018-10-25T06:04:03.186000", "dataset": "LL0_463_backache_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_463_backache", "about": {"problemID": "LL0_463_backache_problem", "problemName": "backache_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData file:\nThis data from \"Problem-Solving\" on \"backache in pregnancy\"\nis in somewhat different\nformat from that listed in the book. Each integer is preceded by a space.\nThis makes it easier to read. Each line is split in two separated by an\nampersand. Each line also has a full stop (or period) at the end of each\nline which should be removed. If you have any queries, please contact me.\nChris Chatfield.\ncc@maths.bath.ac.uk\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_463_backache_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "col_33"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-463-backache"}, "LL0_464_prnn_synth": {"pipeline": {"_id": "54b58abb-5fbe-46b7-b748-38c7388d9420", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 19, "min_samples_split": 0.14619091231685796, "min_samples_leaf": 0.34317241593451275, "n_estimators": 406, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "54b58abb-5fbe-46b7-b748-38c7388d9420", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8396719137987212, "rank": 0.16032808620156355, "metric": "f1Macro", "ts": "2018-10-25T05:55:10.404000", "dataset": "LL0_464_prnn_synth_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_464_prnn_synth", "about": {"problemID": "LL0_464_prnn_synth_problem", "problemName": "prnn_synth_problem", "problemDescription": "**Author**: B.D. Ripley  \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDataset from `Pattern Recognition and Neural Networks' by B.D. Ripley. Cambridge University Press (1996)  ISBN  0-521-46086-7. The background to the datasets is described in section 1.4; this file relates the computer-readable files to that description.\n\n**synthetic two-class problem**\nData from Ripley (1994a).\n\nThis has two real-valued co-ordinates (xs and ys) and a class (xc)\nwhich is 0 or 1.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_464_prnn_synth_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "yc"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-464-prnn-synth"}, "LL0_469_analcatdata_dmft": {"pipeline": {"_id": "8f92c2d8-5e9c-4411-a72d-81a6e09c9f06", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 24}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 7, "min_samples_split": 0.25512388473450526, "min_samples_leaf": 0.2865986580077524, "n_estimators": 28, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "8f92c2d8-5e9c-4411-a72d-81a6e09c9f06", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.23943892204628026, "rank": 0.7605610779539503, "metric": "f1Macro", "ts": "2018-10-25T05:03:24.132000", "dataset": "LL0_469_analcatdata_dmft_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_469_analcatdata_dmft", "about": {"problemID": "LL0_469_analcatdata_dmft_problem", "problemName": "analcatdata_dmft_problem", "problemDescription": "**Author**: Unknown   \n**Source**: [Jeffrey S. Simonoff](http://people.stern.nyu.edu/jsimonof/AnalCatData/Data/) - 2003    \n**Please cite**: Jeffrey S. Simonoff, Analyzing Categorical Data, Springer-Verlag, 2003\n\nOne of the datasets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff. It contains data on the DMFT Index (Decayed, Missing, and Filled Teeth) before and after different prevention strategies. The prevention strategy is commonly used as the (categorical) target.\n\n### Attribute information  \n* DMFT.Begin and DMFT.End: DMFT index before and after the prevention strategy\n* Gender of the individual\n* Ethnicity of the individual", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_469_analcatdata_dmft_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Prevention"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-469-analcatdata-dmft"}, "LL0_475_analcatdata_germangss": {"pipeline": {"_id": "76133992-8d51-4e48-a8f6-af038f7a2cab", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 32}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 923, "max_depth": 4, "learning_rate": 0.6168783502473139, "gamma": 0.7506191531825029, "min_child_weight": 4}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "76133992-8d51-4e48-a8f6-af038f7a2cab", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.49367684546265317, "rank": 0.5063231545379729, "metric": "f1Macro", "ts": "2018-10-25T00:34:55.362000", "dataset": "LL0_475_analcatdata_germangss_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_475_analcatdata_germangss", "about": {"problemID": "LL0_475_analcatdata_germangss_problem", "problemName": "analcatdata_germangss_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: 1\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_475_analcatdata_germangss_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "Political_system"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-475-analcatdata-germangss"}, "LL0_478_collins": {"pipeline": {"_id": "67604895-8307-46f6-8bc4-42e3cf262ff4", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 34}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 148, "max_depth": 6, "learning_rate": 0.4517719901275682, "gamma": 0.9821760377010559, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "67604895-8307-46f6-8bc4-42e3cf262ff4", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 5.333687685962207e-16, "metric": "f1Macro", "ts": "2018-10-25T01:22:10.229000", "dataset": "LL0_478_collins_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_478_collins", "about": {"problemID": "LL0_478_collins_problem", "problemName": "LL0_478_collins_problem", "problemDescription": "**Author**: Jeff Collins  \n**Source**: StatLib  \n**Please cite**:   \n\n**Deactivated because this version only has half the data and has clear label leakage cause by 'Genre'. Use version 4 instead.**\n\nThe following are data used in an analysis of the Brown and Frown corpora for my doctoral dissertation titled ``Variations in Written English: Characterizing Authors' Rhetorical Language Choices Across Corpora of Published Texts\" (Completed at Carnegie Mellon Univ, 2003).  The source of the corpora was the ICAME CD-ROM  (get info at <http>).\n\nThe data were generated from the texts using tagging and visualization software, Docuscope.\n\nThe first row is the variable names. The genre of each text (assigned by the Brown corpus compilers) is in 'Genre' column and the corpus is listed in the 'corpus' column with 1=Brown and 2=Frown corpus.\n\nThe dataset may be freely used and distributed for non-commercial purposes.\n\nJeff Collins <jeff> 11 July 2003\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_478_collins_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 24, "colName": "Corp.Genre"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-478-collins"}, "LL0_481_biomed": {"pipeline": {"_id": "07aab4de-9156-4857-85aa-cc621f09dec2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 20}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 11, "min_samples_split": 0.009722643917254215, "min_samples_leaf": 0.002449446575428924, "n_estimators": 17, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "07aab4de-9156-4857-85aa-cc621f09dec2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9260919540229885, "rank": 0.07390804597777212, "metric": "f1Macro", "ts": "2018-10-25T04:48:01.836000", "dataset": "LL0_481_biomed_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_481_biomed", "about": {"problemID": "LL0_481_biomed_problem", "problemName": "biomed_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFebruary 23, 1982\n\nThe 1982 annual meetings of the American Statistical Association (ASA)\nwill be held August 16-19, 1982 in Cincinnati.  At that meeting, the ASA\nCommittee on Statistical Graphics plans to sponsor an \"Exposition of\nStatistical Graphics Technology.\"  The purpose of this activity is to\nmore fully inform the ASA membership about the capabilities and uses of\ncomputer graphcis in statistical work.   This letter is to invite you to\nparticipate in the Exposition.\n\nAttached is a set of biomedical data containing 209 observations (134\nfor \"normals\" and 75 for \"carriers\").  Each vendor of provider of\nstatistical graphics software participating in the Exposition is to\nanalyze these data using their software and to prepare tabular, graphical\nand text output illustrating the use of graphics in these analyses and\nsummarizing their conclusions.  The tabular and graphical materials must be\ndirect computer output from the statistical graphics software; the\ntextual descriptions and summaries need not be.  The total display space\navailable to each participant at the meeting will be a standard poster-\nboard (approximately 4' x 2 1/2').  All entries will be displayed in one\nlocation at the meetings, together with brief written commentary by\nthe committee summarizing the results of this activity.\n\nReference\n\nExposition of Statistical Graphics Technology,\nL. H. Cox, M. M. Johnson, K. Kafadar,\nASA Proc Stat. Comp Section, 1982, pp 55-56.\nEnclosures\n\n\nTHE DATA\n\nThe following data arose in a study to develop screening methods to\nidentify carriers of a rare genetic disorder. Four measurements m1,\nm2, m3, m4 were made on blood samples. One of these, m1, has been used\nbefore.\nBecause the disease is rare, there are only a few carriers of\nthe disease from whom data are available. The data come in two files,\none for normals and one for carriers of the disease. A description of\nthe files is provided. The data have been stripped of the names and\nother identifiers. Otherwise the data are as received by the analyst.\n\n\nPURPOSE OF THE ANALYSIS\n\nThe purpose of the analysis is to develop a screening procedure to\ndetect carriers and to describe its effectiveness.  Experts in the\nfield have noted that young people tend to have higher measurements.\nThe laboratory which prepared the measurements is worried that there\nmay be a systematic drift over time in their measurement process.\nThese effects should be considered in the analysis.  Can graphical\ndisplays show the differences between the distributions of carriers\nand normals?\n\n\nFILE DESCRIPTION\n\n\nColumn\tContent\n\n1\tObservation number (sequence number per patient)\nNote that there are several samples per patient\nfor some patients.\n2-8\tBlank\n9-12\tHospital identification number for blood sample\n13-18\tBlank\n19-20\tAge of patient\n21-26\tBlank\n27-32\tDate that blood sample was taken (mmddyy)\nNote that all day entries are 00.\n33-39\tBlank\n40-43\tml (measurement 1) sss.s\n44-50\tBlank\n51-54\tm2 (measurement 2) xxx.x Eight missing data points.\n55-61\tBlank\n62-65\tm3 (measurement 3) xxx.x\n66-72\tBlank\n73-75\tm4 (measurement 4) xxx Seven missing data points.\n\n\n\nInformation about the dataset\nCLASSTYPE: nominal\nCLASSINDEX: last", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_481_biomed_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-481-biomed"}, "LL0_482_arsenic_male_bladder": {"pipeline": {"_id": "ddf56154-1cd6-4d36-bd78-2a4a7908ace7", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 0}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 101, "max_depth": 9, "learning_rate": 0.03192911485917094, "gamma": 0.45575858306892636, "min_child_weight": 2}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "ddf56154-1cd6-4d36-bd78-2a4a7908ace7", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 19.951457370697803, "rank": 19.95145737069805, "metric": "meanSquaredError", "ts": "2018-10-24T21:46:09.356000", "dataset": "LL0_482_arsenic_male_bladder_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_482_arsenic_male_bladder", "about": {"problemID": "LL0_482_arsenic_male_bladder_problem", "problemName": "arsenic_male_bladder_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_482_arsenic_male_bladder_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "events"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-482-arsenic-male-bladder"}, "LL0_488_colleges_aaup": {"pipeline": {"_id": "98123aa6-7232-4c59-b992-e1caa243559d", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 106, "max_depth": 4, "learning_rate": 0.3066241547086772, "gamma": 0.7706899055305141, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "98123aa6-7232-4c59-b992-e1caa243559d", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7810611493263059, "rank": 0.21893885067392876, "metric": "f1Macro", "ts": "2018-10-25T00:40:07.913000", "dataset": "LL0_488_colleges_aaup_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_488_colleges_aaup", "about": {"problemID": "LL0_488_colleges_aaup_problem", "problemName": "LL0_488_colleges_aaup_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe AAUP dataset for the ASA Statistical Graphics Section's 1995\nData Analysis Exposition contains information on faculty salaries\nfor 1161 American colleges and universities.  The data may be\nobtained in either of two formats.\n\nAAUP.DATA contains the raw data in comma delimited fields with a\nsingle data line for each school. The order of variables is the\nsame as given below for the fixed column version, although the\nspacing varies for each school.\n\nAAUP2.DATA has the data arranged in fixed columns, with two data\nlines for each school and a maximum line length of 80 characters.\n\nThis dataset is taken from the March-April 1994 issue of Academe.\nThanks to Maryse Eymonerie, Consultant to AAUP, for assistance in\nsupplying the data.  Faculty salary data are for the 1993-94\nschool year. You may wish to consult a copy of the special issue\nof Academe for more detailed descriptions of the variables.\n\nData Revised: Wed Jan 18 1995\n\nVARIABLE DESCRIPTIONS (AAUP2.DAT)\nFixed column format with two data lines per school\n\nLine #1\n1 -  5   FICE (Federal ID number)\n7 - 37   College name\n38 - 39   State (postal code)\n40 - 43   Type  (I, IIA, or IIB)\n44 - 48   Average salary - full professors\n49 - 52   Average salary - associate professors\n53 - 56   Average salary - assistant professors\n57 - 60   Average salary - all ranks\n61 - 65   Average compensation - full professors\n66 - 69   Average compensation - associate professors\n70 - 73   Average compensation - assistant professors\n74 - 78   Average compensation - all ranks\n\nLine #2\n1 -  4   Number of full professors\n5 -  8   Number of associate professors\n9 - 12   Number of assistant professors\n13 - 16   Number of instructors\n17 - 21   Number of faculty - all ranks\n\nMissing values are denoted with *\nAll salary and compensation figures are yearly in $100's\n\n**************************************************************\nTo obtain the dataset from Statlib, send one of the single line\nmessages below to the address statlib@lib.stat.cmu.edu\n\nsend aaup.data from colleges\nor\nsend aaup2.data from colleges\n\n\nFor more information on the ASA Statistical Graphics Section's\n1995 Data Analysis Exposition send the message\n\nsend readme from colleges\n\n%%%%%%%%%%%%%%\nINFORMATION %\n%%%%%%%%%%%%%%\n\nWHAT'S WHAT AMONG AMERICAN COLLEGES AND UNIVERSITIES?\n\nThis is the subject of the 1995 Data Analysis Exposition\nsponsored by the Statistical Graphics Section of the American\nStatistical Association.  The purpose of the Exposition is to\nencourage statisticians to demonstrate techniques, especially\ngraphical, for analyzing data and displaying the results of an\nanalysis.  Individuals and groups will work with the same set of\ndata and present their analyses at a special session as part of\nthe annual Joint Statistical Meetings in Orlando, Florida on\nAugust 13th-17th, 1995.  The datasets for 1995 are drawn from two\nsources, U.S. News & World Report's Guide to Americas Best\nColleges and the AAUP (American Association of University\nProfessors) 1994 Salary Survey which appeared in the March-April\n1994 issue of Academe.\n\nThe U.S. News data contains information on tuition, room & board\ncosts, SAT or ACT scores, application/acceptance rates,\ngraduation rate, student/faculty ratio, spending per student, and\na number of other variables for 1300+ schools. The AAUP data\nincludes average salary, overall compensation, and number of\nfaculty broken down by full, associate, and assistant professor\nranks.\n\nThe raw data and documentation are contained in the files\ndescribed below.  To obtain any of these files send a message to\nstatlib@lib.stat.cmu.edu of the following form  (substituting the\nfile you want for XXXXX)\n\nsend XXXXX from colleges\n\nAvailable files\n\nusnews.doc      Documentation for the U.S. News data\nusnews.data     U.S. News data in comma delimited format\nusnews3.data    U.S. News data in fixed column format\n\naaup.doc        Documentation for the AAUP salary data\naaup.data       AAUP salary data in comma delimited format\naaup2.data      AAUP salary data in fixed column format\n\nTwo versions of each dataset are provided to accommodate users\nwith different software constraints.  The comma delimited\nversions (USNEWS.DATA and AAUP.DATA) contain information for each\ncollege on a separate line with values delimited by commas.  The\nfixed column versions (USNEWS3.DATA and AAUP2.DATA) use 2 or 3\ndata lines per school and a maximum line length of 80 characters.\n\nTo participate in the 1995 Data Analysis Exposition you must send\nan abstract form to the American Statistical Association by\nFebruary 1st, 1995.  Information is available from the ASA\nMeetings Department by e-mail (meetings@asa.mhs.compuserve.com),\nphone (703-684-1221), fax (703-684-2037), or surface mail (ASA,\n1429 Duke St., Alexandria, VA 22314).  Your initial abstract may\nbe fairly general since you may do the bulk of your analysis\nafter the February 1 deadline.\n\nYou may choose your own path to proceed in analyzing the data or\nuse some of the suggested questions below to get started.\n\n... How well can we model tuition using the other variables?\n... How might we cluster colleges into similar comparison groups?\n... How can we best display faculty salary structure?\n... Can we find a reasonable way to rank the schools?\n\nYou may work on your own or put together a team.  Show off the\ncapabilities of your favorite software package or use the data\nfor a class project and display your students results.  You may\nchoose to consider just a subset of schools or examine regional\npatterns.  The main point is to find innovative ways to display\nthe interesting features of the data.\n\nFurther questions about the 1995 Exposition can be directed to\nRobin Lock, Mathematics Department, St. Lawrence University,\nCanton, NY 13617  e-mail   rlock@vm.stlawu.edu\n\nIf you would like to be informed about any subsequent adjustments\nor error fixes to the 1995 Exposition data, please send an e-mail\nmessage to register your interest to rlock@vm.stlawu.edu.\n\nSpecial thanks for providing data for the 1995 Exposition to:\nRobert Morse, Director of Research for America's Best Colleges at\nU.S. News & World Report\nMaryse Eymonerie, Consultant to AAUP.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_488_colleges_aaup_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Type"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-488-colleges-aaup"}, "LL0_494_analcatdata_hiroshima": {"pipeline": {"_id": "ea373a39-edb9-40df-9359-038618781e31", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 7, "min_samples_split": 0.09962789322110742, "min_samples_leaf": 0.062275048678940244, "n_estimators": 27}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "ea373a39-edb9-40df-9359-038618781e31", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 22.106822256360314, "rank": 22.10682225636084, "metric": "meanSquaredError", "ts": "2018-10-24T21:19:49.026000", "dataset": "LL0_494_analcatdata_hiroshima_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_494_analcatdata_hiroshima", "about": {"problemID": "LL0_494_analcatdata_hiroshima_problem", "problemName": "LL0_494_analcatdata_hiroshima_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: 2\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_494_analcatdata_hiroshima_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "Aberrant_cells"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-494-analcatdata-hiroshima"}, "LL0_49_heart_c": {"pipeline": {"_id": "42311714-6553-47e8-b68d-64472352118f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 88}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 2, "min_samples_split": 0.42577622020226646, "min_samples_leaf": 0.1386486538637611, "n_estimators": 134, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "42311714-6553-47e8-b68d-64472352118f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8748427345953325, "rank": 0.12515726540540392, "metric": "f1Macro", "ts": "2018-10-25T05:54:19.941000", "dataset": "LL0_49_heart_c_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_49_heart_c", "about": {"problemID": "LL0_49_heart_c_problem", "problemName": "LL0_49_heart_c_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\nPublication Request: \n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n    This file describes the contents of the heart-disease directory.\n \n    This directory contains 4 databases concerning heart disease diagnosis.\n    All attributes are numeric-valued.  The data was collected from the\n    four following locations:\n \n      1. Cleveland Clinic Foundation (cleveland.data)\n      2. Hungarian Institute of Cardiology, Budapest (hungarian.data)\n      3. V.A. Medical Center, Long Beach, CA (long-beach-va.data)\n      4. University Hospital, Zurich, Switzerland (switzerland.data)\n \n    Each database has the same instance format.  While the databases have 76\n    raw attributes, only 14 of them are actually used.  Thus I've taken the\n    liberty of making 2 copies of each database: one with all the attributes\n    and 1 with the 14 attributes actually used in past experiments.\n \n    The authors of the databases have requested:\n \n       ...that any publications resulting from the use of the data include the \n       names of the principal investigator responsible for the data collection\n       at each institution.  They would be:\n \n        1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n           Robert Detrano, M.D., Ph.D.\n \n    Thanks in advance for abiding by this request.\n \n    David Aha\n    July 22, 1988\n    >>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n \n 1. Title: Heart Disease Databases\n \n 2. Source Information:\n    (a) Creators: \n        -- 1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n        -- 2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n        -- 3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n        -- 4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:\n              Robert Detrano, M.D., Ph.D.\n    (b) Donor: David W. Aha (aha@ics.uci.edu) (714) 856-8779   \n    (c) Date: July, 1988\n \n 3. Past Usage:\n     1. Detrano,~R., Janosi,~A., Steinbrunn,~W., Pfisterer,~M., Schmid,~J.,\n        Sandhu,~S., Guppy,~K., Lee,~S., & Froelicher,~V. (1989).  {it \n        International application of a new probability algorithm for the \n        diagnosis of coronary artery disease.}  {it American Journal of \n        Cardiology}, {it 64},304--310.\n        -- International Probability Analysis \n        -- Address: Robert Detrano, M.D.\n                    Cardiology 111-C\n                    V.A. Medical Center\n                    5901 E. 7th Street\n                    Long Beach, CA 90028\n        -- Results in percent accuracy: (for 0.5 probability threshold)\n              Data Name:  CDF    CADENZA\n           -- Hungarian   77     74\n              Long beach  79     77\n              Swiss       81     81\n           -- Approximately a 77% correct classification accuracy with a\n              logistic-regression-derived discriminant function\n     2. David W. Aha & Dennis Kibler\n        -- \n           \n           \n           -- Instance-based prediction of heart-disease presence with the \n              Cleveland database\n              -- NTgrowth: 77.0% accuracy\n              --       C4: 74.8% accuracy\n     3. John Gennari\n        -- Gennari, J.~H., Langley, P, & Fisher, D. (1989). Models of\n           incremental concept formation. {it Artificial Intelligence, 40},\n           11--61.\n        -- Results: \n           -- The CLASSIT conceptual clustering system achieved a 78.9% accuracy\n              on the Cleveland database.\n \n 4. Relevant Information:\n      This database contains 76 attributes, but all published experiments\n      refer to using a subset of 14 of them.  In particular, the Cleveland\n      database is the only one that has been used by ML researchers to \n      this date.  The \"goal\" field refers to the presence of heart disease\n      in the patient.  It is integer valued from 0 (no presence) to 4.\n      Experiments with the Cleveland database have concentrated on simply\n      attempting to distinguish presence (values 1,2,3,4) from absence (value\n      0).  \n    \n      The names and social security numbers of the patients were recently \n      removed from the database, replaced with dummy values.\n \n      One file has been \"processed\", that one containing the Cleveland \n      database.  All four unprocessed files also exist in this directory.\n     \n 5. Number of Instances: \n         Database:    # of instances:\n           Cleveland: 303\n           Hungarian: 294\n         Switzerland: 123\n       Long Beach VA: 200\n \n 6. Number of Attributes: 76 (including the predicted attribute)\n \n 7. Attribute Information:\n    -- Only 14 used\n       -- 1. #3  (age)       \n       -- 2. #4  (sex)       \n       -- 3. #9  (cp)        \n       -- 4. #10 (trestbps)  \n       -- 5. #12 (chol)      \n       -- 6. #16 (fbs)       \n       -- 7. #19 (restecg)   \n       -- 8. #32 (thalach)   \n       -- 9. #38 (exang)     \n       -- 10. #40 (oldpeak)   \n       -- 11. #41 (slope)     \n       -- 12. #44 (ca)        \n       -- 13. #51 (thal)      \n       -- 14. #58 (num)       (the predicted attribute)\n \n    -- Complete attribute documentation:\n       1 id: patient identification number\n       2 ccf: social security number (I replaced this with a dummy value of 0)\n       3 age: age in years\n       4 sex: sex (1 = male; 0 = female)\n       5 painloc: chest pain location (1 = substernal; 0 = otherwise)\n       6 painexer (1 = provoked by exertion; 0 = otherwise)\n       7 relrest (1 = relieved after rest; 0 = otherwise)\n       8 pncaden (sum of 5, 6, and 7)\n       9 cp: chest pain type\n         -- Value 1: typical angina\n         -- Value 2: atypical angina\n         -- Value 3: non-anginal pain\n         -- Value 4: asymptomatic\n      10 trestbps: resting blood pressure (in mm Hg on admission to the \n         hospital)\n      11 htn\n      12 chol: serum cholestoral in mg/dl\n      13 smoke: I believe this is 1 = yes; 0 = no (is or is not a smoker)\n      14 cigs (cigarettes per day)\n      15 years (number of years as a smoker)\n      16 fbs: (fasting blood sugar > 120 mg/dl)  (1 = true; 0 = false)\n      17 dm (1 = history of diabetes; 0 = no such history)\n      18 famhist: family history of coronary artery disease (1 = yes; 0 = no)\n      19 restecg: resting electrocardiographic results\n         -- Value 0: normal\n         -- Value 1: having ST-T wave abnormality (T wave inversions and/or ST \n                     elevation or depression of > 0.05 mV)\n         -- Value 2: showing probable or definite left ventricular hypertrophy\n                     by Estes' criteria\n      20 ekgmo (month of exercise ECG reading)\n      21 ekgday(day of exercise ECG reading)\n      22 ekgyr (year of exercise ECG reading)\n      23 dig (digitalis used furing exercise ECG: 1 = yes; 0 = no)\n      24 prop (Beta blocker used during exercise ECG: 1 = yes; 0 = no)\n      25 nitr (nitrates used during exercise ECG: 1 = yes; 0 = no)\n      26 pro (calcium channel blocker used during exercise ECG: 1 = yes; 0 = no)\n      27 diuretic (diuretic used used during exercise ECG: 1 = yes; 0 = no)\n      28 proto: exercise protocol\n           1 = Bruce     \n           2 = Kottus\n           3 = McHenry\n           4 = fast Balke\n           5 = Balke\n           6 = Noughton \n           7 = bike 150 kpa min/min  (Not sure if \"kpa min/min\" is what was \n               written!)\n           8 = bike 125 kpa min/min  \n           9 = bike 100 kpa min/min\n          10 = bike 75 kpa min/min\n          11 = bike 50 kpa min/min\n          12 = arm ergometer\n      29 thaldur: duration of exercise test in minutes\n      30 thaltime: time when ST measure depression was noted\n      31 met: mets achieved\n      32 thalach: maximum heart rate achieved\n      33 thalrest: resting heart rate\n      34 tpeakbps: peak exercise blood pressure (first of 2 parts)\n      35 tpeakbpd: peak exercise blood pressure (second of 2 parts)\n      36 dummy\n      37 trestbpd: resting blood pressure\n      38 exang: exercise induced angina (1 = yes; 0 = no)\n      39 xhypo: (1 = yes; 0 = no)\n      40 oldpeak = ST depression induced by exercise relative to rest\n      41 slope: the slope of the peak exercise ST segment\n         -- Value 1: upsloping\n         -- Value 2: flat\n         -- Value 3: downsloping\n      42 rldv5: height at rest\n      43 rldv5e: height at peak exercise\n      44 ca: number of major vessels (0-3) colored by flourosopy\n      45 restckm: irrelevant\n      46 exerckm: irrelevant\n      47 restef: rest raidonuclid (sp?) ejection fraction\n      48 restwm: rest wall (sp?) motion abnormality\n         0 = none\n         1 = mild or moderate\n         2 = moderate or severe\n         3 = akinesis or dyskmem (sp?)\n      49 exeref: exercise radinalid (sp?) ejection fraction\n      50 exerwm: exercise wall (sp?) motion \n      51 thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n      52 thalsev: not used\n      53 thalpul: not used\n      54 earlobe: not used\n      55 cmo: month of cardiac cath (sp?)  (perhaps \"call\")\n      56 cday: day of cardiac cath (sp?)\n      57 cyr: year of cardiac cath (sp?)\n      58 num: diagnosis of heart disease (angiographic disease status)\n         -- Value 0: < 50% diameter narrowing\n         -- Value 1: > 50% diameter narrowing\n         (in any major vessel: attributes 59 through 68 are vessels)\n      59 lmt\n      60 ladprox\n      61 laddist\n      62 diag\n      63 cxmain\n      64 ramus\n      65 om1\n      66 om2\n      67 rcaprox\n      68 rcadist\n      69 lvx1: not used\n      70 lvx2: not used\n      71 lvx3: not used\n      72 lvx4: not used\n      73 lvf: not used\n      74 cathef: not used\n      75 junk: not used\n      76 name: last name of patient \n         (I replaced this with the dummy string \"name\")\n \n 9. Missing Attribute Values: Several.  Distinguished with value -9.0.\n \n 10. Class Distribution:\n         Database:      0   1   2   3   4 Total\n           Cleveland: 164  55  36  35  13   303\n           Hungarian: 188  37  26  28  15   294\n         Switzerland:   8  48  32  30   5   123\n       Long Beach VA:  51  56  41  42  10   200\n\n 'slope' is ordered\n\n\n\n\n Relabeled values in attribute 'sex'\n    From: 0                       To: female              \n    From: 1                       To: male                \n\n\n Relabeled values in attribute 'cp'\n    From: 1                       To: typ_angina          \n    From: 4                       To: asympt              \n    From: 3                       To: non_anginal         \n    From: 2                       To: atyp_angina         \n\n\n Relabeled values in attribute 'fbs'\n    From: 1                       To: t                   \n    From: 0                       To: f                   \n\n\n Relabeled values in attribute 'restecg'\n    From: 2                       To: left_vent_hyper     \n    From: 0                       To: normal              \n    From: 1                       To: st_t_wave_abnormality\n\n\n Relabeled values in attribute 'exang'\n    From: 0                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute 'slope'\n    From: 1                       To: up                  \n    From: 2                       To: flat                \n    From: 3                       To: down                \n\n\n Relabeled values in attribute 'thal'\n    From: 6                       To: fixed_defect        \n    From: 3                       To: normal              \n    From: 7                       To: reversable_defect   \n\n\n Relabeled values in attribute 'num'\n    From: '0'                     To: '<50'               \n    From: '1'                     To: '>50_1'             \n    From: '2'                     To: '>50_2'             \n    From: '3'                     To: '>50_3'             \n    From: '4'                     To: '>50_4'", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_49_heart_c_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "num"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-49-heart-c"}, "LL0_500_analcatdata_vineyard": {"pipeline": {"_id": "8a522396-7b5d-4b9e-9136-27ad2d131a2b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 70}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 255, "max_depth": 9, "learning_rate": 0.2709289194738541, "gamma": 0.7092377620776344, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "8a522396-7b5d-4b9e-9136-27ad2d131a2b", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 4.167433223937698, "rank": 4.167433223938011, "metric": "meanSquaredError", "ts": "2018-10-24T20:20:30.933000", "dataset": "LL0_500_analcatdata_vineyard_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_500_analcatdata_vineyard", "about": {"problemID": "LL0_500_analcatdata_vineyard_problem", "problemName": "analcatdata_vineyard_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_500_analcatdata_vineyard_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Lugs"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-500-analcatdata-vineyard"}, "LL0_503_wind": {"pipeline": {"_id": "336c9082-c420-4c38-8e89-933c619f7abc", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 6}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 506, "max_depth": 5, "learning_rate": 0.030792538883768095, "gamma": 0.30714732741135387, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "336c9082-c420-4c38-8e89-933c619f7abc", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 9.413193037777939, "rank": 9.41319303777851, "metric": "meanSquaredError", "ts": "2018-10-24T20:52:37.859000", "dataset": "LL0_503_wind_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_503_wind", "about": {"problemID": "LL0_503_wind_problem", "problemName": "LL0_503_wind_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nwind   daily average wind speeds for 1961-1978 at 12 synoptic meteorological\nstations in the Republic of Ireland (Haslett and raftery 1989).\n\nThese data were analyzed in detail in the following article:\nHaslett, J. and Raftery, A. E. (1989). Space-time Modelling with\nLong-memory Dependence: Assessing Ireland's Wind Power Resource\n(with Discussion). Applied Statistics 38, 1-50.\n\nEach line corresponds to one day of data in the following format:\nyear, month, day, average wind speed at each of the stations in the order given\nin Fig.4 of Haslett and Raftery :\nRPT, VAL, ROS, KIL, SHA, BIR, DUB, CLA, MUL, CLO, BEL, MAL\n\nFortan format : ( i2, 2i3, 12f6.2)\n\nThe data are in knots, not in m/s.\n\nPermission granted for unlimited distribution.\n\nPlease report all anomalies to fraley@stat.washington.edu\n\nBe aware that the dataset is 532494 bytes long (thats over half a\nMegabyte).  Please be sure you want the data before you request it.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_503_wind_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 15, "colName": "MAL"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-503-wind"}, "LL0_504_analcatdata_supreme": {"pipeline": {"_id": "94d9d22e-f3df-4bc0-96a4-66151d682007", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 838, "max_depth": 3, "learning_rate": 0.9064972620777123, "gamma": 0.07530161741374375, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "94d9d22e-f3df-4bc0-96a4-66151d682007", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.00455504077540197, "rank": 0.004555040775920917, "metric": "meanSquaredError", "ts": "2018-10-24T21:31:16.753000", "dataset": "LL0_504_analcatdata_supreme_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_504_analcatdata_supreme", "about": {"problemID": "LL0_504_analcatdata_supreme_problem", "problemName": "analcatdata_supreme_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_504_analcatdata_supreme_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "Log_exposure"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-504-analcatdata-supreme"}, "LL0_509_places": {"pipeline": {"_id": "4cbcdfbc-bbdc-4843-8986-c9b5ac27440a", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 98}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 966, "max_depth": 4, "learning_rate": 0.17373812653657583, "gamma": 0.27111437707751407, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "4cbcdfbc-bbdc-4843-8986-c9b5ac27440a", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 867778.1543605849, "rank": 867778.1543605849, "metric": "meanSquaredError", "ts": "2018-10-24T20:27:08.361000", "dataset": "LL0_509_places_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_509_places", "about": {"problemID": "LL0_509_places_problem", "problemName": "LL0_509_places_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis dataset is taken from the Places Rated Almanac, by Richard\nBoyer and David Savageau, copyrighted and published by Rand McNally.\nThis book order (SBN) number is 0-528-88008-X, and it retails for\n$14.95 .  The data are reproduced by kind permission of the\npublisher, and with the request that the copyright notice of Rand\nMcNally, and the names of the authors appear in any paper or\npresentation using these data.\n\nThe nine rating criteria used by Places Rated Almanac are:\nClimate & Terrain\nHousing\nHealth Care & Environment\nCrime\nTransportation\nEducation\nThe Arts\nRecreation\nEconomics\n\nFor all but two of the above criteria, the higher the score, the\nbetter.  For Housing and Crime, the lower the score the better.\n\nThe scores are computed using the following component statistics for\neach criterion (see the Places Rated Almanac for details):\n\nClimate & Terrain: very hot and very cold months, seasonal\ntemperature variation, heating- and cooling-degree days, freezing\ndays, zero-degree days, ninety-degree days.\n\nHousing: utility bills, property taxes, mortgage payments.\n\nHealth Care & Environment: per capita physicians, teaching hospitals,\nmedical schools, cardiac rehabilitation centers, comprehensive cancer\ntreatment centers, hospices, insurance/hospitalization costs index,\nflouridation of drinking water, air pollution.\n\nCrime: violent crime rate, property crime rate.\n\nTransportation: daily commute, public transportation, Interstate\nhighways, air service, passenger rail service.\n\nEducation: pupil/teacher ratio in the public K-12 system, effort\nindex in K-12, accademic options in higher education.\n\nThe Arts: museums, fine arts and public radio stations, public\ntelevision stations, universities offering a degree or degrees in the\narts, symphony orchestras, theatres, opera companies, dance\ncompanies, public libraries.\n\nRecreation: good restaurants, public golf courses, certified lanes\nfor tenpin bowling, movie theatres, zoos, aquariums, family theme\nparks, sanctioned automobile race tracks, pari-mutuel betting\nattractions, major- and minor- league professional sports teams, NCAA\nDivision I football and basketball teams, miles of ocean or Great\nLakes coastline, inland water, national forests, national parks, or\nnational wildlife refuges, Consolidated Metropolitan Statistical Area\naccess.\n\nEconomics: average household income adjusted for taxes and living\ncosts, income growth, job growth.\n\n\nThe data are recorded in two ASCII files, PLACES.DAT, and\nPLACES.KEY .  The first file contains 329 observations, 9 columns\nplus an index column.  The index stands for the location.  PLACES.KEY\ngives the index in the first column and the associated name of the\nplace in the second column.  All data analysis can be done with\nnumeric variables and the index, as read in from PLACES.DAT .\nAlternatively, the numerical key can be replaced by the alphabetic\nname, as given by PLACES.KEY .\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: 9", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_509_places_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "Economics"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-509-places"}, "LL0_50_tic_tac_toe": {"pipeline": {"_id": "6f55cf45-c4a9-4858-9684-7b79fb069239", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 499, "max_depth": 8, "learning_rate": 0.08556332838980218, "gamma": 0.27644105157980936, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6f55cf45-c4a9-4858-9684-7b79fb069239", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 1.27222080487294e-13, "metric": "f1Macro", "ts": "2018-10-25T00:06:06.259000", "dataset": "LL0_50_tic_tac_toe_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_50_tic_tac_toe", "about": {"problemID": "LL0_50_tic_tac_toe_problem", "problemName": "tic_tac_toe_problem", "problemDescription": "**Author**: David W. Aha    \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Tic-Tac-Toe+Endgame) - 1991   \n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)\n\n**Tic-Tac-Toe Endgame database**  \nThis database encodes the complete set of possible board configurations at the end of tic-tac-toe games, where \"x\" is assumed to have played first.  The target concept is \"win for x\" (i.e., true when \"x\" has one of 8 possible ways to create a \"three-in-a-row\").  \n\n### Attribute Information  \n\n     (x=player x has taken, o=player o has taken, b=blank)\n     1. top-left-square: {x,o,b}\n     2. top-middle-square: {x,o,b}\n     3. top-right-square: {x,o,b}\n     4. middle-left-square: {x,o,b}\n     5. middle-middle-square: {x,o,b}\n     6. middle-right-square: {x,o,b}\n     7. bottom-left-square: {x,o,b}\n     8. bottom-middle-square: {x,o,b}\n     9. bottom-right-square: {x,o,b}\n    10. Class: {positive,negative}", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_50_tic_tac_toe_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-50-tic-tac-toe"}, "LL0_511_plasma_retinol": {"pipeline": {"_id": "2463e799-7c65-4468-b2e4-88adda7d6418", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 16}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 17, "min_samples_split": 0.1817175797468111, "min_samples_leaf": 0.042598238096108174, "n_estimators": 31}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "2463e799-7c65-4468-b2e4-88adda7d6418", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 42063.963846855695, "rank": 42063.963846855695, "metric": "meanSquaredError", "ts": "2018-10-24T20:50:07.534000", "dataset": "LL0_511_plasma_retinol_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_511_plasma_retinol", "about": {"problemID": "LL0_511_plasma_retinol_problem", "problemName": "LL0_511_plasma_retinol_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDeterminants of Plasma Retinol and Beta-Carotene Levels\n\nSummary:\nObservational studies have suggested that low dietary intake or low plasma concentrations of retinol, beta-carotene, or other carotenoids might be associated with increased risk of developing certain types of cancer.  However, relatively few studies have investigated the determinants of plasma concentrations of these micronutrients. We designed a cross-sectional study to investigate the relationship between personal characteristics and dietary factors, and plasma concentrations of retinol, beta-carotene and other carotenoids. Study subjects (N = 315) were patients who had an elective surgical procedure during a three-year period to biopsy or remove a lesion of the lung, colon, breast, skin, ovary or uterus that was found to be non-cancerous. We display the data for only two of the analytes.\nPlasma concentrations of the micronutrients varied widely from subject to subject.  While plasma retinol levels varied by age and sex, the only dietary predictor was alcohol consumption (R^2 = .38). Plasma beta-carotene levels were log-transformed prior to the analyses due to severe asymmetry of the residuals on the original scale. For log beta-carotene, dietary intake, regular use of vitamins, and intake of fiber were associated with higher plasma concentrations, while Quetelet Index (defined as weight/height^2 in the units kg/m^2) and cholesterol intake were associated with lower plasma levels, adjusting for the other factors (R^2 = .50). There was one extremely high leverage point in alcohol consumption that was deleted prior to the analyses. Plasma concentrations of retinol and beta-carotene were not correlated.\nWe conclude that there is wide variability in plasma concentrations of these micronutrients in humans, and that much of this variability is associated with dietary habits and personal characteristics.  A better understanding of the physiological relationship between some personal characteristics and plasma concentrations of these micronutrients will require further study.\n\nAuthorization: Contact Authors\n\nReference: These data have not been published yet but a related reference is\nNierenberg DW, Stukel TA, Baron JA, Dain BJ, Greenberg ER.  Determinants of plasma levels of beta-carotene and retinol.  American Journal of Epidemiology 1989;130:511-521.\n\nDescription:  This datafile contains 315 observations on 14 variables.  This data set can be used to demonstrate multiple regression, transformations, categorical variables, outliers, pooled tests of significance and model building strategies.\n\nVariable Names in order from left to right:\nAGE: Age (years)\nSEX: Sex (1=Male, 2=Female).\nSMOKSTAT: Smoking status (1=Never, 2=Former, 3=Current Smoker)\nQUETELET: Quetelet (weight/(height^2))\nVITUSE: Vitamin Use (1=Yes, fairly often, 2=Yes, not often, 3=No)\nCALORIES: Number of calories consumed per day.\nFAT: Grams of fat consumed per day.\nFIBER: Grams of fiber consumed per day.\nALCOHOL: Number of alcoholic drinks consumed per week.\nCHOLESTEROL: Cholesterol consumed (mg per day).\nBETADIET: Dietary beta-carotene consumed (mcg per day).\nRETDIET: Dietary retinol consumed (mcg per day)\nBETAPLASMA: Plasma beta-carotene (ng/ml)\nRETPLASMA: Plasma Retinol (ng/ml)\n\n\n\n\nTherese Stukel\nDartmouth Hitchcock Medical Center\nOne Medical Center Dr.\nLebanon, NH 03756\ne-mail: stukel@dartmouth.edu\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_511_plasma_retinol_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "RETPLASMA"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-511-plasma-retinol"}, "LL0_512_balloon": {"pipeline": {"_id": "5a6b435e-8554-448a-81be-8b67be177bf1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 61}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 435, "max_depth": 7, "learning_rate": 0.6261670292275643, "gamma": 0.0006489878162654339, "min_child_weight": 4}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "5a6b435e-8554-448a-81be-8b67be177bf1", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.00022869127083657644, "rank": 0.00022869127144633229, "metric": "meanSquaredError", "ts": "2018-10-24T20:14:03.770000", "dataset": "LL0_512_balloon_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_512_balloon", "about": {"problemID": "LL0_512_balloon_problem", "problemName": "LL0_512_balloon_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe data consist of 2001 observations taken from a balloon about 30 kilometres\nabove the surface of the earth. In the section of the flight shown here the\nballoon increases in height. As radiation increases with height there is a\nnon-decreasing trend in the data. The outliers are caused by the fact that the\nballoon slowly rotates, causing the ropes from which the measuring instrument\nis suspended to cut off the direct radiation from the sun. The first column\ncontains the raw data, the second column the residuals after the removal of a\nnon-decreasing trend.\nReference:\nDavies, L. and Gather, U. (1993), \"The Identification of Multiple\nOutliers\" (discussion paper), to appear in JASA.\nMailing address:  Laurie Davies\nUniversitaet-Gesamthochschule Essen\nFachbereich 6 Mathematik\nUniversitaetsstrasse 3\nD-4300 Essen 1\nGermany\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_512_balloon_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "residual"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-512-balloon"}, "LL0_519_vinnie": {"pipeline": {"_id": "9bc23cb4-e2fe-4472-9fe4-8dc97f7217ce", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 77}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 5, "min_samples_split": 0.037373776593164786, "min_samples_leaf": 0.04140737884175811, "n_estimators": 403}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "9bc23cb4-e2fe-4472-9fe4-8dc97f7217ce", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.3647976332710927, "rank": 2.3647976332720755, "metric": "meanSquaredError", "ts": "2018-10-24T21:15:55.058000", "dataset": "LL0_519_vinnie_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_519_vinnie", "about": {"problemID": "LL0_519_vinnie_problem", "problemName": "LL0_519_vinnie_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFollowing are data on the shooting of Vinnie Johnson of the Detroit\nPistons during the 1985-1986 through 1988-1989 seasons. Source was the\nNew York Times.\nThe data are analyzed in the Carnegie Mellon Ph.D. Thesis of\nKate Hsiao and some results are cited in Example 2 of Kass, R.E. and\nRaftery, A.E. (1995), Bayes Factors, J. Amer. Statist. Assoc.,\nThe first column is the year, with 85 indicating 1985-1986, etc..\nThe second column is Field Goals, the third column is Field Goal\nAttempts.\nA more complete version of the data, including free throws, is\nappended together with additional information.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_519_vinnie_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "field_goals"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-519-vinnie"}, "LL0_520_analcatdata_wildcat": {"pipeline": {"_id": "7de48f39-22a8-4007-a33d-c7f66efd8b31", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 54}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 10, "min_samples_split": 0.08762930723800187, "min_samples_leaf": 0.0155786198289139, "n_estimators": 35}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "7de48f39-22a8-4007-a33d-c7f66efd8b31", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 11.867222919937205, "rank": 11.867222919938007, "metric": "meanSquaredError", "ts": "2018-10-24T20:36:25.618000", "dataset": "LL0_520_analcatdata_wildcat_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_520_analcatdata_wildcat", "about": {"problemID": "LL0_520_analcatdata_wildcat_problem", "problemName": "analcatdata_wildcat_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_520_analcatdata_wildcat_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "Wildcat_strikes"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-520-analcatdata-wildcat"}, "LL0_522_pm10": {"pipeline": {"_id": "2e012223-94a3-47ee-812d-132b1d9f3f57", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 29}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 382, "max_depth": 4, "learning_rate": 0.4101081181948818, "gamma": 0.7446270234994893, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "2e012223-94a3-47ee-812d-132b1d9f3f57", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.4120479591348792, "rank": 0.41204795913539194, "metric": "meanSquaredError", "ts": "2018-10-24T20:40:56.752000", "dataset": "LL0_522_pm10_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_522_pm10", "about": {"problemID": "LL0_522_pm10_problem", "problemName": "LL0_522_pm10_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe data are a subsample of 500 observations from a data set\nthat originate in a study where air pollution at a road is\nrelated to traffic volume and meteorological variables,\ncollected by the Norwegian Public Roads Administration. The\nresponse variable (column 1) consist of hourly values of the\nlogarithm of the concentration of PM10 (particles), measured at\nAlnabru in Oslo, Norway, between October 2001 and August 2003.\nThe predictor variables (columns 2 to 8) are the logarithm of\nthe number of cars per hour, temperature $2$ meter above ground\n(degree C), wind speed (meters/second), the temperature\ndifference between $25$ and $2$ meters above ground (degree C),\nwind direction (degrees between 0 and 360), hour of day and day\nnumber from October 1. 2001. Submitted by Magne Aldrin\n(magne.aldrin@nr.no). [28/Jul/04] (19kbytes)\n\nNote: description of data is from this website\nhttp://lib.stat.cmu.edu/datasets/\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_522_pm10_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "pm10_concentration"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-522-pm10"}, "LL0_524_pbc": {"pipeline": {"_id": "aedb6a60-489c-4ac9-be24-4b517857373d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 100, "max_depth": 5, "learning_rate": 0.16966469062277445, "gamma": 0.48181422760857995, "min_child_weight": 6}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "aedb6a60-489c-4ac9-be24-4b517857373d", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.4091699261811822, "rank": 0.40916992618178466, "metric": "meanSquaredError", "ts": "2018-10-24T21:14:24.062000", "dataset": "LL0_524_pbc_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_524_pbc", "about": {"problemID": "LL0_524_pbc_problem", "problemName": "LL0_524_pbc_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n------------------------------------------------------------------------\nPrimary Biliary Cirrhosis\n\nThe data set found in appendix D of Fleming and Harrington, Counting\nProcesses and Survival Analysis, Wiley, 1991.  The only differences are:\nage is in days\nstatus is coded as 0=censored, 1=censored due to liver tx, 2=death\nthe sex and stage variables are not missing for obs 313-418\n\nQuoting from F&H.  \"The following pages contain the data from the Mayo Clinic\ntrial in primary biliary cirrhosis (PBC) of the liver conducted between 1974\nand 1984.  A description of the clinical background for the trial and the\ncovariates recorded here is in Chapter 0, especially Section 0.2.  A more\nextended discussion can be found in Dickson, et al., Hepatology 10:1-7 (1989)\nand in Markus, et al., N Eng J of Med 320:1709-13 (1989).\n\"A total of 424 PBC patients, referred to Mayo Clinic during that ten-year\ninterval, met eligibility criteria for the randomized placebo controlled\ntrial of the drug D-penicillamine.  The first 312 cases in the data set\nparticipated in the randomized trial and contain largely complete data.  The\nadditional 112 cases did not participate in the clinical trial, but consented\nto have basic measurements recorded and to be followed for survival.  Six of\nthose cases were lost to follow-up shortly after diagnosis, so the data here\nare on an additional 106 cases as well as the 312 randomized participants.\nMissing data items are denoted by `.'. \"\n\nVariables:\ncase number\nnumber of days between registration and the earlier of death,\ntransplantion, or study analysis time in July, 1986\nstatus\ndrug: 1= D-penicillamine, 2=placebo\nage in days\nsex: 0=male, 1=female\npresence of asictes:       0=no 1=yes\npresence of hepatomegaly   0=no 1=yes\npresence of spiders        0=no 1=yes\npresence of edema          0=no edema and no diuretic therapy for edema;\n.5 = edema present without diuretics, or edema resolved by diuretics;\n1 = edema despite diuretic therapy\nserum bilirubin in mg/dl\nserum cholesterol in mg/dl\nalbumin in gm/dl\nurine copper in ug/day\nalkaline phosphatase in U/liter\nSGOT in U/ml\ntriglicerides in mg/dl\nplatelets per cubic ml / 1000\nprothrombin time in seconds\nhistologic stage of disease\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: 3", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_524_pbc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "status"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-524-pbc"}, "LL0_529_pollen": {"pipeline": {"_id": "7f5e3bee-23c3-482e-8c1d-7a1ad1f9d1e4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 56}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 419, "max_depth": 3, "learning_rate": 0.06118443472104995, "gamma": 0.5278918729564608, "min_child_weight": 7}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "7f5e3bee-23c3-482e-8c1d-7a1ad1f9d1e4", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.2719563161304555, "rank": 2.271956316131336, "metric": "meanSquaredError", "ts": "2018-10-24T20:12:49.497000", "dataset": "LL0_529_pollen_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_529_pollen", "about": {"problemID": "LL0_529_pollen_problem", "problemName": "LL0_529_pollen_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis dataset is synthetic.  It was generated by David Coleman\nat RCA Laboratories in Princeton, N.J.  For convenience, we will\nrefer to it as the POLLEN DATA.  The first three variables are the\nlengths of geometric features observed sampled pollen grains - in the\nx, y, and z dimensions: a \"ridge\" along x, a \"nub\" in the y\ndirection, and a \"crack\" in along the z dimension.  The fourth\nvariable is pollen grain weight, and the fifth is density.\n\nThere are 3848 observations, in random order (for people whose\nsoftware packages cannot handle this much data, it is recommended\nthat the data be sampled).  The dataset is broken up into eight\npieces, POLLEN1.DAT - POLLEN8.DAT, each with 481 observations.\nWe will call the variables:\n\n1. RIDGE\n2. NUB\n3. CRACK\n4. WEIGHT\n5. DENSITY\n\n6. OBSERVATION NUMBER (for convenience)\n\nThe data analyst is advised that there is more than one \"feature\" to\nthese data.  Each feature can be observed through various graphical\ntechniques, but analytic methods, as well, can help \"crack\" the\ndataset.\n\nAdditional Info:\n\nI no longer have the description handed out during the JSM, but can\ntell you how I generated the data, in minitab.\n\n1. Part A was generated: 5000 (I think) 5-variable, uncorrelated, i.i.d.\nGaussian observations.\n\n2. To get part B, I duplicated part A, then reversed the sign on the\nobservations for 3 of the 5 variables.\n\n3. Part B was appended to Part A.\n\n4. The order of the observations was randomized.\n\n5. While waiting for my tardy car-pool companion, I took a piece of\ngraph paper, and figured out a dot-matrix representation of the word,\n\"EUREKA.\"  I then added these observations to the \"center\" of the\ndatatset.\n\n6. The data were scaled, by variable (something like 1,3,5,7,11).\n\n7. The data were rotated, then translated.\n\n8. A few points in space within the datacloud were chosen as ellipsoid\ncenters, then for each center, all observations within a (scaled and\nrotated) radius were identified, and eliminated - to form ellipsoidal\nvoids.\n\n9. The variables were given entirely ficticious names.\n\nFYI, only the folks at Bell Labs, Murray Hill, found everything,\nincluding the voids.\n\nHope this is helpful!\n\nReferences:\n\nBecker, R.A., Denby, L., McGill, R., and Wilks,\nA. (1986). Datacryptanalysis: A Case Study.\nProceedings of the Section on Statistical Graphics, 92-97.\n\nSlomka, M. (1986). The Analysis of a Synthetic Data Set.\nProceedings of the Section on Statistical Graphics, 113-116.\n\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_529_pollen_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "DENSITY"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-529-pollen"}, "LL0_531_boston": {"pipeline": {"_id": "368ad9b1-17f2-4114-8a5e-96cfb7ec6d73", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 41}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 899, "max_depth": 8, "learning_rate": 0.06176146354076251, "gamma": 0.07117937916844397, "min_child_weight": 6}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "368ad9b1-17f2-4114-8a5e-96cfb7ec6d73", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 10.951862102619838, "rank": 10.951862102619906, "metric": "meanSquaredError", "ts": "2018-10-24T20:25:26.982000", "dataset": "LL0_531_boston_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_531_boston", "about": {"problemID": "LL0_531_boston_problem", "problemName": "LL0_531_boston_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\nprices and the demand for clean air', J. Environ. Economics & Management,\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\npages 244-261 of the latter.\nVariables in order:\nCRIM     per capita crime rate by town\nZN       proportion of residential land zoned for lots over 25,000 sq.ft.\nINDUS    proportion of non-retail business acres per town\nCHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\nNOX      nitric oxides concentration (parts per 10 million)\nRM       average number of rooms per dwelling\nAGE      proportion of owner-occupied units built prior to 1940\nDIS      weighted distances to five Boston employment centres\nRAD      index of accessibility to radial highways\nTAX      full-value property-tax rate per $10,000\nPTRATIO  pupil-teacher ratio by town\nB        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\nLSTAT    % lower status of the population\nMEDV     Median value of owner-occupied homes in $1000's\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_531_boston_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "MEDV"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-531-boston"}, "LL0_536_arsenic_male_lung": {"pipeline": {"_id": "8a77c6b4-9a8f-41e3-bd7e-9f90cbc6fe88", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 37}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 73, "max_depth": 4, "learning_rate": 0.018638624791505465, "gamma": 0.226717430842845, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "8a77c6b4-9a8f-41e3-bd7e-9f90cbc6fe88", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 1121.333072006617, "rank": 1121.3330720066176, "metric": "meanSquaredError", "ts": "2018-10-24T20:09:35.935000", "dataset": "LL0_536_arsenic_male_lung_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_536_arsenic_male_lung", "about": {"problemID": "LL0_536_arsenic_male_lung_problem", "problemName": "arsenic_male_lung_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_536_arsenic_male_lung_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "events"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-536-arsenic-male-lung"}, "LL0_540_mu284": {"pipeline": {"_id": "20e86bd2-21ba-468f-95f4-e6e62dc35c53", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 386, "max_depth": 5, "learning_rate": 0.017075872142062187, "gamma": 0.2310906725108578, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "20e86bd2-21ba-468f-95f4-e6e62dc35c53", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.20684792661650953, "rank": 0.2068479266165859, "metric": "meanSquaredError", "ts": "2018-10-24T20:13:16.803000", "dataset": "LL0_540_mu284_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_540_mu284", "about": {"problemID": "LL0_540_mu284_problem", "problemName": "mu284_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis file contains the data in \"The MU284 Population\" from Appendix B of\nthe book \"Model Assisted Survey Sampling\" by Sarndal, Swensson and Wretman,\npublished by Springer-Verlag, New York, 1992. The data set contains 284\nobservations on 11 variables, plus a line with variabel names. Please\nconsult the mentioned appendix for more information about this data set.\nThe data were scanned from the book and interpreted with OCR-technique.\nPlease note that errors may occur in such a process. The result was\nmacro-edited against \"The Clustered MU284 Population\" in Appendix C of the\nbook. Please use the data at your own risk - I take no responsibility for\nany problems eventual remaining errors will cause you.\nfour typos in the first printing of the book have been corrected:\nLabel 107, ME84 should be 1100, not 1110\nLabel 141, RMT85 should be 396, not 369\nLabel 220, ME84 should be 461, not 491\nLabel 229, ME84 should be 1239, not 1238.\nThe data was submitted to StatLib with the permission of Springer-Verlag\n(ref: John Kimmel).\nEsbjorn Ohlsson\nStockholm University\nesbj@matematik.su.se\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_540_mu284_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "CL"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-540-mu284"}, "LL0_547_no2": {"pipeline": {"_id": "ea594bfc-ab38-4e28-8ffa-9a15222bf29d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 91}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 261, "max_depth": 9, "learning_rate": 0.10092784028970825, "gamma": 0.02671662067265712, "min_child_weight": 9}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "ea594bfc-ab38-4e28-8ffa-9a15222bf29d", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.1996428658920943, "rank": 0.19964286589210206, "metric": "meanSquaredError", "ts": "2018-10-24T20:08:49.728000", "dataset": "LL0_547_no2_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_547_no2", "about": {"problemID": "LL0_547_no2_problem", "problemName": "LL0_547_no2_problem", "problemDescription": "**Author**: Magne Aldrin (magne.aldrin@nr.no)  \n**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 2004  \n**Please cite**:   \n\nThe data are a subsample of 500 observations from a data set that originate in a study where air pollution at a road is\nrelated to traffic volume and meteorological variables, collected by the Norwegian Public Roads Administration. The response variable (column 1) consist of hourly values of the logarithm of the concentration of NO2 (particles), measured at Alnabru in Oslo, Norway, between October 2001 and August 2003. \n\nThe predictor variables (columns 2 to 8) are the logarithm of the number of cars per hour, temperature $$2$$ meter above ground (degree C), wind speed (meters/second), the temperature difference between $$25$$ and $$2$$ meters above ground (degree C), wind direction (degrees between 0 and 360), hour of day and day number from October 1. 2001.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_547_no2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "no2_concentration"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-547-no2"}, "LL0_549_strikes": {"pipeline": {"_id": "f9ec67be-b083-421a-ba3f-7a9243fa2609", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 25}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 989, "max_depth": 7, "learning_rate": 0.0024407492238945894, "gamma": 0.09109313928158613, "min_child_weight": 2}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "f9ec67be-b083-421a-ba3f-7a9243fa2609", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 231583.72299940875, "rank": 231583.72299940875, "metric": "meanSquaredError", "ts": "2018-10-24T20:14:48.730000", "dataset": "LL0_549_strikes_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_549_strikes", "about": {"problemID": "LL0_549_strikes_problem", "problemName": "LL0_549_strikes_problem", "problemDescription": "**Author**: Bruce Western (western@datacomm.iue.it)   \n**Source**: [StatLib](http://lib.stat.cmu.edu/datasets/) - 1999  \n**Please cite**:   \n\nThe data consist of annual observations on the level of strike volume (days lost due to industrial disputes per 1000 wage salary earners), and their covariates in 18 OECD countries from 1951-1985. The average level and variance of strike volume varies across countries. The data distribution also features a long right tail and several large outliers. \n\nThe 7 data fields include the following variables:  \n>\n(1) country code;  \n(2) year;  \n(3) strike volume;  \n(4) unemployment;  \n(5) inflation;  \n(6) parliamentary representation of social democratic and labor parties  \n(7) a time-invariant measure of union centralization.\n\nThese data were analyzed in the forthcoming paper by Bruce Western, \"Vague Theory and Model Uncertainty in Macrosociology,\" which is to appear in Sociological Methodology. Permission is given by the author to freely use and redistribute these data.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_549_strikes_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "strike_volume"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-549-strikes"}, "LL0_54_vehicle": {"pipeline": {"_id": "1ed9ef6a-39d0-4096-972c-29dd498ec3a6", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 72}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 900, "max_depth": 3, "learning_rate": 0.6880818696456491, "gamma": 0.131615464169474, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "1ed9ef6a-39d0-4096-972c-29dd498ec3a6", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7785184838431298, "rank": 0.22148151615721845, "metric": "f1Macro", "ts": "2018-10-25T00:56:59.238000", "dataset": "LL0_54_vehicle_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_54_vehicle", "about": {"problemID": "LL0_54_vehicle_problem", "problemName": "LL0_54_vehicle_problem", "problemDescription": "**Author**:  Peter Mowforth  \n**Source**: UCI -   \n**Please cite**: Siebert,JP. Turing Institute Research Memorandum TIRM-87-018 \"Vehicle Recognition Using Rule Based Methods\" (March 1987)  \n\n NAME\n         vehicle silhouettes\n \n PURPOSE\n         to classify a given silhouette as one of four types of vehicle,\n         using  a set of features extracted from the silhouette. The\n         vehicle may be viewed from one of many different angles.  \n \n PROBLEM TYPE\n         classification\n         \n SOURCE\n         Drs.Pete Mowforth and Barry Shepherd\n         Turing Institute\n         George House\n         36 North Hanover St.\n         Glasgow\n         G1 2AD\n \n CONTACT\n         Alistair Sutherland\n         Statistics Dept.\n         Strathclyde University\n         Livingstone Tower\n         26 Richmond St.\n         GLASGOW G1 1XH\n         Great Britain\n         \n         Tel: 041 552 4400 x3033\n         \n         Fax: 041 552 4711 \n         \n         e-mail: alistair@uk.ac.strathclyde.stams\n \n HISTORY\n         This data was originally gathered at the TI in 1986-87 by\n         JP Siebert. It was partially financed by Barr and Stroud Ltd.\n         The original purpose was to find a method of distinguishing\n         3D objects within a 2D image by application of an ensemble of\n         shape feature extractors to the 2D silhouettes of the objects.\n         Measures of shape features extracted from example silhouettes\n         of objects to be discriminated were used to generate a class-\n         ification rule tree by means of computer induction.\n          This object recognition strategy was successfully used to \n         discriminate between silhouettes of model cars, vans and buses\n         viewed from constrained elevation but all angles of rotation.\n          The rule tree classification performance compared favourably\n         to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neigh-\n         bour) statistical classifiers in terms of both error rate and\n         computational efficiency. An investigation of these rule trees\n         generated by example indicated that the tree structure was \n         heavily influenced by the orientation of the objects, and grouped\n         similar object views into single decisions.\n \n DESCRIPTION\n          The features were extracted from the silhouettes by the HIPS\n         (Hierarchical Image Processing System) extension BINATTS, which \n         extracts a combination of scale independent features utilising\n         both classical moments based measures such as scaled variance,\n         skewness and kurtosis about the major/minor axes and heuristic\n         measures such as hollows, circularity, rectangularity and\n         compactness.\n          Four \"Corgie\" model vehicles were used for the experiment:\n         a double decker bus, Cheverolet van, Saab 9000 and an Opel Manta 400.\n         This particular combination of vehicles was chosen with the \n         expectation that the bus, van and either one of the cars would\n         be readily distinguishable, but it would be more difficult to\n         distinguish between the cars.\n          The images were acquired by a camera looking downwards at the\n         model vehicle from a fixed angle of elevation (34.2 degrees\n         to the horizontal). The vehicles were placed on a diffuse\n         backlit surface (lightbox). The vehicles were painted matte black\n         to minimise highlights. The images were captured using a CRS4000\n         framestore connected to a vax 750. All images were captured with\n         a spatial resolution of 128x128 pixels quantised to 64 greylevels.\n         These images were thresholded to produce binary vehicle silhouettes,\n         negated (to comply with the processing requirements of BINATTS) and\n         thereafter subjected to shrink-expand-expand-shrink HIPS modules to\n         remove \"salt and pepper\" image noise.\n          The vehicles were rotated and their angle of orientation was measured\n         using a radial graticule beneath the vehicle. 0 and 180 degrees\n         corresponded to \"head on\" and \"rear\" views respectively while 90 and\n         270 corresponded to profiles in opposite directions. Two sets of\n         60 images, each set covering a full 360 degree rotation, were captured\n         for each vehicle. The vehicle was rotated by a fixed angle between \n         images. These datasets are known as e2 and e3 respectively.\n          A further two sets of images, e4 and e5, were captured with the camera \n         at elevations of 37.5 degs and 30.8 degs respectively. These sets\n         also contain 60 images per vehicle apart from e4.van which contains\n         only 46 owing to the difficulty of containing the van in the image\n         at some orientations.\n \n ATTRIBUTES\n         \n         COMPACTNESS     (average perim)**2/area\n         \n         CIRCULARITY     (average radius)**2/area\n         \n         DISTANCE CIRCULARITY    area/(av.distance from border)**2\n         \n         RADIUS RATIO    (max.rad-min.rad)/av.radius\n         \n         PR.AXIS ASPECT RATIO    (minor axis)/(major axis)\n         \n         MAX.LENGTH ASPECT RATIO (length perp. max length)/(max length)\n         \n         SCATTER RATIO   (inertia about minor axis)/(inertia about major axis)\n         \n         ELONGATEDNESS           area/(shrink width)**2\n         \n         PR.AXIS RECTANGULARITY  area/(pr.axis length*pr.axis width)\n         \n         MAX.LENGTH RECTANGULARITY area/(max.length*length perp. to this)\n         \n         SCALED VARIANCE         (2nd order moment about minor axis)/area\n         ALONG MAJOR AXIS\n         \n         SCALED VARIANCE         (2nd order moment about major axis)/area\n         ALONG MINOR AXIS \n         \n         SCALED RADIUS OF GYRATION       (mavar+mivar)/area\n         \n         SKEWNESS ABOUT  (3rd order moment about major axis)/sigma_min**3\n         MAJOR AXIS\n         \n         SKEWNESS ABOUT  (3rd order moment about minor axis)/sigma_maj**3\n         MINOR AXIS\n                 \n         KURTOSIS ABOUT  (4th order moment about major axis)/sigma_min**4\n         MINOR AXIS  \n                 \n         KURTOSIS ABOUT  (4th order moment about minor axis)/sigma_maj**4\n         MAJOR AXIS\n         \n         HOLLOWS RATIO   (area of hollows)/(area of bounding polygon)\n         \n          Where sigma_maj**2 is the variance along the major axis and\n         sigma_min**2 is the variance along the minor axis, and\n         \n         area of hollows= area of bounding poly-area of object \n         \n          The area of the bounding polygon is found as a side result of\n         the computation to find the maximum length. Each individual\n         length computation yields a pair of calipers to the object\n         orientated at every 5 degrees. The object is propagated into\n         an image containing the union of these calipers to obtain an\n         image of the bounding polygon. \n         \n NUMBER OF CLASSES\n \n         4       OPEL, SAAB, BUS, VAN\n \n NUMBER OF EXAMPLES\n \n                 Total no. = 946\n                 \n                 No. in each class\n                 \n                   opel 240\n                   saab 240\n                   bus  240\n                   van  226\n                 \n                 \n                 100 examples are being kept by Strathclyde for validation.\n                 So StatLog partners will receive 846 examples.\n \n NUMBER OF ATTRIBUTES\n \n                 No. of atts. = 18", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_54_vehicle_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 19, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-54-vehicle"}, "LL0_550_quake": {"pipeline": {"_id": "8d0a06e1-6a76-43d4-b9ae-992bb4be056e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 67}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 28, "max_depth": 3, "learning_rate": 0.40712400083485467, "gamma": 0.14344465813084495, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "8d0a06e1-6a76-43d4-b9ae-992bb4be056e", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.035473742452669606, "rank": 0.03547374245267104, "metric": "meanSquaredError", "ts": "2018-10-24T20:12:20.522000", "dataset": "LL0_550_quake_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_550_quake", "about": {"problemID": "LL0_550_quake_problem", "problemName": "LL0_550_quake_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFile README\n-----------\n\nsmoothmeth  A collection of the data sets used in the book \"Smoothing\nMethods in Statistics,\" by Jeffrey S. Simonoff,\nSpringer-Verlag, New York, 1996. Submitted by Jeff\nSimonoff (jsimonoff@stern.nyu.edu).\n\n\nThis submission consists of 37 files, plus this README file.\nEach file represents a data set analyzed in the book.\nThe names of the files correspond to the names given in\nthe book. The data files are written in plain ASCII (character)\ntext. Missing values are represented by \"M\" in all data files.\n\nSeveral of the files include an alphabetic (labeling) variable. It is\nlikely that these files would have to be input into a package using fixed,\nrather than free, format. The relevant files, along with appropriate\nFortran format statements, are as follows:\n\nadptvisa.dat: (f10.4,4x,f7.4,3x,a20)\n\nairaccid.dat: (i3,3x,a34)\n\nbasesal.dat : (f8.1,4x,a17)\n\nbaskball.dat: (f7.4,4x,f6.4,3x,i3,4x,f5.2,3x,i2,3x,a17)\n\ncars93.dat  : (f5.1,2x,i2,2x,i2,3x,f3.1,2x,i3,3x,f4.1,2x,i4,2x,a21)\n\nelusage.dat : (i4,3x,f7.3,2x,a7)\n\nhckshoot.dat: (f7.3,4x,i1,4x,a20)\n\njantemp.dat : (i6,3x,a30)\n\nmarathon.dat: (f10.2,4x,a27)\n\nnewscirc.dat: (f8.2,3x,f7.2,2x,a25)\n\nracial.dat  : (f7.4,4x,a32)\n\nsafewatr.dat: (i5,3x,i3,3x,a26)\n\nschlvote.dat: (i3,4x,f5.2,2x,i8,4x,f4.1,5x,f5.2,2x,i7,2x,a25)\n\nDescription of data sources, and further information about the data sets,\ncan be found in the \"Descriptions of the data sets\" section of the book.\nPointing a World Wide Web browser to the URL\n\nhttp://www.stern.nyu.edu/SOR/SmoothMeth\n\nwill provide access to a site devoted to the book.\n\nNOTICE: These datasets may be used freely for scientific,\neducational and/or non-commercial purposes, provided suitable\nacknowledgment is given (by citing the reference above).\n\n\nFile: ../data/smoothmeth/quake.dat\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_550_quake_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "col_4"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-550-quake"}, "LL0_555_analcatdata_apnea3": {"pipeline": {"_id": "875a8383-7e51-48ca-8934-663b6670d049", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "auto", "max_depth": 15, "min_samples_split": 0.003965491530323182, "min_samples_leaf": 0.0010843766183715657, "n_estimators": 278}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "875a8383-7e51-48ca-8934-663b6670d049", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 815429.9805317493, "rank": 815429.9805317493, "metric": "meanSquaredError", "ts": "2018-10-24T21:07:58.838000", "dataset": "LL0_555_analcatdata_apnea3_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_555_analcatdata_apnea3", "about": {"problemID": "LL0_555_analcatdata_apnea3_problem", "problemName": "analcatdata_apnea3_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_555_analcatdata_apnea3_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Count"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-555-analcatdata-apnea3"}, "LL0_557_analcatdata_apnea1": {"pipeline": {"_id": "2da29bae-33bc-448b-8cf2-dfbf90f3b888", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 25}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 791, "max_depth": 7, "learning_rate": 0.9263120392992631, "gamma": 0.8287509582171559, "min_child_weight": 3}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "2da29bae-33bc-448b-8cf2-dfbf90f3b888", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 783022.268348448, "rank": 783022.268348448, "metric": "meanSquaredError", "ts": "2018-10-24T22:09:12.227000", "dataset": "LL0_557_analcatdata_apnea1_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_557_analcatdata_apnea1", "about": {"problemID": "LL0_557_analcatdata_apnea1_problem", "problemName": "analcatdata_apnea1_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nanalcatdata    A collection of data sets used in the book \"Analyzing Categorical Data,\"\nby Jeffrey S. Simonoff, Springer-Verlag, New York, 2003. The submission\nconsists of a zip file containing two versions of each of 84 data sets,\nplus this README file. Each data set is given in comma-delimited ASCII\n(.csv) form, and Microsoft Excel (.xls) form.\n\nNOTICE: These data sets may be used freely for scientific, educational and/or\nnoncommercial purposes, provided suitable acknowledgment is given (by citing\nthe above-named reference).\n\nFurther details concerning the book, including information on statistical software\n(including sample S-PLUS/R and SAS code), are available at the web site\n\nhttp://www.stern.nyu.edu/~jsimonof/AnalCatData\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last\n\n\nNote: Quotes, Single-Quotes and Backslashes were removed, Blanks replaced\nwith Underscores", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_557_analcatdata_apnea1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Count"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-557-analcatdata-apnea1"}, "LL0_558_bank32nh": {"pipeline": {"_id": "e59ff71c-3e3b-4ad9-b662-31e9c93b0656", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "e59ff71c-3e3b-4ad9-b662-31e9c93b0656", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.007004379354280799, "rank": 0.007004379355070319, "metric": "meanSquaredError", "ts": "2018-10-31T04:09:20.287000", "dataset": "LL0_558_bank32nh_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_558_bank32nh", "about": {"problemID": "LL0_558_bank32nh_problem", "problemName": "LL0_558_bank32nh_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nA family of datasets synthetically generated from a simulation of how bank-customers choose their banks. Tasks are\nbased on predicting the fraction of bank customers who leave the bank because of full queues. The bank family of\ndatasets are generated from a simplistic simulator, which simulates the queues in a series of banks. The simulator was\nconstructed with the explicit purpose of generating a family of datasets for DELVE. Customers come from several\nresidential areas, choose their preferred bank depending on distances and have tasks of varying complexity, and various\nlevels of patience. Each bank has several queues, that open and close according to demand. The tellers have various\neffectivities, and customers may change queue, if their patience expires. In the rej prototasks, the object is to predict the\nrate of rejections, ie the fraction of customers that are turned away from the bank because all the open tellers have full\nqueues.\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nOrginal source: DELVE repository of data.\nCharacteristics: Data set contains 8192 (4500+3692) cases. and 33 continuous\nattributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_558_bank32nh_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 33, "colName": "rej"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-558-bank32nh"}, "LL0_55_hepatitis": {"pipeline": {"_id": "8d594a6f-168a-45d3-8178-6240a7b456cc", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 71}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 718, "max_depth": 4, "learning_rate": 0.16493021768603944, "gamma": 0.09641578538287565, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "8d594a6f-168a-45d3-8178-6240a7b456cc", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8744100447196421, "rank": 0.12558995528086733, "metric": "f1Macro", "ts": "2018-10-25T00:32:36.992000", "dataset": "LL0_55_hepatitis_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_55_hepatitis", "about": {"problemID": "LL0_55_hepatitis_problem", "problemName": "hepatitis_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Hepatitis Domain\n \n 2. Sources:\n      (a) unknown\n      (b) Donor: G.Gong  (Carnegie-Mellon University) via \n                    Bojan Cestnik\n                    Jozef Stefan Institute\n                    Jamova 39\n                    61000 Ljubljana\n                    Yugoslavia (tel.: (38)(+61) 214-399 ext.287) }\n      (c) Date: November, 1988\n \n 3. Past Usage:\n     1. Diaconis,P. & Efron,B. (1983).  Computer-Intensive Methods in \n        Statistics.  Scientific American, Volume 248.\n        -- Gail Gong reported a 80% classfication accuracy\n     2. Cestnik,G., Konenenko,I, & Bratko,I. (1987). Assistant-86: A\n        Knowledge-Elicitation Tool for Sophisticated Users.  In I.Bratko\n        & N.Lavrac (Eds.) Progress in Machine Learning, 31-45, Sigma Press.\n        -- Assistant-86: 83% accuracy\n \n 4. Relevant Information:\n     Please ask Gail Gong for further information on this database.\n \n 5. Number of Instances: 155\n \n 6. Number of Attributes: 20 (including the class attribute)\n \n 7. Attribute information: \n      1. Class: DIE, LIVE\n      2. AGE: 10, 20, 30, 40, 50, 60, 70, 80\n      3. SEX: male, female\n      4. STEROID: no, yes\n      5. ANTIVIRALS: no, yes\n      6. FATIGUE: no, yes\n      7. MALAISE: no, yes\n      8. ANOREXIA: no, yes\n      9. LIVER BIG: no, yes\n     10. LIVER FIRM: no, yes\n     11. SPLEEN PALPABLE: no, yes\n     12. SPIDERS: no, yes\n     13. ASCITES: no, yes\n     14. VARICES: no, yes\n     15. BILIRUBIN: 0.39, 0.80, 1.20, 2.00, 3.00, 4.00\n         -- see the note below\n     16. ALK PHOSPHATE: 33, 80, 120, 160, 200, 250\n     17. SGOT: 13, 100, 200, 300, 400, 500, \n     18. ALBUMIN: 2.1, 3.0, 3.8, 4.5, 5.0, 6.0\n     19. PROTIME: 10, 20, 30, 40, 50, 60, 70, 80, 90\n     20. HISTOLOGY: no, yes\n \n     The BILIRUBIN attribute appears to be continuously-valued.  I checked\n     this with the donater, Bojan Cestnik, who replied:\n \n       About the hepatitis database and BILIRUBIN problem I would like to say\n       the following: BILIRUBIN is continuous attribute (= the number of it's\n       \"values\" in the ASDOHEPA.DAT file is negative!!!); \"values\" are quoted\n       because when speaking about the continuous attribute there is no such \n       thing as all possible values. However, they represent so called\n       \"boundary\" values; according to these \"boundary\" values the attribute\n       can be discretized. At the same time, because of the continious\n       attribute, one can perform some other test since the continuous\n       information is preserved. I hope that these lines have at least roughly \n       answered your question. \n \n 8. Missing Attribute Values: (indicated by \"?\")\n      Attribute Number:    Number of Missing Values:\n                     1:    0\n                     2:    0\n                     3:    0\n                     4:    1\n                     5:    0\n                     6:    1\n                     7:    1\n                     8:    1\n                     9:    10\n                    10:    11\n                    11:    5\n                    12:    5\n                    13:    5\n                    14:    5\n                    15:    6\n                    16:    29\n                    17:    4\n                    18:    16\n                    19:    67\n                    20:    0\n \n 9. Class Distribution:\n      DIE: 32\n     LIVE: 123\n \n \n\n\n\n\n Relabeled values in attribute SEX\n    From: 2                       To: male                \n    From: 1                       To: female              \n\n\n Relabeled values in attribute STEROID\n    From: 1                       To: no                  \n    From: 2                       To: yes                 \n\n\n Relabeled values in attribute ANTIVIRALS\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute FATIGUE\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute MALAISE\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute ANOREXIA\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute LIVER_BIG\n    From: 1                       To: no                  \n    From: 2                       To: yes                 \n\n\n Relabeled values in attribute LIVER_FIRM\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute SPLEEN_PALPABLE\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute SPIDERS\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute ASCITES\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute VARICES\n    From: 2                       To: no                  \n    From: 1                       To: yes                 \n\n\n Relabeled values in attribute HISTOLOGY\n    From: 1                       To: no                  \n    From: 2                       To: yes", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_55_hepatitis_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 20, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-55-hepatitis"}, "LL0_560_bodyfat": {"pipeline": {"_id": "d15a40b5-a8d0-4423-8c86-23bb4f258bc5", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 28, "min_samples_split": 0.013994143689669005, "min_samples_leaf": 0.0025091044831553944, "n_estimators": 35}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "d15a40b5-a8d0-4423-8c86-23bb4f258bc5", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.19218471977178, "rank": 2.1921847197725106, "metric": "meanSquaredError", "ts": "2018-10-24T20:26:20.700000", "dataset": "LL0_560_bodyfat_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_560_bodyfat", "about": {"problemID": "LL0_560_bodyfat_problem", "problemName": "bodyfat_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nShort Summary:\nLists estimates of the percentage of body fat determined by underwater\nweighing and various body circumference measurements for 252 men.\n\nClassroom use of this data set:\nThis data set can be used to illustrate multiple regression techniques.\nAccurate measurement of body fat is inconvenient/costly and it is\ndesirable to have easy methods of estimating body fat that are not\ninconvenient/costly.\n\nMore Details:\nA variety of popular health books suggest that the readers assess their\nhealth, at least in part, by estimating their percentage of body fat. In\nBailey (1994), for instance, the reader can estimate body fat from tables\nusing their age and various skin-fold measurements obtained by using a\ncaliper. Other texts give predictive equations for body fat using body\ncircumference measurements (e.g. abdominal circumference) and/or skin-fold\nmeasurements. See, for instance, Behnke and Wilmore (1974), pp. 66-67;\nWilmore (1976), p. 247; or Katch and McArdle (1977), pp. 120-132).\n\nPercentage of body fat for an individual can be estimated once body density\nhas been determined. Folks (e.g. Siri (1956)) assume that the body consists\nof two components - lean body tissue and fat tissue. Letting\n\nD = Body Density (gm/cm^3)\nA = proportion of lean body tissue\nB = proportion of fat tissue (A+B=1)\na = density of lean body tissue (gm/cm^3)\nb = density of fat tissue (gm/cm^3)\n\nwe have\n\nD = 1/[(A/a) + (B/b)]\n\nsolving for B we find\n\nB = (1/D)*[ab/(a-b)] - [b/(a-b)].\n\nUsing the estimates a=1.10 gm/cm^3 and b=0.90 gm/cm^3 (see Katch and McArdle\n(1977), p. 111 or Wilmore (1976), p. 123) we come up with \"Siri's equation\":\n\nPercentage of Body Fat (i.e. 100*B) = 495/D - 450.\n\nVolume, and hence body density, can be accurately measured a variety of ways.\nThe technique of underwater weighing \"computes body volume as the difference\nbetween body weight measured in air and weight measured during water\nsubmersion. In other words, body volume is equal to the loss of weight in\nwater with the appropriate temperature correction for the water's density\"\n(Katch and McArdle (1977), p. 113). Using this technique,\n\nBody Density = WA/[(WA-WW)/c.f. - LV]\n\nwhere\n\nWA = Weight in air (kg)\nWW = Weight in water (kg)\nc.f. = Water correction factor (=1 at 39.2 deg F as one-gram of water\noccupies exactly one cm^3 at this temperature, =.997 at 76-78 deg F)\nLV = Residual Lung Volume (liters)\n\n(Katch and McArdle (1977), p. 115). Other methods of determining body volume\nare given in Behnke and Wilmore (1974), p. 22 ff.\n\n\nThe variables listed below, from left to right, are:\n\nDensity determined from underwater weighing\nPercent body fat from Siri's (1956) equation\nAge (years)\nWeight (lbs)\nHeight (inches)\nNeck circumference (cm)\nChest circumference (cm)\nAbdomen 2 circumference (cm)\nHip circumference (cm)\nThigh circumference (cm)\nKnee circumference (cm)\nAnkle circumference (cm)\nBiceps (extended) circumference (cm)\nForearm circumference (cm)\nWrist circumference (cm)\n\n(Measurement standards are apparently those listed in Benhke and Wilmore\n(1974), pp. 45-48 where, for instance, the abdomen 2 circumference is\nmeasured \"laterally, at the level of the iliac crests, and anteriorly, at\nthe umbilicus\".)\n\nThese data are used to produce the predictive equations for lean\nbody weight given in the abstract \"Generalized body composition prediction\nequation for men using simple measurement techniques\", K.W. Penrose, A.G.\nNelson, A.G. Fisher, FACSM, Human Performance Research Center, Brigham Young\nUniversity, Provo, Utah  84602 as listed in _Medicine and Science in Sports\nand Exercise_, vol. 17, no. 2, April 1985, p. 189. (The predictive equations\nwere obtained from the first 143 of the 252 cases that are listed below).\nThe data were generously supplied by Dr. A. Garth Fisher who gave permission to\nfreely distribute the data and use for non-commercial purposes.\n\nReferences:\n\nBailey, Covert (1994). _Smart Exercise: Burning Fat, Getting Fit_,\nHoughton-Mifflin Co., Boston, pp. 179-186.\n\nBehnke, A.R. and Wilmore, J.H. (1974). _Evaluation and Regulation of Body\nBuild and Composition_, Prentice-Hall, Englewood Cliffs, N.J.\n\nSiri, W.E. (1956), \"Gross composition of the body\", in _Advances in\nBiological and Medical Physics_, vol. IV, edited by J.H. Lawrence and C.A.\nTobias, Academic Press, Inc., New York.\n\nKatch, Frank and McArdle, William (1977). _Nutrition, Weight Control, and\nExercise_, Houghton Mifflin Co., Boston.\n\nWilmore, Jack (1976). _Athletic Training and Physical Fitness: Physiological\nPrinciples of the Conditioning Process_, Allyn and Bacon, Inc., Boston.\n\n\n\nRoger W. Johnson\nDepartment of Mathematics & Computer Science\nSouth Dakota School of Mines & Technology\n501 East St. Joseph Street\nRapid City, SD  57701\n\nemail address: rwjohnso@silver.sdsmt.edu\nweb address: http://silver.sdsmt.edu/~rwjohnso\n\n\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_560_bodyfat_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 15, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-560-bodyfat"}, "LL0_562_cpu_small": {"pipeline": {"_id": "3fa5d2f6-e815-454c-85ce-7066660dc803", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 94}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 669, "max_depth": 10, "learning_rate": 0.020940812925960284, "gamma": 0.7105971804275552, "min_child_weight": 10}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "3fa5d2f6-e815-454c-85ce-7066660dc803", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 7.307001247057957, "rank": 7.307001247058006, "metric": "meanSquaredError", "ts": "2018-10-24T20:40:09.869000", "dataset": "LL0_562_cpu_small_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_562_cpu_small", "about": {"problemID": "LL0_562_cpu_small_problem", "problemName": "LL0_562_cpu_small_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe Computer Activity databases are a collection of computer systems\nactivity measures. The data was collected from a Sun Sparcstation\n20/712 with 128 Mbytes of memory running in a multi-user university\ndepartment. Users would typically be doing a large variety of tasks\nranging from accessing the internet, editing files or running very\ncpu-bound programs.  The data was collected continuously on two\nseparate occasions. On both occassions, system activity was gathered\nevery 5 seconds. The final dataset is taken from both occasions with\nequal numbers of observations coming from each collection epoch.\n\nSystem measures used:\n1. lread - Reads (transfers per second ) between system memory and user memory.\n2. lwrite - writes (transfers per second) between system memory and user memory.\n3. scall - Number of system calls of all types per second.\n4. sread - Number of system read calls per second.\n5. swrite - Number of system write calls per second .\n6. fork - Number of system fork calls per second.\n7. exec - Number of system exec calls per second.\n8. rchar - Number of characters transferred per second by system read calls.\n9. wchar - Number of characters transfreed per second by system write calls.\n10. pgout - Number of page out requests per second.\n11. ppgout - Number of pages, paged out per second.\n12. pgfree - Number of pages per second placed on the free list.\n13. pgscan - Number of pages checked if they can be freed per second.\n14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.\n15. pgin - Number of page-in requests per second.\n16. ppgin - Number of pages paged in per second.\n17. pflt - Number of page faults caused by protection errors (copy-on-writes).\n18. vflt - Number of page faults caused by address translation.\n19. runqsz - Process run queue size.\n20. freemem - Number of memory pages available to user processes.\n21. freeswap - Number of disk blocks available for page swapping.\n22. usr - Portion of time (%) that cpus run in user mode.\n23. sys - Portion of time (%) that cpus run in system mode.\n24. wio - Portion of time (%) that cpus are idle waiting for block IO.\n25. idle - Portion of time (%) that cpus are otherwise idle.\n\nThe two different regression tasks obtained from these databases are:\n\nCompAct\nPredict usr, the portion of time that cpus run in user mode from all attributes 1-21.\n\nCompAct(s)\nPredict usr using a restricted number (excluding the paging information (10-18)\n\nOriginal source: DELVE repository of data.\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nCharacteristics: 8192 cases, 13 continuous attributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_562_cpu_small_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "usr"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-562-cpu-small"}, "LL0_567_kdd_coil_1": {"pipeline": {"_id": "b1de5e11-075d-4f18-a53b-a2e74c09c7fe", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 19}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 17, "min_samples_split": 0.05181347297806612, "min_samples_leaf": 0.023722110618368195, "n_estimators": 447}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "b1de5e11-075d-4f18-a53b-a2e74c09c7fe", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 262.65038747834143, "rank": 262.6503874783418, "metric": "meanSquaredError", "ts": "2018-10-24T21:03:28.145000", "dataset": "LL0_567_kdd_coil_1_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_567_kdd_coil_1", "about": {"problemID": "LL0_567_kdd_coil_1_problem", "problemName": "LL0_567_kdd_coil_1_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\n%%%%%%%%%%%%%%%%%%%\nData-Description %\n%%%%%%%%%%%%%%%%%%%\n\nCOIL 1999 Competition Data\n\nData Type\n\nmultivariate\n\nAbstract\n\nThis data set is from the 1999 Computational Intelligence and Learning\n(COIL) competition. The data contains measurements of river chemical\nconcentrations and algae densities.\n\nSources\n\nOriginal Owner\n\n[1]ERUDIT\nEuropean Network for Fuzzy Logic and Uncertainty Modelling\nin Information Technology\n\nDonor\n\nJens Strackeljan\nTechnical University Clausthal\nInstitute of Applied Mechanics\nGraupenstr. 3, 38678 Clausthal-Zellerfeld, Germany\n[2]tmjs@itm.tu-clausthal.de\n\nDate Donated: September 9, 1999\n\nData Characteristics\n\nThis data comes from a water quality study where samples were taken\nfrom sites on different European rivers of a period of approximately\none year. These samples were analyzed for various chemical substances\nincluding: nitrogen in the form of nitrates, nitrites and ammonia,\nphosphate, pH, oxygen, chloride. In parallel, algae samples were\ncollected to determine the algae population distributions.\n\nOther Relevant Information\n\nThe competition involved the prediction of algal frequency\ndistributions on the basis of the measured concentrations of the\nchemical substances and the global information concerning the season\nwhen the sample was taken, the river size and its flow velocity. The\ncompetition [3]instructions contain additional information on the\nprediction task.\n\nData Format\n\nThere are a total of 340 examples each containing 17 values. The first\n11 values of each data set are the season, the river size, the fluid\nvelocity and 8 chemical concentrations which should be relevant for\nthe algae population distribution. The last 8 values of each example\nare the distribution of different kinds of algae. These 8 kinds are\nonly a very small part of the whole community, but for the competition\nwe limited the number to 7. The value 0.0 means that the frequency is\nvery low. The data set also contains some empty fields which are\nlabeled with the string XXXXX.\n\nThe training data are saved in the file: analysis.data (ASCII format).\n\nTable 1: Structure of the file analysis.data\n\nA\n\n\nK\n\na\n\n\ng\n\nCC[1,1]\n\n\nCC[1,11]\n\nAG[1,1]\n\n\nAG[1,7]\n\nCC[200,1]\n\n\nCC[200,11]\n\nAG[200,1]\n\n\nAG[200,7]\n\nExplanation:\nCC[i,j]: Chemical concentration or river characteristic\nAG[i,j]: Algal frequency\n\nThe chemical parameters are labeled as A, ..., K. The columns of the\nalgaes are labeled as a, ..,g.\n\nPast Usage\n\n[4]The Third (1999) International COIL Competition Home Page\n_________________________________________________________________\n\n\n[5]The UCI KDD Archive\n[6]Information and Computer Science\n[7]University of California, Irvine\nIrvine, CA 92697-3425\n\nLast modified: October 13, 1999\n\nReferences\n\n1. http://www.erudit.de/\n2. mailto:tmjs@itm.tu-clausthal.de\n3. file://localhost/research/ml/datasets/uci/raw/data/ucikdd/coil/instructions.txt\n4. http://www.erudit.de/erudit/activities/ic-99/index.htm\n5. http://kdd.ics.uci.edu/\n6. http://www.ics.uci.edu/\n7. http://www.uci.edu/\n\n%%%%%%%%%%%%%%%%%%%\nTask-Description %\n%%%%%%%%%%%%%%%%%%%\n\n\nThird International Competition\n\nProtecting rivers and streams by monitoring chemical concentrations and\nalgae communities.\n\n\nIntelligent Techniques for Monitoring Water Quality using chemical\nindicators and algae population\n\nRecent years have been characterised by increasing concern at the\nimpact man is having on the environment.\nThe impact on the environment of toxic waste, from a wide variety\nof manufacturing processes, is well known. More recently, however,\nit has become clear that the more subtle effects of nutrient level\nand chemical balance changes arising from farming land run-off and\nsewage water treatment also have a serious, but indirect, effect on\nthe states of rivers, lakes and even the sea.  In temperate climates\nacross the world summers are characterized by numerous reports excessive\nsummer algae growth resulting in poor water clarity, mass deaths of\nriver fish from reduced oxygen levels and the closure of recreational\nwater facilities on account of the toxic effects of this annual algal bloom.\nReducing the impact of these man-made changes in river nutrient levels\nhas stimulated much biological research with the aim of identifying\nthe crucial chemical control variables for the biological\nprocesses.\n\nThe data used in this problem comes from one such study.\nDuring the research study water quality samples were\ntaken from sites on different European rivers of a period of\napproximately one year.  These samples were analyzed for various\nchemical substances including: nitrogen in the form of nitrates,\nnitrites and ammonia, phosphate, pH, oxygen, chloride.\nIn parallel, algae samples were collected to determine the algae population\ndistributions. It is well known that the dynamics of the\nalgae community is determined by external chemical\nenvironment with one or more factors being predominant.\nWhile the chemical analysis is cheap and easily\nautomated, the biological part involves microscopic examination,\nrequires trained manpower and is therefore both\nexpensive and slow.\n\nDiatoms like Cymbella are major contributors to primary production\nthroughout the world. The diatom reacts with\nlarge sensitivity to even small changes in acidity .\n\nOver a three and half billion year history algae have evolved and\nadapted as primary plant colonizers of almost\nevery known habitant in terrestrial and aquatic environments.\nThey respond very rapidly to man-made environment changes.\n\n\n\nThe relationship between the chemical and biological features is\ncomplex and can be expected to need the application of advanced\ntechniques. Typical of such real-life problems, the particular\ndata set for the problem contains a mixture of (fuzzy) qualiative\nvariables and numerical measurement values, with much of the data\nbeing incomplete.\n\nThe competition task is the prediction of algal frequency distributions\non the basis of  the measured concentrations of the chemical\nsubstances and the global information concerning the season when the sample\nwas taken, the river size and its flow velocity. The two last variables\nare given as linguistic variables.\n\n340 data sets were taken and each contain 17 values. The\nfirst 11 values of each data set are the season, the river\nsize, the fluid velocity and 8 chemical concentrations which\nshould be relevant for the algae population distribution.\nThe last 8 values of each data set are the distribution of\ndifferent kinds of algae. These 8 kinds are only a very small\npart of the whole community, but for the competition we limited\nthe number to 7. The value 0.0 means that the frequency is very low.\nThe data set also contains some empty fields which are labeled\nwith the string XXXXX.\n\nEach participant in the competition receives 200 complete data sets\n(training data) and 140 data sets (evaluation data) containing only\nthe 11 values of the river descriptions and the chemical concentrations.\n\nThis training data is to be used in obtainin\na 'model' providing a prediction of the algal distributions associated\nwith the evaluation data.\n\n\n\nThe training data are saved in the file:\n\nanalysis.txt (ASCII format).\n\nStructure of the file analysis.txt\n\nA                          K              a                   g\nCC1,1   ...                CC1,11         AG1,1    ...        AG1,7\n....                        ...            ...                 ...\n\n\nCC200,1 ...                CC200,11       AG240,1  ...        AG240,7\n\n\nExplanation:\nCCi,j:  Chemical concentration    j=1,..11\nAGi,k: Algal frequency            k=1...7\n\n\nThe chemical parameters are labeled as A, ..., K.\nThe columns of the algaes are labeled as a, ..,g.\n\n\nEvaluation data are saved in file eval.txt (ASCII format).\n\n\nTable 2: Structure of the file eval.*\nA                               K\nCC1,1     ...                   CC1,11\n\n.....                            ...\n\nCC140,1   ...                   CC140,11\n\n_____________________________________________________________\n\nObjective\n\nThe objective of the competition is to provide a prediction\nmodel on basis of the training data. Having obtained this\nprediction model, each participant must provide the solution\nin the form of the results of applying this model to the\nevaluation data. The results obtained in this way should\ncorrespond to the results of the evaluation data\n(which are known to the organizer). The criteria used to evaluate\nthe results is given below.\nAll 7 Algae frequency distributions must be determined.\nFor this purpose any number of partial models may be developed.\n\n_____________________________________________________________\n\nJudgment of the results\n\nTo judge the results, the sum of squared errors will be calculated.\nThe following Table describes the results of a particular participant.\n\nMatrix of results\na                     g\n\nRes1,1   ...          Res1,7\n\n....                   ...\n\nRes140,1              Res140,7\n\n\nAll solutions that lead to a smallest total error will\nbe regarded as winner of the contest.\n\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: last\n\nALGAE #: 1/7", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_567_kdd_coil_1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 12, "colName": "algae_1"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-567-kdd-coil-1"}, "LL0_56_vote": {"pipeline": {"_id": "c4483f01-0a26-4c55-9372-7178568f914c", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 36}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 477, "max_depth": 4, "learning_rate": 0.857686118202689, "gamma": 0.8594954830878844, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "c4483f01-0a26-4c55-9372-7178568f914c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.956805866119289, "rank": 0.043194133881545395, "metric": "f1Macro", "ts": "2018-10-25T00:47:05.635000", "dataset": "LL0_56_vote_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_56_vote", "about": {"problemID": "LL0_56_vote_problem", "problemName": "LL0_56_vote_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: 1984 United States Congressional Voting Records Database\n \n 2. Source Information:\n     (a) Source:  Congressional Quarterly Almanac, 98th Congress, \n                  2nd session 1984, Volume XL: Congressional Quarterly Inc. \n                  Washington, D.C., 1985.\n     (b) Donor: Jeff Schlimmer (Jeffrey.Schlimmer@a.gp.cs.cmu.edu)\n     (c) Date: 27 April 1987 \n \n 3. Past Usage\n    - Publications\n      1. Schlimmer, J. C. (1987).  Concept acquisition through \n         representational adjustment.  Doctoral dissertation, Department of \n         Information and Computer Science, University of California, Irvine, CA.\n         -- Results: about 90%-95% accuracy appears to be STAGGER's asymptote\n      - Predicted attribute: party affiliation (2 classes)\n \n 4. Relevant Information:\n       This data set includes votes for each of the U.S. House of\n       Representatives Congressmen on the 16 key votes identified by the\n       CQA.  The CQA lists nine different types of votes: voted for, paired\n       for, and announced for (these three simplified to yea), voted\n       against, paired against, and announced against (these three\n       simplified to nay), voted present, voted present to avoid conflict\n       of interest, and did not vote or otherwise make a position known\n       (these three simplified to an unknown disposition).\n \n 5. Number of Instances: 435 (267 democrats, 168 republicans)\n \n 6. Number of Attributes: 16 + class name = 17 (all Boolean valued)\n \n 7. Attribute Information:\n    1. Class Name: 2 (democrat, republican)\n    2. handicapped-infants: 2 (y,n)\n    3. water-project-cost-sharing: 2 (y,n)\n    4. adoption-of-the-budget-resolution: 2 (y,n)\n    5. physician-fee-freeze: 2 (y,n)\n    6. el-salvador-aid: 2 (y,n)\n    7. religious-groups-in-schools: 2 (y,n)\n    8. anti-satellite-test-ban: 2 (y,n)\n    9. aid-to-nicaraguan-contras: 2 (y,n)\n   10. mx-missile: 2 (y,n)\n   11. immigration: 2 (y,n)\n   12. synfuels-corporation-cutback: 2 (y,n)\n   13. education-spending: 2 (y,n)\n   14. superfund-right-to-sue: 2 (y,n)\n   15. crime: 2 (y,n)\n   16. duty-free-exports: 2 (y,n)\n   17. export-administration-act-south-africa: 2 (y,n)\n \n 8. Missing Attribute Values: Denoted by \"?\"\n \n    NOTE: It is important to recognize that \"?\" in this database does \n          not mean that the value of the attribute is unknown.  It \n          means simply, that the value is not \"yea\" or \"nay\" (see \n          \"Relevant Information\" section above).\n \n    Attribute:  #Missing Values:\n            1:  0\n            2:  0\n            3:  12\n            4:  48\n            5:  11\n            6:  11\n            7:  15\n            8:  11\n            9:  14\n           10:  15\n           11:  22\n           12:  7\n           13:  21\n           14:  31\n           15:  25\n           16:  17\n           17:  28\n \n 9. Class Distribution: (2 classes)\n    1. 45.2 percent are democrat\n    2. 54.8 percent are republican\n \n Class predictiveness and predictability: Pr(C|A=V) and Pr(A=V|C)\n  Attribute 1: (A = handicapped-infants)\n   0.91;  1.21  (C=democrat; V=y)\n   0.09;  0.10  (C=republican; V=y)\n   0.43;  0.38  (C=democrat; V=n)\n   0.57;  0.41  (C=republican; V=n)\n   0.75;  0.03  (C=democrat; V=?)\n   0.25;  0.01  (C=republican; V=?)\n  Attribute 2: (A = water-project-cost-sharing)\n   0.62;  0.45  (C=democrat; V=y)\n   0.38;  0.23  (C=republican; V=y)\n   0.62;  0.45  (C=democrat; V=n)\n   0.38;  0.23  (C=republican; V=n)\n   0.58;  0.10  (C=democrat; V=?)\n   0.42;  0.06  (C=republican; V=?)\n  Attribute 3: (A = adoption-of-the-budget-resolution)\n   0.91;  0.87  (C=democrat; V=y)\n   0.09;  0.07  (C=republican; V=y)\n   0.17;  0.11  (C=democrat; V=n)\n   0.83;  0.44  (C=republican; V=n)\n   0.64;  0.03  (C=democrat; V=?)\n   0.36;  0.01  (C=republican; V=?)\n  Attribute 4: (A = physician-fee-freeze)\n   0.08;  0.05  (C=democrat; V=y)\n   0.92;  0.50  (C=republican; V=y)\n   0.99;  0.92  (C=democrat; V=n)\n   0.01;  0.01  (C=republican; V=n)\n   0.73;  0.03  (C=democrat; V=?)\n   0.27;  0.01  (C=republican; V=?)\n  Attribute 5: (A = el-salvador-aid)\n   0.26;  0.21  (C=democrat; V=y)\n   0.74;  0.48  (C=republican; V=y)\n   0.96;  0.75  (C=democrat; V=n)\n   0.04;  0.02  (C=republican; V=n)\n   0.80;  0.04  (C=democrat; V=?)\n   0.20;  0.01  (C=republican; V=?)\n  Attribute 6: (A = religious-groups-in-schools)\n   0.45;  0.46  (C=democrat; V=y)\n   0.55;  0.46  (C=republican; V=y)\n   0.89;  0.51  (C=democrat; V=n)\n   0.11;  0.05  (C=republican; V=n)\n   0.82;  0.03  (C=democrat; V=?)\n   0.18;  0.01  (C=republican; V=?)\n  Attribute 7: (A = anti-satellite-test-ban)\n   0.84;  0.75  (C=democrat; V=y)\n   0.16;  0.12  (C=republican; V=y)\n   0.32;  0.22  (C=democrat; V=n)\n   0.68;  0.38  (C=republican; V=n)\n   0.57;  0.03  (C=democrat; V=?)\n   0.43;  0.02  (C=republican; V=?)\n  Attribute 8: (A = aid-to-nicaraguan-contras)\n   0.90;  0.82  (C=democrat; V=y)\n   0.10;  0.07  (C=republican; V=y)\n   0.25;  0.17  (C=democrat; V=n)\n   0.75;  0.41  (C=republican; V=n)\n   0.27;  0.01  (C=democrat; V=?)\n   0.73;  0.03  (C=republican; V=?)\n  Attribute 9: (A = mx-missile)\n   0.91;  0.70  (C=democrat; V=y)\n   0.09;  0.06  (C=republican; V=y)\n   0.29;  0.22  (C=democrat; V=n)\n   0.71;  0.45  (C=republican; V=n)\n   0.86;  0.07  (C=democrat; V=?)\n   0.14;  0.01  (C=republican; V=?)\n  Attribute 10: (A = immigration)\n   0.57;  0.46  (C=democrat; V=y)\n   0.43;  0.28  (C=republican; V=y)\n   0.66;  0.52  (C=democrat; V=n)\n   0.34;  0.23  (C=republican; V=n)\n   0.57;  0.01  (C=democrat; V=?)\n   0.43;  0.01  (C=republican; V=?)\n  Attribute 11: (A = synfuels-corporation-cutback)\n   0.86;  0.48  (C=democrat; V=y)\n   0.14;  0.06  (C=republican; V=y)\n   0.48;  0.47  (C=democrat; V=n)\n   0.52;  0.43  (C=republican; V=n)\n   0.57;  0.04  (C=democrat; V=?)\n   0.43;  0.03  (C=republican; V=?)\n  Attribute 12: (A = education-spending)\n   0.21;  0.13  (C=democrat; V=y)\n   0.79;  0.42  (C=republican; V=y)\n   0.91;  0.80  (C=democrat; V=n)\n   0.09;  0.06  (C=republican; V=n)\n   0.58;  0.07  (C=democrat; V=?)\n   0.42;  0.04  (C=republican; V=?)\n  Attribute 13: (A = superfund-right-to-sue)\n   0.35;  0.27  (C=democrat; V=y)\n   0.65;  0.42  (C=republican; V=y)\n   0.89;  0.67  (C=democrat; V=n)\n   0.11;  0.07  (C=republican; V=n)\n   0.60;  0.06  (C=democrat; V=?)\n   0.40;  0.03  (C=republican; V=?)\n  Attribute 14: (A = crime)\n   0.36;  0.34  (C=democrat; V=y)\n   0.64;  0.49  (C=republican; V=y)\n   0.98;  0.63  (C=democrat; V=n)\n   0.02;  0.01  (C=republican; V=n)\n   0.59;  0.04  (C=democrat; V=?)\n   0.41;  0.02  (C=republican; V=?)\n  Attribute 15: (A = duty-free-exports)\n   0.92;  0.60  (C=democrat; V=y)\n   0.08;  0.04  (C=republican; V=y)\n   0.39;  0.34  (C=democrat; V=n)\n   0.61;  0.44  (C=republican; V=n)\n   0.57;  0.06  (C=democrat; V=?)\n   0.43;  0.04  (C=republican; V=?)\n  Attribute 16: (A = export-administration-act-south-africa)\n   0.64;  0.65  (C=democrat; V=y)\n   0.36;  0.30  (C=republican; V=y)\n   0.19;  0.04  (C=democrat; V=n)\n   0.81;  0.15  (C=republican; V=n)\n   0.79;  0.31  (C=democrat; V=?)\n   0.21;  0.07  (C=republican; V=?)", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_56_vote_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 17, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-56-vote"}, "LL0_572_bank8fm": {"pipeline": {"_id": "324b8c1a-847a-4cce-8d1b-afbf64c60d84", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 29}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 936, "max_depth": 6, "learning_rate": 0.2127187081862124, "gamma": 0.0023440295041275983, "min_child_weight": 4}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "324b8c1a-847a-4cce-8d1b-afbf64c60d84", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.0009203897866721874, "rank": 0.0009203897870396929, "metric": "meanSquaredError", "ts": "2018-10-24T20:52:29.903000", "dataset": "LL0_572_bank8fm_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_572_bank8fm", "about": {"problemID": "LL0_572_bank8fm_problem", "problemName": "LL0_572_bank8fm_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nA family of datasets synthetically generated from a simulation of how bank-customers choose their banks. Tasks are\nbased on predicting the fraction of bank customers who leave the bank because of full queues. The bank family of\ndatasets are generated from a simplistic simulator, which simulates the queues in a series of banks. The simulator was\nconstructed with the explicit purpose of generating a family of datasets for DELVE. Customers come from several\nresidential areas, choose their preferred bank depending on distances and have tasks of varying complexity, and various\nlevels of patience. Each bank has several queues, that open and close according to demand. The tellers have various\neffectivities, and customers may change queue, if their patience expires. In the rej prototasks, the object is to predict the\nrate of rejections, ie the fraction of customers that are turned away from the bank because all the open tellers have full\nqueues.\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nOrginal source: DELVE repository of data.\nCharacteristics: Data set contains 8192 (4500+3692) cases. and 9 continuous\nattributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_572_bank8fm_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 9, "colName": "rej"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-572-bank8fm"}, "LL0_573_cpu_act": {"pipeline": {"_id": "0cedf212-7bb6-4404-aedb-7638fb811a44", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 91}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 702, "max_depth": 8, "learning_rate": 0.024300953984378815, "gamma": 0.8863136276919128, "min_child_weight": 9}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "0cedf212-7bb6-4404-aedb-7638fb811a44", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 5.412540800985417, "rank": 5.412540800985856, "metric": "meanSquaredError", "ts": "2018-10-24T21:55:51.371000", "dataset": "LL0_573_cpu_act_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_573_cpu_act", "about": {"problemID": "LL0_573_cpu_act_problem", "problemName": "LL0_573_cpu_act_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThe Computer Activity databases are a collection of computer systems\nactivity measures. The data was collected from a Sun Sparcstation\n20/712 with 128 Mbytes of memory running in a multi-user university\ndepartment. Users would typically be doing a large variety of tasks\nranging from accessing the internet, editing files or running very\ncpu-bound programs.  The data was collected continuously on two\nseparate occasions. On both occassions, system activity was gathered\nevery 5 seconds. The final dataset is taken from both occasions with\nequal numbers of observations coming from each collection epoch.\n\nSystem measures used:\n1. lread - Reads (transfers per second ) between system memory and user memory.\n2. lwrite - writes (transfers per second) between system memory and user memory.\n3. scall - Number of system calls of all types per second.\n4. sread - Number of system read calls per second.\n5. swrite - Number of system write calls per second .\n6. fork - Number of system fork calls per second.\n7. exec - Number of system exec calls per second.\n8. rchar - Number of characters transferred per second by system read calls.\n9. wchar - Number of characters transfreed per second by system write calls.\n10. pgout - Number of page out requests per second.\n11. ppgout - Number of pages, paged out per second.\n12. pgfree - Number of pages per second placed on the free list.\n13. pgscan - Number of pages checked if they can be freed per second.\n14. atch - Number of page attaches (satisfying a page fault by reclaiming a page in memory) per second.\n15. pgin - Number of page-in requests per second.\n16. ppgin - Number of pages paged in per second.\n17. pflt - Number of page faults caused by protection errors (copy-on-writes).\n18. vflt - Number of page faults caused by address translation.\n19. runqsz - Process run queue size.\n20. freemem - Number of memory pages available to user processes.\n21. freeswap - Number of disk blocks available for page swapping.\n22. usr - Portion of time (%) that cpus run in user mode.\n23. sys - Portion of time (%) that cpus run in system mode.\n24. wio - Portion of time (%) that cpus are idle waiting for block IO.\n25. idle - Portion of time (%) that cpus are otherwise idle.\n\nThe two different regression tasks obtained from these databases are:\n\nCompAct\nPredict usr, the portion of time that cpus run in user mode from all attributes 1-21.\n\nCompAct(s)\nPredict usr using a restricted number (excluding the paging information (10-18)\n\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nOriginal source: DELVE repository of data.\nCharacteristics: 8192 cases, 22 continuous attributes", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_573_cpu_act_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 22, "colName": "usr"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-573-cpu-act"}, "LL0_574_house_16h": {"pipeline": {"_id": "833642b2-b65f-4b4b-a74f-cb0a10a56a4c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 60}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 311, "max_depth": 9, "learning_rate": 0.04044437110476817, "gamma": 0.34386387814004926, "min_child_weight": 10}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "833642b2-b65f-4b4b-a74f-cb0a10a56a4c", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 984912360.59951, "rank": 984912360.59951, "metric": "meanSquaredError", "ts": "2018-10-24T20:33:37.521000", "dataset": "LL0_574_house_16h_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_574_house_16h", "about": {"problemID": "LL0_574_house_16h_problem", "problemName": "LL0_574_house_16h_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis database was designed on the basis of data provided by US Census\nBureau [http://www.census.gov] (under Lookup Access\n[http://www.census.gov/cdrom/lookup]: Summary Tape File 1). The data\nwere collected as part of the 1990 US census. These are mostly counts\ncumulated at different survey levels. For the purpose of this data set\na level State-Place was used. Data from all states was obtained. Most\nof the counts were changed into appropriate proportions.  There are 4\ndifferent data sets obtained from this database: House(8H) House(8L)\nHouse(16H) House(16L) These are all concerned with predicting the\nmedian price of the house in the region based on demographic\ncomposition and a state of housing market in the region. A number in\nthe name signifies the number of attributes of the data set. A\nfollowing letter denotes a very rough approximation to the difficulty\nof the task. For Low task difficulty, more correlated attributes were\nchosen as signified by univariate smooth fit of that input on the\ntarget. Tasks with High difficulty have had their attributes chosen to\nmake the modelling more difficult due to higher variance or lower\ncorrelation of the inputs to the target.\n\nOriginal source: DELVE repository of data.\nSource: collection of regression datasets by Luis Torgo (ltorgo@ncc.up.pt) at\nhttp://www.ncc.up.pt/~ltorgo/Regression/DataSets.html\nCharacteristics: 22784 cases, 17 continuous attributes.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_574_house_16h_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 17, "colName": "price"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-574-house-16h"}, "LL0_59_ionosphere": {"pipeline": {"_id": "5b19039c-43a2-4a93-9cbd-c4de689602f9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 20}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 3, "min_samples_split": 0.22191615802592027, "min_samples_leaf": 0.02808460779779199, "n_estimators": 211, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "5b19039c-43a2-4a93-9cbd-c4de689602f9", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9302211165578156, "rank": 0.0697788834423847, "metric": "f1Macro", "ts": "2018-10-25T06:10:31.617000", "dataset": "LL0_59_ionosphere_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_59_ionosphere", "about": {"problemID": "LL0_59_ionosphere_problem", "problemName": "LL0_59_ionosphere_problem", "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title: Johns Hopkins University Ionosphere database\n\n2. Source Information:\n   -- Donor: Vince Sigillito (vgs@aplcen.apl.jhu.edu)\n   -- Date: 1989\n   -- Source: Space Physics Group\n              Applied Physics Laboratory\n              Johns Hopkins University\n              Johns Hopkins Road\n              Laurel, MD 20723 \n\n3. Past Usage:\n   -- Sigillito, V. G., Wing, S. P., Hutton, L. V., & Baker, K. B. (1989).\n      Classification of radar returns from the ionosphere using neural \n      networks. Johns Hopkins APL Technical Digest, 10, 262-266.\n\n      They investigated using backprop and the perceptron training algorithm\n      on this database.  Using the first 200 instances for training, which\n      were carefully split almost 50% positive and 50% negative, they found\n      that a \"linear\" perceptron attained 90.7%, a \"non-linear\" perceptron\n      attained 92%, and backprop an average of over 96% accuracy on the \n      remaining 150 test instances, consisting of 123 \"good\" and only 24 \"bad\"\n      instances.  (There was a counting error or some mistake somewhere; there\n      are a total of 351 rather than 350 instances in this domain.) Accuracy\n      on \"good\" instances was much higher than for \"bad\" instances.  Backprop\n      was tested with several different numbers of hidden units (in [0,15])\n      and incremental results were also reported (corresponding to how well\n      the different variants of backprop did after a periodic number of \n      epochs).\n\n      David Aha (aha@ics.uci.edu) briefly investigated this database.\n      He found that nearest neighbor attains an accuracy of 92.1%, that\n      Ross Quinlan's C4 algorithm attains 94.0% (no windowing), and that\n      IB3 (Aha & Kibler, IJCAI-1989) attained 96.7% (parameter settings:\n      70% and 80% for acceptance and dropping respectively).\n\n4. Relevant Information:\n   This radar data was collected by a system in Goose Bay, Labrador.  This\n   system consists of a phased array of 16 high-frequency antennas with a\n   total transmitted power on the order of 6.4 kilowatts.  See the paper\n   for more details.  The targets were free electrons in the ionosphere.\n   \"Good\" radar returns are those showing evidence of some type of structure \n   in the ionosphere.  \"Bad\" returns are those that do not; their signals pass\n   through the ionosphere.  \n\n   Received signals were processed using an autocorrelation function whose\n   arguments are the time of a pulse and the pulse number.  There were 17\n   pulse numbers for the Goose Bay system.  Instances in this databse are\n   described by 2 attributes per pulse number, corresponding to the complex\n   values returned by the function resulting from the complex electromagnetic\n   signal.\n\n5. Number of Instances: 351\n\n6. Number of Attributes: 34 plus the class attribute\n   -- All 34 predictor attributes are continuous\n\n7. Attribute Information:     \n   -- All 34 are continuous, as described above\n   -- The 35th attribute is either \"good\" or \"bad\" according to the definition\n      summarized above.  This is a binary classification task.\n\n8. Missing Values: None", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_59_ionosphere_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 35, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-59-ionosphere"}, "LL0_60_waveform_5000": {"pipeline": {"_id": "c3b84b63-da1c-4993-b199-a18f90e813b2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 84}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 296, "max_depth": 9, "learning_rate": 0.12519758432537798, "gamma": 0.4839796319707599, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "c3b84b63-da1c-4993-b199-a18f90e813b2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8583569025934163, "rank": 0.1416430974071666, "metric": "f1Macro", "ts": "2018-10-25T01:40:04.231000", "dataset": "LL0_60_waveform_5000_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_60_waveform_5000", "about": {"problemID": "LL0_60_waveform_5000_problem", "problemName": "LL0_60_waveform_5000_problem", "problemDescription": "**Author**: Breiman,L., Friedman,J.H., Olshen,R.A., & Stone,C.J.  \n**Source**: [UCI](http://archive.ics.uci.edu/ml/datasets/waveform+database+generator+(version+2)) - 1988  \n**Please cite**: [UCI](http://archive.ics.uci.edu/ml/citation_policy.html)    \n\n**Waveform Database Generator**  \nGenerator generating 3 classes of waves. Each class is generated from a combination of 2 of 3 \"base\" waves.  \n\nFor details, see Breiman,L., Friedman,J.H., Olshen,R.A., and Stone,C.J. (1984). \nClassification and Regression Trees. Wadsworth International, pp 49-55, 169. \n\nNote: There is [an earlier version](http://archive.ics.uci.edu/ml/datasets/Waveform+Database+Generator+(Version+1)) of this dataset that only has 21 attributes (it does not add the 19 noise features).\n\n### Attribute Information\n\n40 attributes describing the waveform, all of which include noise. The latter 19 attributes are all noise attributes with mean 0 and variance 1.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_60_waveform_5000_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 41, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-60-waveform-5000"}, "LL0_6332_cylinder_bands": {"pipeline": {"_id": "0d201bc5-bb78-4937-8ca7-b950283a606e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 31}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 597, "max_depth": 3, "learning_rate": 0.3854835417276693, "gamma": 0.02788340948848811, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "0d201bc5-bb78-4937-8ca7-b950283a606e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8388034681571288, "rank": 0.16119653184324603, "metric": "f1Macro", "ts": "2018-10-25T01:26:52.990000", "dataset": "LL0_6332_cylinder_bands_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_6332_cylinder_bands", "about": {"problemID": "LL0_6332_cylinder_bands_problem", "problemName": "cylinder_bands_problem", "problemDescription": "**Author**: Bob Evans, RR Donnelley & Sons Co.  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Cylinder+Bands) - August, 1995  \n**Please cite**:  [UCI citation policy](https://archive.ics.uci.edu/ml/citation_policy.html)\n\n### Description\n\nCylinder bands UCI dataset - Process delays known as cylinder banding in rotogravure printing were substantially mitigated using control rules discovered by decision tree induction.\n \n### Attribute Information\n\nThere are 40 attributes for 540 observations, including the class: 20 are numeric and 20 are nominal.  \nThere are missing values in 302 of the instances.\n\n```\n   1. timestamp: numeric;19500101 - 21001231  \n   2. cylinder number: nominal  \n   3. customer: nominal;  \n   4. job number: nominal;   \n   5. grain screened: nominal; yes, no  \n   6. ink color: nominal;  key, type  \n   7. proof on ctd ink:  nominal;  yes, no   \n   8. blade mfg: nominal;  benton, daetwyler, uddeholm  \n   9. cylinder division: nominal;  gallatin, warsaw, mattoon  \n  10. paper type: nominal;  uncoated, coated, super  \n  11. ink type: nominal;  uncoated, coated, cover  \n  12. direct steam: nominal; use; yes, no *  \n  13. solvent type: nominal;  xylol, lactol, naptha, line, other  \n  14. type on cylinder:  nominal;  yes, no   \n  15. press type: nominal; use; 70 wood hoe, 70 motter, 70 albert, 94 motter  \n  16. press: nominal;  821, 802, 813, 824, 815, 816, 827, 828  \n  17. unit number: nominal;  1, 2, 3, 4, 5, 6, 7, 8, 9, 10  \n  18. cylinder size: nominal;  catalog, spiegel, tabloid  \n  19. paper mill location: nominal; north us, south us, canadian, \n      scandanavian, mid european  \n  20. plating tank: nominal; 1910, 1911, other  \n  21. proof cut: numeric;  0-100  \n  22. viscosity: numeric;  0-100  \n  23. caliper: numeric;  0-1.0  \n  24. ink temperature: numeric;  5-30  \n  25. humifity: numeric;  5-120  \n  26. roughness: numeric;  0-2  \n  27. blade pressure: numeric;  10-75  \n  28. varnish pct: numeric;  0-100  \n  29. press speed: numeric;  0-4000  \n  30. ink pct: numeric;  0-100  \n  31. solvent pct: numeric;  0-100  \n  32. ESA Voltage: numeric;  0-16  \n  33. ESA Amperage: numeric;  0-10  \n  34. wax: numeric ;  0-4.0  \n  35. hardener:  numeric; 0-3.0  \n  36. roller durometer:  numeric;  15-120  \n  37. current density:  numeric;  20-50  \n  38. anode space ratio:  numeric;  70-130  \n  39. chrome content: numeric; 80-120  \n  40. band type: nominal; class; band, no band  \n```\n\n**Notes**:  \n* cylinder number is an identifier and should be ignored when modeling the data\n* data set consists of 540 observations. UCI explanation states 541, which is wrong. \n\n### Relevant Papers\n\nEvans, B., and Fisher, D. (1994). Overcoming process delays with decision tree induction. IEEE Expert, Vol. 9, No. 1, 60--66.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_6332_cylinder_bands_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 40, "colName": "band_type"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-6332-cylinder-bands"}, "LL0_664_chscase_census6": {"pipeline": {"_id": "9bf3690e-8d42-484f-875d-213aaeb59762", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 23, "min_samples_split": 0.033395678289670355, "min_samples_leaf": 0.36701004416207317, "n_estimators": 122}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "9bf3690e-8d42-484f-875d-213aaeb59762", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2.225257019639074, "rank": 2.225257019639585, "metric": "meanSquaredError", "ts": "2018-10-24T20:41:05.492000", "dataset": "LL0_664_chscase_census6_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_664_chscase_census6", "about": {"problemID": "LL0_664_chscase_census6_problem", "problemName": "LL0_664_chscase_census6_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFile README\n-----------\n\nchscase  A collection of the data sets used in the book\n\"A Casebook for a First Course in Statistics and Data Analysis,\"\nby Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,\nJohn Wiley and Sons, New York, 1995. Submitted by\nSamprit Chatterjee (schatterjee@stern.nyu.edu),\nMark Handcock (mhandcock@stern.nyu.edu) and\nJeff Simonoff (jsimonoff@stern.nyu.edu)\n\nThis submission consists of 38 files, plus this README file.\nEach file represents a data set analyzed in the book. The names\nof the files correspond to the names used in the book. The data\nfiles are written in plain ASCII (character) text. Missing\nvalues are represented by \"M\" in all data files.\n\nMore information about the data sets and the book can be\nobtained via gopher at the address\nswis.stern.nyu.edu\n\nThe information is filed under\n---> Academic Departments & Research Centers\n---> Statistics and Operations Research\n---> Publications\n---> A Casebook for a First Course in Statistics and Data Analysis\n---> Welcome!\n\nIt can also be accessed from the World Wide Web (WWW) using a\nWWW browser (e.g., netscape) starting from the URL address\nhttp://www.stern.nyu.edu/SOR/Casebook\n\n\n\nNOTICE: These datasets may be used freely for scientific,\neducational and/or non-commercial purposes, provided suitable\nacknowledgment is given (by citing the Chatterjee, Handcock and\nSimonoff reference above).\n\nFile: census6.dat\n\nNote: attribute names were generated automatically since there was no\ninformation in the data itself.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_664_chscase_census6_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "col_7"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-664-chscase-census6"}, "LL0_666_rmftsa_ladata": {"pipeline": {"_id": "e52ac355-6bd5-4332-9f34-2ec8fa2fd657", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 98}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 590, "max_depth": 9, "learning_rate": 0.11697228636041679, "gamma": 0.6676661271762301, "min_child_weight": 1}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "e52ac355-6bd5-4332-9f34-2ec8fa2fd657", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 3.238919200153853, "rank": 3.2389192001540876, "metric": "meanSquaredError", "ts": "2018-10-24T20:09:08.899000", "dataset": "LL0_666_rmftsa_ladata_dataset_TRAIN", "test_id": "20181024200501872083"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_666_rmftsa_ladata", "about": {"problemID": "LL0_666_rmftsa_ladata_problem", "problemName": "LL0_666_rmftsa_ladata_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData Sets for 'Regression Models for Time Series Analysis' by\nB. Kedem and K. Fokianos, Wiley 2002. Submitted by Kostas\nFokianos (fokianos@ucy.ac.cy) [8/Nov/02] (176k)\n\nNote: - attribute names were generated manually\n- information about data taken from here:\nhttp://lib.stat.cmu.edu/datasets/\n\nFile: ../data/rmftsa/ladata\n\nLA Pollution-Mortality Study:\n1970-1979, 508 observations,  6-day spacing. Weekly FILTERED data.\nThe data were lowpass filtered, filtering out frequencies above 0.1\ncycles per day.\nMortality:          (1) Mrt: Total Mortality\n(2) Rsp: Respiratory Mortality\n(3) Crd: Cardiovascular Mortality\nWeather:            (4) Tmp: Temperature\n(5) Hum: Relative Humidity\nPollution:          (6) Crb: Carbon Monoxide\n(7) Slf: Sulfur Dioxideglm.LAshumway\n(8) Nit: Nitrogen Dioxide\n(9) Hdr: Hydrocarbons\n(10) Ozn: Ozone\n(11) Par: Particulates\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_666_rmftsa_ladata_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "Respiratory_Mortality"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-666-rmftsa-ladata"}, "LL0_676_disclosure_x_tampered": {"pipeline": {"_id": "b4d818c4-87d0-4a00-8667-82e627701645", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 48}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 30, "min_samples_split": 0.3977662048562816, "min_samples_leaf": 0.019658977458585022, "n_estimators": 38}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "b4d818c4-87d0-4a00-8667-82e627701645", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 938043683.7766081, "rank": 938043683.7766081, "metric": "meanSquaredError", "ts": "2018-10-24T20:31:49.716000", "dataset": "LL0_676_disclosure_x_tampered_dataset_TRAIN", "test_id": "20181024201213536304"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_676_disclosure_x_tampered", "about": {"problemID": "LL0_676_disclosure_x_tampered_problem", "problemName": "LL0_676_disclosure_x_tampered_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData Used in \"A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL\nINTRUDER BEHAVIOR FOR CONTINUOUS DATA\"\nby Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil\n\nBackground:\n==========\nIn this paper we develop an approach to data disclosure in survey settings by\nadopting a probabilistic definition of disclosure due to Dalenius. Our approach\nis based on the principle that a data collection agency must consider\ndisclosure from the perspective of an intruder in order to efficiently evaluate\ndata disclosure limitation procedures. The probabilistic definition and our\nattempt to study optimal intruder behavior lead naturally to a Bayesian\nformulation.  We apply the methods in a small-scale simulation study using data\nadapted from an actual survey conducted by the Institute for Social Research at\nYork University. (See Sections 1-3 of the paper for details oF the model\nformulation and related issues.)\n\nThe Data:\n========\nOur case study uses data from the survey data Elite Canadian\nDecision-Makers collected by the Institute for Social Research at York\nUniversity.  This survey was conducted in 1981 using telephone\ninterviews and there were 1348 respondents, but many of these did not\nsupply complete data.  We have extracted data on 12 variables, each of which\nwas measured on a 5-point scale:\n\nCivil-liberties:\n- ---------------\nC1 - Free speech is just not worth it.\nC2 - We have gone too far in pushing equal rights in this country.\nC3 - It is better to live in an  orderly  society  than  to  allow people so\nmuch freedom.\nC5 - Free speech ought to be allowed for all political groups.\n\nAttitudes towards Jews:\n- ----------------------\nA15 - Most Jews don't care what happens to people who are not Jews.\nA18 - Jews are more willing than others to use shady practices  to\nget ahead.\n\nCanada-US relationship:\n- ----------------------\nCUS1 - Ensure independent Canada.\nCUS5 - Canada should have free trade with the USA.\nCUS6 - Canada's way of life is influenced strongly by USA.\nCUS7 - Canada benefits from US investments.\n\n\nIn addition, we have data on two approximately continuous variables:\n\nPersonal information:\n- --------------------\nIncome - Total family income before taxes (with top-coding at \\$80,000).\nAge - Based on year of birth.\n\n\nWe transformed the original survey data  as follows in order to create\na database of approximately continuous variables:\n\n[A]  We add categorical  variables  (all  but  income) to increase the number\nof levels. (When necessary we reversed the order of levels of a response  to a\nquestion.)  The new variables are defined as follows:\n\nCivil     = C1 + C2 + C3 + (8 - C5)\nAttitude  = A15 + A18\nCan/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7\n\nAfter we removed cases with missing observations and  two  cases involving\nyoung children, we had a  data-base consisting of 662 observations.\n\n[B]  In order to enhance continuity, we took the following measures:\n\nAge:  We added normal  distributed  variates,  with  0   mean  and\nvariance 4 to all observations.\nIncome: We added uniform variates on the range of $0 - $10,000 to all incomes\nbelow $80,000.  Since all cases of incomes exceeding $80,000 were\nlumped together  in  the  survey,  we simulated their values by means\nof a t(8) distribution. Drawing values from the upper 38% tail of t(8),\nwe evaluated the values of income as $60,000 + 25,000*t(8).\nOther variables: We added  normal distributed variates, with 0 mean and\nvariance  0.5 to the variables.\n\nWe assume that the agency releases information about all\nvariables, except for Attitudes (towards Jews), which  is unavailable to\nthe intruder and is at the center of the intruder's investigation.\n\nWe denote the released data by\n\nZ = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.\n\nWe assume that the intruder's data, X, are accurate and are related to Z via\nthe following transformation:\nx(0,j) = z(i,j)*theta(i,j) + xi(j),\n\nwhere theta(i,j) is a bias removing parameter normally distributed with mean 1\nand variance  v(j), and xi(j) is normally distributed disturbance with 0  mean\nand variance sigma2(j).\n\nThe following table provides the values of\nv(j), sigma2(j) used in the study:\n\nv(j)     sigma2(j)\nCivil                      0.1732       25\nCan/US                     0.1732       25\nAge                        0.1732       9\nIncome (in $10000's)       0.1732       4\n\n\nWe first generated several realizations of the above transformation on small\nsubsets of the data to ascertain the impact of the process of the error\non the data. In Table 4-1 in the paper we present 10 records the the intruder's\naccurate data, X, and the biased and corrupted released data, Z, which we\nobtained from one realization of the transformation.\n\nSection 4.2 of the paper contains details of the implementation of our Bayesian\nmodel.\n\nData Used in the Computations:\n=============================\nWe conducted a complete simulation of the procedures for the complete set of\n662 cases.  We considered four different scenarios for the simulation. (The\nnames of datasets used in each of the scenarios appear in brackets below. The\ndatasets are appended to this text.)\n\n* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for\nall j). [Z.DATA]\n* The released data contains only noise (i.e., v(j)=0 for all j and\nand $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]\n* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)\nas given in the above Table). [X_BIAS.DATA]\n* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as\ngiven in the above Table). [X_TAMPERED.DATA]\n\nWe took each individual in turn as the object of the intruder's efforts and\ncarried out the calculations.\n\nStructure of the Datasets:\n- -------------------------\nEach attached dataset consists of four space-separated columns containing the\ndata on Age, Civil, Can/US and Income ($) respectively.\n\n\n\nDataset: X_TAMPERED\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_676_disclosure_x_tampered_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Income"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-676-disclosure-x-tampered"}, "LL0_679_rmftsa_sleepdata": {"pipeline": {"_id": "1e7da477-68de-4d38-83bf-36343d6359ee", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 9}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 21, "min_samples_split": 0.008784735289716426, "min_samples_leaf": 0.020896048124546266, "n_estimators": 50, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "1e7da477-68de-4d38-83bf-36343d6359ee", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.43082066303287964, "rank": 0.5691793369677357, "metric": "f1Macro", "ts": "2018-10-25T06:16:51.997000", "dataset": "LL0_679_rmftsa_sleepdata_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_679_rmftsa_sleepdata", "about": {"problemID": "LL0_679_rmftsa_sleepdata_problem", "problemName": "LL0_679_rmftsa_sleepdata_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData Sets for 'Regression Models for Time Series Analysis' by\nB. Kedem and K. Fokianos, Wiley 2002. Submitted by Kostas\nFokianos (fokianos@ucy.ac.cy) [8/Nov/02] (176k)\n\nNote: - attribute names were generated manually\n- information about data taken from here:\nhttp://lib.stat.cmu.edu/datasets/\n\nFile: ../data/rmftsa/sleepdata.txt\n\nSleep state measurements of a newborn infant (column 2) together\nwith his heart rate (column 1) and temperature (column 3).\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_679_rmftsa_sleepdata_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sleep_state"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-679-rmftsa-sleepdata"}, "LL0_688_visualizing_soil": {"pipeline": {"_id": "edde168e-361f-4c53-87a6-b3535751e2ca", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 831, "max_depth": 7, "learning_rate": 0.014655562376610032, "gamma": 0.0368300719569955, "min_child_weight": 3}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "edde168e-361f-4c53-87a6-b3535751e2ca", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.0010426596402945726, "rank": 0.0010426596411962654, "metric": "meanSquaredError", "ts": "2018-10-31T05:23:07.256000", "dataset": "LL0_688_visualizing_soil_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_688_visualizing_soil", "about": {"problemID": "LL0_688_visualizing_soil_problem", "problemName": "LL0_688_visualizing_soil_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis S dump contains 22 data sets from the\nbook Visualizing Data published by\nHobart Press (books@hobart.com).\nThe dump was created by data.dump()\nand can be read back into S by data.restore().\nThe name of each S data set is the name of\nthe data set used in the book. To find the\ndescription of the data set in the book look\nunder the entry - data, name - in the index.\nFor example, one data set is barley.\nTo find the description of barley, look\nin the index under the entry - data, barley.\n\nFile: ../data/visualizing/soil.csv\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_688_visualizing_soil_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "track"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-688-visualizing-soil"}, "LL0_690_visualizing_galaxy": {"pipeline": {"_id": "7e064d52-fdfb-474b-bf6e-b0d562f41ec0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 8, "min_samples_split": 0.0020124207978192794, "min_samples_leaf": 0.00522859548705184, "n_estimators": 364}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "7e064d52-fdfb-474b-bf6e-b0d562f41ec0", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 245.801769022365, "rank": 245.8017690223658, "metric": "meanSquaredError", "ts": "2018-10-24T20:18:09.773000", "dataset": "LL0_690_visualizing_galaxy_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_690_visualizing_galaxy", "about": {"problemID": "LL0_690_visualizing_galaxy_problem", "problemName": "LL0_690_visualizing_galaxy_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis S dump contains 22 data sets from the\nbook Visualizing Data published by\nHobart Press (books@hobart.com).\nThe dump was created by data.dump()\nand can be read back into S by data.restore().\nThe name of each S data set is the name of\nthe data set used in the book. To find the\ndescription of the data set in the book look\nunder the entry - data, name - in the index.\nFor example, one data set is barley.\nTo find the description of barley, look\nin the index under the entry - data, barley.\n\nFile: ../data/visualizing/galaxy.csv\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_690_visualizing_galaxy_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "velocity"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-690-visualizing-galaxy"}, "LL0_694_diggle_table_a2": {"pipeline": {"_id": "b075ed0c-d481-462b-9fc5-c984a33bb813", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 600, "max_depth": 5, "learning_rate": 0.3668487835255142, "gamma": 0.516609472579897, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "b075ed0c-d481-462b-9fc5-c984a33bb813", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 1.0, "rank": 6.262068051597902e-16, "metric": "f1Macro", "ts": "2018-10-31T04:54:51.971000", "dataset": "LL0_694_diggle_table_a2_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_694_diggle_table_a2", "about": {"problemID": "LL0_694_diggle_table_a2_problem", "problemName": "LL0_694_diggle_table_a2_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nDATA-SETS FROM DIGGLE, P.J. (1990). TIME SERIES : A BIOSTATISTICAL\nINTRODUCTION. Oxford University Press.\n\nTable: Table A2 Wool prices\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_694_diggle_table_a2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "col_1"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-694-diggle-table-a2"}, "LL0_703_chscase_foot": {"pipeline": {"_id": "0c8b1aae-4b7a-417c-89ca-57253148c75e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": null, "max_depth": 15, "min_samples_split": 0.12947224012912684, "min_samples_leaf": 0.12342795083076338, "n_estimators": 180}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "0c8b1aae-4b7a-417c-89ca-57253148c75e", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.6475658029878617, "rank": 0.6475658029884752, "metric": "meanSquaredError", "ts": "2018-10-24T21:12:48.091000", "dataset": "LL0_703_chscase_foot_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_703_chscase_foot", "about": {"problemID": "LL0_703_chscase_foot_problem", "problemName": "chscase_foot_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFile README\n-----------\n\nchscase  A collection of the data sets used in the book\n\"A Casebook for a First Course in Statistics and Data Analysis,\"\nby Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,\nJohn Wiley and Sons, New York, 1995. Submitted by\nSamprit Chatterjee (schatterjee@stern.nyu.edu),\nMark Handcock (mhandcock@stern.nyu.edu) and\nJeff Simonoff (jsimonoff@stern.nyu.edu)\n\nThis submission consists of 38 files, plus this README file.\nEach file represents a data set analyzed in the book. The names\nof the files correspond to the names used in the book. The data\nfiles are written in plain ASCII (character) text. Missing\nvalues are represented by \"M\" in all data files.\n\nMore information about the data sets and the book can be\nobtained via gopher at the address\nswis.stern.nyu.edu\n\nThe information is filed under\n---> Academic Departments & Research Centers\n---> Statistics and Operations Research\n---> Publications\n---> A Casebook for a First Course in Statistics and Data Analysis\n---> Welcome!\n\nIt can also be accessed from the World Wide Web (WWW) using a\nWWW browser (e.g., netscape) starting from the URL address\nhttp://www.stern.nyu.edu/SOR/Casebook\n\n\n\nNOTICE: These datasets may be used freely for scientific,\neducational and/or non-commercial purposes, provided suitable\nacknowledgment is given (by citing the Chatterjee, Handcock and\nSimonoff reference above).\n\nFile: foot.dat\n\nNote: attribute names were generated automatically since there was no\ninformation in the data itself.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_703_chscase_foot_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "col_6"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-703-chscase-foot"}, "LL0_709_disclosure_x_bias": {"pipeline": {"_id": "c43db199-dbd1-485b-8a11-0e14faf7c674", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 75}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 14, "min_samples_split": 0.036546913045995826, "min_samples_leaf": 0.007592146925008631, "n_estimators": 83}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "c43db199-dbd1-485b-8a11-0e14faf7c674", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 586618224.4308872, "rank": 586618224.4308872, "metric": "meanSquaredError", "ts": "2018-10-24T20:22:40.518000", "dataset": "LL0_709_disclosure_x_bias_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_709_disclosure_x_bias", "about": {"problemID": "LL0_709_disclosure_x_bias_problem", "problemName": "disclosure_x_bias_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nData Used in \"A BAYESIAN APPROACH TO DATA DISCLOSURE: OPTIMAL\nINTRUDER BEHAVIOR FOR CONTINUOUS DATA\"\nby Stephen E. Fienberg, Udi E. Makov, and Ashish P. Sanil\n\nBackground:\n==========\nIn this paper we develop an approach to data disclosure in survey settings by\nadopting a probabilistic definition of disclosure due to Dalenius. Our approach\nis based on the principle that a data collection agency must consider\ndisclosure from the perspective of an intruder in order to efficiently evaluate\ndata disclosure limitation procedures. The probabilistic definition and our\nattempt to study optimal intruder behavior lead naturally to a Bayesian\nformulation.  We apply the methods in a small-scale simulation study using data\nadapted from an actual survey conducted by the Institute for Social Research at\nYork University. (See Sections 1-3 of the paper for details oF the model\nformulation and related issues.)\n\nThe Data:\n========\nOur case study uses data from the survey data Elite Canadian\nDecision-Makers collected by the Institute for Social Research at York\nUniversity.  This survey was conducted in 1981 using telephone\ninterviews and there were 1348 respondents, but many of these did not\nsupply complete data.  We have extracted data on 12 variables, each of which\nwas measured on a 5-point scale:\n\nCivil-liberties:\n- ---------------\nC1 - Free speech is just not worth it.\nC2 - We have gone too far in pushing equal rights in this country.\nC3 - It is better to live in an  orderly  society  than  to  allow people so\nmuch freedom.\nC5 - Free speech ought to be allowed for all political groups.\n\nAttitudes towards Jews:\n- ----------------------\nA15 - Most Jews don't care what happens to people who are not Jews.\nA18 - Jews are more willing than others to use shady practices  to\nget ahead.\n\nCanada-US relationship:\n- ----------------------\nCUS1 - Ensure independent Canada.\nCUS5 - Canada should have free trade with the USA.\nCUS6 - Canada's way of life is influenced strongly by USA.\nCUS7 - Canada benefits from US investments.\n\n\nIn addition, we have data on two approximately continuous variables:\n\nPersonal information:\n- --------------------\nIncome - Total family income before taxes (with top-coding at \\$80,000).\nAge - Based on year of birth.\n\n\nWe transformed the original survey data  as follows in order to create\na database of approximately continuous variables:\n\n[A]  We add categorical  variables  (all  but  income) to increase the number\nof levels. (When necessary we reversed the order of levels of a response  to a\nquestion.)  The new variables are defined as follows:\n\nCivil     = C1 + C2 + C3 + (8 - C5)\nAttitude  = A15 + A18\nCan/US    = (5 - CUS1) + CUS5 + (5 - CUS6) + CUS7\n\nAfter we removed cases with missing observations and  two  cases involving\nyoung children, we had a  data-base consisting of 662 observations.\n\n[B]  In order to enhance continuity, we took the following measures:\n\nAge:  We added normal  distributed  variates,  with  0   mean  and\nvariance 4 to all observations.\nIncome: We added uniform variates on the range of $0 - $10,000 to all incomes\nbelow $80,000.  Since all cases of incomes exceeding $80,000 were\nlumped together  in  the  survey,  we simulated their values by means\nof a t(8) distribution. Drawing values from the upper 38% tail of t(8),\nwe evaluated the values of income as $60,000 + 25,000*t(8).\nOther variables: We added  normal distributed variates, with 0 mean and\nvariance  0.5 to the variables.\n\nWe assume that the agency releases information about all\nvariables, except for Attitudes (towards Jews), which  is unavailable to\nthe intruder and is at the center of the intruder's investigation.\n\nWe denote the released data by\n\nZ = (( z(i,j) ))   with i=1,..,662; j=1,2,3,4.\n\nWe assume that the intruder's data, X, are accurate and are related to Z via\nthe following transformation:\nx(0,j) = z(i,j)*theta(i,j) + xi(j),\n\nwhere theta(i,j) is a bias removing parameter normally distributed with mean 1\nand variance  v(j), and xi(j) is normally distributed disturbance with 0  mean\nand variance sigma2(j).\n\nThe following table provides the values of\nv(j), sigma2(j) used in the study:\n\nv(j)     sigma2(j)\nCivil                      0.1732       25\nCan/US                     0.1732       25\nAge                        0.1732       9\nIncome (in $10000's)       0.1732       4\n\n\nWe first generated several realizations of the above transformation on small\nsubsets of the data to ascertain the impact of the process of the error\non the data. In Table 4-1 in the paper we present 10 records the the intruder's\naccurate data, X, and the biased and corrupted released data, Z, which we\nobtained from one realization of the transformation.\n\nSection 4.2 of the paper contains details of the implementation of our Bayesian\nmodel.\n\nData Used in the Computations:\n=============================\nWe conducted a complete simulation of the procedures for the complete set of\n662 cases.  We considered four different scenarios for the simulation. (The\nnames of datasets used in each of the scenarios appear in brackets below. The\ndatasets are appended to this text.)\n\n* The released data contains no bias or noise (i.e. v(j)=0 and sigma2(j)=0 for\nall j). [Z.DATA]\n* The released data contains only noise (i.e., v(j)=0 for all j and\nand $sigma2(j)$ as given in the above Table). [X_NOISE.DATA]\n* The released data contains only bias (i.e., sigma2(j)=0 for all j and v(j)\nas given in the above Table). [X_BIAS.DATA]\n* The released data contains both bias and noise (i.e., v(j) and sigma2(j) as\ngiven in the above Table). [X_TAMPERED.DATA]\n\nWe took each individual in turn as the object of the intruder's efforts and\ncarried out the calculations.\n\nStructure of the Datasets:\n- -------------------------\nEach attached dataset consists of four space-separated columns containing the\ndata on Age, Civil, Can/US and Income ($) respectively.\n\n\n\nDataset: X_BIAS\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_709_disclosure_x_bias_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "Income"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-709-disclosure-x-bias"}, "LL0_712_chscase_geyser1": {"pipeline": {"_id": "8b373795-f58e-479a-860f-f63699c10280", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 49}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 6, "min_samples_split": 0.03609397707542791, "min_samples_leaf": 0.05624095544854871, "n_estimators": 8}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "8b373795-f58e-479a-860f-f63699c10280", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 43.826160302201394, "rank": 43.82616030220163, "metric": "meanSquaredError", "ts": "2018-10-24T20:23:59.052000", "dataset": "LL0_712_chscase_geyser1_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_712_chscase_geyser1", "about": {"problemID": "LL0_712_chscase_geyser1_problem", "problemName": "chscase_geyser1_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nFile README\n-----------\n\nchscase  A collection of the data sets used in the book\n\"A Casebook for a First Course in Statistics and Data Analysis,\"\nby Samprit Chatterjee, Mark S. Handcock and Jeffrey S. Simonoff,\nJohn Wiley and Sons, New York, 1995. Submitted by\nSamprit Chatterjee (schatterjee@stern.nyu.edu),\nMark Handcock (mhandcock@stern.nyu.edu) and\nJeff Simonoff (jsimonoff@stern.nyu.edu)\n\nThis submission consists of 38 files, plus this README file.\nEach file represents a data set analyzed in the book. The names\nof the files correspond to the names used in the book. The data\nfiles are written in plain ASCII (character) text. Missing\nvalues are represented by \"M\" in all data files.\n\nMore information about the data sets and the book can be\nobtained via gopher at the address\nswis.stern.nyu.edu\n\nThe information is filed under\n---> Academic Departments & Research Centers\n---> Statistics and Operations Research\n---> Publications\n---> A Casebook for a First Course in Statistics and Data Analysis\n---> Welcome!\n\nIt can also be accessed from the World Wide Web (WWW) using a\nWWW browser (e.g., netscape) starting from the URL address\nhttp://www.stern.nyu.edu/SOR/Casebook\n\n\n\nNOTICE: These datasets may be used freely for scientific,\neducational and/or non-commercial purposes, provided suitable\nacknowledgment is given (by citing the Chatterjee, Handcock and\nSimonoff reference above).\n\nFile: geyser1.dat\n\nNote: attribute names were generated automatically since there was no\ninformation in the data itself.\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_712_chscase_geyser1_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "col_3"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-712-chscase-geyser1"}, "LL0_721_pwLinear": {"pipeline": {"_id": "4cbbdaab-881c-45cc-8c38-498381b62835", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 31}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 284, "max_depth": 9, "learning_rate": 0.7256925046405867, "gamma": 0.006119548846593936, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "4cbbdaab-881c-45cc-8c38-498381b62835", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8769471399960025, "rank": 0.12305286000405445, "metric": "f1Macro", "ts": "2018-10-25T00:12:23.643000", "dataset": "LL0_721_pwLinear_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_721_pwLinear", "about": {"problemID": "LL0_721_pwLinear_problem", "problemName": "pwLinear_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_721_pwLinear_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 11, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-721-pwLinear"}, "LL0_733_machine_cpu": {"pipeline": {"_id": "2b04ebc6-4c3c-4aac-bff8-5f784facccec", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 56}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 13, "min_samples_split": 0.1402906507357941, "min_samples_leaf": 0.028886898802444837, "n_estimators": 110, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "2b04ebc6-4c3c-4aac-bff8-5f784facccec", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9342006269592478, "rank": 0.06579937304088321, "metric": "f1Macro", "ts": "2018-10-25T05:46:03.955000", "dataset": "LL0_733_machine_cpu_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_733_machine_cpu", "about": {"problemID": "LL0_733_machine_cpu_problem", "problemName": "machine_cpu_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_733_machine_cpu_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-733-machine-cpu"}, "LL0_747_servo": {"pipeline": {"_id": "ca046a7a-c513-4898-9ee6-3329bbe5b091", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 44}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 25, "min_samples_split": 0.03257862813891918, "min_samples_leaf": 0.015918367131842293, "n_estimators": 250, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "ca046a7a-c513-4898-9ee6-3329bbe5b091", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9756521739130435, "rank": 0.02434782608700928, "metric": "f1Macro", "ts": "2018-10-25T11:46:34.676000", "dataset": "LL0_747_servo_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_747_servo", "about": {"problemID": "LL0_747_servo_problem", "problemName": "servo_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_747_servo_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-747-servo"}, "LL0_788_triazines": {"pipeline": {"_id": "3920a7ac-65f3-4ed3-bd3b-38598e623500", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 0}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 108, "max_depth": 8, "learning_rate": 0.9948305908184797, "gamma": 0.9872246464632366, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "3920a7ac-65f3-4ed3-bd3b-38598e623500", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8202756892230576, "rank": 0.1797243107770612, "metric": "f1Macro", "ts": "2018-10-25T01:13:17.417000", "dataset": "LL0_788_triazines_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_788_triazines", "about": {"problemID": "LL0_788_triazines_problem", "problemName": "triazines_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_788_triazines_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 61, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-788-triazines"}, "LL0_801_chscase_funds": {"pipeline": {"_id": "279930c6-5f01-4c48-bbc6-e66613cb2fab", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 32}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 8, "min_samples_split": 0.4201430790748987, "min_samples_leaf": 0.3054607377460195, "n_estimators": 150, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "279930c6-5f01-4c48-bbc6-e66613cb2fab", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7009720250509724, "rank": 0.2990279749497792, "metric": "f1Macro", "ts": "2018-10-25T06:09:11.038000", "dataset": "LL0_801_chscase_funds_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_801_chscase_funds", "about": {"problemID": "LL0_801_chscase_funds_problem", "problemName": "chscase_funds_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_801_chscase_funds_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-801-chscase-funds"}, "LL0_811_rmftsa_ctoarrivals": {"pipeline": {"_id": "e2a805ad-ae54-4228-be08-ca23cd0be859", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 94}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 28, "min_samples_split": 0.15260314269151073, "min_samples_leaf": 0.007066789473945958, "n_estimators": 8, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "e2a805ad-ae54-4228-be08-ca23cd0be859", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9662650975747475, "rank": 0.033734902425738546, "metric": "f1Macro", "ts": "2018-10-25T05:04:22.272000", "dataset": "LL0_811_rmftsa_ctoarrivals_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_811_rmftsa_ctoarrivals", "about": {"problemID": "LL0_811_rmftsa_ctoarrivals_problem", "problemName": "rmftsa_ctoarrivals_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_811_rmftsa_ctoarrivals_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-811-rmftsa-ctoarrivals"}, "LL0_814_chscase_vine2": {"pipeline": {"_id": "78746c18-658b-429f-8d3b-c73acf7c248c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 45}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 29, "min_samples_split": 0.023977903302714293, "min_samples_leaf": 0.0017216889367256123, "n_estimators": 404, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "78746c18-658b-429f-8d3b-c73acf7c248c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.850895927618876, "rank": 0.14910407238171822, "metric": "f1Macro", "ts": "2018-10-25T06:26:23.909000", "dataset": "LL0_814_chscase_vine2_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_814_chscase_vine2", "about": {"problemID": "LL0_814_chscase_vine2_problem", "problemName": "chscase_vine2_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_814_chscase_vine2_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 3, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-814-chscase-vine2"}, "LL0_840_autoHorse": {"pipeline": {"_id": "54f9b397-81bb-43da-a533-4f6bd4090e1f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 17}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 952, "max_depth": 7, "learning_rate": 0.9001536838364682, "gamma": 0.7411081304357324, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "54f9b397-81bb-43da-a533-4f6bd4090e1f", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9605003813882533, "rank": 0.0394996186118272, "metric": "f1Macro", "ts": "2018-10-25T01:29:56.087000", "dataset": "LL0_840_autoHorse_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_840_autoHorse", "about": {"problemID": "LL0_840_autoHorse_problem", "problemName": "autoHorse_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_840_autoHorse_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 26, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-840-autoHorse"}, "LL0_844_breastTumor": {"pipeline": {"_id": "8db330fd-f56b-4063-9b04-04b32475b02a", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 5}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 8, "min_samples_split": 0.3169481869329688, "min_samples_leaf": 0.02109403708697835, "n_estimators": 33, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "8db330fd-f56b-4063-9b04-04b32475b02a", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6484813806180771, "rank": 0.3515186193828275, "metric": "f1Macro", "ts": "2018-10-25T06:30:32.919000", "dataset": "LL0_844_breastTumor_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_844_breastTumor", "about": {"problemID": "LL0_844_breastTumor_problem", "problemName": "breastTumor_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_844_breastTumor_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-844-breastTumor"}, "LL0_851_tecator": {"pipeline": {"_id": "e55d6908-9eb3-41e2-939b-a030ca4447ae", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 10}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 194, "max_depth": 7, "learning_rate": 0.6377224927178687, "gamma": 0.7130524343981586, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "e55d6908-9eb3-41e2-939b-a030ca4447ae", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9418887110217915, "rank": 0.058111288978780096, "metric": "f1Macro", "ts": "2018-10-25T01:51:03.430000", "dataset": "LL0_851_tecator_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_851_tecator", "about": {"problemID": "LL0_851_tecator_problem", "problemName": "tecator_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_851_tecator_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 125, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-851-tecator"}, "LL0_852_analcatdata_gsssexsurvey": {"pipeline": {"_id": "039c6f0e-0f1a-46c1-8cf3-2b76f0eb447b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 14, "min_samples_split": 0.44397336459334125, "min_samples_leaf": 0.19994822784711097, "n_estimators": 392, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "039c6f0e-0f1a-46c1-8cf3-2b76f0eb447b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6190100250626566, "rank": 0.38098997493741954, "metric": "f1Macro", "ts": "2018-10-25T06:03:21.234000", "dataset": "LL0_852_analcatdata_gsssexsurvey_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_852_analcatdata_gsssexsurvey", "about": {"problemID": "LL0_852_analcatdata_gsssexsurvey_problem", "problemName": "analcatdata_gsssexsurvey_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_852_analcatdata_gsssexsurvey_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-852-analcatdata-gsssexsurvey"}, "LL0_853_housing": {"pipeline": {"_id": "d00356b6-d4e9-4e2b-a1f6-e7d6df18c5f1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 960, "max_depth": 7, "learning_rate": 0.6590750376166913, "gamma": 0.8365946745788951, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "d00356b6-d4e9-4e2b-a1f6-e7d6df18c5f1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8895064433209404, "rank": 0.11049355667999057, "metric": "f1Macro", "ts": "2018-10-25T01:38:36.641000", "dataset": "LL0_853_housing_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_853_housing", "about": {"problemID": "LL0_853_housing_problem", "problemName": "housing_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_853_housing_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 14, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-853-housing"}, "LL0_854_fishcatch": {"pipeline": {"_id": "ec0f73a7-1f91-4895-b297-62f2504869bd", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 51}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 29, "min_samples_split": 0.039082452615065696, "min_samples_leaf": 0.013149933637319752, "n_estimators": 15, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "ec0f73a7-1f91-4895-b297-62f2504869bd", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9811965811965813, "rank": 0.01880341880355703, "metric": "f1Macro", "ts": "2018-10-25T05:19:11.578000", "dataset": "LL0_854_fishcatch_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_854_fishcatch", "about": {"problemID": "LL0_854_fishcatch_problem", "problemName": "fishcatch_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_854_fishcatch_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-854-fishcatch"}, "LL0_8_liver_disorders": {"pipeline": {"_id": "294797a0-cc95-4a0a-ada7-23c63d567e73", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 11, "min_samples_split": 0.011484863286722323, "min_samples_leaf": 0.017790397076987183, "n_estimators": 21}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "294797a0-cc95-4a0a-ada7-23c63d567e73", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 9.036622136823322, "rank": 9.036622136823999, "metric": "meanSquaredError", "ts": "2018-10-24T21:14:24.396000", "dataset": "LL0_8_liver_disorders_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_8_liver_disorders", "about": {"problemID": "LL0_8_liver_disorders_problem", "problemName": "LL0_8_liver_disorders_problem", "problemDescription": "**Author**: BUPA Medical Research Ltd. Donor: Richard S. Forsyth   \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/Liver+Disorders) - 5/15/1990  \n**Please cite**: \n\n**BUPA liver disorders**\n \nThe first 5 variables are all blood tests which are thought to be sensitive to liver disorders that might arise from excessive alcohol consumption.  Each line in the dataset constitutes the record of a single male individual. \n\n**Important note:** The 7th field (selector) has been widely misinterpreted in the past as a dependent variable representing presence or absence of a liver disorder. This is incorrect [1]. The 7th field was created by BUPA researchers as a train/test selector. It is not suitable as a dependent variable for classification. The dataset does not contain any variable representing presence or absence of a liver disorder. Researchers who wish to use this dataset as a classification benchmark should follow the method used in experiments by the donor (Forsyth & Rada, 1986, Machine learning: applications in expert systems and information retrieval) and others (e.g. Turney, 1995, Cost-sensitive classification: Empirical evaluation of a hybrid genetic decision tree induction algorithm), who used the 6th field (drinks), after dichotomising, as a dependent variable for classification. Because of widespread misinterpretation in the past, researchers should take care to state their method clearly.\n \n**Attribute information**  \n    1. mcv mean corpuscular volume  \n    2. alkphos alkaline phosphotase  \n    3. sgpt alanine aminotransferase  \n    4. sgot  aspartate aminotransferase  \n    5. gammagt gamma-glutamyl transpeptidase  \n    6. drinks number of half-pint equivalents of alcoholic beverages drunk per day  \n    7. selector field created by the BUPA researchers to split the data into train/test sets  \n\n[1] McDermott & Forsyth 2016, Diagnosing a disorder in a classification benchmark, Pattern Recognition Letters, Volume 73. Note Forsyth is named on the UCI page as the original donor of the dataset.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_8_liver_disorders_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "drinks"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-8-liver-disorders"}, "LL0_939_chscase_whale": {"pipeline": {"_id": "6e721f55-aacb-468a-86d5-454a14ec073b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 40}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 730, "max_depth": 6, "learning_rate": 0.8014792386459624, "gamma": 0.5961933041903531, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "6e721f55-aacb-468a-86d5-454a14ec073b", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9922962962962962, "rank": 0.007703703703703793, "metric": "f1Macro", "ts": "2018-10-24T23:56:43.856000", "dataset": "LL0_939_chscase_whale_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_939_chscase_whale", "about": {"problemID": "LL0_939_chscase_whale_problem", "problemName": "chscase_whale_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_939_chscase_whale_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-939-chscase-whale"}, "LL0_941_lowbwt": {"pipeline": {"_id": "235a168e-7715-4423-9e4c-2ac147f92107", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 518, "max_depth": 10, "learning_rate": 0.8299563281011216, "gamma": 0.9987473395781947, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "235a168e-7715-4423-9e4c-2ac147f92107", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8703270078734475, "rank": 0.12967299212746297, "metric": "f1Macro", "ts": "2018-10-31T05:05:11.942000", "dataset": "LL0_941_lowbwt_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_941_lowbwt", "about": {"problemID": "LL0_941_lowbwt_problem", "problemName": "lowbwt_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N').", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_941_lowbwt_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 10, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-941-lowbwt"}, "LL0_947_arsenic_male_bladder": {"pipeline": {"_id": "86e69e6e-8280-4dc1-915e-a3a679cd78ae", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 64}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 292, "max_depth": 3, "learning_rate": 0.6092300344948947, "gamma": 0.38086800707450186, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "86e69e6e-8280-4dc1-915e-a3a679cd78ae", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8501441941253558, "rank": 0.14985580587465774, "metric": "f1Macro", "ts": "2018-10-25T00:06:21.909000", "dataset": "LL0_947_arsenic_male_bladder_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_947_arsenic_male_bladder", "about": {"problemID": "LL0_947_arsenic_male_bladder_problem", "problemName": "LL0_947_arsenic_male_bladder_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_947_arsenic_male_bladder_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-947-arsenic-male-bladder"}, "LL0_949_arsenic_female_bladder": {"pipeline": {"_id": "cf6fc09d-9cdd-4637-a593-0b33f98edc87", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 94}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 718, "max_depth": 4, "learning_rate": 0.8585662605596024, "gamma": 0.4593513522044239, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "cf6fc09d-9cdd-4637-a593-0b33f98edc87", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.7047768782403152, "rank": 0.29522312175971244, "metric": "f1Macro", "ts": "2018-10-25T00:04:44.679000", "dataset": "LL0_949_arsenic_female_bladder_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_949_arsenic_female_bladder", "about": {"problemID": "LL0_949_arsenic_female_bladder_problem", "problemName": "arsenic_female_bladder_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). It converts the numeric target feature to a two-class nominal target feature by computing the mean and classifying all instances with a lower target value as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_949_arsenic_female_bladder_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-949-arsenic-female-bladder"}, "LL0_953_splice": {"pipeline": {"_id": "adf2e39e-8060-4614-af1d-4d1d251087d1", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 88}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 559, "max_depth": 7, "learning_rate": 0.13609054940974707, "gamma": 0.13099321473506054, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "adf2e39e-8060-4614-af1d-4d1d251087d1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9702137008561363, "rank": 0.0297862991442803, "metric": "f1Macro", "ts": "2018-10-25T00:17:15.333000", "dataset": "LL0_953_splice_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_953_splice", "about": {"problemID": "LL0_953_splice_problem", "problemName": "LL0_953_splice_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL0_953_splice_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 62, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-953-splice"}, "LL0_962_mfeat_morphological": {"pipeline": {"_id": "090e70ca-44f9-4f71-98cd-04828ed2fa74", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 78}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "auto", "max_depth": 16, "min_samples_split": 0.014914552202695391, "min_samples_leaf": 0.022333651403203782, "n_estimators": 483, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf8071", "id": "090e70ca-44f9-4f71-98cd-04828ed2fa74", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9929581514032085, "rank": 0.007041848597071178, "metric": "f1Macro", "ts": "2018-10-25T05:46:01.801000", "dataset": "LL0_962_mfeat_morphological_dataset_TRAIN", "test_id": "20181025043231171172"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_962_mfeat_morphological", "about": {"problemID": "LL0_962_mfeat_morphological_problem", "problemName": "mfeat_morphological_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_962_mfeat_morphological_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-962-mfeat-morphological"}, "LL0_968_analcatdata_birthday": {"pipeline": {"_id": "1bf29d0c-14c3-4ccf-bca6-51f59f67493c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 57}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 508, "max_depth": 7, "learning_rate": 0.3702237571122594, "gamma": 0.9941354542830136, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "1bf29d0c-14c3-4ccf-bca6-51f59f67493c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8137876161766078, "rank": 0.18621238382397778, "metric": "f1Macro", "ts": "2018-10-25T00:04:04.718000", "dataset": "LL0_968_analcatdata_birthday_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_968_analcatdata_birthday", "about": {"problemID": "LL0_968_analcatdata_birthday_problem", "problemName": "analcatdata_birthday_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_968_analcatdata_birthday_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 4, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-968-analcatdata-birthday"}, "LL0_999_audiology": {"pipeline": {"_id": "e7338a3d-4a61-40f6-a059-5bef59026a5e", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 95}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 13, "min_samples_split": 0.012937809938065762, "min_samples_leaf": 0.005930782753515338, "n_estimators": 481, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "e7338a3d-4a61-40f6-a059-5bef59026a5e", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9562833112833113, "rank": 0.04371668871742644, "metric": "f1Macro", "ts": "2018-10-25T04:44:31.118000", "dataset": "LL0_999_audiology_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_999_audiology", "about": {"problemID": "LL0_999_audiology_problem", "problemName": "audiology_problem", "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nBinarized version of the original data set (see version 1). The multi-class target feature is converted to a two-class nominal target feature by re-labeling the majority class as positive ('P') and all others as negative ('N'). Originally converted by Quan Sun.", "taskType": "classification", "taskSubType": "binary", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_999_audiology_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 70, "colName": "binaryClass"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-999-audiology"}, "LL0_acled": {"pipeline": {"_id": "0743e9fa-abf4-4aaa-a5ca-c93e8bbfad34", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 430, "max_depth": 3, "learning_rate": 0.3088773156187371, "gamma": 0.26193536851890964, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "0743e9fa-abf4-4aaa-a5ca-c93e8bbfad34", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8671473840216443, "rank": 0.13285261597841608, "metric": "accuracy", "ts": "2018-10-31T05:38:09.150000", "dataset": "acled_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_acled", "about": {"problemID": "acled_problem", "problemName": "acled_problem", "problemDescription": "This is a multi-class classification problem. Given a protest/political violence event, predict whether it was one of nine classes.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.1.1", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "acled_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 8, "colName": "event_type"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.4746, "stratified": false, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-acled"}, "LL0_uci_dow_jones_index": {"pipeline": {"_id": "5f0ff18e-5739-4438-955d-603782d69297", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 81}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 25, "min_samples_split": 0.04180098314970265, "min_samples_leaf": 0.005395475153846764, "n_estimators": 316}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "5f0ff18e-5739-4438-955d-603782d69297", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.003569704607926328, "rank": 0.003569704607980381, "metric": "meanSquaredError", "ts": "2018-10-24T21:02:36.678000", "dataset": "LL0_uci_dow_jones_index_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_uci_dow_jones_index", "about": {"problemID": "LL0_uci_dow_jones_index_problem", "problemName": "dow_jones_index_problem", "problemDescription": "Dataset to predict the DOW Jones index.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_uci_dow_jones_index_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 16, "colName": "percent_return_next_dividend_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.52, "stratified": false, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-uci-dow-jones-index"}, "LL0_uci_facebook_metrics": {"pipeline": {"_id": "16b22955-9bef-489f-9fca-f5c6a1f9af71", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 38}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 16, "min_samples_split": 0.008693732270186492, "min_samples_leaf": 0.010681519258292738, "n_estimators": 382}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "16b22955-9bef-489f-9fca-f5c6a1f9af71", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 1736969.0023515623, "rank": 1736969.0023515623, "metric": "meanSquaredError", "ts": "2018-10-24T20:22:51.624000", "dataset": "LL0_uci_facebook_metrics_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_uci_facebook_metrics", "about": {"problemID": "LL0_uci_facebook_metrics_problem", "problemName": "facebook_metrics_problem", "problemDescription": "Dataset to predict number of likes and interactions on Facebook for a renowned cosmetic's brand.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_uci_facebook_metrics_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "Page_total_likes_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-uci-facebook-metrics"}, "LL0_uci_forest_fires": {"pipeline": {"_id": "6358c899-108d-4f38-92f5-5401cb0c8107", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 79}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 23, "min_samples_split": 0.0020866106027069824, "min_samples_leaf": 0.0664866165903373, "n_estimators": 25}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "6358c899-108d-4f38-92f5-5401cb0c8107", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 2069.4439270189405, "rank": 2069.4439270189405, "metric": "meanSquaredError", "ts": "2018-10-24T22:10:41.055000", "dataset": "LL0_uci_forest_fires_dataset_TRAIN", "test_id": "20181024201213536304"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_uci_forest_fires", "about": {"problemID": "LL0_uci_forest_fires_problem", "problemName": "forest_fires_problem", "problemDescription": "Dataset to predict number the burned area of forest fires from meteorological data.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_uci_forest_fires_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 13, "colName": "area_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-uci-forest-fires"}, "LL0_uci_las_vegas_strip": {"pipeline": {"_id": "3b90d23a-afd8-41ab-a4d8-332533136a6b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 45}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 21, "min_samples_split": 0.16183892054697377, "min_samples_leaf": 0.011363591903751403, "n_estimators": 292}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "3b90d23a-afd8-41ab-a4d8-332533136a6b", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.9457023921719611, "rank": 0.9457023921724775, "metric": "meanSquaredError", "ts": "2018-10-24T20:27:41.523000", "dataset": "LL0_uci_las_vegas_strip_dataset_TRAIN", "test_id": "20181024201043921067"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_uci_las_vegas_strip", "about": {"problemID": "LL0_uci_las_vegas_strip_problem", "problemName": "las_vegas_strip_problem", "problemDescription": "Dataset to predict the ratings of hotels on the Las Vegas Strip.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_uci_las_vegas_strip_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 5, "colName": "Score_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-uci-las-vegas-strip"}, "LL0_uci_yacht_hydrodynamics": {"pipeline": {"_id": "c24d1890-b84a-444e-9896-bf9de01ab96d", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 451, "max_depth": 3, "learning_rate": 0.2606511673396348, "gamma": 0.0004898635069590096, "min_child_weight": 5}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "c24d1890-b84a-444e-9896-bf9de01ab96d", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.4710803525816578, "rank": 0.4710803525823187, "metric": "meanSquaredError", "ts": "2018-10-31T05:08:38.429000", "dataset": "LL0_uci_yacht_hydrodynamics_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL0_uci_yacht_hydrodynamics", "about": {"problemID": "LL0_uci_yacht_hydrodynamics_problem", "problemName": "yacht_hydrodynamics_problem", "problemDescription": "Dataset to predict the hydrodynamic performance of sailing yachts from dimensions and velocity.", "taskType": "regression", "taskSubType": "univariate", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL0_uci_yacht_hydrodynamics_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 7, "colName": "output_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL0-uci-yacht-hydrodynamics"}, "LL1_1196_bng_pharynx_": {"pipeline": {"_id": "97ac09b1-a431-4ed9-b0d7-bee7afec78f0", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 249, "max_depth": 4, "learning_rate": 0.40000091826548356, "gamma": 0.3964276157378259, "min_child_weight": 7}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "97ac09b1-a431-4ed9-b0d7-bee7afec78f0", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 85402.72605592893, "rank": 85402.72605592893, "metric": "meanSquaredError", "ts": "2018-10-24T22:00:35.824000", "dataset": "LL1_1196_bng_pharynx__dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_1196_bng_pharynx_", "about": {"problemID": "LL1_1196_bng_pharynx__problem", "problemName": "LL1_1196_bng_pharynx__problem", "problemDescription": "**Author**:   \n**Please cite**:   \n\nJuan J. Rodriguez, Ludmila I. Kuncheva, Carlos J. Alonso (2006). Rotation Forest: A new classifier ensemble method. IEEE Transactions on Pattern Analysis and Machine Intelligence. 28(10):1619-1630. URL http://doi.ieeecomputersociety.org/10.1109/TPAMI.2006.211.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_1196_bng_pharynx__dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 12, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-1196-bng-pharynx-"}, "LL1_1478_har": {"pipeline": {"_id": "9e9ae532-b55d-4dda-acb9-4eda3bbb0ef1", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "9e9ae532-b55d-4dda-acb9-4eda3bbb0ef1", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9905146190326082, "rank": 0.009485380967554398, "metric": "f1Macro", "ts": "2018-10-31T04:30:01.967000", "dataset": "LL1_1478_har_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_1478_har", "about": {"problemID": "LL1_1478_har_problem", "problemName": "LL1_1478_har_problem", "problemDescription": "**Author**: Jorge L. Reyes-Ortiz, Davide Anguita, Alessandro Ghio, Luca Oneto and Xavier Parra  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)  \n**Please cite**: Davide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. A Public Domain Dataset for Human Activity Recognition Using Smartphones. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.   \n\n### Description\n\nHuman Activity Recognition (HAR) database built from the recordings of 30 subjects performing activities of daily living (ADL) while carrying a waist-mounted smartphone with embedded inertial sensors. This dataset version contains all the training and testing examples provided in the original data repository.\n\n### Source\n\nJorge L. Reyes-Ortiz(1,2), Davide Anguita(1), Alessandro Ghio(1), Luca Oneto(1) and Xavier Parra(2)\n1 - Smartlab - Non-Linear Complex Systems Laboratory DITEN - Universit\u00e0 degli Studi di Genova, Genoa (I-16145), Italy. \n2 - CETpD - Technical Research Centre for Dependency Care and Autonomous Living Universitat Polit\u00e8cnica de Catalunya (BarcelonaTech). Vilanova i la Geltr\u00fa (08800), Spain, activityrecognition '@' smartlab.ws\n\n### Data Set Information\n\nThe experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II) on the waist. Using its embedded accelerometer and gyroscope, we captured 3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz. The experiments have been video-recorded to label the data manually. The obtained dataset has been randomly partitioned into two sets, where 70% of the volunteers were selected for generating the training data and 30% the test data. \n\nThe sensor signals (accelerometer and gyroscope) were pre-processed by applying noise filters and then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window). The sensor acceleration signal, which has gravitational and body motion components, was separated using a Butterworth low-pass filter into body acceleration and gravity. The gravitational force is assumed to have only low-frequency components, therefore a filter with 0.3 Hz cutoff frequency was used. From each window, a vector of features was obtained by calculating variables from the time and frequency domain.\n\n\n### Attribute Information\n\nFor each record in the dataset it is provided: \n* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration. \n* Triaxial Angular velocity from the gyroscope. \n* A 561-feature vector with time and frequency domain variables. \n* It's activity label. \n\n### Relevant Papers\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. International Workshop of Ambient Assisted Living (IWAAL 2012). Vitoria-Gasteiz, Spain. Dec 2012 \n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra, Jorge L. Reyes-Ortiz. Energy Efficient Smartphone-Based Activity Recognition using Fixed-Point Arithmetic. Journal of Universal Computer Science. Special Issue in Ambient Assisted Living: Home Care. Volume 19, Issue 9. May 2013\n\nDavide Anguita, Alessandro Ghio, Luca Oneto, Xavier Parra and Jorge L. Reyes-Ortiz. Human Activity Recognition on Smartphones using a Multiclass Hardware-Friendly Support Vector Machine. 4th International Workshop of Ambient Assisted Living, IWAAL 2012, Vitoria-Gasteiz, Spain, December 3-5, 2012. Proceedings. Lecture Notes in Computer Science 2012, pp 216-223. \n\nJorge Luis Reyes-Ortiz, Alessandro Ghio, Xavier Parra-Llanas, Davide Anguita, Joan Cabestany, Andreu Catal\u00e0. Human Activity and Motion Disorder Recognition: Towards Smarter Interactive Cognitive Environments. 21th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2013. Bruges, Belgium 24-26 April 2013.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_1478_har_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 562, "colName": "Class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-1478-har"}, "LL1_150_covertype": {"pipeline": {"_id": "9c18f266-c508-4a72-a915-82957d363352", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 47}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 755, "max_depth": 7, "learning_rate": 0.7495482521473891, "gamma": 0.07299281611601682, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9c18f266-c508-4a72-a915-82957d363352", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9388988435208756, "rank": 0.06110115648003152, "metric": "f1Macro", "ts": "2018-10-25T12:47:02.620000", "dataset": "LL1_150_covertype_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_150_covertype", "about": {"problemID": "LL1_150_covertype_problem", "problemName": "LL1_150_covertype_problem", "problemDescription": "**Author**: Albert Bifet  \n**Source**: [MOA](http://moa.cms.waikato.ac.nz/datasets/) - 2009  \n**Please cite**:   \n\nNormalized version of the Forest Covertype dataset (see version 1), so that the numerical values are between 0 and 1. Contains the forest cover type for 30 x 30 meter cells obtained from US Forest Service (USFS) Region 2 Resource Information System &#40;RIS&#41; data. It contains 581,012 instances and 54 attributes, and it has been used in several papers on data stream classification.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_150_covertype_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 55, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-150-covertype"}, "LL1_4532_higgs": {"pipeline": {"_id": "322485b5-a81c-4312-a868-632ab96cd140", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 95, "max_depth": 7, "learning_rate": 0.10346901867894776, "gamma": 0.742777712235176, "min_child_weight": 6}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "322485b5-a81c-4312-a868-632ab96cd140", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.18158684216095866, "rank": 0.18158684216124388, "metric": "meanSquaredError", "ts": "2018-10-24T22:08:04.649000", "dataset": "LL1_4532_higgs_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_4532_higgs", "about": {"problemID": "LL1_4532_higgs_problem", "problemName": "LL1_4532_higgs_problem", "problemDescription": "**Author**: Daniel Whiteson daniel'@'uci.edu\", Assistant Professor, Physics, Univ. of California Irvine  \n**Source**: [UCI](https://archive.ics.uci.edu/ml/datasets/HIGGS)  \n**Please cite**: Baldi, P., P. Sadowski, and D. Whiteson. Searching for Exotic Particles in High-energy Physics with Deep Learning. Nature Communications 5 (July 2, 2014).  \n\nData Set Information:\n\nThe data has been produced using Monte Carlo simulations. The first 21 features (columns 2-22) are kinematic properties measured by the particle detectors in the accelerator. The last seven features are functions of the first 21 features; these are high-level features derived by physicists to help discriminate between the two classes. There is an interest in using deep learning methods to obviate the need for physicists to manually develop such features. Benchmark results using Bayesian Decision Trees from a standard physics package and 5-layer neural networks are presented in the original paper. The last 500,000 examples are used as a test set.\n\n\nAttribute Information:\n\nThe first column is the class label (1 for signal, 0 for background), followed by the 28 features (21 low-level features then 7 high-level features): lepton pT, lepton eta, lepton phi, missing energy magnitude, missing energy phi, jet 1 pt, jet 1 eta, jet 1 phi, jet 1 b-tag, jet 2 pt, jet 2 eta, jet 2 phi, jet 2 b-tag, jet 3 pt, jet 3 eta, jet 3 phi, jet 3 b-tag, jet 4 pt, jet 4 eta, jet 4 phi, jet 4 b-tag, m_jj, m_jjj, m_lv, m_jlv, m_bb, m_wbb, m_wwbb. For more detailed information about each feature see the original paper.\n\n\nRelevant Papers:\n\nBaldi, P., P. Sadowski, and D. Whiteson. &ldquo;Searching for Exotic Particles in High-energy Physics with Deep Learning. Nature Communications 5 (July 2, 2014).", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_4532_higgs_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-4532-higgs"}, "LL1_4549_buzzinsocialmedia_twitter": {"pipeline": {"_id": "692ab41b-0445-4d22-bfe8-34d9313b7c46", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "692ab41b-0445-4d22-bfe8-34d9313b7c46", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 29104.83382444735, "rank": 29104.83382444735, "metric": "meanSquaredError", "ts": "2018-10-31T04:32:44.540000", "dataset": "LL1_4549_buzzinsocialmedia_twitter_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_4549_buzzinsocialmedia_twitter", "about": {"problemID": "LL1_4549_buzzinsocialmedia_twitter_problem", "problemName": "LL1_4549_buzzinsocialmedia_twitter_problem", "problemDescription": "**Author**: Creators :  Fran\u00e7ois Kawala (1\",\"2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2) Institutions :  (1) Universit\u00e9 Joseph Fourier (Grenoble I) Laboratoire d'informatique de Grenoble (LIG) (2) BestofMedia Group Donor:  BestofMedia (ediemert '@' bestofmedia.com)  \n**Source**: UCI \n**Please cite**: Pr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.  \n\nAbstract: This data-set contains examples of buzz events from two different social networks: Twitter, and Tom's Hardware, a forum network focusing on new technology with more conservative dynamics.\nSource:\n\nCreators : \nFran&ccedil;ois Kawala (1,2) Ahlame Douzal (1) Eric Gaussier (1) Eustache Diemert (2)\nInstitutions : \n(1) Universit&eacute; Joseph Fourier (Grenoble I)\nLaboratoire d'informatique de Grenoble (LIG)\n(2) BestofMedia Group\nDonor: \nBestofMedia (ediemert '@' bestofmedia.com)\n\n\nData Set Information:\n\nPlease see [Web Link]\n\n\nAttribute Information:\n\nPlease see [Web Link]\n\n\nRelevant Papers:\n\nPr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.\n\n\n\nCitation Request:\n\nPr&eacute;dictions d&rsquo;activit&eacute; dans les r&eacute;seaux sociaux en ligne (F. Kawala, A. Douzal-Chouakria, E. Gaussier, E. Dimert), In Actes de la Conf&eacute;rence sur les Mod&egrave;les et l&prime;Analyse des R&eacute;seaux : Approches Math&eacute;matiques et Informatique (MARAMI), pp. 16, 2013.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_4549_buzzinsocialmedia_twitter_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 78, "colName": "Annotation"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-4549-buzzinsocialmedia-twitter"}, "LL1_50words": {"pipeline": {"_id": "4bc2879f-c8e7-483b-b014-e0c1898e0f57", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 319, "max_depth": 8, "learning_rate": 0.973410987177923, "gamma": 0.37985104352979693, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "4bc2879f-c8e7-483b-b014-e0c1898e0f57", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.09381074252625832, "rank": 0.9061892574740144, "metric": "f1Macro", "ts": "2018-10-31T04:20:51.309000", "dataset": "LL1_50words_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_50words", "about": {"problemID": "LL1_50words_problem", "problemName": "LL1_50words_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_50words_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.503, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-50words"}, "LL1_5587_comet_mc": {"pipeline": {"_id": "33190553-d9ac-4f73-af7c-d2a9c1a65686", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 12}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 880, "max_depth": 10, "learning_rate": 0.22561845446495055, "gamma": 0.42657312706272976, "min_child_weight": 4}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "33190553-d9ac-4f73-af7c-d2a9c1a65686", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.00485559441681634, "rank": 0.0048555944172402705, "metric": "meanSquaredError", "ts": "2018-10-25T04:40:42.617000", "dataset": "LL1_5587_comet_mc_dataset_TRAIN", "test_id": "20181024200846214852"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_5587_comet_mc", "about": {"problemID": "LL1_5587_comet_mc_problem", "problemName": "LL1_5587_comet_mc_problem", "problemDescription": "**Author**: COMET collaboration  \n**Acknowledgements**: Chen WU, Ewen Gillies  \n**Source**: Unknown - Date unknown\n**Please cite**: Monte-Carlo simulation of COMET detector, COMET collaboration, http://comet.kek.jp/  \n\n## Guess which points belong to signal track\n\n[COMET](http://comet.kek.jp/Introduction.html) is an experiment being constructed at the J-PARC proton beam laboratory in Japan. It will search for coherent neutrino-less conversion of a muon to an electron, &mu;- + N(A,Z) &rarr; e- + N(A,Z). This process breaks the law of lepton conservation. If detected, it will be a signal of new physics.\n\nThe previous upper limit for this decay was set [5] by the SINDRUM II experiment in 2006. COMET is designed to have 10,000 times better sensitivity.\n\n## Cylindrical Drift Chamber\nThe COMET experiment is looking for muon to electron conversion, &mu;- + N &rarr; e- + N. COMET Phase-I will the Cylindrical Drift Chamber as the primary detector for physics measurements. Specifically, the momentum of resulting particles will be measured using the CyDet, which is a cylindrical wire array detector.\n\nThe particles flying out of muon-stopping target and registered by the CyDet. Among those we are interested in tracks left by electrons with specific energy, which are produced by muon to electron conversion.\n\nThe CyDet consists of 4482 sensitive wires organized in 18 layers. Each wire measures the energy deposited by a passing charged particle. Within each of the layers, the wires have same distance to the stopping target and stereometry angle. \n\n![Scheme of COMET cylindrical detector](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/comet_3d.gif)\n\nThere is magnetic field in the detector, which causes electron moves in helical path as shown below. This electron deposits energy in the wires close to the flight path. The radius of helix is proportional to transverse momentum of the electron:\n\nR = p_t/(eB)\n\nwhere p_t is transverse momentum, B is strength of magnetic field, e is charge of electron.\n\n![Trajectory of electron in margetic field](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMEThelixing.png)\n\nThe energy deposited on each wire is measured at the end plate of the cylindrical detector. An example of the resulting signal event can be seen below, where blue dots are background hits and red are hits from signal electrons:\n\n![Energy depositions in COMET](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMET2dprojection.png)\n\n## More details\n1. [COMET official site](http://comet.kek.jp/)\n2. [COMET conceptual design report](http://comet.kek.jp/Documents_files/comet-cdr-v1.0.pdf)\n3. [\u0420\u0430\u0440\u0438\u0442\u0435\u0442\u044b \u043c\u0438\u043a\u0440\u043e\u043c\u0438\u0440\u0430](https://nplus1.ru/news/2015/05/29/reareevents)  - if you aren't deep into HEP, this article in russian is probably good starting point to understand what is COMET about. \n4. [COMET presentation](http://www-physics.lbl.gov/seminars/old/LBNL2014KUNO.pdf)\n5. [A search for \u03bc-e conversion in muonic gold](http://www.researchgate.net/publication/226763791_A_search_for_-e_conversion_in_muonic_gold)\n\n## Important note\nDatasets available for this challenge are results of preliminary Monte Carlo simulation. They don't completely represent properties of COMET's detector and thus cannot be used to estimate final properties of tracking system, but are appropriate to test different approaches to tracking.\n\n## Acknowledgements\nWe thank COMET collaboration (and specially Chen WU) for allowing us to use this dataset.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_5587_comet_mc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-5587-comet-mc"}, "LL1_5648_comet_mc": {"pipeline": {"_id": "53258d69-2ab7-4ac6-bc6d-f0010657f7e5", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "53258d69-2ab7-4ac6-bc6d-f0010657f7e5", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.005495986539658562, "rank": 0.005495986540589414, "metric": "meanSquaredError", "ts": "2018-10-31T04:54:16.226000", "dataset": "LL1_5648_comet_mc_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_5648_comet_mc", "about": {"problemID": "LL1_5648_comet_mc_problem", "problemName": "LL1_5648_comet_mc_problem", "problemDescription": "**Author**: COMET collaboration  \n**Acknowledgements**: Chen WU, Ewen Gillies  \n**Source**: Unknown - Date unknown\n**Please cite**: Monte-Carlo simulation of COMET detector, COMET collaboration, http://comet.kek.jp/  \n\n## Guess which points belong to signal track\n\n[COMET](http://comet.kek.jp/Introduction.html) is an experiment being constructed at the J-PARC proton beam laboratory in Japan. It will search for coherent neutrino-less conversion of a muon to an electron, &amp;mu;- + N(A,Z) &amp;rarr; e- + N(A,Z). This process breaks the law of lepton conservation. If detected, it will be a signal of new physics.\n\nThe previous upper limit for this decay was set [5] by the SINDRUM II experiment in 2006. COMET is designed to have 10,000 times better sensitivity.\n\nWires positions are available in a [supplementary file](https://drive.google.com/file/d/0B_gdsqrqzUJyMHcyUVFHa05FLXc/view?usp=sharing)\n\n## Cylindrical Drift Chamber\nThe COMET experiment is looking for muon to electron conversion, &amp;mu;- + N &amp;rarr; e- + N. COMET Phase-I will the Cylindrical Drift Chamber as the primary detector for physics measurements. Specifically, the momentum of resulting particles will be measured using the CyDet, which is a cylindrical wire array detector.\n\nThe particles flying out of muon-stopping target and registered by the CyDet. Among those we are interested in tracks left by electrons with specific energy, which are produced by muon to electron conversion.\n\nThe CyDet consists of 4482 sensitive wires organized in 18 layers. Each wire measures the energy deposited by a passing charged particle. Within each of the layers, the wires have same distance to the stopping target and stereometry angle. \n\n![Scheme of COMET cylindrical detector](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/comet_3d.gif)\n\nThere is magnetic field in the detector, which causes electron moves in helical path as shown below. This electron deposits energy in the wires close to the flight path. The radius of helix is proportional to transverse momentum of the electron:\n\nR = p_t/(eB)\n\nwhere p_t is transverse momentum, B is strength of magnetic field, e is charge of electron.\n\n![Trajectory of electron in margetic field](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMEThelixing.png)\n\nThe energy deposited on each wire is measured at the end plate of the cylindrical detector. An example of the resulting signal event can be seen below, where blue dots are background hits and red are hits from signal electrons:\n\n![Energy depositions in COMET](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMET2dprojection.png)\n\n## More details\n1. [COMET official site](http://comet.kek.jp/)\n2. [COMET conceptual design report](http://comet.kek.jp/Documents_files/comet-cdr-v1.0.pdf)\n3. [\u0420\u0430\u0440\u0438\u0442\u0435\u0442\u044b \u043c\u0438\u043a\u0440\u043e\u043c\u0438\u0440\u0430](https://nplus1.ru/news/2015/05/29/reareevents)  - if you aren't deep into HEP, this article in russian is probably good starting point to understand what is COMET about. \n4. [COMET presentation](http://www-physics.lbl.gov/seminars/old/LBNL2014KUNO.pdf)\n5. [A search for &mu;-e conversion in muonic gold](http://www.researchgate.net/publication/226763791_A_search_for_-e_conversion_in_muonic_gold)\n\n## Important note\nDatasets available for this challenge are results of preliminary Monte Carlo simulation. They don't completely represent properties of COMET's detector and thus cannot be used to estimate final properties of tracking system, but are appropriate to test different approaches to tracking.\n\n## Acknowledgements\nWe thank COMET collaboration (and specially Chen WU) for allowing us to use this dataset.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_5648_comet_mc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-5648-comet-mc"}, "LL1_5889_comet_mc": {"pipeline": {"_id": "4b279f5a-8e4d-47fb-b6de-8a6d6949fbf6", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/regression/default", "template": "5bceaa5d49e71569e8bf7f7c", "id": "4b279f5a-8e4d-47fb-b6de-8a6d6949fbf6", "loader": {"data_modality": "single_table", "task_type": "regression"}, "score": 0.005382995533627241, "rank": 0.005382995534558455, "metric": "meanSquaredError", "ts": "2018-10-31T04:53:33.833000", "dataset": "LL1_5889_comet_mc_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_5889_comet_mc", "about": {"problemID": "LL1_5889_comet_mc_problem", "problemName": "LL1_5889_comet_mc_problem", "problemDescription": "**Author**: COMET collaboration  \n**Acknowledgements**: Chen WU, Ewen Gillies  \n**Source**: Unknown - Date unknown\n**Please cite**: Monte-Carlo simulation of COMET detector, COMET collaboration, http://comet.kek.jp/\n\n## Guess which points belong to signal track\n\n[COMET](http://comet.kek.jp/Introduction.html) is an experiment being constructed at the J-PARC proton beam laboratory in Japan. It will search for coherent neutrino-less conversion of a muon to an electron, &mu;- + N(A,Z) &rarr; e- + N(A,Z). This process breaks the law of lepton conservation. If detected, it will be a signal of new physics.\n\nThe previous upper limit for this decay was set [5] by the SINDRUM II experiment in 2006. COMET is designed to have 10,000 times better sensitivity.\n\nWires positions are available in a [supplementary file](https://drive.google.com/file/d/0B_gdsqrqzUJyMHcyUVFHa05FLXc/view?usp=sharing)\n\n## Cylindrical Drift Chamber\nThe COMET experiment is looking for muon to electron conversion, &amp;amp;mu;- + N &amp;amp;rarr; e- + N. COMET Phase-I will the Cylindrical Drift Chamber as the primary detector for physics measurements. Specifically, the momentum of resulting particles will be measured using the CyDet, which is a cylindrical wire array detector.\n\nThe particles flying out of muon-stopping target and registered by the CyDet. Among those we are interested in tracks left by electrons with specific energy, which are produced by muon to electron conversion.\n\nThe CyDet consists of 4482 sensitive wires organized in 18 layers. Each wire measures the energy deposited by a passing charged particle. Within each of the layers, the wires have same distance to the stopping target and stereometry angle. \n\n![Scheme of COMET cylindrical detector](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/comet_3d.gif)\n\nThere is magnetic field in the detector, which causes electron moves in helical path as shown below. This electron deposits energy in the wires close to the flight path. The radius of helix is proportional to transverse momentum of the electron:\n\nR = p_t/(eB)\n\nwhere p_t is transverse momentum, B is strength of magnetic field, e is charge of electron.\n\n![Trajectory of electron in margetic field](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMEThelixing.png)\n\nThe energy deposited on each wire is measured at the end plate of the cylindrical detector. An example of the resulting signal event can be seen below, where blue dots are background hits and red are hits from signal electrons:\n\n![Energy depositions in COMET](https://kaggle2.blob.core.windows.net/competitions/inclass/4520/media/COMET2dprojection.png)\n\n## Data format\nFormat of data\nInformation about position of straw tubes is kept in [supplementary file](https://drive.google.com/file/d/0B_gdsqrqzUJyMHcyUVFHa05FLXc/view?usp=sharing), it has following information:\n\n1. wire_id - zero-based index of straw tubes\n2. wire_rho - distance to stopping target\n3. wire_phi - phi angle in the plane perpendicular to beam\n\nEach event is a 'snapshot' of detector, it consists of data taken from all 4482 wires: energy and relative time.\n\nEvent is written only when hodoscope detects particle. Relative time is difference between time when straw tube detected energy and time of hodoscope.\n\nData in train.csv is organized as following:\n\n1. event_id - zero-based index of event\n2. wire_id - zero-based index of wire\n3. global_id - zero-based identifier for each entry in file\n4. energy - energy deposited at wire \n5. relative_time = ( time of readout - hodoscope time)\n6. label (0 = not activated or background, 1=signal hit)\nWire with zero energy deposition is not activated.\n\n## More details\n1. [COMET official site](http://comet.kek.jp/)\n2. [COMET conceptual design report](http://comet.kek.jp/Documents_files/comet-cdr-v1.0.pdf)\n3. [\u0420\u0430\u0440\u0438\u0442\u0435\u0442\u044b \u043c\u0438\u043a\u0440\u043e\u043c\u0438\u0440\u0430](https://nplus1.ru/news/2015/05/29/reareevents)  - if you aren't deep into HEP, this article in Russian is probably good starting point to understand what is COMET about. \n4. [COMET presentation](http://www-physics.lbl.gov/seminars/old/LBNL2014KUNO.pdf)\n5. [A search for &amp;mu;-e conversion in muonic gold](http://www.researchgate.net/publication/226763791_A_search_for_-e_conversion_in_muonic_gold)\n\n## Important note\nDatasets available for this challenge are results of preliminary Monte Carlo simulation. They don't completely represent properties of COMET's detector and thus cannot be used to estimate final properties of tracking system, but are appropriate to test different approaches to tracking.\n\n## Acknowledgements\nWe thank COMET collaboration (and specially Chen WU) for allowing us to use this dataset.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_5889_comet_mc_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 6, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "stratified": true, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "meanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-5889-comet-mc"}, "LL1_acetylene_production_industry": {"pipeline": {"_id": "dd1cc564-4b4e-4d08-b721-074634170398", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 3}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 24, "min_samples_split": 0.04149480860694435, "min_samples_leaf": 0.018544651588585107, "n_estimators": 285}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "dd1cc564-4b4e-4d08-b721-074634170398", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 436.0604934463319, "rank": 436.06049344633226, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:59:27.365000", "dataset": "LL1_acetylene_production_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_acetylene_production_industry", "about": {"problemID": "LL1_acetylene_production_industry_problem", "problemName": "Predict_LL1_acetylene_production_industry", "problemDescription": "Predict Acetylene, production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_acetylene_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-acetylene-production-industry"}, "LL1_Adiac": {"pipeline": {"_id": "e5896acf-6c1a-4914-a8e7-043aa829ff93", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 842, "max_depth": 5, "learning_rate": 0.4415273162545229, "gamma": 0.09659653063551199, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "e5896acf-6c1a-4914-a8e7-043aa829ff93", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.456019656019656, "rank": 0.5439803439805113, "metric": "f1Macro", "ts": "2018-10-31T05:54:26.924000", "dataset": "LL1_Adiac_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Adiac", "about": {"problemID": "LL1_Adiac_problem", "problemName": "LL1_Adiac_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Adiac_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.501, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Adiac"}, "LL1_airline_twitter_sentiment": {"pipeline": {"_id": "d21eb7f0-7af4-49c2-b435-7121bca34d9c", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 47}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 765, "max_depth": 4, "learning_rate": 0.21393899654688686, "gamma": 0.5214917067741964, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "d21eb7f0-7af4-49c2-b435-7121bca34d9c", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6497864900914634, "rank": 0.3502135099091151, "metric": "accuracy", "ts": "2018-10-25T01:23:42.797000", "dataset": "LL1_airline_twitter_sentiment_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_airline_twitter_sentiment", "about": {"problemID": "LL1_airline_twitter_sentiment_problem", "problemName": "Airline Twitter sentiment prediction problem", "problemDescription": "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \u201clate flight\u201d or \u201crude service\u201d).", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_airline_twitter_sentiment_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-airline-twitter-sentiment"}, "LL1_air_carriers_certificated_passenger_load_industry": {"pipeline": {"_id": "9806e1b7-d6eb-4cb0-89bf-2470173bb7ce", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 13}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 14, "max_depth": 9, "learning_rate": 0.782244031987801, "gamma": 0.5139625428951903, "min_child_weight": 5}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "9806e1b7-d6eb-4cb0-89bf-2470173bb7ce", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 341.3516967973622, "rank": 341.35169679736276, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:54:27.369000", "dataset": "LL1_air_carriers_certificated_passenger_load_industry_dataset_TRAIN", "test_id": "20181024201659517805"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_air_carriers_certificated_passenger_load_industry", "about": {"problemID": "LL1_air_carriers_certificated_passenger_load_industry_problem", "problemName": "Predict_LL1_air_carriers_certificated_passenger_load_industry", "problemDescription": "Predict Air carriers (certificated), passenger-load factor INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_air_carriers_certificated_passenger_load_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-air-carriers-certificated-passenger-load-industry"}, "LL1_aluminum_products_total_mill_shipments_industry": {"pipeline": {"_id": "2ecb5402-b1d3-47ed-b0a1-69a56391ecf7", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 5}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 795, "max_depth": 4, "learning_rate": 0.01224280738481276, "gamma": 0.1551955461847967, "min_child_weight": 4}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8015", "id": "2ecb5402-b1d3-47ed-b0a1-69a56391ecf7", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 322.8838468023237, "rank": 322.88384680232394, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:33:13.549000", "dataset": "LL1_aluminum_products_total_mill_shipments_industry_dataset_TRAIN", "test_id": "20181024201659517805"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_aluminum_products_total_mill_shipments_industry", "about": {"problemID": "LL1_aluminum_products_total_mill_shipments_industry_problem", "problemName": "Predict_LL1_aluminum_products_total_mill_shipments_industry", "problemDescription": "Predict Aluminum Products, total mill shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_aluminum_products_total_mill_shipments_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-aluminum-products-total-mill-shipments-industry"}, "LL1_aluminum_sulfate_commercial_production_industry": {"pipeline": {"_id": "567541bd-00f3-4d92-9847-d47dcdfa01f4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 36, "max_depth": 3, "learning_rate": 0.2564283073585406, "gamma": 0.7219278304976113, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "567541bd-00f3-4d92-9847-d47dcdfa01f4", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 446.26810425582016, "rank": 446.26810425582033, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:16:33.650000", "dataset": "LL1_aluminum_sulfate_commercial_production_industry_dataset_TRAIN", "test_id": "20181024201519018358"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_aluminum_sulfate_commercial_production_industry", "about": {"problemID": "LL1_aluminum_sulfate_commercial_production_industry_problem", "problemName": "Predict_LL1_aluminum_sulfate_commercial_production_industry", "problemDescription": "Predict Aluminum sulfate, commercial, production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_aluminum_sulfate_commercial_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-aluminum-sulfate-commercial-production-industry"}, "LL1_apple_sentiment_analysis": {"pipeline": {"_id": "aeead9a3-fe12-47ed-b558-2c7bd79bbfcc", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 294, "max_depth": 7, "learning_rate": 0.27952484033532665, "gamma": 0.5622884918899774, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "aeead9a3-fe12-47ed-b558-2c7bd79bbfcc", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.6437297137564582, "rank": 0.35627028624407664, "metric": "accuracy", "ts": "2018-10-31T05:40:37.077000", "dataset": "LL1_apple_sentiment_analysis_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_apple_sentiment_analysis", "about": {"problemID": "LL1_apple_sentiment_analysis_problem", "problemName": "Apple Computers Twitter sentiment analysis problem", "problemDescription": "A look into the sentiment around Apple, based on tweets containing #AAPL, @apple, etc. Contributors were given a tweet and asked whether the user was positive, negative, or neutral about Apple.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_apple_sentiment_analysis_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-apple-sentiment-analysis"}, "LL1_ArrowHead": {"pipeline": {"_id": "b1eb184d-cccf-4e26-901e-ed224c630e56", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 668, "max_depth": 6, "learning_rate": 0.9561017731408107, "gamma": 0.7397116207178583, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "b1eb184d-cccf-4e26-901e-ed224c630e56", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.4882539682539682, "rank": 0.5117460317463558, "metric": "f1Macro", "ts": "2018-10-31T04:41:50.622000", "dataset": "LL1_ArrowHead_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ArrowHead", "about": {"problemID": "LL1_ArrowHead_problem", "problemName": "LL1_ArrowHead_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ArrowHead_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.829, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ArrowHead"}, "LL1_batteries_auto_type_replacement_shipments_industry": {"pipeline": {"_id": "e6faf161-ec57-4859-8d2b-911c6038500c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 81}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 26, "min_samples_split": 0.020260523597821475, "min_samples_leaf": 0.00014050608104257184, "n_estimators": 456}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "e6faf161-ec57-4859-8d2b-911c6038500c", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 593.0678425789835, "rank": 593.0678425789838, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:39:31.405000", "dataset": "LL1_batteries_auto_type_replacement_shipments_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_batteries_auto_type_replacement_shipments_industry", "about": {"problemID": "LL1_batteries_auto_type_replacement_shipments_industry_problem", "problemName": "Predict_LL1_batteries_auto_type_replacement_shipments_industry", "problemDescription": "Predict Batteries (auto-type replacement), shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_batteries_auto_type_replacement_shipments_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-batteries-auto-type-replacement-shipments-industry"}, "LL1_bituminous_coal_consumption_total_industry": {"pipeline": {"_id": "e6b5b088-fc53-448a-a638-91a2da6241c3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": null, "max_depth": 20, "min_samples_split": 0.007011376554983029, "min_samples_leaf": 0.005652776892181875, "n_estimators": 132}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "e6b5b088-fc53-448a-a638-91a2da6241c3", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 459.192701520483, "rank": 459.19270152048324, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:37:11.644000", "dataset": "LL1_bituminous_coal_consumption_total_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_bituminous_coal_consumption_total_industry", "about": {"problemID": "LL1_bituminous_coal_consumption_total_industry_problem", "problemName": "Predict_LL1_bituminous_coal_consumption_total_industry", "problemDescription": "Predict Bituminous coal, consumption, total INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_bituminous_coal_consumption_total_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.12766, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-bituminous-coal-consumption-total-industry"}, "LL1_bituminous_coal_stocks_electric_power_industry": {"pipeline": {"_id": "b1e77b25-500e-42a9-b78d-9ddecae751a4", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 24}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "auto", "max_depth": 30, "min_samples_split": 0.015829753565150716, "min_samples_leaf": 0.0007565403767716093, "n_estimators": 128}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "b1e77b25-500e-42a9-b78d-9ddecae751a4", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 245.23357401493723, "rank": 245.23357401493737, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:19:27.209000", "dataset": "LL1_bituminous_coal_stocks_electric_power_industry_dataset_TRAIN", "test_id": "20181024202005579087"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_bituminous_coal_stocks_electric_power_industry", "about": {"problemID": "LL1_bituminous_coal_stocks_electric_power_industry_problem", "problemName": "Predict_LL1_bituminous_coal_stocks_electric_power_industry", "problemDescription": "Predict Bituminous coal, stocks, electric power utilities INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_bituminous_coal_stocks_electric_power_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-bituminous-coal-stocks-electric-power-industry"}, "LL1_Blogosphere_net": {"pipeline": {"_id": "26ad402e-a23f-4a71-a363-311a0c97817f", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 776, "max_depth": 7, "learning_rate": 0.23682192509322986, "gamma": 0.8950180649335349, "min_child_weight": 2}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "graph/graph_matching/default", "template": "5bceaa5d49e71569e8bf7f7b", "id": "26ad402e-a23f-4a71-a363-311a0c97817f", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.9059887005649718, "rank": 0.09401129943533734, "metric": "accuracy", "ts": "2018-10-31T04:40:46.693000", "dataset": "LL1_Blogosphere_net_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Blogosphere_net", "about": {"problemID": "LL1_Blogosphere_net_problem", "problemName": "Blogosphere graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_Blogosphere_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.9, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Blogosphere-net"}, "LL1_castings_gray_ductile_iron_total_industry": {"pipeline": {"_id": "518c54b5-cce7-4cdc-87ca-9c46f7bcc127", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 53}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 16, "max_depth": 5, "learning_rate": 0.43411798827420367, "gamma": 0.8550962406318333, "min_child_weight": 8}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "518c54b5-cce7-4cdc-87ca-9c46f7bcc127", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 459.29727378222634, "rank": 459.29727378222634, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:19:38.096000", "dataset": "LL1_castings_gray_ductile_iron_total_industry_dataset_TRAIN", "test_id": "20181024201519018358"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_castings_gray_ductile_iron_total_industry", "about": {"problemID": "LL1_castings_gray_ductile_iron_total_industry_problem", "problemName": "Predict_LL1_castings_gray_ductile_iron_total_industry", "problemDescription": "Predict Castings, gray and ductile iron, total shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_castings_gray_ductile_iron_total_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-castings-gray-ductile-iron-total-industry"}, "LL1_castings_shipments_steel_for_sale_industry": {"pipeline": {"_id": "2369ef4d-5fd7-4fa5-a1df-2f6633b57c5b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "auto", "max_depth": 25, "min_samples_split": 0.0378367337880299, "min_samples_leaf": 0.010076718518708127, "n_estimators": 182}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "2369ef4d-5fd7-4fa5-a1df-2f6633b57c5b", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 460.10774900675085, "rank": 460.10774900675136, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:21:06.224000", "dataset": "LL1_castings_shipments_steel_for_sale_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_castings_shipments_steel_for_sale_industry", "about": {"problemID": "LL1_castings_shipments_steel_for_sale_industry_problem", "problemName": "Predict_LL1_castings_shipments_steel_for_sale_industry", "problemDescription": "Predict Castings (shipments), steel-for sale INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_castings_shipments_steel_for_sale_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-castings-shipments-steel-for-sale-industry"}, "LL1_cigars_large_taxable_withdrawals_industry": {"pipeline": {"_id": "f5899919-b382-4555-9ac0-4569cf17bc48", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 25, "min_samples_split": 0.007303909612582171, "min_samples_leaf": 0.014784894579097941, "n_estimators": 17}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "f5899919-b382-4555-9ac0-4569cf17bc48", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 579.4936656791062, "rank": 579.493665679107, "metric": "rootMeanSquaredError", "ts": "2018-10-24T22:18:52.390000", "dataset": "LL1_cigars_large_taxable_withdrawals_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_cigars_large_taxable_withdrawals_industry", "about": {"problemID": "LL1_cigars_large_taxable_withdrawals_industry_problem", "problemName": "Predict_LL1_cigars_large_taxable_withdrawals_industry", "problemDescription": "Predict Cigars (large), taxable withdrawals INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_cigars_large_taxable_withdrawals_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-cigars-large-taxable-withdrawals-industry"}, "LL1_CinC_ECG_torso": {"pipeline": {"_id": "2625ec53-5a5a-45d3-9c97-628bb9e8cdfb", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 599, "max_depth": 3, "learning_rate": 0.6754862577463722, "gamma": 0.25178604405187743, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "2625ec53-5a5a-45d3-9c97-628bb9e8cdfb", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.3747222222222222, "rank": 0.6252777777786969, "metric": "f1Macro", "ts": "2018-10-31T04:34:43.958000", "dataset": "LL1_CinC_ECG_torso_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_CinC_ECG_torso", "about": {"problemID": "LL1_CinC_ECG_torso_problem", "problemName": "LL1_CinC_ECG_torso_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_CinC_ECG_torso_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.972, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-CinC-ECG-torso"}, "LL1_claritin_twitter": {"pipeline": {"_id": "8926250c-1354-4914-9b8c-ec8b602c32a5", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 23}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 486, "max_depth": 3, "learning_rate": 0.18420343001135364, "gamma": 0.6592221492137758, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd106fb49e71569e8bf806d", "id": "8926250c-1354-4914-9b8c-ec8b602c32a5", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5211310666550915, "rank": 0.47886893334528824, "metric": "accuracy", "ts": "2018-10-25T00:36:23.767000", "dataset": "LL1_claritin_twitter_dataset_TRAIN", "test_id": "20181024235843843810"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_claritin_twitter", "about": {"problemID": "LL1_claritin_twitter_problem", "problemName": "Claritin Twitter categorization problem", "problemDescription": "This is a multiClass classification problem. This dataset has all  tweets that mention Claritin for October, 2012.  The tweets are tagged with sentiment, the author\u2019s gender, and whether or not they mention any of the top 10 adverse events reported to the FDA.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_claritin_twitter_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-claritin-twitter"}, "LL1_Coachella_tweet_classification": {"pipeline": {"_id": "26f33588-e60b-4d80-9a07-3d0622ed3963", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 79}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 12, "min_samples_split": 0.40630908511217173, "min_samples_leaf": 0.07574452441608642, "n_estimators": 225, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "26f33588-e60b-4d80-9a07-3d0622ed3963", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5936125321807862, "rank": 0.40638746781921387, "metric": "accuracy", "ts": "2018-10-25T05:37:17.975000", "dataset": "LL1_Coachella_tweet_classification_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Coachella_tweet_classification", "about": {"problemID": "LL1_Coachella_tweet_classification_problem", "problemName": "Coachella 2015 Tweets classification problem", "problemDescription": "A sentiment analysis job about the lineup of Coachella 2015. We wrote about it here. An additional, thousand-row data set about which artists fans were most excited about can be found here. The button to the right concerns sentiment about the festival overall.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Coachella_tweet_classification_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Coachella-tweet-classification"}, "LL1_coated_paper_unfilled_orders_industry": {"pipeline": {"_id": "7542605e-85cf-4507-8be4-82ead289a225", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 7}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "auto", "max_depth": 10, "min_samples_split": 0.03109061849212078, "min_samples_leaf": 0.002556974447887605, "n_estimators": 458}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "7542605e-85cf-4507-8be4-82ead289a225", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 333.70518918362956, "rank": 333.7051891836296, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:36:28.474000", "dataset": "LL1_coated_paper_unfilled_orders_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_coated_paper_unfilled_orders_industry", "about": {"problemID": "LL1_coated_paper_unfilled_orders_industry_problem", "problemName": "Predict_LL1_coated_paper_unfilled_orders_industry", "problemDescription": "Predict Coated paper, unfilled orders INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_coated_paper_unfilled_orders_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-coated-paper-unfilled-orders-industry"}, "LL1_coffee_green_imports_brazil_industry": {"pipeline": {"_id": "08e08e80-65ea-4ad3-ab35-62e091165308", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 34}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 8, "min_samples_split": 0.03883113955198802, "min_samples_leaf": 0.04853345083486886, "n_estimators": 24}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "08e08e80-65ea-4ad3-ab35-62e091165308", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 1887.291748987024, "rank": 1887.2917489870242, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:02:27.779000", "dataset": "LL1_coffee_green_imports_brazil_industry_dataset_TRAIN", "test_id": "20181024202005579087"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_coffee_green_imports_brazil_industry", "about": {"problemID": "LL1_coffee_green_imports_brazil_industry_problem", "problemName": "Predict_LL1_coffee_green_imports_brazil_industry", "problemDescription": "Predict Coffee (green), imports from Brazil INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_coffee_green_imports_brazil_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-coffee-green-imports-brazil-industry"}, "LL1_copper_production_mine_recoverable_industry": {"pipeline": {"_id": "ac71a1cc-8280-49cb-b6b7-4ea7169205d1", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 42}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 25, "min_samples_split": 0.20118402842771868, "min_samples_leaf": 0.0012342391869981264, "n_estimators": 451}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "ac71a1cc-8280-49cb-b6b7-4ea7169205d1", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 265.757870659456, "rank": 265.7578706594564, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:46:36.527000", "dataset": "LL1_copper_production_mine_recoverable_industry_dataset_TRAIN", "test_id": "20181024202005579087"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_copper_production_mine_recoverable_industry", "about": {"problemID": "LL1_copper_production_mine_recoverable_industry_problem", "problemName": "Predict_LL1_copper_production_mine_recoverable_industry", "problemDescription": "Predict Copper production, mine recoverable INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_copper_production_mine_recoverable_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.12587, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-copper-production-mine-recoverable-industry"}, "LL1_cotton_fiber_consumption_industry": {"pipeline": {"_id": "d90242b8-d86f-43a4-b532-1207b1f21b8f", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 96}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 19, "min_samples_split": 0.1476385445217232, "min_samples_leaf": 0.013530845470835159, "n_estimators": 206}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "d90242b8-d86f-43a4-b532-1207b1f21b8f", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 658.1636196691239, "rank": 658.1636196691243, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:13:27.181000", "dataset": "LL1_cotton_fiber_consumption_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_cotton_fiber_consumption_industry", "about": {"problemID": "LL1_cotton_fiber_consumption_industry_problem", "problemName": "Predict_LL1_cotton_fiber_consumption_industry", "problemDescription": "Predict Cotton fiber, consumption INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_cotton_fiber_consumption_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-cotton-fiber-consumption-industry"}, "LL1_cotton_stocks_in_us_domestic_industry": {"pipeline": {"_id": "8154aaaa-ae22-47fa-8029-800601d46e6d", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 73}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 19, "min_samples_split": 0.0014393308006818535, "min_samples_leaf": 0.0017767657842646368, "n_estimators": 186}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "8154aaaa-ae22-47fa-8029-800601d46e6d", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 1055.6270713430572, "rank": 1055.627071343058, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:35:11.327000", "dataset": "LL1_cotton_stocks_in_us_domestic_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_cotton_stocks_in_us_domestic_industry", "about": {"problemID": "LL1_cotton_stocks_in_us_domestic_industry_problem", "problemName": "Predict_LL1_cotton_stocks_in_us_domestic_industry", "problemDescription": "Predict Cotton stocks in the U.S., domestic, pub. storage and compresses INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_cotton_stocks_in_us_domestic_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-cotton-stocks-in-us-domestic-industry"}, "LL1_Cricket_Y": {"pipeline": {"_id": "df21abc2-5859-4177-8bcc-e3bcb6422a00", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 593, "max_depth": 8, "learning_rate": 0.3126614155984522, "gamma": 0.9787151742965261, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "df21abc2-5859-4177-8bcc-e3bcb6422a00", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.28896827759443855, "rank": 0.7110317224060637, "metric": "f1Macro", "ts": "2018-10-31T04:57:50.300000", "dataset": "LL1_Cricket_Y_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Cricket_Y", "about": {"problemID": "LL1_Cricket_Y_problem", "problemName": "LL1_Cricket_Y_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Cricket_Y_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Cricket-Y"}, "LL1_crude_gypsum_excl_byproduct_production_industry": {"pipeline": {"_id": "984e2a3b-69b1-4f02-af30-d513c760fc16", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 4}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 79, "max_depth": 3, "learning_rate": 0.051887185862011576, "gamma": 0.9759466036124996, "min_child_weight": 3}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "984e2a3b-69b1-4f02-af30-d513c760fc16", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 707.796869603982, "rank": 707.7968696039828, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:37:34.055000", "dataset": "LL1_crude_gypsum_excl_byproduct_production_industry_dataset_TRAIN", "test_id": "20181024201519018358"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_crude_gypsum_excl_byproduct_production_industry", "about": {"problemID": "LL1_crude_gypsum_excl_byproduct_production_industry_problem", "problemName": "Predict_LL1_crude_gypsum_excl_byproduct_production_industry", "problemDescription": "Predict Crude gypsum (excl. byproduct), production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_crude_gypsum_excl_byproduct_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-crude-gypsum-excl-byproduct-production-industry"}, "LL1_crude_petroleum_production_industry": {"pipeline": {"_id": "6246eeab-2887-4f0a-b236-4d974071cb4c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 61}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 19, "min_samples_split": 0.006956072510257988, "min_samples_leaf": 0.06109987550510455, "n_estimators": 25}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "6246eeab-2887-4f0a-b236-4d974071cb4c", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 153.0517462664177, "rank": 153.05174626641812, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:20:07.054000", "dataset": "LL1_crude_petroleum_production_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_crude_petroleum_production_industry", "about": {"problemID": "LL1_crude_petroleum_production_industry_problem", "problemName": "Predict_LL1_crude_petroleum_production_industry", "problemDescription": "Predict Crude petroleum, production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_crude_petroleum_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-crude-petroleum-production-industry"}, "LL1_DIC28_net": {"pipeline": {"_id": "c199324d-75b7-46ac-be9c-2f81f86f2439", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 15}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 20, "min_samples_split": 0.09198419273011564, "min_samples_leaf": 0.3060264048965515, "n_estimators": 47, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/graph_matching/random_forest_classifier", "template": "5bd9f2c149e71534685a9d9e", "id": "c199324d-75b7-46ac-be9c-2f81f86f2439", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.6444444444444445, "rank": 0.3555555555558642, "metric": "accuracy", "ts": "2018-10-31T20:04:20.929000", "dataset": "LL1_DIC28_net_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182406178134"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_DIC28_net", "about": {"problemID": "LL1_DIC28_net_problem", "problemName": "DIC28 graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_DIC28_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.9, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-DIC28-net"}, "LL1_domestic_product_demand_total_industry": {"pipeline": {"_id": "a356c581-574f-475e-b494-1912bf973bad", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 6}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": null, "max_depth": 11, "min_samples_split": 0.16989788667896558, "min_samples_leaf": 0.09102346189819666, "n_estimators": 29}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "a356c581-574f-475e-b494-1912bf973bad", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 208.90242885922075, "rank": 208.90242885922146, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:24:04.936000", "dataset": "LL1_domestic_product_demand_total_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_domestic_product_demand_total_industry", "about": {"problemID": "LL1_domestic_product_demand_total_industry_problem", "problemName": "Predict_LL1_domestic_product_demand_total_industry", "problemDescription": "Predict Domestic product demand, total INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_domestic_product_demand_total_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-domestic-product-demand-total-industry"}, "LL1_ECG200": {"pipeline": {"_id": "8cf0ec17-a79c-4ca5-b372-0dbb2b9b5459", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 206, "max_depth": 6, "learning_rate": 0.9501888324881003, "gamma": 0.6620931296090303, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "8cf0ec17-a79c-4ca5-b372-0dbb2b9b5459", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.8785105143280895, "rank": 0.12148948567241462, "metric": "f1", "ts": "2018-10-31T04:30:42.186000", "dataset": "LL1_ECG200_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ECG200", "about": {"problemID": "LL1_ECG200_problem", "problemName": "LL1_ECG200_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ECG200_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ECG200"}, "LL1_ECGFiveDays": {"pipeline": {"_id": "bc0d21fe-6785-456a-8324-13c6f8b96db6", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 629, "max_depth": 7, "learning_rate": 0.4344711815475589, "gamma": 0.010567715502156738, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "bc0d21fe-6785-456a-8324-13c6f8b96db6", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.82, "rank": 0.18000000000003447, "metric": "f1", "ts": "2018-10-31T05:16:13.526000", "dataset": "LL1_ECGFiveDays_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ECGFiveDays", "about": {"problemID": "LL1_ECGFiveDays_problem", "problemName": "LL1_ECGFiveDays_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ECGFiveDays_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.974, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ECGFiveDays"}, "LL1_ElectricDevices": {"pipeline": {"_id": "376afe79-2ddb-401a-9346-e922cc11d115", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 672, "max_depth": 9, "learning_rate": 0.06523123030989175, "gamma": 0.3197227056114773, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "376afe79-2ddb-401a-9346-e922cc11d115", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.5703242762736815, "rank": 0.42967572372650836, "metric": "f1Macro", "ts": "2018-10-31T04:44:46.778000", "dataset": "LL1_ElectricDevices_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ElectricDevices", "about": {"problemID": "LL1_ElectricDevices_problem", "problemName": "LL1_ElectricDevices_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ElectricDevices_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.463, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ElectricDevices"}, "LL1_ERDOS972_net": {"pipeline": {"_id": "223744ac-ff23-4d38-90a7-92f272dd82dd", "primitives": ["mlprimitives.trivial.TrivialPredictor"], "init_params": {"mlprimitives-trivial-TrivialPredictor": {"method": null}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-trivial-TrivialPredictor#1": {"default": 0, "method": null}}, "tunable_hyperparameters": {"mlprimitives-trivial-TrivialPredictor#1": {}}, "name": "trivial.None", "template": null, "id": "223744ac-ff23-4d38-90a7-92f272dd82dd", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.0, "rank": 1.000000000000656, "metric": "accuracy", "ts": "2018-10-31T04:09:09.529000", "dataset": "LL1_ERDOS972_net_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ERDOS972_net", "about": {"problemID": "LL1_ERDOS972_net_problem", "problemName": "ERDOS972 graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_ERDOS972_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.9, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ERDOS972-net"}, "LL1_ethyl_alcohol_spirits_production_industry": {"pipeline": {"_id": "59cd14ea-acf9-4197-82e4-568971abbec8", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 7, "min_samples_split": 0.06687750869758767, "min_samples_leaf": 0.005315013502041366, "n_estimators": 143}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "59cd14ea-acf9-4197-82e4-568971abbec8", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 524.7911718979009, "rank": 524.7911718979009, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:56:25.288000", "dataset": "LL1_ethyl_alcohol_spirits_production_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ethyl_alcohol_spirits_production_industry", "about": {"problemID": "LL1_ethyl_alcohol_spirits_production_industry_problem", "problemName": "Predict_LL1_ethyl_alcohol_spirits_production_industry", "problemDescription": "Predict Ethyl alcohol and spirits, production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_ethyl_alcohol_spirits_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.1295, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ethyl-alcohol-spirits-production-industry"}, "LL1_FaceFour": {"pipeline": {"_id": "f99f9f11-6a85-48c1-8449-29c6c7d72cd4", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 65, "max_depth": 8, "learning_rate": 0.566330392751835, "gamma": 0.3002975053712742, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "f99f9f11-6a85-48c1-8449-29c6c7d72cd4", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.47111111111111115, "rank": 0.5288888888889804, "metric": "f1Macro", "ts": "2018-10-31T05:08:14.942000", "dataset": "LL1_FaceFour_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_FaceFour", "about": {"problemID": "LL1_FaceFour_problem", "problemName": "LL1_FaceFour_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_FaceFour_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.786, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-FaceFour"}, "LL1_FISH": {"pipeline": {"_id": "3629c915-a387-4ff6-8411-feb391b987be", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 15, "max_depth": 6, "learning_rate": 0.1563099312242524, "gamma": 0.27607348137053156, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "3629c915-a387-4ff6-8411-feb391b987be", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.38129663986806844, "rank": 0.6187033601321031, "metric": "f1Macro", "ts": "2018-10-31T04:26:42.956000", "dataset": "LL1_FISH_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_FISH", "about": {"problemID": "LL1_FISH_problem", "problemName": "LL1_FISH_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_FISH_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-FISH"}, "LL1_fluid_milk_wholesale_price_all_industry": {"pipeline": {"_id": "e2e0d91d-dcef-49c9-9e78-556e4c6254a9", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 81}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "auto", "max_depth": 18, "min_samples_split": 0.03247669999967324, "min_samples_leaf": 0.008272161079266618, "n_estimators": 365}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "e2e0d91d-dcef-49c9-9e78-556e4c6254a9", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 58.77469378277768, "rank": 58.77469378277867, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:34:25.714000", "dataset": "LL1_fluid_milk_wholesale_price_all_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_fluid_milk_wholesale_price_all_industry", "about": {"problemID": "LL1_fluid_milk_wholesale_price_all_industry_problem", "problemName": "Predict_LL1_fluid_milk_wholesale_price_all_industry", "problemDescription": "Predict Fluid milk, wholesale price (all grades), U.S. average INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_fluid_milk_wholesale_price_all_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-fluid-milk-wholesale-price-all-industry"}, "LL1_fluid_power_shipments_hydraulic_index_industry": {"pipeline": {"_id": "5a8a9a54-d668-494c-bb36-666cc235ad4b", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 59}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 21, "min_samples_split": 0.05182620748327222, "min_samples_leaf": 0.010526113444985675, "n_estimators": 486}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "5a8a9a54-d668-494c-bb36-666cc235ad4b", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 238.27346882525336, "rank": 238.27346882525399, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:36:13.518000", "dataset": "LL1_fluid_power_shipments_hydraulic_index_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_fluid_power_shipments_hydraulic_index_industry", "about": {"problemID": "LL1_fluid_power_shipments_hydraulic_index_industry_problem", "problemName": "Predict_LL1_fluid_power_shipments_hydraulic_index_industry", "problemDescription": "Predict Fluid power shipments - hydraulic index INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_fluid_power_shipments_hydraulic_index_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13433, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-fluid-power-shipments-hydraulic-index-industry"}, "LL1_food_dairy_products_glass_containers_industry": {"pipeline": {"_id": "11df8086-2fa2-4ebe-b01d-6b40dd3c2be0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 83}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 1, "min_samples_split": 0.04400477658078482, "min_samples_leaf": 0.16476509037159112, "n_estimators": 8}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "11df8086-2fa2-4ebe-b01d-6b40dd3c2be0", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 516.2235221553515, "rank": 516.2235221553525, "metric": "rootMeanSquaredError", "ts": "2018-10-24T22:01:42.959000", "dataset": "LL1_food_dairy_products_glass_containers_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_food_dairy_products_glass_containers_industry", "about": {"problemID": "LL1_food_dairy_products_glass_containers_industry_problem", "problemName": "Predict_LL1_food_dairy_products_glass_containers_industry", "problemDescription": "Predict Food and dairy products glass containers, shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_food_dairy_products_glass_containers_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-food-dairy-products-glass-containers-industry"}, "LL1_food_narrow_neck_glass_containers_industry": {"pipeline": {"_id": "0857e250-ca9a-4263-9f19-a01f9163e617", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 66}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 8, "min_samples_split": 0.01210997960229284, "min_samples_leaf": 0.0036392927727490368, "n_estimators": 228}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "0857e250-ca9a-4263-9f19-a01f9163e617", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 662.0263341287098, "rank": 662.0263341287101, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:40:12.473000", "dataset": "LL1_food_narrow_neck_glass_containers_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_food_narrow_neck_glass_containers_industry", "about": {"problemID": "LL1_food_narrow_neck_glass_containers_industry_problem", "problemName": "Predict_LL1_food_narrow_neck_glass_containers_industry", "problemDescription": "Predict Food (narrow-neck) glass containers, shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_food_narrow_neck_glass_containers_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-food-narrow-neck-glass-containers-industry"}, "LL1_FordA": {"pipeline": {"_id": "0ca22976-21a4-4839-be13-1be03a9a9e42", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 20, "max_depth": 9, "learning_rate": 0.08807957670712174, "gamma": 0.7115457942968372, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "0ca22976-21a4-4839-be13-1be03a9a9e42", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.5372262401184088, "rank": 0.4627737598824717, "metric": "f1", "ts": "2018-10-31T04:49:38.992000", "dataset": "LL1_FordA_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_FordA", "about": {"problemID": "LL1_FordA_problem", "problemName": "LL1_FordA_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_FordA_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.732, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-FordA"}, "LL1_FordB": {"pipeline": {"_id": "6b0a6721-0482-46b4-ba54-8d207bae1ffa", "primitives": ["mlprimitives.trivial.TrivialPredictor"], "init_params": {"mlprimitives-trivial-TrivialPredictor": {"method": "mode"}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-trivial-TrivialPredictor#1": {"default": 0, "method": "mode"}}, "tunable_hyperparameters": {"mlprimitives-trivial-TrivialPredictor#1": {}}, "name": "trivial.mode", "template": null, "id": "6b0a6721-0482-46b4-ba54-8d207bae1ffa", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.6710405370656595, "rank": 0.32895946293439826, "metric": "f1", "ts": "2018-10-31T04:08:57.987000", "dataset": "LL1_FordB_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_FordB", "about": {"problemID": "LL1_FordB_problem", "problemName": "LL1_FordB_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_FordB_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.818, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-FordB"}, "LL1_gasoline_incl_aviation_production_industry": {"pipeline": {"_id": "636e2e0e-070c-42d1-ad58-5638f5f580b8", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 93}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 20, "min_samples_split": 0.031890173932977356, "min_samples_leaf": 0.005363204150194955, "n_estimators": 247}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "636e2e0e-070c-42d1-ad58-5638f5f580b8", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 193.94420716598722, "rank": 193.9442071659881, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:24:43.019000", "dataset": "LL1_gasoline_incl_aviation_production_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_gasoline_incl_aviation_production_industry", "about": {"problemID": "LL1_gasoline_incl_aviation_production_industry_problem", "problemName": "Predict_LL1_gasoline_incl_aviation_production_industry", "problemDescription": "Predict Gasoline (incl. aviation), production INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_gasoline_incl_aviation_production_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-gasoline-incl-aviation-production-industry"}, "LL1_global_warming_sentiment": {"pipeline": {"_id": "4228cdfa-d366-41f1-b170-44e7e4c150cb", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 76, "max_depth": 3, "learning_rate": 0.07299873175888716, "gamma": 0.0057041441816431115, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "4228cdfa-d366-41f1-b170-44e7e4c150cb", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.739599053368089, "rank": 0.2604009466322278, "metric": "accuracy", "ts": "2018-10-31T04:27:39.793000", "dataset": "LL1_global_warming_sentiment_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_global_warming_sentiment", "about": {"problemID": "LL1_global_warming_sentiment_problem", "problemName": "Sentiment Analysis problem \u2013 Global Warming/Climate Change", "problemDescription": "This is a binary text classification problem. Data consists of tweets for belief in the existence of global warming or climate change. The possible answers were \u201cYes\u201d if the tweet suggests global warming is occurring, \u201cNo\u201d if the tweet suggests global warming is not occurring, and \u201cI can\u2019t tell\u201d if the tweet is ambiguous or unrelated to global warming.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_global_warming_sentiment_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-global-warming-sentiment"}, "LL1_groundwood_paper_uncoated_new_orders_industry": {"pipeline": {"_id": "a0179fa7-9cbb-4a52-9012-80b9ef827fb6", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 8}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 28, "min_samples_split": 0.2635336524277574, "min_samples_leaf": 0.19758259398484432, "n_estimators": 5}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "a0179fa7-9cbb-4a52-9012-80b9ef827fb6", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 804.280900457996, "rank": 804.280900457997, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:32:37.060000", "dataset": "LL1_groundwood_paper_uncoated_new_orders_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_groundwood_paper_uncoated_new_orders_industry", "about": {"problemID": "LL1_groundwood_paper_uncoated_new_orders_industry_problem", "problemName": "Predict_LL1_groundwood_paper_uncoated_new_orders_industry", "problemDescription": "Predict Groundwood paper uncoated, new orders INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_groundwood_paper_uncoated_new_orders_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-groundwood-paper-uncoated-new-orders-industry"}, "LL1_HandOutlines": {"pipeline": {"_id": "7f16907f-00c6-4b86-a23d-a9dd8cb8a022", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 328, "max_depth": 5, "learning_rate": 0.006377077187694646, "gamma": 0.03680144062030255, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "7f16907f-00c6-4b86-a23d-a9dd8cb8a022", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.8017558664446156, "rank": 0.198244133555669, "metric": "f1", "ts": "2018-10-31T05:54:40.566000", "dataset": "LL1_HandOutlines_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_HandOutlines", "about": {"problemID": "LL1_HandOutlines_problem", "problemName": "LL1_HandOutlines_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_HandOutlines_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.73, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-HandOutlines"}, "LL1_Haptics": {"pipeline": {"_id": "1894a7b9-f5f8-4f81-8d1b-bb019a5b51dc", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 660, "max_depth": 5, "learning_rate": 0.23181654967733667, "gamma": 0.7860730319548405, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "1894a7b9-f5f8-4f81-8d1b-bb019a5b51dc", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.3331504457015293, "rank": 0.6668495542989868, "metric": "f1Macro", "ts": "2018-10-31T04:26:02.233000", "dataset": "LL1_Haptics_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Haptics", "about": {"problemID": "LL1_Haptics_problem", "problemName": "LL1_Haptics_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Haptics_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.665, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Haptics"}, "LL1_hosiery_shipments_industry": {"pipeline": {"_id": "7efc270c-b841-46db-ac5d-fcb0bca7d574", "primitives": ["featuretools.dfs", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 3}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 4, "min_samples_split": 0.2338933074904484, "min_samples_leaf": 0.009458016184253166, "n_estimators": 29}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "dfs/categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8019", "id": "7efc270c-b841-46db-ac5d-fcb0bca7d574", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 450.2088846771412, "rank": 450.20888467714127, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:02:54.779000", "dataset": "LL1_hosiery_shipments_industry_dataset_TRAIN", "test_id": "20181024202005579087"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_hosiery_shipments_industry", "about": {"problemID": "LL1_hosiery_shipments_industry_problem", "problemName": "Predict_LL1_hosiery_shipments_industry", "problemDescription": "Predict Hosiery, shipments INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_hosiery_shipments_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-hosiery-shipments-industry"}, "LL1_imports_net": {"pipeline": {"_id": "59b9e91c-fbd3-40f7-b321-3e116e99ff31", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 75}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 929, "max_depth": 10, "learning_rate": 0.4671064799031647, "gamma": 0.8982718224166012, "min_child_weight": 1}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "graph/graph_matching/default", "template": "5bceaa5d49e71569e8bf7f7b", "id": "59b9e91c-fbd3-40f7-b321-3e116e99ff31", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.8095238095238096, "rank": 0.19047619047621817, "metric": "accuracy", "ts": "2018-10-31T04:50:49.097000", "dataset": "LL1_imports_net_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_imports_net", "about": {"problemID": "LL1_imports_net_problem", "problemName": "Imports graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_imports_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-imports-net"}, "LL1_iron_ore_imports_industry": {"pipeline": {"_id": "b9e06e38-bd2d-4646-ad1a-332852a591a4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 89}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": null, "max_depth": 10, "min_samples_split": 0.024520873557713957, "min_samples_leaf": 0.0002572078975252766, "n_estimators": 170}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "b9e06e38-bd2d-4646-ad1a-332852a591a4", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 828.7574149996115, "rank": 828.7574149996121, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:51:13.757000", "dataset": "LL1_iron_ore_imports_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_iron_ore_imports_industry", "about": {"problemID": "LL1_iron_ore_imports_industry_problem", "problemName": "Predict_LL1_iron_ore_imports_industry", "problemDescription": "Predict Iron ore imports INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_iron_ore_imports_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.12587, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-iron-ore-imports-industry"}, "LL1_iron_steel_imports_steel_mill_industry": {"pipeline": {"_id": "92dd332b-27d1-4fbc-9975-0d8be69f33d0", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 27}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "log2", "max_depth": 3, "min_samples_split": 0.03649206590985897, "min_samples_leaf": 0.0020712826615537183, "n_estimators": 67}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "92dd332b-27d1-4fbc-9975-0d8be69f33d0", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 1181.106650551183, "rank": 1181.1066505511833, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:29:19.446000", "dataset": "LL1_iron_steel_imports_steel_mill_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_iron_steel_imports_steel_mill_industry", "about": {"problemID": "LL1_iron_steel_imports_steel_mill_industry_problem", "problemName": "Predict_LL1_iron_steel_imports_steel_mill_industry", "problemDescription": "Predict Iron and Steel imports, steel mill products INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_iron_steel_imports_steel_mill_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13534, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-iron-steel-imports-steel-mill-industry"}, "LL1_iron_steel_scrap_consumption_industry": {"pipeline": {"_id": "58a02798-5488-4e85-a76a-acd9dafecd69", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 85}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 20, "min_samples_split": 0.008815991422506667, "min_samples_leaf": 0.008621892075502615, "n_estimators": 299}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "58a02798-5488-4e85-a76a-acd9dafecd69", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 286.3984416406501, "rank": 286.3984416406509, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:18:43.179000", "dataset": "LL1_iron_steel_scrap_consumption_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_iron_steel_scrap_consumption_industry", "about": {"problemID": "LL1_iron_steel_scrap_consumption_industry_problem", "problemName": "Predict_LL1_iron_steel_scrap_consumption_industry", "problemDescription": "Predict Iron and Steel Scrap, consumption INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_iron_steel_scrap_consumption_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-iron-steel-scrap-consumption-industry"}, "LL1_ItalyPowerDemand": {"pipeline": {"_id": "5aa01f26-863a-4b43-82b4-96b270f39571", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 921, "max_depth": 3, "learning_rate": 0.6593522354289555, "gamma": 0.0029709714826569034, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "5aa01f26-863a-4b43-82b4-96b270f39571", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.7458423929012163, "rank": 0.2541576070991492, "metric": "f1", "ts": "2018-10-31T05:46:44.840000", "dataset": "LL1_ItalyPowerDemand_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ItalyPowerDemand", "about": {"problemID": "LL1_ItalyPowerDemand_problem", "problemName": "LL1_ItalyPowerDemand_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ItalyPowerDemand_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.939, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ItalyPowerDemand"}, "LL1_IzmenjavaBratSestra_net": {"pipeline": {"_id": "2b7d827b-0023-46a6-9ea1-dc7a5a556791", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 3}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 14, "min_samples_split": 0.387760611770593, "min_samples_leaf": 0.06805004804536138, "n_estimators": 433, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/graph_matching/random_forest_classifier", "template": "5bd9f2c149e71534685a9d9e", "id": "2b7d827b-0023-46a6-9ea1-dc7a5a556791", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.6021083743842365, "rank": 0.39789162561601593, "metric": "accuracy", "ts": "2018-10-31T20:10:04.704000", "dataset": "LL1_IzmenjavaBratSestra_net_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182406178134"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_IzmenjavaBratSestra_net", "about": {"problemID": "LL1_IzmenjavaBratSestra_net_problem", "problemName": "IzmenjavaBratSestra network graph matching problem", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_IzmenjavaBratSestra_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-IzmenjavaBratSestra-net"}, "LL1_lead_production_recovered_scrap_industry": {"pipeline": {"_id": "89ad58b5-e4c6-4c4e-991c-e4c12f8395fa", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 71}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 24, "max_depth": 4, "learning_rate": 0.22873177142465706, "gamma": 0.3555591726212822, "min_child_weight": 5}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "categorical_encoder/imputer/standard_scaler/xgbregressor", "template": "5bd0cf9849e71569e8bf8013", "id": "89ad58b5-e4c6-4c4e-991c-e4c12f8395fa", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 344.8098202516524, "rank": 344.80982025165275, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:55:13.953000", "dataset": "LL1_lead_production_recovered_scrap_industry_dataset_TRAIN", "test_id": "20181024201519018358"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_lead_production_recovered_scrap_industry", "about": {"problemID": "LL1_lead_production_recovered_scrap_industry_problem", "problemName": "Predict_LL1_lead_production_recovered_scrap_industry", "problemDescription": "Predict Lead production, recovered from scrap INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_lead_production_recovered_scrap_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-lead-production-recovered-scrap-industry"}, "LL1_lead_stocks_consumers_industry": {"pipeline": {"_id": "820091cb-7a32-496c-938e-91c7ae3339be", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 47}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": null, "max_depth": 9, "min_samples_split": 0.03123857680704897, "min_samples_leaf": 0.006798636244484729, "n_estimators": 425}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "820091cb-7a32-496c-938e-91c7ae3339be", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 405.058764662232, "rank": 405.0587646622321, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:10:34.794000", "dataset": "LL1_lead_stocks_consumers_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_lead_stocks_consumers_industry", "about": {"problemID": "LL1_lead_stocks_consumers_industry_problem", "problemName": "Predict_LL1_lead_stocks_consumers_industry", "problemDescription": "Predict Lead stocks, consumers' INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_lead_stocks_consumers_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-lead-stocks-consumers-industry"}, "LL1_Lighting7": {"pipeline": {"_id": "407702bd-74e2-4192-954d-db716fc4f0e8", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 525, "max_depth": 7, "learning_rate": 0.9592905695810913, "gamma": 0.3178142297755925, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "407702bd-74e2-4192-954d-db716fc4f0e8", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.5031663574520717, "rank": 0.4968336425482353, "metric": "f1Macro", "ts": "2018-10-31T05:20:09.104000", "dataset": "LL1_Lighting7_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Lighting7", "about": {"problemID": "LL1_Lighting7_problem", "problemName": "LL1_Lighting7_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Lighting7_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.51, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Lighting7"}, "LL1_liquefied_gases_production_total_industry": {"pipeline": {"_id": "5422f61a-b5a0-4d63-a64c-4d7f9836bf51", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 41, "max_depth": 3, "learning_rate": 0.14726886517820525, "gamma": 0.3872373338096101, "min_child_weight": 2}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "single_table/time_series_forecasting/default", "template": "5bceaa5c49e71569e8bf7f7a", "id": "5422f61a-b5a0-4d63-a64c-4d7f9836bf51", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 248.46638488696195, "rank": 248.46638488696266, "metric": "rootMeanSquaredError", "ts": "2018-10-31T04:45:29.001000", "dataset": "LL1_liquefied_gases_production_total_industry_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_liquefied_gases_production_total_industry", "about": {"problemID": "LL1_liquefied_gases_production_total_industry_problem", "problemName": "Predict_LL1_liquefied_gases_production_total_industry", "problemDescription": "Predict Liquefied gases, production, total INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_liquefied_gases_production_total_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-liquefied-gases-production-total-industry"}, "LL1_lumber_douglas_fir_other_softwoods_industry": {"pipeline": {"_id": "526729b2-62f3-4b10-8ee8-d5d2938f9de3", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 58}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mae", "max_features": "log2", "max_depth": 13, "min_samples_split": 0.0034154676814077364, "min_samples_leaf": 0.004399853831555631, "n_estimators": 204}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "526729b2-62f3-4b10-8ee8-d5d2938f9de3", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 207.10889920362519, "rank": 207.108899203626, "metric": "rootMeanSquaredError", "ts": "2018-10-24T21:43:58.863000", "dataset": "LL1_lumber_douglas_fir_other_softwoods_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_lumber_douglas_fir_other_softwoods_industry", "about": {"problemID": "LL1_lumber_douglas_fir_other_softwoods_industry_problem", "problemName": "Predict_LL1_lumber_douglas_fir_other_softwoods_industry", "problemDescription": "Predict Lumber, douglas fir, other softwoods, producer price index INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_lumber_douglas_fir_other_softwoods_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.13433, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-lumber-douglas-fir-other-softwoods-industry"}, "LL1_lumber_imports_total_sawmill_industry": {"pipeline": {"_id": "4678c2a8-1c17-46e2-bc06-fcf204b6a2b4", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 90}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": "auto", "max_depth": 9, "min_samples_split": 0.007922212165469282, "min_samples_leaf": 0.00520817636968828, "n_estimators": 443}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "4678c2a8-1c17-46e2-bc06-fcf204b6a2b4", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 331.33601675729216, "rank": 331.3360167572924, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:46:36.479000", "dataset": "LL1_lumber_imports_total_sawmill_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_lumber_imports_total_sawmill_industry", "about": {"problemID": "LL1_lumber_imports_total_sawmill_industry_problem", "problemName": "Predict_LL1_lumber_imports_total_sawmill_industry", "problemDescription": "Predict Lumber, imports, total sawmill INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_lumber_imports_total_sawmill_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-lumber-imports-total-sawmill-industry"}, "LL1_lumber_production_hardwoods_industry": {"pipeline": {"_id": "f457ba51-161b-4bfb-b564-9235e224680c", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestRegressor"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 88}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestRegressor#1": {"n_jobs": -1, "criterion": "mse", "max_features": null, "max_depth": 24, "min_samples_split": 0.06258089012891993, "min_samples_leaf": 0.017335887898194905, "n_estimators": 108}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestRegressor#1": {"criterion": {"type": "str", "default": "mse", "values": ["mse", "mae"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_regressor", "template": "5bd0cf9849e71569e8bf8017", "id": "f457ba51-161b-4bfb-b564-9235e224680c", "loader": {"data_modality": "single_table", "task_type": "time_series_forecasting"}, "score": 405.40197964034974, "rank": 405.4019796403501, "metric": "rootMeanSquaredError", "ts": "2018-10-24T20:33:57.526000", "dataset": "LL1_lumber_production_hardwoods_industry_dataset_TRAIN", "test_id": "20181024201841111384"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_lumber_production_hardwoods_industry", "about": {"problemID": "LL1_lumber_production_hardwoods_industry_problem", "problemName": "Predict_LL1_lumber_production_hardwoods_industry", "problemDescription": "Predict Lumber, production, hardwoods INDUSTRY ", "taskType": "timeSeriesForecasting", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_lumber_production_hardwoods_industry_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.125, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-lumber-production-hardwoods-industry"}, "LL1_Meat": {"pipeline": {"_id": "bb2eba59-8271-4f59-a25c-c926059e687d", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 822, "max_depth": 10, "learning_rate": 0.6025230247559277, "gamma": 0.9562439641615664, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "bb2eba59-8271-4f59-a25c-c926059e687d", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.8305820105820108, "rank": 0.16941798941849925, "metric": "f1Macro", "ts": "2018-10-31T04:54:55.914000", "dataset": "LL1_Meat_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Meat", "about": {"problemID": "LL1_Meat_problem", "problemName": "LL1_Meat_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Meat_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Meat"}, "LL1_MedicalImages": {"pipeline": {"_id": "f9dc0444-ed9e-41dd-b144-e7cb589e17d5", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 235, "max_depth": 9, "learning_rate": 0.8355937194089852, "gamma": 0.28829259073656865, "min_child_weight": 5}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "f9dc0444-ed9e-41dd-b144-e7cb589e17d5", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.34785582729928893, "rank": 0.6521441727015631, "metric": "f1Macro", "ts": "2018-10-31T05:33:47.785000", "dataset": "LL1_MedicalImages_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_MedicalImages", "about": {"problemID": "LL1_MedicalImages_problem", "problemName": "LL1_MedicalImages_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_MedicalImages_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.666, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-MedicalImages"}, "LL1_MiddlePhalanxOutlineAgeGroup": {"pipeline": {"_id": "6fca215a-ae31-4042-abbf-c9bf6fd83ef9", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "6fca215a-ae31-4042-abbf-c9bf6fd83ef9", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.4909706867932802, "rank": 0.509029313207703, "metric": "f1Macro", "ts": "2018-10-31T04:09:09.686000", "dataset": "LL1_MiddlePhalanxOutlineAgeGroup_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_MiddlePhalanxOutlineAgeGroup", "about": {"problemID": "LL1_MiddlePhalanxOutlineAgeGroup_problem", "problemName": "LL1_MiddlePhalanxOutlineAgeGroup_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_MiddlePhalanxOutlineAgeGroup_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.722, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-MiddlePhalanxOutlineAgeGroup"}, "LL1_MiddlePhalanxTW": {"pipeline": {"_id": "00fdc716-d6c0-4711-94e7-e88cbadc7cf2", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 149, "max_depth": 5, "learning_rate": 0.41122438470368494, "gamma": 0.3320092647598293, "min_child_weight": 6}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "00fdc716-d6c0-4711-94e7-e88cbadc7cf2", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.45044048083353505, "rank": 0.5495595191668255, "metric": "f1Macro", "ts": "2018-10-31T04:13:53.184000", "dataset": "LL1_MiddlePhalanxTW_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_MiddlePhalanxTW", "about": {"problemID": "LL1_MiddlePhalanxTW_problem", "problemName": "LL1_MiddlePhalanxTW_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_MiddlePhalanxTW_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.722, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-MiddlePhalanxTW"}, "LL1_MoteStrain": {"pipeline": {"_id": "49fa2ab3-b6ad-4409-9079-668d66fc6121", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 41, "max_depth": 3, "learning_rate": 0.044747282286113466, "gamma": 0.49940500230599494, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "49fa2ab3-b6ad-4409-9079-668d66fc6121", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.8533333333333333, "rank": 0.14666666666722372, "metric": "f1", "ts": "2018-10-31T04:15:03.153000", "dataset": "LL1_MoteStrain_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_MoteStrain", "about": {"problemID": "LL1_MoteStrain_problem", "problemName": "LL1_MoteStrain_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_MoteStrain_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.984, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-MoteStrain"}, "LL1_net_nomination_seed": {"pipeline": {"_id": "5dd3021b-51d8-4757-8b3c-b3a9114d93b9", "primitives": ["networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 74}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 13, "min_samples_split": 0.19093847768399153, "min_samples_leaf": 0.0036044679255859266, "n_estimators": 87, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/vertex_nomination/random_forest_classifier", "template": "5bd9f2c249e71534685a9da2", "id": "5dd3021b-51d8-4757-8b3c-b3a9114d93b9", "loader": {"data_modality": "graph", "task_type": "vertex_nomination"}, "score": 0.95, "rank": 0.05000000000000915, "metric": "accuracy", "ts": "2018-10-31T18:26:01.159000", "dataset": "LL1_net_nomination_seed_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182509788210"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_net_nomination_seed", "about": {"problemID": "LL1_net_nomination_seed_problem", "problemName": "LL1 sample vertex nomination problem", "problemDescription": "Data consists of one graph, G1, whose nodes contain two attributes, attr1 and attr2. Associated with each node is a classLabel that has to be learned and predicted.", "taskType": "vertexNomination", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_net_nomination_seed_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "classLabel"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-net-nomination-seed"}, "LL1_nuclear_emotions": {"pipeline": {"_id": "bff16a3f-02d8-40b9-9e71-fcf6f9e42279", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 46}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 20, "min_samples_split": 0.43837832805689303, "min_samples_leaf": 0.3913376436295468, "n_estimators": 392, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/random_forest_classifier", "template": "5bd106fb49e71569e8bf806f", "id": "bff16a3f-02d8-40b9-9e71-fcf6f9e42279", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.8214794464794466, "rank": 0.17852055352055343, "metric": "accuracy", "ts": "2018-10-25T05:32:00.966000", "dataset": "LL1_nuclear_emotions_dataset_TRAIN", "test_id": "20181025042919337776"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_nuclear_emotions", "about": {"problemID": "LL1_nuclear_emotions_problem", "problemName": "Emotions prediction about nuclear energy from Twitter problem", "problemDescription": "This is a multiClass text classification problem. This dataset is a collection of tweets related to nuclear energy along with the crowd\u2019s evaluation of the tweet\u2019s sentiment. The possible sentiment categories are: \u201cPositive,\u201d \u201cNegative,\u201d \u201cNeutral/author is just sharing information,\u201d \u201cTweet NOT related to nuclear energy,\u201d and \u201cI can\u2019t tell.\u201d", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_nuclear_emotions_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-nuclear-emotions"}, "LL1_OSULeaf": {"pipeline": {"_id": "b23c2488-7944-488a-8d90-10b216d0c8f4", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 342, "max_depth": 7, "learning_rate": 0.5902058073588565, "gamma": 0.9518978400970716, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "b23c2488-7944-488a-8d90-10b216d0c8f4", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.479761837291249, "rank": 0.5202381627096963, "metric": "f1Macro", "ts": "2018-10-31T04:43:03.513000", "dataset": "LL1_OSULeaf_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_OSULeaf", "about": {"problemID": "LL1_OSULeaf_problem", "problemName": "LL1_OSULeaf_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_OSULeaf_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.548, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-OSULeaf"}, "LL1_RefrigerationDevices": {"pipeline": {"_id": "6f74acbc-35e9-40dd-a76c-3b0444d2ad77", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 1000, "max_depth": 4, "learning_rate": 0.7201752581223733, "gamma": 0.1745627752690332, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "6f74acbc-35e9-40dd-a76c-3b0444d2ad77", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.6023468852074692, "rank": 0.39765311479270865, "metric": "f1Macro", "ts": "2018-10-31T04:41:58.675000", "dataset": "LL1_RefrigerationDevices_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_RefrigerationDevices", "about": {"problemID": "LL1_RefrigerationDevices_problem", "problemName": "LL1_RefrigerationDevices_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_RefrigerationDevices_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-RefrigerationDevices"}, "LL1_REVIJE_net": {"pipeline": {"_id": "8f8b33c7-f9ee-496f-808e-ee4217bcbc95", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 23, "min_samples_split": 0.19338215431498823, "min_samples_leaf": 0.2511553722463436, "n_estimators": 93, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/graph_matching/random_forest_classifier", "template": "5bd9f2c149e71534685a9d9e", "id": "8f8b33c7-f9ee-496f-808e-ee4217bcbc95", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.6933333333333332, "rank": 0.3066666666666702, "metric": "accuracy", "ts": "2018-10-31T18:50:34.517000", "dataset": "LL1_REVIJE_net_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182406178134"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_REVIJE_net", "about": {"problemID": "LL1_REVIJE_net_problem", "problemName": "REVIJE graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_REVIJE_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-REVIJE-net"}, "LL1_SAMPSON_net": {"pipeline": {"_id": "50119d4e-bab9-4f3c-aa01-632cae9934ba", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 12}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 8, "min_samples_split": 0.22063388540915838, "min_samples_leaf": 0.4459860468601945, "n_estimators": 22, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/graph_matching/random_forest_classifier", "template": "5bd9f2c149e71534685a9d9e", "id": "50119d4e-bab9-4f3c-aa01-632cae9934ba", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.9, "rank": 0.10000000000027594, "metric": "accuracy", "ts": "2018-10-31T19:36:33.840000", "dataset": "LL1_SAMPSON_net_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182406178134"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_SAMPSON_net", "about": {"problemID": "LL1_SAMPSON_net_problem", "problemName": "SAMPSON graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_SAMPSON_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-SAMPSON-net"}, "LL1_scenes15": {"pipeline": {"_id": "38fd58a4-6227-449c-b279-375b1182c613", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "keras.applications.mobilenet.preprocess_input", "keras.applications.mobilenet.MobileNet", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {"weights": "imagenet", "pooling": "avg", "include_top": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "keras-applications-mobilenet-preprocess_input#1": {}, "keras-applications-mobilenet-MobileNet#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "image/classification/default", "template": "5bceaa5d49e71569e8bf7f7e", "id": "38fd58a4-6227-449c-b279-375b1182c613", "loader": {"data_modality": "image", "task_type": "classification"}, "score": 0.5466666666666666, "rank": 0.45333333333399456, "metric": "accuracy", "ts": "2018-10-31T04:31:37.550000", "dataset": "LL1_scenes15_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_scenes15", "about": {"problemID": "LL1_scenes15_problem", "problemName": "LL1_scenes15_problem", "problemURI": "http://www.ee.princeton.edu/seminars/iss/Fall2007/Papers-Slides/Fei-FeiPerona2005.pdf", "problemDescription": "Given 4485 images depicting 15 different natural scenes (e.g. store, bedroom, suburb, mountain), classify each image into the correct scene", "taskType": "classification", "taskSubType": "multiClass", "problemVersion": "1.0", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "scenes15_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.66, "stratified": false, "numRepeats": 0, "randomSeed": 42, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-scenes15"}, "LL1_ScreenType": {"pipeline": {"_id": "413a7591-5971-4aca-894c-8d2b1a688588", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 108, "max_depth": 8, "learning_rate": 0.21273196885586276, "gamma": 0.9537526974159806, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "413a7591-5971-4aca-894c-8d2b1a688588", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.4203167643160087, "rank": 0.5796832356843229, "metric": "f1Macro", "ts": "2018-10-31T05:30:49.440000", "dataset": "LL1_ScreenType_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ScreenType", "about": {"problemID": "LL1_ScreenType_problem", "problemName": "LL1_ScreenType_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ScreenType_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ScreenType"}, "LL1_sentiment_deflategate": {"pipeline": {"_id": "6ba0951b-d845-45e3-be2d-e38c97a3ba05", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 350, "max_depth": 3, "learning_rate": 0.7185952771178197, "gamma": 0.7862816546784778, "min_child_weight": 7}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "6ba0951b-d845-45e3-be2d-e38c97a3ba05", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.43995489296216894, "rank": 0.5600451070381789, "metric": "accuracy", "ts": "2018-10-31T04:17:48.007000", "dataset": "LL1_sentiment_deflategate_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_sentiment_deflategate", "about": {"problemID": "LL1_sentiment_deflategate_problem", "problemName": "New England Patriots Deflategate sentiment prediction problem", "problemDescription": "This is a multiclass classification problem on twitter data. Before the 2015 Super Bowl, there was a great deal of chatter around deflated footballs and whether the Patriots cheated. This data set looks at Twitter sentiment on important days during the scandal to gauge public sentiment about the whole ordeal.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_sentiment_deflategate_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-sentiment-deflategate"}, "LL1_sentiment_self_drive": {"pipeline": {"_id": "0f620e20-01f1-496a-8157-16e5c75c55fb", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 692, "max_depth": 3, "learning_rate": 0.1560476545398749, "gamma": 0.6244600098688798, "min_child_weight": 8}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "single_table/classification/default", "template": "5bceaa5d49e71569e8bf7f81", "id": "0f620e20-01f1-496a-8157-16e5c75c55fb", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.5931336716133391, "rank": 0.40686632838722925, "metric": "accuracy", "ts": "2018-10-31T04:59:33.340000", "dataset": "LL1_sentiment_self_drive_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_sentiment_self_drive", "about": {"problemID": "LL1_sentiment_self_drive_problem", "problemName": "Twitter sentiment prediction of Self-driving cars", "problemDescription": "This is a multiclass classification problem on twitter data. The classes 5, 4, 3, 2, 1, 0 correspond to very positive, slightly positive, neutral, slightly negative, or very negative.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_sentiment_self_drive_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-sentiment-self-drive"}, "LL1_SmallKitchenAppliances": {"pipeline": {"_id": "2d9a674b-4b47-4177-af56-d4cfbb3f6ffd", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 434, "max_depth": 8, "learning_rate": 0.4145741049822754, "gamma": 0.9648942429164201, "min_child_weight": 9}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "2d9a674b-4b47-4177-af56-d4cfbb3f6ffd", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.6436080386542867, "rank": 0.3563919613466303, "metric": "f1Macro", "ts": "2018-10-31T05:43:19.344000", "dataset": "LL1_SmallKitchenAppliances_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_SmallKitchenAppliances", "about": {"problemID": "LL1_SmallKitchenAppliances_problem", "problemName": "LL1_SmallKitchenAppliances_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_SmallKitchenAppliances_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-SmallKitchenAppliances"}, "LL1_SonyAIBORobotSurface": {"pipeline": {"_id": "db5cf889-48b0-453a-b540-598b82a4c6cb", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 23, "max_depth": 4, "learning_rate": 0.013426369391811521, "gamma": 0.3954778892506696, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "db5cf889-48b0-453a-b540-598b82a4c6cb", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.5999999999999999, "rank": 0.40000000000016017, "metric": "f1", "ts": "2018-10-31T05:22:26.292000", "dataset": "LL1_SonyAIBORobotSurface_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_SonyAIBORobotSurface", "about": {"problemID": "LL1_SonyAIBORobotSurface_problem", "problemName": "LL1_SonyAIBORobotSurface_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_SonyAIBORobotSurface_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.968, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-SonyAIBORobotSurface"}, "LL1_SonyAIBORobotSurfaceII": {"pipeline": {"_id": "78d97941-569e-48df-8e6e-a72cb1a1533c", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 13, "max_depth": 5, "learning_rate": 0.08947780276452266, "gamma": 0.2475589999491974, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "78d97941-569e-48df-8e6e-a72cb1a1533c", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.8514285714285714, "rank": 0.14857142857146294, "metric": "f1", "ts": "2018-10-31T05:04:22.286000", "dataset": "LL1_SonyAIBORobotSurfaceII_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_SonyAIBORobotSurfaceII", "about": {"problemID": "LL1_SonyAIBORobotSurfaceII_problem", "problemName": "LL1_SonyAIBORobotSurfaceII_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_SonyAIBORobotSurfaceII_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.972, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-SonyAIBORobotSurfaceII"}, "LL1_SwedishLeaf": {"pipeline": {"_id": "3f661b95-0389-4728-a854-c2b2a96ff2ed", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 213, "max_depth": 3, "learning_rate": 0.5482472837766937, "gamma": 0.39638850547822835, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "3f661b95-0389-4728-a854-c2b2a96ff2ed", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.5447183393275734, "rank": 0.4552816606729068, "metric": "f1Macro", "ts": "2018-10-31T09:10:13.164000", "dataset": "LL1_SwedishLeaf_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_SwedishLeaf", "about": {"problemID": "LL1_SwedishLeaf_problem", "problemName": "LL1_SwedishLeaf_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_SwedishLeaf_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.556, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-SwedishLeaf"}, "LL1_ToeSegmentation2": {"pipeline": {"_id": "158a5501-2bdc-47ea-af8d-4824b92c8cf6", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 704, "max_depth": 3, "learning_rate": 0.24396122120697494, "gamma": 0.9448414166957383, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "158a5501-2bdc-47ea-af8d-4824b92c8cf6", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.753968253968254, "rank": 0.2460317460317624, "metric": "f1", "ts": "2018-10-31T10:40:40.156000", "dataset": "LL1_ToeSegmentation2_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_ToeSegmentation2", "about": {"problemID": "LL1_ToeSegmentation2_problem", "problemName": "LL1_ToeSegmentation2_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_ToeSegmentation2_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.783, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-ToeSegmentation2"}, "LL1_Trace": {"pipeline": {"_id": "cb061faa-fe2b-4fe0-b84f-1c0b2541dca0", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 559, "max_depth": 10, "learning_rate": 0.8761927475289297, "gamma": 0.2514819892676564, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "cb061faa-fe2b-4fe0-b84f-1c0b2541dca0", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 1.0, "rank": 7.719210813623046e-14, "metric": "f1Macro", "ts": "2018-10-31T05:35:34.815000", "dataset": "LL1_Trace_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Trace", "about": {"problemID": "LL1_Trace_problem", "problemName": "LL1_Trace_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Trace_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.5, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Trace"}, "LL1_Two_Patterns": {"pipeline": {"_id": "1e89a232-7eb8-4768-88e7-d45d4fa5fdec", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 798, "max_depth": 6, "learning_rate": 0.7099399472498011, "gamma": 0.2529660562757621, "min_child_weight": 10}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "1e89a232-7eb8-4768-88e7-d45d4fa5fdec", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.3754301062356128, "rank": 0.624569893765223, "metric": "f1Macro", "ts": "2018-10-31T09:45:24.861000", "dataset": "LL1_Two_Patterns_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_Two_Patterns", "about": {"problemID": "LL1_Two_Patterns_problem", "problemName": "LL1_Two_Patterns_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_Two_Patterns_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-Two-Patterns"}, "LL1_USAIR97_net": {"pipeline": {"_id": "d34e2b0e-ddb0-4870-84f9-43a84c0f4bd6", "primitives": ["networkx.link_prediction_feature_extraction", "networkx.graph_feature_extraction", "mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "sklearn.ensemble.RandomForestClassifier"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"networkx-link_prediction_feature_extraction#1": {"functions": ["networkx.jaccard_coefficient", "networkx.resource_allocation_index", "networkx.adamic_adar_index", "networkx.preferential_attachment"]}, "networkx-graph_feature_extraction#1": {"functions": ["networkx.degree_centrality", "networkx.closeness_centrality", "networkx.betweenness_centrality", "networkx.clustering"]}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 2}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 21, "min_samples_split": 0.1525708931242391, "min_samples_leaf": 0.04121639333071866, "n_estimators": 30, "class_weight": "balanced"}}, "tunable_hyperparameters": {"networkx-link_prediction_feature_extraction#1": {}, "networkx-graph_feature_extraction#1": {}, "mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}}, "name": "graph/graph_matching/random_forest_classifier", "template": "5bd9f2c149e71534685a9d9e", "id": "d34e2b0e-ddb0-4870-84f9-43a84c0f4bd6", "loader": {"data_modality": "graph", "task_type": "graph_matching"}, "score": 0.7131868131868132, "rank": 0.286813186813478, "metric": "accuracy", "ts": "2018-10-31T19:27:36.536000", "dataset": "LL1_USAIR97_net_dataset_TRAIN", "tuner_type": "gp", "test_id": "20181031182406178134"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_USAIR97_net", "about": {"problemID": "LL1_USAIR97_net_problem", "problemName": "USAIR97 graph data matching", "problemDescription": "No description provided", "taskType": "graphMatching", "problemSchemaVersion": "3.0"}, "inputs": {"data": [{"datasetID": "LL1_USAIR97_net_dataset", "targets": [{"targetIndex": 0, "resID": "2", "colIndex": 3, "colName": "match"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.9, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-USAIR97-net"}, "LL1_UWaveGestureLibraryAll": {"pipeline": {"_id": "cc281e09-e481-4a0e-86f5-cde41fca1cdf", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 395, "max_depth": 4, "learning_rate": 0.5229399326994075, "gamma": 0.8467443886039018, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "cc281e09-e481-4a0e-86f5-cde41fca1cdf", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.24946463518804549, "rank": 0.7505353648121893, "metric": "f1Macro", "ts": "2018-10-31T05:34:58.178000", "dataset": "LL1_UWaveGestureLibraryAll_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_UWaveGestureLibraryAll", "about": {"problemID": "LL1_UWaveGestureLibraryAll_problem", "problemName": "LL1_UWaveGestureLibraryAll_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_UWaveGestureLibraryAll_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-UWaveGestureLibraryAll"}, "LL1_uWaveGestureLibrary_Z": {"pipeline": {"_id": "7e2ada10-c1a1-42f4-af53-361641fc0115", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 485, "max_depth": 4, "learning_rate": 0.28211365920217124, "gamma": 0.5101621670289467, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "7e2ada10-c1a1-42f4-af53-361641fc0115", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.3596720689951927, "rank": 0.640327931005517, "metric": "f1Macro", "ts": "2018-10-31T04:36:39.404000", "dataset": "LL1_uWaveGestureLibrary_Z_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_uWaveGestureLibrary_Z", "about": {"problemID": "LL1_uWaveGestureLibrary_Z_problem", "problemName": "LL1_uWaveGestureLibrary_Z_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_uWaveGestureLibrary_Z_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.8, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-uWaveGestureLibrary-Z"}, "LL1_WordsSynonyms": {"pipeline": {"_id": "1284b8ce-ad0d-4224-b3fe-feb2ea4f4b12", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 3, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 826, "max_depth": 8, "learning_rate": 0.5894245350155707, "gamma": 0.3608434736956653, "min_child_weight": 3}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "1284b8ce-ad0d-4224-b3fe-feb2ea4f4b12", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.09672546890873031, "rank": 0.9032745310913735, "metric": "f1Macro", "ts": "2018-10-31T04:30:32.483000", "dataset": "LL1_WordsSynonyms_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_WordsSynonyms", "about": {"problemID": "LL1_WordsSynonyms_problem", "problemName": "LL1_WordsSynonyms_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_WordsSynonyms_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.705, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-WordsSynonyms"}, "LL1_WormsTwoClass": {"pipeline": {"_id": "5b16827d-c231-4fc0-b087-3e2fbccf1558", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": false, "with_std": false}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 911, "max_depth": 4, "learning_rate": 0.609653608378255, "gamma": 0.7695105186424903, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "5b16827d-c231-4fc0-b087-3e2fbccf1558", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 0.6049417249417249, "rank": 0.39505827505873226, "metric": "f1", "ts": "2018-10-31T05:09:03.170000", "dataset": "LL1_WormsTwoClass_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "LL1_WormsTwoClass", "about": {"problemID": "LL1_WormsTwoClass_problem", "problemName": "LL1_WormsTwoClass_problem", "problemDescription": "A time series classification problem.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "LL1_WormsTwoClass_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "label"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.702, "stratified": true, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "LL1-WormsTwoClass"}, "New-years-resolutions-DFE": {"pipeline": {"_id": "b36c00ef-8e2f-4a9e-81d3-ff410fd0d4b7", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": false, "max_features": 458}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 16, "min_samples_split": 0.3169615852869801, "min_samples_leaf": 0.00021853567761033986, "n_estimators": 57, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "b36c00ef-8e2f-4a9e-81d3-ff410fd0d4b7", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.2706945937831033, "rank": 0.7293054062173098, "metric": "accuracy", "ts": "2018-10-31T04:47:40.118000", "dataset": "New-years-resolutions-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "New-years-resolutions-DFE", "about": {"problemID": "New-years-resolutions-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "New-years-resolutions-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 3, "colName": "resolution_topics"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "New-years-resolutions-DFE"}, "Political-media-DFE": {"pipeline": {"_id": "1c58aa48-9697-4329-94e6-b24a73f469dd", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": false, "max_features": 452}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 15, "min_samples_split": 0.1052259608164755, "min_samples_leaf": 0.008524179576886231, "n_estimators": 185, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "1c58aa48-9697-4329-94e6-b24a73f469dd", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.39551842870697684, "rank": 0.6044815712932317, "metric": "accuracy", "ts": "2018-10-31T05:37:06.837000", "dataset": "Political-media-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "Political-media-DFE", "about": {"problemID": "Political-media-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "Political-media-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 11, "colName": "message"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "Political-media-DFE"}, "primary-plutchik-wheel-DFE": {"pipeline": {"_id": "f9fff807-3294-4eea-814a-2a563f44d491", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": false, "max_features": 78}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": null, "max_depth": 7, "min_samples_split": 0.02947162778021113, "min_samples_leaf": 0.004417495352900791, "n_estimators": 168, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "f9fff807-3294-4eea-814a-2a563f44d491", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.2703178087541255, "rank": 0.7296821912467928, "metric": "accuracy", "ts": "2018-10-31T05:50:29.584000", "dataset": "primary-plutchik-wheel-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "primary-plutchik-wheel-DFE", "about": {"problemID": "primary-plutchik-wheel-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "primary-plutchik-wheel-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "emotion"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "primary-plutchik-wheel-DFE"}, "progressive-tweet-sentiment": {"pipeline": {"_id": "8a77adb9-873a-4310-a88a-227e7416f1dc", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": true, "max_features": 856}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 29, "min_samples_split": 0.02885229625756755, "min_samples_leaf": 0.0008157520962072825, "n_estimators": 337, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "8a77adb9-873a-4310-a88a-227e7416f1dc", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.6763696094411382, "rank": 0.32363039055949644, "metric": "accuracy", "ts": "2018-10-31T05:49:38.440000", "dataset": "progressive-tweet-sentiment_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "progressive-tweet-sentiment", "about": {"problemID": "progressive-tweet-sentiment_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "progressive-tweet-sentiment_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "q1_from_reading_the_tweet_which_of_the_options_below_is_most_likely_to_be_true_about_the_stance_or_outlook_of_the_tweeter_towards_the_target"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "progressive-tweet-sentiment"}, "smart-app-functionality-DFE": {"pipeline": {"_id": "19c2b89a-76fa-4c22-80c4-667f934ce909", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 648}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 9, "min_samples_split": 0.01886108766377682, "min_samples_leaf": 0.005592934052828986, "n_estimators": 214, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "19c2b89a-76fa-4c22-80c4-667f934ce909", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.6306483601616555, "rank": 0.369351639838561, "metric": "accuracy", "ts": "2018-10-31T05:35:09.966000", "dataset": "smart-app-functionality-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "smart-app-functionality-DFE", "about": {"problemID": "smart-app-functionality-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "smart-app-functionality-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 8, "colName": "choose_the_corresponding_functionalities"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "smart-app-functionality-DFE"}, "socialmedia-disaster-tweets-DFE": {"pipeline": {"_id": "dc33de12-6361-4550-bdc9-e4b5d597aafd", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 26}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "log2", "max_depth": 23, "min_samples_split": 0.20255258215239955, "min_samples_leaf": 0.0004943688291334024, "n_estimators": 418, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "dc33de12-6361-4550-bdc9-e4b5d597aafd", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.7048245259199604, "rank": 0.29517547408069955, "metric": "accuracy", "ts": "2018-10-31T04:18:32.955000", "dataset": "socialmedia-disaster-tweets-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "socialmedia-disaster-tweets-DFE", "about": {"problemID": "socialmedia-disaster-tweets-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "socialmedia-disaster-tweets-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "choose_one"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "socialmedia-disaster-tweets-DFE"}, "text_emotion": {"pipeline": {"_id": "b37ff579-fac3-42bb-a135-9ff31ac4b516", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": false, "max_features": 810}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 13, "min_samples_split": 0.2626208302167264, "min_samples_leaf": 0.0020855324797057467, "n_estimators": 100, "class_weight": null}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "b37ff579-fac3-42bb-a135-9ff31ac4b516", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.30828052019971325, "rank": 0.6917194798005927, "metric": "accuracy", "ts": "2018-10-31T05:28:34.474000", "dataset": "text_emotion_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "text_emotion", "about": {"problemID": "text_emotion_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "text_emotion_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 3, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "text-emotion"}, "tweet_global_warming": {"pipeline": {"_id": "ee5c2b9e-cf74-4b7d-95f3-972b92149a47", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": true, "max_features": 957}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "most_frequent"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 3, "min_samples_split": 0.03143836745663344, "min_samples_leaf": 0.0046487042265009396, "n_estimators": 370, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "ee5c2b9e-cf74-4b7d-95f3-972b92149a47", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.8557146829810902, "rank": 0.1442853170190399, "metric": "accuracy", "ts": "2018-10-31T05:18:28.787000", "dataset": "tweet_global_warming_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "tweet_global_warming", "about": {"problemID": "tweet_global_warming_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "tweet_global_warming_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "tweet-global-warming"}, "twitter-airline-sentiment": {"pipeline": {"_id": "13f96097-d36a-4134-9613-0ade6f6ed60c", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": false, "max_features": 579}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "gini", "max_features": "auto", "max_depth": 26, "min_samples_split": 0.27584327736440506, "min_samples_leaf": 0.007598024448208986, "n_estimators": 118, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "13f96097-d36a-4134-9613-0ade6f6ed60c", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.8920758846963042, "rank": 0.10792411530450428, "metric": "accuracy", "ts": "2018-10-31T06:05:22.936000", "dataset": "twitter-airline-sentiment_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "twitter-airline-sentiment", "about": {"problemID": "twitter-airline-sentiment_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "twitter-airline-sentiment_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 3, "colName": "airline_sentiment"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "twitter-airline-sentiment"}, "twitter-hate-speech-classifier-DFE-a845520": {"pipeline": {"_id": "38f9fbc1-c991-462b-bbb9-ff38139baa5a", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": true, "binary": false, "max_features": 924}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": null, "max_depth": 14, "min_samples_split": 0.08756362154970358, "min_samples_leaf": 0.0026806392886153255, "n_estimators": 230, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "38f9fbc1-c991-462b-bbb9-ff38139baa5a", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.7109492314751321, "rank": 0.2890507685251398, "metric": "accuracy", "ts": "2018-10-31T05:59:57.268000", "dataset": "twitter-hate-speech-classifier-DFE-a845520_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "twitter-hate-speech-classifier-DFE-a845520", "about": {"problemID": "twitter-hate-speech-classifier-DFE-a845520_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "twitter-hate-speech-classifier-DFE-a845520_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "does_this_tweet_contain_hate_speech"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "twitter-hate-speech-classifier-DFE-a845520"}, "uu1_datasmash": {"pipeline": {"_id": "e6a1b50b-3740-4408-ba70-f9a2bd37205a", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"encode": true, "max_depth": 1, "remove_low_information": true}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 300, "max_depth": 3, "learning_rate": 0.1, "gamma": 0, "min_child_weight": 1}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "timeseries/classification/default", "template": "5bceaa5d49e71569e8bf7f84", "id": "e6a1b50b-3740-4408-ba70-f9a2bd37205a", "loader": {"data_modality": "timeseries", "task_type": "classification"}, "score": 1.0, "rank": 6.930409537038425e-13, "metric": "f1Macro", "ts": "2018-10-31T04:26:47.441000", "dataset": "uu1_datasmash_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "uu1_datasmash", "about": {"problemID": "uu1_datasmash_problem", "problemName": "timeseries classification problem", "problemDescription": "timeseries classification problem provided by UChicago performers", "taskType": "classification", "taskSubType": "multiClass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "uu1_datasmash_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 2, "colName": "class"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.065, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1Macro"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "uu1-datasmash"}, "uu3_world_development_indicators": {"pipeline": {"_id": "74d8b37f-8d73-42c4-9dfc-3b38d73655e5", "primitives": ["featuretools.dfs", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "xgboost.XGBRegressor"], "init_params": {"featuretools-dfs#1": {"encode": true}}, "input_names": {}, "output_names": {}, "hyperparameters": {"featuretools-dfs#1": {"encode": true, "max_depth": 2, "remove_low_information": false}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": true}, "xgboost-XGBRegressor#1": {"n_jobs": -1, "n_estimators": 539, "max_depth": 5, "learning_rate": 0.2958282731574736, "gamma": 0.1496521410579611, "min_child_weight": 7}}, "tunable_hyperparameters": {"featuretools-dfs#1": {"max_depth": {"type": "int", "default": 1, "range": [1, 3], "values": null}, "remove_low_information": {"type": "bool", "default": true}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "xgboost-XGBRegressor#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0.1, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}}, "name": "multi_table/regression/default", "template": "5bceaa5d49e71569e8bf7f82", "id": "74d8b37f-8d73-42c4-9dfc-3b38d73655e5", "loader": {"data_modality": "multi_table", "task_type": "regression"}, "score": 0.6536276140258243, "rank": 0.6536276140265381, "metric": "rootMeanSquaredError", "ts": "2018-10-31T05:23:27.225000", "dataset": "uu3_world_development_indicators_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "uu3_world_development_indicators", "about": {"problemID": "uu3_world_development_indicators_problem", "problemName": "Life expectancy prediction problem", "problemDescription": "Life expectancy prediction problem from world development indicators data. The World Development Indicators from the World Bank contain over a thousand annual indicators of economic development from hundreds of countries around the world.", "taskType": "regression", "taskSubType": "univariate", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "uu3_world_development_indicators_dataset", "targets": [{"targetIndex": 0, "resID": "6", "colIndex": 6, "colName": "Value"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "rootMeanSquaredError"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "uu3-world-development-indicators"}, "uu4_SPECT": {"pipeline": {"_id": "9e862619-d969-490f-ba2a-7867b5908fa2", "primitives": ["mlprimitives.feature_extraction.CategoricalEncoder", "sklearn.preprocessing.Imputer", "sklearn.preprocessing.StandardScaler", "mlprimitives.preprocessing.ClassEncoder", "xgboost.XGBClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"copy": true, "features": "auto", "max_labels": 1}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "mean"}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": true, "with_std": false}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_jobs": -1, "n_estimators": 102, "max_depth": 4, "learning_rate": 0.5421401829382341, "gamma": 0.07356195774756902, "min_child_weight": 2}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-feature_extraction-CategoricalEncoder#1": {"max_labels": {"type": "int", "default": 0, "range": [0, 100]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-preprocessing-StandardScaler#1": {"with_mean": {"type": "bool", "default": true}, "with_std": {"type": "bool", "default": true}}, "mlprimitives-preprocessing-ClassEncoder#1": {}, "xgboost-XGBClassifier#1": {"n_estimators": {"type": "int", "default": 100, "range": [10, 1000]}, "max_depth": {"type": "int", "default": 3, "range": [3, 10]}, "learning_rate": {"type": "float", "default": 0.1, "range": [0, 1]}, "gamma": {"type": "float", "default": 0, "range": [0, 1]}, "min_child_weight": {"type": "int", "default": 1, "range": [1, 10]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "categorical_encoder/imputer/standard_scaler/xgbclassifier", "template": "5bd0ce5249e71569e8bf8003", "id": "9e862619-d969-490f-ba2a-7867b5908fa2", "loader": {"data_modality": "single_table", "task_type": "classification"}, "score": 0.9264480174380063, "rank": 0.07355198256232413, "metric": "f1", "ts": "2018-10-25T01:47:06.017000", "dataset": "uu4_SPECT_dataset_TRAIN", "test_id": "20181024234726559170"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "uu4_SPECT", "about": {"problemID": "uu4_SPECT_problem", "problemName": "SPECT Heart prediction problem", "problemDescription": "This is a binary classification problem on the SPECT dataset - data on cardiac Single Proton Emission Computed Tomography (SPECT) images. Each patient classified into two categories: normal and abnormal.", "taskType": "classification", "taskSubType": "binary", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "uu4_SPECT_dataset", "targets": [{"targetIndex": 0, "resID": "0", "colIndex": 1, "colName": "OVERALL_DIAGNOSIS"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.3, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "f1"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "uu4-SPECT"}, "weather-agg-DFE": {"pipeline": {"_id": "eba72e35-e591-4d7f-aa86-2beacc5c04aa", "primitives": ["mlprimitives.preprocessing.ClassEncoder", "mlprimitives.feature_extraction.StringVectorizer", "sklearn.preprocessing.Imputer", "sklearn.ensemble.RandomForestClassifier", "mlprimitives.preprocessing.ClassDecoder"], "init_params": {}, "input_names": {}, "output_names": {}, "hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"features": "auto", "input": "content", "decode_error": "ignore", "analyzer": "word", "lowercase": false, "binary": true, "max_features": 686}, "sklearn-preprocessing-Imputer#1": {"missing_values": "NaN", "axis": 0, "copy": true, "strategy": "median"}, "sklearn-ensemble-RandomForestClassifier#1": {"n_jobs": -1, "criterion": "entropy", "max_features": "log2", "max_depth": 22, "min_samples_split": 0.009334577375670306, "min_samples_leaf": 0.0005793607710543239, "n_estimators": 417, "class_weight": "balanced"}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "tunable_hyperparameters": {"mlprimitives-preprocessing-ClassEncoder#1": {}, "mlprimitives-feature_extraction-StringVectorizer#1": {"lowercase": {"type": "bool", "default": true}, "binary": {"type": "bool", "default": true}, "max_features": {"type": "int", "default": 1, "range": [1, 1000]}}, "sklearn-preprocessing-Imputer#1": {"strategy": {"type": "str", "default": "mean", "values": ["mean", "median", "most_frequent"]}}, "sklearn-ensemble-RandomForestClassifier#1": {"criterion": {"type": "str", "default": "entropy", "values": ["entropy", "gini"]}, "max_features": {"type": "str", "default": null, "range": [null, "auto", "log2"]}, "max_depth": {"type": "int", "default": 10, "range": [1, 30]}, "min_samples_split": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "min_samples_leaf": {"type": "float", "default": 0.1, "range": [0.0001, 0.5]}, "n_estimators": {"type": "int", "default": 30, "values": [2, 500]}, "class_weight": {"type": "str", "default": null, "range": [null, "balanced"]}}, "mlprimitives-preprocessing-ClassDecoder#1": {}}, "name": "text/classification/default", "template": "5bceaa5e49e71569e8bf7f8b", "id": "eba72e35-e591-4d7f-aa86-2beacc5c04aa", "loader": {"data_modality": "text", "task_type": "classification"}, "score": 0.609922849372907, "rank": 0.3900771506276925, "metric": "accuracy", "ts": "2018-10-31T05:09:05.353000", "dataset": "weather-agg-DFE_dataset_TRAIN", "tuner_type": "uniform", "test_id": "20181031040541366347"}, "datasetDoc": {"about": {"datasetID": "weather-agg-DFE_dataset_TEST", "datasetName": "Weather sentiment", "description": "Here, contributors were asked to grade the sentiment of a particular tweet relating to the weather.", "citation": "", "license": "Creative Commons", "source": "Figure Eight", "sourceURI": "https://www.figure-eight.com/data-for-everyone/", "approximateSize": "0.1 MB", "datasetSchemaVersion": "3.0", "redacted": false, "datasetVersion": "1.0"}, "dataResources": [{"resID": "0", "resPath": "text/", "resType": "text", "resFormat": ["text/plain"], "isCollection": true}, {"resID": "1", "resPath": "tables/learningData.csv", "resType": "table", "resFormat": ["text/csv"], "isCollection": false, "columns": [{"colIndex": 0, "colName": "d3mIndex", "colType": "integer", "role": ["index"]}, {"colIndex": 1, "colName": "raw_text_file", "colType": "string", "role": ["attribute"], "refersTo": {"resID": "0", "resObject": "item"}}, {"colIndex": 2, "colName": "_unit_id", "colType": "integer", "role": ["attribute"]}, {"colIndex": 3, "colName": "_canary", "colType": "string", "role": ["attribute"]}, {"colIndex": 4, "colName": "_unit_state", "colType": "categorical", "role": ["attribute"]}, {"colIndex": 5, "colName": "_trusted_judgments", "colType": "integer", "role": ["attribute"]}, {"colIndex": 6, "colName": "_last_judgment_at", "colType": "string", "role": ["attribute"]}, {"colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather", "colType": "categorical", "role": ["suggestedTarget"]}, {"colIndex": 8, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather:confidence", "colType": "real", "role": ["attribute"]}, {"colIndex": 9, "colName": "gold_answer", "colType": "string", "role": ["attribute"]}, {"colIndex": 10, "colName": "tweet_id", "colType": "integer", "role": ["attribute"]}]}], "_id": "weather-agg-DFE_dataset_TEST"}, "problemDoc": {"_id": "weather-agg-DFE", "about": {"problemID": "weather-agg-DFE_problem", "problemName": "", "problemDescription": "", "taskType": "classification", "taskSubType": "multiclass", "problemSchemaVersion": "3.0", "problemVersion": "1.0"}, "inputs": {"data": [{"datasetID": "weather-agg-DFE_dataset", "targets": [{"targetIndex": 0, "resID": "1", "colIndex": 7, "colName": "what_emotion_does_the_author_express_specifically_about_the_weather"}]}], "dataSplits": {"method": "holdOut", "testSize": 0.2, "numRepeats": 0, "splitsFile": "dataSplits.csv"}, "performanceMetrics": [{"metric": "accuracy"}]}, "expectedOutputs": {"predictionsFile": "predictions.csv"}}, "dataset_path": "weather-agg-DFE"}}