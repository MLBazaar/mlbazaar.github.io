{
    "_id": "LL0_32_pendigits",
    "about": {
        "problemID": "LL0_32_pendigits_problem",
        "problemName": "LL0_32_pendigits_problem",
        "problemDescription": "**Author**:   \n**Source**: Unknown -   \n**Please cite**:   \n\n1. Title of Database: Pen-Based Recognition of Handwritten Digits\n \n 2. Source:\n \tE. Alpaydin, F. Alimoglu\n \tDepartment of Computer Engineering\n \tBogazici University, 80815 Istanbul Turkey\n \talpaydin@boun.edu.tr\n \tJuly 1998\n \n 3. Past Usage:\n \tF. Alimoglu (1996) Combining Multiple Classifiers for Pen-Based\n \tHandwritten Digit Recognition, \n \tMSc Thesis, Institute of Graduate Studies in Science and \n \tEngineering, Bogazici University.\n \thttp://www.cmpe.boun.edu.tr/~alimoglu/alimoglu.ps.gz\n \n \tF. Alimoglu, E. Alpaydin, \"Methods of Combining Multiple Classifiers \n \tBased on Different Representations for Pen-based Handwriting\n \tRecognition,\" Proceedings of the Fifth Turkish Artificial \n \tIntelligence and Artificial Neural Networks Symposium (TAINN 96), \n \tJune 1996, Istanbul, Turkey.\n \thttp://www.cmpe.boun.edu.tr/~alimoglu/tainn96.ps.gz\n \n \t\n 4. Relevant Information:\n \n \tWe create a digit database by collecting 250 samples from 44 writers.\n \tThe samples written by 30 writers are used for training,\n \tcross-validation and writer dependent testing, and the digits \n \twritten by the other 14 are used for writer independent testing. This\n \tdatabase is also available in the UNIPEN format.\n \n \tWe use a WACOM PL-100V pressure sensitive tablet with an integrated \n \tLCD display and a cordless stylus. The input and display areas are\n \tlocated in the same place. Attached to the serial port of an Intel \n \t486 based PC, it allows us to collect handwriting samples. The tablet\n \tsends $x$ and $y$ tablet coordinates and pressure level values of the\n \tpen at fixed time intervals (sampling rate) of 100 miliseconds. \n \n \tThese writers are asked to write 250 digits in random order inside \n \tboxes of 500 by 500 tablet pixel resolution.  Subject are monitored \n \tonly during the first entry screens. Each screen contains five boxes\n \twith the digits to be written displayed above. Subjects are told to\n \twrite only inside these boxes.  If they make a mistake or are unhappy\n \twith their writing, they are instructed to clear the content of a box \n \tby using an on-screen button. The first ten digits are ignored \n \tbecause most writers are not familiar with this type of input devices,\n \tbut subjects are not aware of this. \n \n \tIn our study, we use only ($x, y$) coordinate information. The stylus\n \tpressure level values are ignored. First we apply normalization to \n \tmake our representation invariant to translations and scale \n \tdistortions. The raw data that we capture from the tablet consist of\n \tinteger values between 0 and 500 (tablet input box resolution). The \n \tnew coordinates are such that the coordinate which has the maximum \n \trange varies between 0 and 100. Usually $x$ stays in this range, since\n \tmost characters are taller than they are wide.  \n \n \tIn order to train and test our classifiers, we need to represent \n \tdigits as constant length feature vectors. A commonly used technique\n \tleading to good results is resampling the ( x_t, y_t) points. \n \tTemporal resampling (points regularly spaced in time) or spatial\n \tresampling (points regularly spaced in arc length) can be used here. \n \tRaw point data are already regularly spaced in time but the distance\n \tbetween them is variable. Previous research showed that spatial\n \tresampling to obtain a constant number of regularly spaced points \n \ton the trajectory yields much better performance, because it provides \n \ta better alignment between points. Our resampling algorithm uses \n \tsimple linear interpolation between pairs of points. The resampled\n \tdigits are represented as a sequence of T points ( x_t, y_t )_{t=1}^T,\n \tregularly spaced in arc length, as opposed to the input sequence, \n \twhich is regularly spaced in time.\n \n \tSo, the input vector size is 2*T, two times the number of points\n \tresampled. We considered spatial resampling to T=8,12,16 points in our\n \texperiments and found that T=8 gave the best trade-off between \n \taccuracy and complexity.\n \n \n 5. Number of Instances\n \tpendigits.tra\tTraining\t7494\n \tpendigits.tes\tTesting\t\t3498\n \t\n \tThe way we used the dataset was to use first half of training for \n \tactual training, one-fourth for validation and one-fourth\n \tfor writer-dependent testing. The test set was used for \n \twriter-independent testing and is the actual quality measure.\n \n 6. Number of Attributes\n \t16 input+1 class attribute\n \n 7. For Each Attribute:\n \tAll input attributes are integers in the range 0..100.\n \tThe last attribute is the class code 0..9\n \n 8. Missing Attribute Values\n \tNone\n \n 9. Class Distribution\n \tClass: No of examples in training set\n \t0:  780\n \t1:  779\n \t2:  780\n \t3:  719\n \t4:  780\n \t5:  720\n \t6:  720\n \t7:  778\n \t8:  719\n \t9:  719\n \tClass: No of examples in testing set\n \t0:  363\n \t1:  364\n \t2:  364\n \t3:  336\n \t4:  364\n \t5:  335\n \t6:  336\n \t7:  364\n \t8:  336\n \t9:  336\n \n Accuracy on the testing set with k-nn \n using Euclidean distance as the metric\n \n  k =  1 : 97.74\n  k =  2 : 97.37\n  k =  3 : 97.80\n  k =  4 : 97.66\n  k =  5 : 97.60\n  k =  6 : 97.57\n  k =  7 : 97.54\n  k =  8 : 97.54\n  k =  9 : 97.46\n  k = 10 : 97.48\n  k = 11 : 97.34",
        "taskType": "classification",
        "taskSubType": "multiClass",
        "problemSchemaVersion": "3.0",
        "problemVersion": "1.0"
    },
    "inputs": {
        "data": [
            {
                "datasetID": "LL0_32_pendigits_dataset",
                "targets": [
                    {
                        "targetIndex": 0,
                        "resID": "0",
                        "colIndex": 17,
                        "colName": "class"
                    }
                ]
            }
        ],
        "dataSplits": {
            "method": "holdOut",
            "testSize": 0.2,
            "stratified": true,
            "numRepeats": 0,
            "randomSeed": 42,
            "splitsFile": "dataSplits.csv"
        },
        "performanceMetrics": [
            {
                "metric": "f1Macro"
            }
        ]
    },
    "expectedOutputs": {
        "predictionsFile": "predictions.csv"
    }
}