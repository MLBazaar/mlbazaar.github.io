{
    "_id": "LL0_529_pollen",
    "about": {
        "problemID": "LL0_529_pollen_problem",
        "problemName": "LL0_529_pollen_problem",
        "problemDescription": "**Author**:   \n**Source**: Unknown - Date unknown  \n**Please cite**:   \n\nThis dataset is synthetic.  It was generated by David Coleman\nat RCA Laboratories in Princeton, N.J.  For convenience, we will\nrefer to it as the POLLEN DATA.  The first three variables are the\nlengths of geometric features observed sampled pollen grains - in the\nx, y, and z dimensions: a \"ridge\" along x, a \"nub\" in the y\ndirection, and a \"crack\" in along the z dimension.  The fourth\nvariable is pollen grain weight, and the fifth is density.\n\nThere are 3848 observations, in random order (for people whose\nsoftware packages cannot handle this much data, it is recommended\nthat the data be sampled).  The dataset is broken up into eight\npieces, POLLEN1.DAT - POLLEN8.DAT, each with 481 observations.\nWe will call the variables:\n\n1. RIDGE\n2. NUB\n3. CRACK\n4. WEIGHT\n5. DENSITY\n\n6. OBSERVATION NUMBER (for convenience)\n\nThe data analyst is advised that there is more than one \"feature\" to\nthese data.  Each feature can be observed through various graphical\ntechniques, but analytic methods, as well, can help \"crack\" the\ndataset.\n\nAdditional Info:\n\nI no longer have the description handed out during the JSM, but can\ntell you how I generated the data, in minitab.\n\n1. Part A was generated: 5000 (I think) 5-variable, uncorrelated, i.i.d.\nGaussian observations.\n\n2. To get part B, I duplicated part A, then reversed the sign on the\nobservations for 3 of the 5 variables.\n\n3. Part B was appended to Part A.\n\n4. The order of the observations was randomized.\n\n5. While waiting for my tardy car-pool companion, I took a piece of\ngraph paper, and figured out a dot-matrix representation of the word,\n\"EUREKA.\"  I then added these observations to the \"center\" of the\ndatatset.\n\n6. The data were scaled, by variable (something like 1,3,5,7,11).\n\n7. The data were rotated, then translated.\n\n8. A few points in space within the datacloud were chosen as ellipsoid\ncenters, then for each center, all observations within a (scaled and\nrotated) radius were identified, and eliminated - to form ellipsoidal\nvoids.\n\n9. The variables were given entirely ficticious names.\n\nFYI, only the folks at Bell Labs, Murray Hill, found everything,\nincluding the voids.\n\nHope this is helpful!\n\nReferences:\n\nBecker, R.A., Denby, L., McGill, R., and Wilks,\nA. (1986). Datacryptanalysis: A Case Study.\nProceedings of the Section on Statistical Graphics, 92-97.\n\nSlomka, M. (1986). The Analysis of a Synthetic Data Set.\nProceedings of the Section on Statistical Graphics, 113-116.\n\n\n\nInformation about the dataset\nCLASSTYPE: numeric\nCLASSINDEX: none specific",
        "taskType": "regression",
        "taskSubType": "univariate",
        "problemSchemaVersion": "3.0",
        "problemVersion": "1.0"
    },
    "inputs": {
        "data": [
            {
                "datasetID": "LL0_529_pollen_dataset",
                "targets": [
                    {
                        "targetIndex": 0,
                        "resID": "0",
                        "colIndex": 5,
                        "colName": "DENSITY"
                    }
                ]
            }
        ],
        "dataSplits": {
            "method": "holdOut",
            "testSize": 0.2,
            "stratified": true,
            "numRepeats": 0,
            "randomSeed": 42,
            "splitsFile": "dataSplits.csv"
        },
        "performanceMetrics": [
            {
                "metric": "meanSquaredError"
            }
        ]
    },
    "expectedOutputs": {
        "predictionsFile": "predictions.csv"
    }
}